Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers If we know and we have a set of data points the best estimate we can make of the variance is We have said that if we must use to approximate the mean the best estimate of usually denoted is The use of rather than in the denominator is distinctly nonintuitive so much so that this equation often causes great irritation Let us see how this equation comes about Suppose that we have a distribution whose mean is and variance is Suppose that we draw values of the random variable from the distribution We want to think about the expected value of Let us write as Squaring this gives From our definition of expected value we can write From our discussion above we can recognize each of these expected values The expected value of is the variance of the original distribution which is Since this is a definition it is exact The best possible estimate of the expected value of is The expected value of is the expected value of the variance of averages of random variables drawn from the original distribution That is the expected value of is what we would get if we repeatedly drew values from the original distribution computed the average of each set of values and then found the variance of this new distribution of average values By the central limit theorem this variance is Thus the expected value of is exactly Since is constant the expected value of is which is equal to zero because by the definition of Substituting our expression for the expected value of becomes so that and That is as originally stated when we must use rather than the true mean in the sum of squared differences the best possible estimate of usually denoted is obtained by dividing by rather than by