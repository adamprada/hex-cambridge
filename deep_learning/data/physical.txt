AcidBase Equilibria Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay The Autoionization of WaterThe Hydrolysis of a Weak BaseContributors and Attributions A great many processes involve proton transfer or acidbase types of reactions As many biological systems depend on carefully controlled pH these types of processes are extremely important The pH is defined by where is the activity of hydronium ions and is the true concentration of hydronium ions both in molL The dissociation of a weak acid in water is governed by the equilibrium defined by The equilibrium constant for such a reaction takes the form As is the case for all thermodynamic equilibrium constants the concentrations are replaced by activities and the equilibrium constant is unitless However if all species behave ideally have unit activity coefficients the units can be used as a very useful guide in solving problems Example Acetic Acid What is the pH of a M HOAc acetic acid solution Ka x M Solution An ICE table will come in very handy here Initial M Change x x x Equilibrium M x x x The equilibrium problem can then be set up as Substituting the values that are known This produces a quadratic equation and thus two values of which satisfy the relationship The negative root is not physically meaningful since the concentrations of and cannot be negative Using the value of as the pH is then calculated via Equation refeq to be The Autoionization of Water Water is a very important solvent as water molecules have large dipole moments which create favorable interactions with ionic compounds Water also has a large dielectric constant which damps the electric field generated by ions in solutions making the comparative interactions with water more favorable than with other ions in solution in many cases But water also dissociates into ions through the reaction The equilibrium constant governing this dissociation is highly temperature dependent The data below are presented by Bandura and Lvov Bandura Lvov T C pKw From these data a vant Hoff plot can be constructed Figure vant Hoff plot for the autoionization of water There is some curvature to the line suggesting some albeit small temperature dependence for for Equation refeqA However from the fit of these data a value of can be determined to be kJmol Of particular note is that the dissociation is endothermic so increases in temperature will lead to a greater degree of dissociation Example Neutral Water What is the pH of neutral water at C normal human body temperature Neutral water no excess of over or vice versa Solution From the bestfit line in the vant Hoff plot of Figure the value of can be calculated Since gives the product of and which must be equal in a neutral solution And the pH is given by Equation refeq Note This is slightly less than a pH of which is normally considered to be neutral But a pH of is only neutral at C At higher temperatures neutral pH is a lower value due to the endothermic nature of the autoionization water While it has a nigher concentration it also has a higher and at the same level so it is still technically neutral The Hydrolysis of a Weak Base Hydrolysis is defined as a reaction with water that splits a water molecule The hydrolysis of a weak base defines the equilibrium constant Kb For this reaction the equilibrium constant is given by The concentration or activity of the pure compound HO is not included in the equilibrium expression because being a pure compound in its standard state it has unit activity throughout the process of establishing equilibrium Further it should be noted that when Kb is combined with the expression for Ka for the weak acid HA Equation refeq As a consequence if one knows for a weak acid one also knows for its conjugate base since the product results in Example What is the pH of a M solution of KF For HF pKa at C Solution The problem involves the hydrolysis of the conjugate base of HF F The hydrolysis reaction is An ICE table is in order here Initial M Change x x x Equilibrium M x x x So the expression for is In this case the small value of insures that the value of x will be negligibly small compared to M In this limit the value of which is equal to OH So is given by And the pH is given by Equation refeq Note The pH of this salt solution is slightly basic This is to be expected as KF can be thought of being formed in the reaction of a weak acid HF with a strong base KOH In the competition to control the pH the strong base ends up winning the battle Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Activities and Fugacities Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Kp and KcContributors and Attributions To this point we have mostly ignored deviations from ideal behavior But it should be noted that thermodynamic equilibrium constants are not expressed in terms of concentrations or pressures but rather in terms of activities and fugacities both being discussed in Chapter Based on these quantities and And since activities and fugacities are unitless thermodynamic equilibrium constants are unitless as well Further it can be noted that the activities of solids and pure liquids are unity assuming ideal behavior since they are in their standard states at the given temperature As such these species never change the magnitude of the equilibrium constant and are generally omitted from the equilibrium constant expression Thermodynamic equilibrium constants are unitless Kp and Kc Oftentimes it is desirable to express the equilibrium constant in terms of concentrations or activities for systems that deviate from ideal behavior To make this conversion the relationship between pressure and concentration from the ideal gas law can be used And noting that the concentration is given by the expression for the equilibrium constant Equation refeq becomes And since for a given temperature is a constant and can be factored out of the expression leaving beginalign K_p left prod_iRTnu_i right left prod_i X_inu_iright pt RTsum nu_i prod X_inu_i pt RTsum nu_i K_c endalign This conversion works for reactions in which all reactants and products are in the gas phase Care must be used when applying this relationship to heterogeneous equilibria Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Adiabatic Compressibility Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay No headers In Chapter we learned about the isothermal compressibility which is defined as is a very useful quantity as it can be measured for many different substances and tabulated Also as we will see in the next chapter it can be used to evaluate several different partial derivatives involving thermodynamic variables In his seminal work Philosophiae Naturalis Principia Mathematica Newton Isaac Newton Doc calculated the speed of sound through air assuming that sound was carried by isothermal compression waves His calculated value of ms was about smaller than experimental determinations He accounted for the difference by pointing to nonideal effects But it turns out that his error albeit an understandable one since sound waves do not appear to change bulk air temperatures was that the compression waves are adiabatic rather than isothermal As such there are small temperature oscillations that occur due to the adiabatic compression followed by expansion of the gas carrying the sound waves The oversight was correct by PierreSimon Laplace OConnor Robertson PierreSimon Laplace LaPlace modeled the compression waves using the adiabatic compressibility defined by Since the entropy is defined by it follows that any adiabatic pathway is also isentropic or proceeds at constant entropy Adiabatic pathways are also isentropic A couple of interesting conclusions can be reached by following the derivation of an expression for the speed of sound where the sound waves are modeled as adiabatic compression waves We can begin by expanding the description of by using Partial Derivative Transformation Type II Applying this the adiabatic compressibility can be expressed or by using transformation type I Using a simple chain rule the partial derivatives can be expanded to get something a little easier to evaluate The utility here is that This means that Equation refeq simplifies to Simplifying what is in the parenthesis yields As will be shown in the next chapter is always bigger than so is always smaller than But there is more We can use this methodology to revisit how pressure affects volume along an adiabat In order to do this we would like to evaluate the partial derivative This can be expanded in the same way as above And further expand And as before noting that the relationships in Equations refNote and refNote Equation refeq can be simplified to Or defining Equation refeq can be easily rearranged to The righthand derivative is easy to evaluate if we assume a specific equation of state For an ideal gas Substitution yields which is now looking like a form that can be integrated Separation of variables yields And integration assuming that g is independent of volume yields or which is easily manipulated to show that or which is what we previously determined for the behavior of an ideal gas along an adiabat Finally it should be noted that the correct expression for the speed of sound is given by where is the density of the medium For an ideal gas this expression becomes where is the molar mass of the gas Isaac Newtons derivation based on the idea that sound waves involved isothermal compressions would produce a result which is missing the factor of accounting for the systematic deviation from experiment which he observed Contributors Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Adiabatic Expansions of An Ideal Gas Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Consider an ideal gas that undergoes a reversible adiabatic expansion from an initial state specified by known values and to a new state in which the value of the volume is known but the value of the temperature is not known For an adiabatic reversible process and Since we have so that For any gas we can assume that is approximately constant over a small temperature range Taking to be constant in the interval we have We obtain the enthalpy change from where we use our idealgas result from Section While these relationships yield the values of the various thermodynamic quantities in terms of the temperature difference we have yet to find the final temperature To find we return to the first law Substituting for and and making use of the ideal gas equation we have from which by separation of variables we have one mole ideal gas reversible adiabatic expansion If we know as a function of temperature we can integrate to find a relationship among and Given any three of these quantities we can use this relationship to find the fourth If is independent of temperature as it is for a monatomic ideal gas we have so that monatomic ideal gas reversible adiabatic expansion For the spontaneous adiabatic expansion of an ideal gas against a constant applied pressure we have so that and Given the initial conditions we can find the final temperature from spontaneous adiabatic process The changes in the remaining state functions can then be calculated from the relationships above In this spontaneous adiabatic process all of the other thermodynamic quantities are different from those of a reversible adiabatic process that reaches the same final volume A Few Ideas from Formal Logic Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Formal logic deals with relationships among propositions where a proposition is any statement of alleged fact Any proposition can be expressed as an ordinary English sentence although it may be more convenient to use mathematical symbols or some other notation The following are all propositions Albert Einstein is deceased Tulsa is in Oklahoma Two plus two equals four A proposition need not be true The last of these examples is a false proposition We represent an arbitrary proposition by any convenient symbol usually a letter of the alphabet Thus we could stipulate that represents any of the propositions above Once we have associated a symbol with a particular proposition the symbol itself is taken to represent an assertion that the proposition is true It is an axiom of ordinary logic that any proposition must be either true or false If we associate the symbol with a particular proposition we write to represent the statement The proposition represented by the symbol is false is called the negation of p We can use the negation of to state the axiom that a proposition must be either true or false To do so we write Either or is true We can write this as the proposition or The negation of the negation of is an assertion that is true that is Logic is concerned with relationships among propositions One important relationship is that of implication If a proposition follows logically from another proposition we say that is implied by Equivalently we say that proposition implies proposition The doubleshafted arrow is used to symbolize this relationship We write to mean That proposition is true implies that proposition is true We usually read this more tersely saying implies Of course is itself a proposition it asserts the truth of a particular logical relationship between propositions and For example let be the proposition Figure A is a square Let be the proposition Figure A is a rectangle Then writing out the proposition we have Figure A is a square implies figure A is a rectangle This is of course a valid implication for this example the proposition is true For reasons that will become clear shortly is called the conditional of and Proposition is often called a sufficient condition while proposition is called a necessary condition That is the truth of is sufficient to establish the truth of Now if proposition is true and proposition is also true can we infer that proposition is true We most certainly cannot In the example we just considered the fact that figure A is a rectangle does not prove that figure A is a square We call the converse of The conditional of and can be true while the converse is false Of course it can happen that both and are true We often write to express this relationship of mutual implication We say that implies and conversely What if and is false That is is true In this case must be false If is true it must also be that is true Using our notation we can express this fact as Equivalently we can write That is and are equivalent propositions if one is true the other must be true is called the contrapositive of The equivalence of the conditional and its contrapositive is a theorem that can be proved rigorously in an axiomatic formulation of logic In our later reasoning about thermodynamic principles we use the equivalence of the conditional and the contrapositive of and The equivalence of the conditional and the contrapositive is the reason that is called a necessary condition If it is necessary that be true for to be true If figure A is to be a square it must be a rectangle It is also intimately related to proof by contradiction Suppose that we know to be true If by assuming that is false is true we can validly demonstrate that must also be false so that is true we have the contradiction that is both true and false and Since cannot be both true and false it must be false that q is false Otherwise stated the equivalence of the conditional and the contrapositive leads not only to and but also to and implies In summary since we know p to be true our assumption that is false together with the valid implication leads to the conclusion that is true which contradicts our original assumption so that the assumption is false and is true A Few Ideas from the Philosophy of Science Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers The goal of science is to create theories that accurately describe physical reality In this book we explore some of the most useful scientific theories that exist They have been tested extensively We know that there are limits to their applicability We expect that further thought and experimentation will expand their scope We expect that some elements of these theories will need to be modified in ways that we cannot anticipate but we do not expect that the core concepts will be invalidated We love theories because they rationalize our environment This is true not only of scientific theories but also of the panoply of conceptual frameworks that we use to organize our views aboutand responses to all of lifes issues We are addicted to theories We find nothing more disconcerting than information that we cannot put into a coherent context Indeed the term cognitive dissonance has entered the language to describe the feeling of disorientation that we experience when things just dont add up Logically confronted with a fact that contradicts one of our theories we are compelled to give up the theory We are not always logical A fact that contradicts a pet theory is unlikely to be accepted at face value We challenge it as indeed we should We scrutinize the offending fact and try to convince ourselves that it is no fact at all merely a spurious artifact Often of course this proves to be the case Sometimes we conclude that the offending fact is spurious when it is not We get stuffy about our theories When we find one that suits us we resist giving it up It has been observed that a revolutionary scientific theory often achieves universal acceptance only after all those who grew up with the predecessor theory have died Science is ultimately a social enterprise To develop and test theories about physical reality participants in this enterprise must be in general agreement about the criteria that are to be applied These criteria are frequently called the philosophy of science To summarize the philosophy of science we begin by observing that the goal of science is to explain the world that we experience through our sensory perceptions It is easy to generate putative explanations that have little or no real value Unfortunate experiences with past explanations have led to a broad consensus that scientific theories must have the following properties operational definitions logical structure predictive capability and testability internal consistency and consistency with any and all experimental observations The theory must be about the properties of some set of things By operational definitions we mean that the subjects of the theory must measurable and the theory must specify a set of operations for making each of these measurements By logical structure we mean that a satisfactory theory must include welldefined rules to specify how the subjects of the theory relate to one another By predictive capability we mean that a satisfactory theory must be capable of predicting the results of experiments that have not been performed By internal consistency we mean that a satisfactory theory must not allow us to logically derive contradictory conclusions which also means that it must not predict more than one outcome for any particular experiment Because a satisfactory theory makes predictions it is also testable It is possible to check whether the predictions correspond to reality We require that the theorys predictions be consistent with the results that we observe when we do the experiment The first four of these requirements really detail the characteristics that a theory must have in order to be considered a proper subject for scientific investigation Only the last requirement speaks to the allimportant issue of whether the theory accurately mirrors physical reality We can never prove that any theory is true What we can prove is that a theory fails to meet one of our criteria Science progresses when we discover a fatal flaw in a currently accepted theory Let us think further about what we mean when we say that a theory must be a logical structure Consider a simple classical syllogism Major premise All dogs are cats Minor premise All cats are white Conclusion All dogs are white As a logical structure this seems to be satisfactory We can represent the whole of its content in a simple diagram See Figure so if we want to view this syllogism as a theory about nature its internal consistency is more or less selfevident Moreover viewed as a theory it makes a prediction All dogs are white If we have operational definitions for dog cat and white that conform to customary usage we can say that this syllogism meets our criteria for a proper subject for scientific investigation Of course as a mirror of reality it fails Figure Venn diagram of a classical syllogism To see the issue of logical structure from another perspective let us consider the theory of evolution Some people summarize the theory of evolution as teaching that the fittest individuals survive and defining survivors as those individuals who are most fit They then point out that these are circular statements and proceed from this observation to the conclusion that the theory of evolution is devoid of real content So it can be dismissed Now if we are not closedminded about evolution this analysis looks like a case of throwing out the baby with the bath water Even so we are likely to be troubled because the circularity is undeniable Does this circularity mean that the theory of evolution is bad science A tautology is a statement that must be true Our analysis attempts to recast the entire content of the theory of evolution as one tautologous statement If the whole of a theory is a single statement and that statement must be true then the theory cannot be tested Our rules require that we reject it However our tautologous summary fails to capture the whole of the theory of evolution If a theory that contains tautologous statements also makes predictions that are not tautologous then it can be tested In the present example we can predict from the theory of evolution that selection of a particular trait through any process will cause increased expression of that trait in succeeding generations Evolution is based on natural selection but it postulates a mechanism that must be valid for any consistent selection process It predicts that a farmer who selects for cows that produce more milk will eventually get cows that produce more milk Thus attempts to apply selective breeding are tests of the central element of the theory of evolution and the success of selective breeding in every aspect of agriculture verifies a prediction of the theory There is no reason to object to a theory that has tautological elements so long as the content of the theory has real substance What we require is that a theorys predictions be nontrivial We object when substantially all of a theorys purported predictions are merely restatements of its premises so that the whole of the theory is an exercise in verbiage We require scientific theories to be internally consistent Normally we do not expect to be able to prove internal consistency What we really mean is that we will discard any theory that we can show to be internally inconsistent The presence of tautologous statements cannot make a theory internally inconsistent Indeed we can expect any internally consistent theory to have tautological elements After all if we try to define all of the subjects of a theory at least some of our definitions will inevitably be circular Another way to describe the logical structure of a physical theory is to say that a theory is a model for some observable part of the world We want the model to include things and rules The rules should specify how the things of the model change When we talk about comparing predictions of the theory to the results of experiment we mean that the changes that occur in the model when we apply the rules of the theory should parallel the changes that occur in the real world when we do the corresponding experiment The idea is analogous to the mathematical concept of a homomorphism A dictionary definition of a homomorphism is a mapping of a mathematical group ring or vector space onto another in such a way that the result obtained by applying an operation to elements of the domain is mapped onto the result of applying the same or a corresponding operation to their images in the range Stated more picturesquely the idea of a homomorphism is that two mathematical structures have the same form If one is laid on top of the other there is a perfect correspondence between them See Figure Figure A homomorphism The idea of a onetoone correspondence between two structures can be extended to the case where one structure is a logical structure and the other is a physical structure Consider the logical structure usually called a truth table associated with the truth of the proposition sentence A is true and sentence B is true The proposition is false unless both A and B are true Now consider the performance of an electrical circuit that consists of a battery switches A and B and a light bulb all connected in series The light is off unless both A and B are on There is a perfect correspondence between the elements of the logical structure and the performance of the circuit See Figure In fact this is a special case of a much more extensive parallelism For any sentence in propositional logic there is a corresponding circuitinvolving batteries switches and a light bulbsuch that the bulb is on if the corresponding sentence is true and off if the sentence is false Moreover there is a mathematical structure called Boolean algebra which is homomorphic to propositional logic and exhibits the same parallelism to circuits Digital computers carry this parallelism to structures of great complexity If we stretch our definition of a homomorphism to include comparisons of logical constructs with physical things we can view a scientific theory as a logical construct that we are trying to make homomorphic with physical reality We want our theory to map onto reality in such a way that changes in the logical construct map onto changes in physical reality Of course what we mean by this is the same thing we meant previously when we said that the predictions of our theory should agree with the results of experiment Figure Mapping a physical system onto a logical construct It is implicit in this view that any scientific theory describes an abstraction from reality If for example we say that a physical system is at a particular temperature this statement represents an approximation in at least two respects First we believe that we can measure temperature in continually more refined ways If we know the temperature to six significant figures this represents a very good approximation but we believe that the true temperature can only be expressed using indeterminably many significant figures To say that the temperature of the system has some value expressed to six significant figures is an approximation albeit a very good one Second it is unlikely that all parts of any real system are actually at the same temperature When we say that a physical system has a particular temperature we mean that any differences in temperature between different parts of the system are too small to affect the behavior in which we are currently interested In our discussions and deliberations about the physical system we replace its actual properties by our best measurement In doing so we abstract something that we believe to be an essential feature from the reality we actually observe Implicit also is the idea that our theories about reality are subject to inevitable limitations In the example above any theory that however accurately predicts the single temperature that we use to describe the real system is inadequate to describe whatever small variations there may be from point to point within it If we expand our theory to encompass variations over say distances of millimeters then the expanded theory will be inadequate to describe variations over some smaller distance Any perfect theory must exactly describe the motions of all of the systems constituent particles This is impossible not only because it conflicts with the basis premises of quantum mechanics but also because it requires the theory to contain information at a level of detail equal to that in the physical system itself One way to express all of the same information at exactly the same level of detail is to have an exact replica of the system This idea has been expressed by saying that an absolutely accurate map of Oklahoma City would have to be as large as Oklahoma City itself For use as a map such a thing would be useless Similarly a theory that predicts temperature is useful only if it predicts the temperature we measure measurement being a part of the process by which we effect abstraction experimentally We can make use of multiple theories of the same phenomenon if each of them has advantages and limitations that we recognize and respect We see however that in the end there can be no single allencompassing theory Any theory must model an approximation to reality In the final analysis reality is reality A Heuristic View of the Cumulative Distribution Function Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers We can use these ideas to create a plot that approximates the cumulative probability distribution function given any set of measurements of a random variable To do so we put the values found in our measurements in order from smallest to largest We label the ordered values where is the smallest By the argument that we develop in the previous section the probability of observing a value less than is about If we were to make a large number of additional measurements a fraction of about of this large number of additional measurements would be less than This fraction is just so we reason that The probability of observing a value between and is also about so the probability of observing a value less than is about and we expect In general the probability of observing a value between and is also about and the probability of observing a value less than is about In other words we expect the cumulative probability distribution function for to be such that the smallest observation corresponds to The quantity is often called the rank probability of the data point Figure An approximate cumulative probability distribution function Figure is a sketch of the sigmoid shape that we usually expect to find when we plot versus the value of This plot approximates the cumulative probability distribution function We expect the sigmoid shape because we expect the observed values of to bunch up around their average value If within some domain of values all possible values of were equally likely we would expect the difference between successive observed values of to be roughly constant which would make the plot look approximately linear At any value of the slope of the curve is just the probabilitydensity function These ideas mean that we can test whether the experimental data are described by any particular mathematical model say To do so we use the mathematical model to predict each of the N rank probability values That is to say we calculate if describes the data well we will find for all Graphically we can test the validity of the relationship by plotting versus If describes the data well this plot will be approximately linear with a slope of one In Section we introduce the normal distribution which is a mathematical model that describes a great many sources of experimental observations The normal distribution is a distribution function that involves two parameters the mean and the standard deviation The ideas we have discussed can be used to develop a particular graph paperusually called normal probability paper If the data are normally distributed plotting them on this paper produces an approximately straight line We can do essentially the same test without benefit of special graph paper by calculating the average and the estimated standard deviation from the experimental data Calculating and is discussed below Using and as estimates of and we can find the modelpredicted probability of observing a value of the random variable that is less than This value is for a normal distribution whose mean is and whose standard deviation is We can find by using standard tables usually called the normal curve of error in mathematical compilations by numerically integrating the normal distributions probability density function or by using a function embedded in a spreadsheet program like Excel If the data are described by the normal distribution function this value must be approximately equal to the rank probability that is we expect A plot of versus will be approximately linear with a slope of about one A Heuristic View of the Probability Density Function Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Suppose that we have a probability density function like that sketched in Figure and that the area under the curve in the interval is If we draw a large number of samples from the distribution our definitions of probability and the probability density function mean that about of the values we draw will lie in the interval We expect the percentage to become closer and closer to as the total number of samples drawn becomes very large The same would be true of any other interval where the area under the curve in the interval is If we draw exactly four samples from this distribution the values can be anywhere in the domain of However if we ask what arrangement of four values best approximates the result of drawing a large number of samples it is clear that this arrangement must have a value in each of the four mutuallyexclusive probability zones We can extend this conclusion to any number of representative points If we ask what arrangement of N points would best represent the arrangement of a large number of points drawn from the distribution the answer is clearly that one of the representative points should lie within each of mutuallyexclusive equalarea segments that span the domain of Figure A sample of four that approximates its distribution We can turn this idea around In the absence of information to the contrary the best assumption we can make about a set of values of a random variable is that each represents an equally probable outcome If our entire store of information about a distribution consists of four data points drawn from the distribution the best description that we can give of the probability density function is that onefourth of the area under the curve lies above a segment of the domain that is associated with each point If we have points the best estimate we can make of the distribution from which the points are drawn is that of the area lies above each of them This view tells us to associate a probability of with an interval around each data point but it does not tell us where to begin or end the interval If we could decide where the interval about each data point began and ended we could estimate the shape of the probability density function For a small number of points we could not expect this estimate to be very accurate but it would be the best possible estimate based on the given data Figure The sample of four that best approximates its distribution Now instead of trying to find the best interval to associate with each data point let us think about the intervals into which the data points divide the domain This small change of perspective leads us to a logical way to divide the domain of into specific intervals of equal probability If we put points on any line these points divide the line into segments There is a segment to the left of every point there are such segments There is one final segment to the right of the rightmost point and so there are segments in all In the absence of information to the contrary the best assumption we can make is that data points divide their domain into segments each of which is associated with equal probability The fraction of the area above each of these segments is also the probability associated with each segment is If as in the example above there are four data points the best assumption we can make about the probability density function is that of its area lies between the left boundary and the leftmost data point and lies between the rightmost data point and the right boundary The three intervals between the four data points each represent an additional of the area Figure indicates the data points that best approximate the distribution sketched in Figure The sketches in Figure describe the probability density functions implied by the indicated sets of data points Figure Approximate probability density functions Angular Momentum Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Orbital Angular Momentum Properties of General Angular Momentaa Consequences of the Commutation Relationsi There is a Maximum and a Minimum Eigenvalue for ii The Raising and Lowering Operators Change the Eigenvalue but not the Eigenvalue When Acting on iii The Eigenvalues are Related to the Maximum and Minimum Eigenvalues Which are Related to One Anotheriv The Quantum Number Can Be Integer or HalfIntegerv More on Summary Coupling of Angular Momentaa Eigenfunctions of b Eigenfunctions of the ClebschGordon Seriesc Generation of the ClebschGordon Coefficientsi The States With Maximum and Minimum MValuesii States With One Lower MValue But the Same Valueiii States With One Lower Valueiv States With Even One Lower Valued An Examplee Coupling Angular Momenta of Equivalent ElectronsContributors and Attributions Orbital Angular Momentum A particle moving with momentum p at a position r relative to some coordinate origin has socalled orbital angular momentum equal to The three components of this angular momentum vector in a Cartesian coordinate system located at the origin mentioned above are given in terms of the Cartesian coordinates of and as follows L_z x p_y y p_x L_x y p_z z p_y L_y z p_x x p_z Using the fundamental commutation relations among the Cartesian coordinates and the Cartesian momenta q_k p_j q_k p_j p_j q_k ihbar delta_jk jk xyz which are proven by considering quantities of the from x p_x p_x xfihbar leftxfracpartial fpartial xfracpartial xfpartial xrightihbar f it can be shown that the above angular momentum operators obey the following set of commutation relations Although the components of do not commute with one another they can be shown to commute with the operator defined by This new operator is referred to as the square of the total angular momentum operator The commutation properties of the components of allow us to conclude that complete sets of functions can be found that are eigenfunctions of and of one but not more than one component of It is convention to select this one component as and to label the resulting simultaneous eigenstates of and as according to the corresponding eigenvalues These eigenfunctions of and of will not in general be eigenfunctions of either or of This means that any measurement of or will necessarily change the wave function if it begins as an eigenfunction of The above expressions for and can be mapped into quantum mechanical operators by substituting and as the corresponding coordinate operators and and for and respectively The resulting operators can then be transformed into spherical coordinates the results of which are Properties of General Angular Momenta There are many types of angular momenta that one encounters in chemistry Orbital angular momenta such as that introduced above arise in electronic motion in atoms in atomatom and electronatom collisions and in rotational motion in molecules Intrinsic spin angular momentum is present in electrons and many other nuclei In this Section we will deal with the behavior of any and all angular momenta and their corresponding eigenfunctions At times an atom or molecule contains more than one type of angular momentum The Hamiltonians interaction potentials present in a particular species may or may not cause these individual angular momenta to be coupled to an appreciable extent ie the Hamiltonian may or may not contain terms that refer simultaneously to two or more of these angular momenta For example the ion which has a ground electronic state its electronic configuration is has electronic spin electronic orbital and molecular rotational angular momenta The full Hamiltonian contains terms that couple the electronic spin and orbital angular momenta thereby causing them individually to not commute with In such cases the eigenstates of the system can be labeled rigorously only by angular momentum quantum numbers and belonging to the total angular momentum operators and The total angular momentum of a collection of individual angular momenta is defined componentbycomponent as follows where labels and and labels the constituents whose angular momenta couple to produce J For the remainder of this Section we will study eigenfunctioneigenvalue relationships that are characteristic of all angular momenta and which are consequences of the commutation relations among the angular momentum vectors three components We will also study how one combines eigenfunctions of two or more angular momenta to produce eigenfunctions of the total a Consequences of the Commutation Relations Any set of three operators that obey will be taken to define an angular momentum whose square commutes with all three of its components It is useful to also introduce two combinations of the three fundamental operators and and to refer to them as raising and lowering operators for reasons that will be made clear below These new operators can be shown to obey the following commutation relations Using only the above commutation properties it is possible to prove important properties of the eigenfunctions and eigenvalues of and Let us assume that we have found a set of simultaneous eigenfunctions of and the fact that these two operators commute tells us that this is possible Let us label the eigenvalues belonging to these functions in terms of the quantities and Although we certainly hint that these quantities must be related to certain and quantum numbers we have not yet proven this although we will soon do so For now we view and simply as symbols that represent the respective eigenvalues Because both and are Hermitian eigenfunctions belonging to different or quantum numbers must be orthogonal We now prove several identities that are needed to discover the information about the eigenvalues and eigenfunctions of general angular momenta that we are after Later in this Section the essential results are summarized i There is a Maximum and a Minimum Eigenvalue for Because all of the components of are Hermitian and because the scalar product of any function with itself is positive semidefinite the following identity holds langle jmtextbfJ_x textbfJ_yjmrangle langle textbfJ_xlangle jm textbfJ_xjmrangle langle textbfJ_ylangle jm textbfJ_yjmrangle ge However is equal to so this inequality implies that which in turn implies that must be less than or equal to Hence for any value of the total angular momentum eigenvalue the zprojection eigenvalue must have a maximum and a minimum value and both of these must be less than or equal to the total angular momentum squared eigenvalue ii The Raising and Lowering Operators Change the Eigenvalue but not the Eigenvalue When Acting on Applying the commutation relations obeyed by to yields another useful result Now using the fact that is an eigenstate of and of these identities give textbfJ_z textbfJ_pm jmrangle mhbar pm hbar textbfJ_pm jmrangle h m jmrangle These equations prove that the functions must either themselves be eigenfunctions of and with eigenvalues and respectively or must equal zero In the former case we see that acting on generates a new eigenstate with the same eigenvalue as but with one unit of h higher or lower in eigenvalue It is for this reason that we call raising and lowering operators Notice that although is indeed an eigenfunction of with eigenvalue is not identical to it is only proportional to Explicit expressions for these coefficients will be obtained below Notice also that because the and hence have the same eigenvalue as in fact sequential application of can be used to show that all for all have this same eigenvalue the eigenvalue must be independent of m For this reason can be labeled by one quantum number j iii The Eigenvalues are Related to the Maximum and Minimum Eigenvalues Which are Related to One Another Earlier we showed that there exists a maximum and a minimum value for m for any given total angular momentum It is when one reaches these limiting cases that applies In particular Applying the following identities respectively to and gives which immediately gives the eigenvalue and in terms of or So we now know the eigenvalues for and However we earlier showed that and have the same eigenvalue when we treated the effect of on and that the eigenvalue is independent of m If we therefore define the quantum number to be we see that the eigenvalues are given by We also see that from which it follows that iv The Quantum Number Can Be Integer or HalfInteger The fact that the values run from to in unit steps because of the property of the operators there clearly can be only integer or halfinteger values for In the former case the quantum number runs over in the latter runs over Only integer and halfinteger values can range from to in steps of unity Species whose intrinsic angular momenta are integers are known as Bosons and those with halfinteger spin are called Fermions v More on Using the above results for the effect of acting on and the fact that and are adjoints of one another two operators and are adjoints if for all and all allows us to write where is the proportionality constant between and the normalized function Likewise the effect of can be expressed as where is the proportionality constant between and the normalized Thus we can solve for after which the effect of on is given by Summary The above results apply to any angular momentum operators The essential findings can be summarized as follows i and have complete sets of simultaneous eigenfunctions We label these eigenfunctions they are orthonormal in both their m and jtype indices ii These eigenfunctions obey iii The raising and lowering operators act on to yield functions that are eigenfunctions of with the same eigenvalue as and eigenfunctions of with eigenvalue of iv When acts on the extremal states or respectively the result is zero The results given above are as stated general Any and all angular momenta have quantum mechanical operators that obey these equations It is convention to designate specific kinds of angular momenta by specific letters however it should be kept in mind that no matter what letters are used there are operators corresponding to and that obey relations as specified above and there are eigenfunctions and eigenvalues that have all of the properties obtained above For electronic or collisional orbital angular momenta it is common to use and for electron spin S and Sz are used for nuclear spin I and Iz are most common and for molecular rotational angular momentum N and Nz are most common although sometimes and may be used Whenever two or more angular momenta are combined or coupled to produce a total angular momentum the latter is designated by and Coupling of Angular Momenta If the Hamiltonian under study contains terms that couple two or more angular momenta then only the components of the total angular momentum and the total will commute with It is therefore essential to label the quantum states of the system by the eigenvalues of and and to construct variational trial or model wave functions that are eigenfunctions of these total angular momentum operators The problem of angular momentum coupling has to do with how to combine eigenfunctions of the uncoupled angular momentum operators which are given as simple products of the eigenfunctions of the individual angular momenta to form eigenfunctions of and a Eigenfunctions of Because the individual elements of are formed additively but is not it is straightforward to form eigenstates of simple products of the form are eigenfunctions of and have eigenvalues equal to the sum of the individual eigenvalues Hence to form an eigenfunction with specified and eigenvalues one must combine only those product states whose sum is equal to the specified value b Eigenfunctions of the ClebschGordon Series The task is then reduced to forming eigenfunctions given particular values for the quantum numbers When coupling pairs of angular momenta and the total angular momentum states can be written according to what we determined above as where the coefficients are called vector coupling coefficients because angular momentum coupling is viewed much like adding two vectors and to produce another vector and where the sum over and is restricted to those terms for which It is more common to express the vector coupling or socalled ClebschGordon CG coefficients as and to view them as elements of a matrix whose columns are labeled by the coupledstate quantum numbers and whose rows are labeled by the quantum numbers characterizing the uncoupled product basis It turns out that this matrix can be shown to be unitary so that the CG coefficients obey sum_mm langle jmjmJMrangle langle jmjmJMrangle delta_jjprime delta_mmprime and sum_JM langle jnjnJMrangle langle jmjmJMrangle delta_nm delta_nm This unitarity of the CG coefficient matrix allows the inverse of the relation giving coupled functions in terms of the product functions to be written as This result expresses the product functions in terms of the coupled angular momentum functions c Generation of the ClebschGordon Coefficients The ClebschGordon coefficients can be generated in a systematic manner however they can also be looked up in books where they have been tabulated eg see Table of R N Zare Angular Momentum John Wiley New York Here we will demonstrate the technique by which the CG coefficients can be obtained but we will do so for rather limited cases and refer the reader to more extensive tabulations for more cases The strategy we take is to generate the state ie the state with maximum value and to then use to generate after which the state ie the state with one lower value is constructed by finding a combination of the product states in terms of which is expressed because both and have the same value which is orthogonal to because and are eigenfunctions of the Hermitian operator corresponding to different eigenvalues they must be orthogonal This same process is then used to generate and by orthogonality construction and so on i The States With Maximum and Minimum MValues We begin with the state having the highest value This state must be formed by taking the highest and the highest values ie and and is given by Only this one product is needed because only the one term with mj and mj contributes to the sum in the above CG series The state with the minimum value is also given as a single product state Notice that these states have values given as since this is the maximum value it must be that the value corresponding to this state is ii States With One Lower MValue But the Same Value Applying to and expressing as the sum of lowering operators for the two individual angular momenta gives This result expresses as follows that is the state which has is formed from the two product states and that have this same value iii States With One Lower Value To find the state that has the same value as the one found above but one lower value we must construct another combination of the two product states with ie and that is orthogonal to the combination representing after doing so we must scale the resulting function so it is properly normalized In this case the desired function is It is straightforward to show that this function is indeed orthogonal to iv States With Even One Lower Value Having expressed and in terms of and we are now prepared to carry on with this stepwise process to generate the states and as combinations of the product states with These product states are and Notice that there are precisely as many product states whose values add up to the desired value as there are total angular momentum states that must be constructed there are three of each in this case The steps needed to find the state are analogous to those taken above One first applies to and to to obtain and respectively as combinations of and One then constructs as a linear combination of the and that is orthogonal to the combinations found for and Once is obtained it is then possible to move on to form and by applying to the three states obtained in the preceding application of the process and to then form as the combination of that is orthogonal to the combinations obtained for and Again notice that there are precisely the correct number of product states four here as there are total angular momentum states to be formed In fact the product states and the total angular momentum states are equal in number and are both members of orthonormal function sets because and as well as and are Hermitian operators which have complete sets of orthonormal eigenfunctions This is why the CG coefficient matrix is unitary because it maps one set of orthonormal functions to another with both sets containing the same number of functions d An Example Example Let us consider an example in which the spin and orbital angular momenta of the Si atom in its ground state can be coupled to produce various states In this case the specific values for and are and We could of course take and but the final wave functions obtained would span the same space as those we are about to determine The state with highest value is the state which can be represented by the product of an spin function representing and a spatial function representing where the first function corresponds to the first openshell orbital and the second function to the second openshell orbital Thus the maximum value is and corresponds to a state with Clearly the state would be given as The states and with one lower value are obtained by applying to as follows To apply or to one must realize that each of these operators is in turn a sum of lowering operators for each of the two openshell electrons The result above can therefore be continued as So the function is given by which can be rewritten as Writing the result in this way makes it clear that is a combination of the product states the terms containing and the terms containing There is a good chance that some readers have noticed that some of the terms in the function would violate the Pauli exclusion principle In particular the term places two electrons into the same orbitals and with the same spin Indeed this electronic function would indeed violate the Pauli principle and it should not be allowed to contribute to the final Si wave functions we are trying to form The full resolution of how to deal with this paradox is given in the following Subsection but for now let me say the following i Once you have learned that all of the spinorbital product functions shown for eg and represent Slater determinants we deal with this in the next Subsection that are antisymmetric with respect to permutation of any pair of electrons you will understand that the Slater determinant corresponding to vanishes ii If instead of considering the configuration of Si we wanted to generate wave functions for the states of Si the same analysis as shown above would pertain except that now the state would have a contribution from This contribution does not violate the Pauli principle and its Slater determinant does not vanish So for the remainder of this treatment of the states of Si dont worry about terms arising that violate the Pauli principle they will not contribute because their Slater determinants will vanish To form the other function with the state we must find another combination of and that is orthogonal to and is normalized Since we immediately see that the requisite function is In the spinorbital notation used above this state is Thus far we have found the states with and To find the states with and we must once again apply the tool In particular we apply to to obtain and we apply to to obtain each of which will be expressed in terms of and The state is then constructed to be a combination of these same product states which is orthogonal to and to The results are as follows JMrangle fracsqrt rangle rangle rangle rangle rangle rangle where in all cases a short hand notation has been used in which the product stated have been represented by their quantum numbers with the spin function always appearing first in the product To finally express all three of these new functions in terms of spinorbital products it is necessary to give the products with in terms of these products For the spin functions we have For the orbital product function we have e Coupling Angular Momenta of Equivalent Electrons If equivalent angular momenta are coupled eg to couple the orbital angular momenta of a or configuration there is a tool one can use to determine which of the term symbols violate the Pauli principle To carry out this step one forms all possible unique determinental product states with nonnegative and values and arranges them into groups according to their and values For example the boxes appropriate to the orbital occupancy that we considered earlier for Si are shown below MS ML p p p p p p p p p p p p pp p p There is no need to form the corresponding states with negative or negative values because they are simply mirror images of those listed above For example the state with and is which can be obtained from the state by replacing a by b and replacing by Given the box entries one can identify those term symbols that arise by applying the following procedure over and over until all entries have been accounted for One identifies the highest value this gives a value of the total spin quantum number that arises in the box For the above example the answer is For all product states of this value one identifies the highest value this gives a value of the total orbital angular momentum that can arise for this For the above example the highest within the states is not hence Knowing an combination one knows the first term symbol that arises from this configuration In the example this is Because the level with this and quantum numbers contains states with and quantum numbers running from to and from to respectively one must remove from the original box this number of product states To do so one simply erases from the box one entry with each such and value Actually since the box need only show those entries with nonnegative and values only these entries need be explicitly deleted In the example this amounts to deleting nine product states with values of After deleting these entries one returns to step and carries out the process again For the example the box after deleting the first nine product states looks as follows those that appear in italics should be viewed as already deleted in counting all of the states MS ML p p p p p p p p p p p p pp p p It should be emphasized that the process of deleting or crossing off entries in various boxes involves only counting how many states there are by no means do we identify the particular wave functions when we cross out any particular entry in a box For example when the product is deleted from the box in accounting for the states in the level we do not claim that itself is a member of the level the product state could just as well been eliminated when accounting for the states Returning to the example at hand after the term symbols states have been accounted for the highest value is hence there is an state and within this value the highest value is hence there is an state This means there is a level with five states having Deleting five appropriate entries from the above box again denoting deletions by italics leaves the following box MS ML p p p p p p p p p p p p pp p p The only remaining entry which thus has the highest and values has and Thus there is also a level in the configuration Thus unlike the nonequivalent case in which and levels arise only the and arise in the situation This box method is useful to carry out whenever one is dealing with equivalent angular momenta If one has mixed equivalent and nonequivalent angular momenta one can determine all possible couplings of the equivalent angular momenta using this method and then use the simpler vector coupling method to add the nonequivalent angular momenta to each of these coupled angular momenta For example the configuration can be handled by vector coupling using the straightforward nonequivalent procedure the d orbital and the third electrons spin to each of and arising from the configuration The result is and Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Applying the Laws of Probability Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers The laws of probability apply to events that are independent If the result of one trial depends on the result of another trial we may still be able to use the laws of probability However to do so we must know the nature of the interdependence If the activity associated with event C precedes the activity associated with event D the probability of D may depend on whether C occurs Suppose that the first activity is tossing a coin and that the second activity is drawing a card from a deck however the deck we use depends on whether the coin comes up heads or tails If the coin is heads we draw a card from an ordinary deck if the coin is tails we draw a coin from a deck with the face cards removed Now we ask about the probability of drawing an ace If the coin is heads the probability of drawing an ace is If the coin is tails the probability of drawing an ace is The combination coin is heads and card is ace has probability The combination coin is tails and card is ace has probability In this case the probability of drawing an ace depends on the modification we make to the deck based on the outcome of the coin toss Applying the laws of probability is straightforward An example that illustrates the application of these laws in a transparent way is provided by villages First Second Third and Fourth which are separated by rivers See Figure Bridges and span the river between First and Second Bridges and span the river between Second and Third Bridges and span the river between Third and Fourth A traveler from First to Fourth who is free to take any route he pleases has a choice from among possible combinations Let us consider the probabilities associated with various events There are possible routes If a traveler chooses his route at random the probability that he will take any particular route is This illustrates our assumption that each event in a set of exhaustive and mutually exclusive events occurs with probability If he chooses a route at random the probability that he goes from First to Second by either bridge or bridge is This illustrates the calculation of the probability of alternative events The probability of the particular route is and we calculate the same probability for any other route from First to Fourth This illustrates the calculation of the probability of a compound event If he crosses bridge the probability that his route will be is zero of course The probability of an event that has already occurred is and the probability of any alternative is zero If he crosses bridge and Given that a traveler has used bridge the probability of the route becomes the probability of path which is Since the probability of the compound event is the probability of the compound event The outcomes of rolling dice rolling provide more illustrations If we roll two dice we can classify the possible outcomes according to the sums of the outcomes for the individual dice There are thirtysix possible outcomes They are displayed in Table Table Outcomes from tossing two dice Outcome for first die Outcome for second die Let us consider the probabilities associated with various dicethrowing events The probability of any given outcome say the first die shows and the second die shows is Since the probability that the first die shows while the second die shows is also the probability that one die shows and the other shows is Four different outcomes correspond to the event that the score is Therefore the probability of rolling is The probability of rolling a score of three or less is the probability of rolling plus the probability of rolling which is Suppose we roll the dice one at a time and that the first die shows The probability of rolling when the second die is thrown is now because only rolling a can make the score and there is a probability of that a will come up when the second die is thrown Suppose the first die is red and the second die is green The probability that the red die comes up and the green die comes up is Above we looked at the number of outcomes associated with a score of to find that the probability of this event is We can use another argument to get this result The probability that two dice roll a score of three is equal to the probability that the first die shows or times the probability that the second die shows whatever score is necessary to make the total equal to three This is Application of the laws of probability is frequently made easier by recognizing a simple restatement of the requirement that events be mutually exclusive In a given trial either an event occurs or it does not Let the probability that an event A occurs be Let the probability that event A does not occur be Since in any given trial the outcome must belong either to event A or to event we have For example if the probability of success in a single trial is the probability of failure is If we consider the outcomes of two successive trials we can group them into four events Event SS First trial is a success second trial is a success Event SF First trial is a success second trial is a failure Event FS First trial is a failure second trial is a success Event FF First trial is a failure second trial is a failure Using the laws of probability we have where and are the probability of event in the first and second trials respectively This situation can be mapped onto a simple diagram We represent the possible outcomes of the first trial by line segments on one side of a unit square We represent the outcomes of the second trial by line segments along an adjoining side of the unit square The four possible events are now represented by the areas of four mutually exclusive and exhaustive portions of the unit square as shown in Figure Figure Success and failure in successive trials A Slightly Philosophical Digression on Energy and Entropy Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers The content of the first law of thermodynamics is that there is a state function which we call energy which has the property that for any process that can occur The content of the second law is that there is a state function which we call entropy which has the property that for any spontaneous process These two state functions exhaust the range of independent possibilities Suppose that we aspire to find a new and independent state function call it which further characterizes the possibilities open to the universe What other condition could B impose on the universeor vice versa The only available candidate might appear to be However this does not represent an independent condition since its role is already filled by the quantity Of course we can imagine a state function which is not simply a function of but for which or according as the process is spontaneous reversible or impossible respectively For any given change would not be the same as however and would make exactly the same predictions If were more easily evaluated than we would prefer to use rather than Nevertheless if there were such a function its role in our description of nature would duplicate the role played by A Third Statement of the Second Law Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Let us consider another frequently cited alternative statement of the second law which for easy reference we call the temperaturebased statement of the second law The temperaturebased statement of the second law The spontaneous transfer of heat from a colder body to a warmer body is impossible In the discussion below we refer to this statement as proposition By body we simply mean any system or object By the spontaneous transfer of heat we mean that the transfer of heat energy can be initiated by bringing the two bodies into contact with one another or by enabling the transmission of radiant energy between them The surroundings do no work and exchange no heat with either reservoir there is no change of any sort in the surroundings We can show that the entropybased statement and the temperaturebased statement of the second law are equivalent Given the definition of entropy one implies the other Let us begin by showing that the entropybased statement implies the temperaturebased statement of the second law That is we prove To do so we prove That is we assume that spontaneous transfer of heat from a colder to a warmer body is possible and show that this leads to a contradiction of the entropybased statement of the second law Let the quantity of heat received by the warmer body be and let the temperatures of the warmer and colder bodies be and respectively We have The colder body receives heat We make the heat increment so small that there is no significant change in the temperature of either body No other changes occur The two bodies are the only portions of the universe that are affected Let the entropy changes for the warmer and colder bodies be and respectively To find and we must find a reversible path to effect the same changes This is straightforward We can effect identically the same change in the warmer body by transferring heat to it through contact with some third body whose temperature is infinitesimally greater than This process is reversible and the entropy change is Similarly the entropy change for the colder body is It follows that However if for a spontaneous process the second law must be false We have shown that a violation of the temperaturebased statement implies a violation of the entropybased statement of the second law so that It is equally easy to show that the temperaturebased statement implies the entropybased statement of the second law To do so we assume that the entropybased statement is false and show that this implies that the temperaturebased statement must be false By the arguments above the entropy change that the universe experiences during the exchange of the heat increment is If the entropybased statement of the second law is false then It follows that that is the spontaneous process transfers heat from the colder to the warmer body This contradicts the temperaturebased statement That is so that Avogadros Hypothesis Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Avogadros hypothesis is another classical gas law It can be stated At the same temperature and pressure equal volumes of different gases contain the same number of molecules When the mass in grams of an ideal gas sample is equal to the gram molar mass traditionally called the molecular weight of the gas the number of molecules in the sample is equal to Avogadros number Avogadros number is the number of molecules in a mole In the modern definition one mole is the number of atoms of in exactly g of That is the number of atoms of in exactly g of is Avogadros number The currently accepted value is molecules per mole We can find the gram atomic mass of any other element by finding the mass of that element that combines with exactly g of in a compound whose molecular formula is known The validity of Avogadros hypothesis follows immediately either from the fact that the Boyles law constant is the same for any gas or from the fact that the Charles law constants and are the same for any gas However this entails a significant circularity these experiments can show that and are the same for any gas only if we know how to find the number of moles of each gas that we use To do so we must know the molar mass of each gas Avogadros hypothesis is crucially important in the history of chemistry Avogadros hypothesis made it possible to determine relative molar masses This made it possible to determine molecular formulas for gaseous substances and to create the atomic mass scale Bands of Orbitals in Solids Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Contributors and Attributions Not only does the particleinabox model offer a useful conceptual representation of electrons moving in polyenes but it also is the zerothorder model of band structures in solids Let us consider a simple onedimensional crystal consisting of a large number of atoms or molecules each with a single orbital the blue spheres shown below that it contributes to the bonding Let us arrange these building blocks in a regular lattice as shown in the Figure Figure The energy levels arising from and an infinite number of orbitals In the top four rows of this figure we show the case with and building blocks To the left of each row we display the energy splitting pattern into which the building blocks orbitals evolve as they overlap and form delocalized molecular orbitals Not surprisingly for one finds a bonding and an antibonding orbital For one has a bonding one nonbonding and one antibonding orbital Finally in the bottom row we attempt to show what happens for an infinitely long chain The key point is that the discrete number of molecular orbitals appearing in the orbital cases evolves into a continuum of orbitals called a band as the number of building blocks becomes large This band of orbital energies ranges from its bottom whose orbital consists of a fully inphase bonding combination of the building block orbitals to its top whose orbital is a fully outofphase antibonding combination In Figure we illustrate these fully bonding and fully antibonding band orbitals for two cases the bottom involving stype building block orbitals and the top involving type orbitals Notice that when the energy gap between the building block and orbitals is larger than is the dispersion spread in energy within the band of or band of orbitals a band gap occurs between the highest member of the band and the lowest member of the band The splitting between the and orbitals is a property of the individual atoms comprising the solid and varies among the elements of the periodic table For example we teach students that the energy gap in C is smaller than the gap in Si which is smaller than the gap in Ge The dispersion in energies that a given band of orbitals is split into as these atomic orbitals combine to form a band is determined by how strongly the orbitals on neighboring atoms overlap Small overlap produces small dispersion and large overlap yields a broad band So the band structure of any particular system can vary from one in which narrow bands weak overlap do not span the energy gap between the energies of their constituent atomic orbitals to bands that overlap strongly large overlap Figure The bonding through antibonding energies and band orbitals arising from and from atomic orbitals Depending on how many valence electrons each building block contributes the various bands formed by overlapping the buildingblock orbitals of the constituent atoms will be filled to various levels For example if each building block orbital shown above has a single valence electron in an sorbital eg as in the case of the alkali metals the sband will be half filled in the ground state with a and b paired electrons Such systems produce very good conductors because their partially filled bands allow electrons to move with very little eg only thermal excitation among other orbitals in this same band On the other hand for alkaline earth systems with two electrons per atom the sband will be completely filled In such cases conduction requires excitation to the lowest members of the nearby porbital band Finally if each building block were an Al s p atom the sband would be full and the pband would be half filled In Figure a we show a qualitative depiction of the bands arising from sodium atoms and orbitals Notice that the band is very narrow because there is little coupling between neighboring orbitals so they are only slightly stabilized or destabilized relative to their energies in the isolated Na atoms In contrast the and bands show greater dispersion ie are wider and the band is even wider The and bands are full but the band is half filled as a result of which solid Na is a good electrical conductor Figure a Example of sodium atoms and orbitals splitting into filled and partially filled bands in sodium metal In describing the band of states that arise from a given atomic orbital within a solid it is common to display the variation in energies of these states as functions of the number of sign changes in the coefficients that describe each orbital as a linear combination of the constituent atomic orbitals Using the onedimensional array of and orbitals shown in Figure as an example The lowest member of the band deriving from the orbitals is a totally bonding combination of all of the constituent orbitals on the sites of the lattice The highestenergy orbital in this band is a totally antibonding combination of the constituent orbitals Each of the intervening orbitals in this band has expansion coefficients that allow the orbital to be written as Clearly for small values of the series of expansion coefficients has few sign changes as the index runs over the sites of the onedimensional lattice For larger n there are more sign changes Thus thinking of the quantum number as labeling the number of sign changes and plotting the energies of the orbitals on the vertical axis versus on the horizontal axis we would obtain a plot that increases from to In fact such plots tend to display quadratic variation of the energy with This observation can be understood by drawing an analogy between the pattern of sign changes belonging to a particular value of and the number of nodes in the onedimensional particleinabox wave function which also is used to model electronic states delocalized along a linear chain As we saw in Chapter the energies for this model system varied as with being the quantum number ranging from to The lowestenergy state with has no nodes the state with has one node and that with has nodes So if we replace by and replace the box length by where is the interatom spacing and is the number of atoms in the chain we obtain from which on can see why the energy can be expected to vary as In contrast for the orbitals the lowestenergy orbital is because this alternation in signs allows each orbital on one site to overlap in a bonding fashion with the orbitals on neighboring sites Therefore the highestenergy orbital in the band is and is totally antibonding The intervening members of this band have orbitals given by with low corresponding to highenergy orbitals having few interatom sign changes but antibonding character and high to lowenergy orbitals having many interatom sign changes So in contrast to the case for the sband orbitals plotting the energies of the orbitals on the vertical axis versus on the horizontal axis we would obtain a plot that decreases from to For bands comprised of orbitals the energies vary with the quantum number in a manner analogous to how the band varies because the orbital with no interatom sign changes is fully bonding For two and threedimensional lattices comprised of s p and d orbitals on the constituent atoms the behavior of the bands derived from these orbitals follows analogous trends It is common to describe the sign alternations arising from site to site in terms of a socalled vector In the onedimensional case discussed above this vector has only one component with elements labeled by the ratio whose value characterizes the number of interatom sign changes For lattices containing many atoms is very large so ranges from zero to a very large number Thus the ratio ranges from zero to unity in small fractional steps so it is common to think of these ratios as describing a continuous parameter varying from zero to one Moreover it is convention to allow the index to range from to so the argument in the cosine function introduced above varies from to In two or threedimensions the vector has two or three elements and can be written in terms of its two or three index ratios respectively as Here and would describe the number of unit cells along the three principal axes of the threedimensional crystal and do likewise in the twodimensional lattice case In such two and three dimensional crystal cases the energies of orbitals within bands derived from s p d etc atomic orbitals display variations that also reflect the number of interatom sign changes However now there are variations as functions of the and indices and these variations can display rather complicated shapes depending on the symmetry of the atoms within the underlying crystal lattice That is as one moves within the threedimensional space by specifying values of the indices and one can move throughout the lattice in different symmetry directions It is convention in the solidstate literature to plot the energies of these bands as these three indices vary from site to site along various symmetry elements of the crystal and to assign a letter to label this symmetry element The band that has no interatom sign changes is labeled as sometimes G in such plots of band structures In much of our discussion below we will analyze the behavior of various bands in the neighborhood of the point because this is where there are the fewest interatom nodes and thus the wave function is easiest to visualize Lets consider a few examples to help clarify these issues In Figure b where we see the band structure of graphene you can see the quadratic variations of the energies with as one moves away from the point labeled with some bands increasing with and others decreasing with Figure b Band structure plot for graphene The band having an energy of ca eV at the point originates from bonding interactions involving orbitals on the carbon atoms while those having energies near eV at the point derive from carbon bonding interactions The parabolic increase with for the based and decrease with for the based orbitals is clear and is expected based on our earlier discussion of how and bands vary with The band having energy near eV at the point involves orbitals involved in bonding interactions and this band shows a parabolic increase with as expected as we move away from the point These are the delocalized orbitals of the graphene sheet The antibonding band decreases quadratically with and has an energy of ca eV at the point Because there are two atoms per unit cell in this case there are a total of eight valence electrons four from each carbon atom to be accommodated in these bands The eight carbon valence electrons fill the bonding and two bands fully as well as the bonding band Only along the direction labeled P in Figure b do the bonding and antibonding bands become degenerate near eV the approach of these two bands is what allows graphene to be semimetallic ie to conduct at modest temperatures high enough to promote excitations from the bonding to the antibonding band It is interesting to contrast the band structure of graphene with that of diamond which is shown in Figure c Figure c Band structure of diamond carbon The band having an energy of ca eV at the point derives from bonding interactions and the three bands near eV at the point come from bonding interactions Again each of these bands displays the expected parabolic behavior as functions of In diamonds two interpenetrating face centered cubic structure there are two carbon atoms per unit cell so we have a total of eight valence electrons to fill the four bonding bands Notice that along no direction in space do these filled bonding bands become degenerate with or are crossed by any of the other bands The other bands remain at higher energy along all directions and thus there is a gap between the bonding bands and the others is large ca eV or more along any direction in space This is why diamond is an insulator the band gap is very large Finally lets compare the graphene and diamond cases with a metallic case such as shown in Figure d for Al and for Ag Figure d Band structures of Al and Ag For Al and Ag there is one atom per unit cell so we have three valence electrons sp and eleven valence electrons ds respectively to fill the bands shown in Figure d Focusing on the points in the Al and Ag band structure plots we can say the following For Al the based band near eV is filled and the three based bands near eV have an occupancy of ie on average there is one electron in one of these three bands each of which can hold two electrons The and bands are parabolic with positive and negative curvature respectively Along several directions eg there are crossings among the bands these crossings allow electrons to be promoted from occupied to previously unoccupied bands The partial occupancy of the bands and the multiple crossings of bands are what allow Al to show metallic behavior For Ag there are six bands between eV and eV Five of these bands change little with and one shows somewhat parabolic dependence on The former five derive from atomic orbitals that are contracted enough to not allow them to overlap much and the latter is based on bonding orbital interaction Ten of the valence electrons fill the five bands and the eleventh resides in the sbased bonding band If the five based bands are ignored the remainder of the Ag band structure looks a lot like that for Al There are numerous band crossings that include in particular the halffilled band These crossings and the partial occupancy of the band cause Ag to have metallic character One more feature of band structures that is often displayed is called the band density of states An example of such a plot is shown in Figure e for the TiN crystal Figure e Energies of orbital bands in TiN along various directions in space left and densities of states right as functions of energy for this same crystal The density of states at energy is computed by summing all those orbitals having an energy between and Clearly as seen in Figure e for bands in which the orbital energies vary strongly with ie socalled broad bands the density of states is low in contrast for narrow bands the density of states is high The densities of states are important because their energies and energy spreads relate to electronic spectral features Moreover just as gaps between the highest occupied bands and the lowest unoccupied bands play central roles in determining whether the sample is an insulator a conductor or a semiconductor gaps in the density of states suggest what frequencies of light will be absorbed or reflected via interband electronic transitions The bands of orbitals arising in any solid lattice provide the orbitals that are available to be occupied by the number of electrons in the crystal Systems whose highest energy occupied band is completely filled and for which the gap in energy to the lowest unfilled band is large are called insulators because they have no way to easily ie with little energy requirement promote some of their higherenergy electrons from orbital to orbital and thus effect conduction The case of diamond discussed above is an example of an insulator If the band gap between a filled band and an unfilled band is small it may be possible for thermal excitation ie collisions with neighboring atoms or molecules to cause excitation of electrons from the former to the latter thereby inducing conductive behavior The band structures of Al and Ag discussed above offer examples of this case A simple depiction of how thermal excitations can induce conduction is illustrated in Figure Figure The valence and conduction bands and the band gap with a small enough gap to allow thermal excitation to excite electrons and create holes in a previously filled band Systems whose highestenergy occupied band is partially filled are also conductors because they have little spacing among their occupied and unoccupied orbitals so electrons can flow easily from one to another Al and Ag are good examples To form a semiconductor one starts with an insulator whose lower band is filled and whose upper band is empty as shown by the broad bands in Fig Figure The filled and empty bands the band gap and empty acceptor or filled donor bands If this insulator material is synthesized with a small amount of dopant whose valence orbitals have energies between the filled and empty bands of the insulator one can generate a semiconductor If the dopant species has no valence electrons ie has an empty valence orbital it gives rise to an empty band lying between the filled and empty bands of the insulator as shown below in case a of Figure In this case the dopant band can act as an electron acceptor for electrons excited either thermally or by light from the filled band of the insulator into the dopants empty band Once electrons enter the dopant band charge can flow because the insulators lower band is no longer filled and the system thus becomes a conductor Another case is illustrated in the b part of Figure Here the dopant has a filled band that lies close in energy to the empty band of the insulator Excitation of electrons from this dopant band to the insulators empty band can induce current to flow because now the insulators upper band is no longer empty Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Bar Graphs and Histograms Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Since a discrete distribution is completely specified by the probabilities of each of its events we can represent it by a bar graph The probability of each event is represented by the height of one bar We can generalize this graphical representation to represent continuous distributions To see what we have in mind let us consider a particular example Let us suppose that we have a radar gun and that we decide to interest ourselves in the typical speeds of cars on a highway just outside of town As we think about this project we recognize that speeds might vary with the time of day and the day of the week Random variations in many other factors might also be important these include weather conditions and accidents in the vicinity To eliminate as many atypical factors as possible we might decide that typical speeds are those of cars going north between pm and pm on weekdays when the road surface is dry and there are no disabled vehicles in view If we have a lot of time and the road is busy we could collect a lot of data Let us suppose that we record the speeds of cars Each datum would be the speed of a car on the road at a time when the selected conditions are satisfied To use this data we want to summarize it in a form that is easy to visualize One way to do this is to aggregate the data to give the number of cars in each mph range the results might look something like the data in Table Figure is a fivechannel bar graph that displays the number of cars in each mph range A great deal of information is lost in the aggregating process In particular nothing on the graph represents the number of automobiles in narrower speed intervals Table Vehicle speed data Speedmph Number of cars Fraction of cars Height for bar area to equal fraction Now suppose that we repeat this task but that we do not have enough time to collect data on as many as more cars We will be curious about the extent to which our two samples agree with one another Since the total number of vehicles will be different the appropriate way to go about this is obviously to compare the fraction of cars in each speed range In fact using fractions enables us to compare any number of such studies To the extent that these studies measure the same thingtypical speeds under the specified conditionsthe fraction of automobiles in any particular speed interval should be approximately constant Dividing the number of automobiles in each speed interval by the total number of automobiles gives a representation that focuses attention on the proportion of automobiles with various speeds The shape of the bar graph remains the same all that changes is the scale we use to label the ordinate See Figure Figure Number of cars versus speed Insofar as any repetition of this experiment gives nearly the same results this is a useful change However the fundamental limitations of the graph remain For example if we want to use the graph to estimate how speeds are distributed in any other set of intervals we have to read values off the ordinate and manipulate them in ways that may not be very satisfactory To estimate the fraction with speeds between mph and mph we might assign half of the automobiles in the mph interval and half of those in the mph interval to the new interval This enables us to estimate that the fraction in the mph interval is This estimate is much less reliable than one that could be made by going back to the raw data for all automobiles Figure Fraction of cars versus speed The data can also be represented as a histogram In a histogram the information is represented by the area rather than the height of the bar In the present case the only visible change to the graph is another change in the numerical values on the ordinate In Figure the area of a bar represents the fraction of automobiles with speeds in the given interval As the speed interval is made smaller any of these bar graphs looks increasingly like a continuous curve See Figure The histogram has the advantage that as the curve becomes continuous the interpretation remains constant the area under the curve between any two speeds always represents the fraction of automobiles with speeds in this interval It turns out that we are adept at visually estimating the relative areas of different parts of a histogram That is from a quick glance at a histogram we are able to obtain a good semiquantitative appreciation of the significance of the underlying data Figure Speed data presented as a histogram If the histogram captures our experience and we expect future events to have the same characteristics the histogram becomes an expression of probability All that is necessary is that we construct the histogram so that the total area under the graph is unity If we let be the area under the graph from to then represents the probability that the speed of a randomly selected automobile will lie between and For any and b the probability that lies in the interval is The function is called the cumulative probability distribution function because its value for any is the fraction of automobiles that have a speed less than is the frequency with which we observe values of the random variable that are less than Equivalently we can say that is the probability that any randomly selected automobile will have a speed less than If we let the width of every interval go to zero the bar graph representation of the histogram becomes a curve and the histogram becomes a continuous function of the random variable See Figure Note that the curvethe enclosing envelopeis not is the area under the enclosing envelope curve Figure Histogram with narrower speed intervals Figure The histogram can be a continuous function Boyles Law Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Robert Boyle discovered Boyles law in Boyles discovery was that the pressure P and volume V of a gas are inversely proportional to one another if the temperature T is held constant We can imagine rediscovering Boyles law by trapping a sample of gas in a tube and then measuring its volume as we change the pressure We would observe behavior like that in Figure We can represent this behavior mathematically as where we recognize that the constant is actually a function of the temperature and of the number of moles of gas in the sample That is the product of pressure and volume is constant for a fixed quantity of gas at a fixed temperature A little thought convinces us that we can be more specific about the dependence on the quantity of gas Suppose that we have a volume of gas at a fixed pressure and temperature and imagine that we introduce a very thin barrier that divides the volume into exactly equal halves without changing anything else In this case the pressure and temperature of the gas in each of the new containers will be the same as they were originally But the volume is half as great and the number of moles in each of the halfsize containers must also be half of the original number That is the pressurevolume product must be directly proportional to the number of moles of gas in the sample where is now a function only of temperature When we repeat this experiment using different gaseous substances we discover a further remarkable fact Not only do they all obey Boyles law but also the value of is the same for any gas Figure Gas volume versus pressure Boyles Law from the MaxwellBoltzmann Probability Density Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers In Chapter we derive Boyles lawBoyles law using simplifying assumptions We are now able to do this derivation much more rigorously We consider the collisions of gas molecules with a small portion of the wall of their container We suppose that the wall is smooth so that we can select a small and compact segment of it that is arbitrarily close to being planar We denote both the segment of the wall and its area as can have any shape so long as it is a smooth flat surface enclosed by a smooth curve Let the volume of the container be and the number of gas molecules in the container be We imagine that we follow the trajectory of one particular molecule as it moves to hit the wall somewhere within We begin our observations at time and suppose that the collision occurs at time Figure Trajectory of a molecule colliding with a wall of its container As sketched in Figure we erect a Cartesian coordinate system with its origin at the location in space of the molecule at time We orient the axes of this coordinate system so that the plane is parallel to the plane of and the zaxis is pointed toward the wall Then the unit vector along the axis and a vector perpendicular to are parallel to one another It is convenient to express the velocity of the selected molecule in spherical coordinates We suppose that referred to the Cartesian coordinate system we have erected the velocity vector of the selected molecule is The vector drawn from the origin of our Cartesian system to the point of impact on the wall follows the trajectory of the molecule from time zero to time The component of the molecular velocity vector is normal to the plane of at the point of impact the magnitude of thecomponent The perpendicular distance from the plane of A to the plane of the Cartesian system is We assume that the collision is perfectly elastic Before collision the velocity component perpendicular to the wall is Afterward it is Only this change in the component contributes to the force on the wall within The and components are not changed by the collision During the collision the molecules momentum change is During our period of observation the average force on the molecule is thus The force that the molecule exerts on the wall is and hence the contribution that this particular collisionby one molecule traveling at velocity makes to the pressure on the wall is We want to find the pressure on segment of the wall that results from all possible impacts To do so we recognize that any other molecule whose velocity components are and and whose location at time enables it to reach within time makes the same contribution to the pressure as the selected molecule does Let us begin by assuming that the velocities of all N of the molecules in the volume are the same as that of the selected molecule In this case we can find the number of the molecules in the container that can reach within time by considering a tubular segment of the interior of the container The long axis of this tube is parallel to the velocity vector of the selected molecule The sides of this tube cut the container wall along the perimeter of This tube also cuts the plane the plane of our coordinate system in such a way as to make an exact replica of in this plane Call this replica The area of is the plane of is parallel to the plane of and the perpendicular distance between the plane of and the plane of is The volume of this tube is therefore Since there are molecules per unit volume the total number of molecules in the tube is When we assume that every molecule has velocity components and all of the molecules in the tube reach within time because each of them travels parallel to the selected molecule and each of them is initially at least as close to as is the selected molecule Therefore each molecule in the tube contributes to the pressure at The total pressure is the pressure per molecule multiplied by the number of molecules However the molecular velocities are not all the same and the pressure contribution is made only by that fraction of the molecules whose velocity components lie in the intervals and This fraction is so that the pressure contribution from molecules whose velocity components lie in these ranges is The total pressure at is just the sum of the contributions from molecules with all possible combinations of velocities and To find this sum we integrate over all possible velocity vectors The allowed values of are There are no constraints on the values of we have However since all of the impacting molecules must have a velocity component in the positive zdirection the possible values of lie in the interval We designate the velocity of the original molecule as and retain this notation to be as specific as possible in describing the tube bounded by and However the velocity components of an arbitrary molecule can have any of the allowed values To integrate See Appendix D over the allowed values we drop the superscripts The pressurepressureon wall at becomes intinfty _ vexpleftfraclambda vrightdv intpi _ mathrmcos theta mathrmsin theta dtheta intpi _ dvarphi and the pressurevolume product becomes Since and are constants this is Boyles law Equating this pressurevolume product to that given by the ideal gas equation we have so that Finally the MaxwellBoltzmann equation becomes and the probability density becomes This derivation can be recast as a computation of the expected value of the pressurepressureexpected value To do so we rephrase our description of the system A molecule whose velocity components are creates a pressure on the area with a probability of The latter term is the probability that a molecule whose velocity is is at time in a location from which it can reach within time If the molecule is to hit the wall within time at time the molecule must be within the tubular segment of volume is The probability that the molecule is within this tubular segment is equal to the fraction of the total volume that this segment occupies Therefore the product is the pressure contribution of a molecule with velocity when is in the interval The total pressure per molecule is the expected value of this pressure contribution the expected value is the integral over the entire volume of velocity space of the pressure contribution times the probability density function for velocities It is useful to view the MaxwellBoltzmann equation as the product of a term called the Boltzmann factorBoltzmann factorand a preexponential term that is proportional to the number of ways that a molecule can have a given velocity If there were no constraints on a molecules speed we would expect that the number of molecules with speeds between and would increase as increases because the probability that a molecule has a speed between and is proportional to the volume in velocity space of a spherical shell of thickness The volume of a spherical shell of thickness is which increases as the square of However the number of molecules with large values of is constrained by the conservation of energy Since the total energy of a collection of molecules is limited only a small proportion of the molecules can have very large velocities The Boltzmann factor introduces this constraint A molecule whose mass is m and whose scalar velocity is has kinetic energy The Boltzmann factor is often written as Buffers Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors and Attributions Buffer solutions which are of enormous importance in controlling pH in various processes can be understood in terms of acidbase equilibrium A buffer is created in a solution which contains both a weak acid and its conjugate base This creates to absorb excess H or supply H to replace what is lost due to neutralization The calculation of the pH of a buffer is straightforward using an ICE table approach Example What is the pH of a solution that is M in KF and M in HF Solution The reaction of interest is Lets use an ICE table Initial M M Change x x x Equilibrium M x x M x This expression results in a quadratic relationship leading to two values of that will make it true Rejecting the negative root the remaining root of the equation indicates So the pH is given by For buffers made from acids with sufficiently large values of pKa the buffer problem can be simplified since the concentration of the acid and its conjugate base will be determined by their preequilibrium values In these cases the pH can be calculated using the HendersonHasselbalch approximation If one considers the expression for Taking the log of both sides and multiplying by yields An rearrangement produces the form of the HendersonHasselbalch approxmimation It should be noted that this approximation will fail if the is too small the concentrations is too small or is too small since the equilibrium concentration will deviate wildly from the preequilibrium values under these conditions Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Calculating Entropy Changes Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Isothermal ChangesIsobaric ChangesIsochoric ChangesAdiabatic ChangesPhase ChangesContributors and Attributions Entropy changes are fairly easy to calculate so long as one knows initial and final state For example if the initial and final volume are the same the entropy can be calculated by assuming a reversible isochoric pathway and determining an expression for That term can then be integrated from the initial condition to the final conditions to determine the entropy change Isothermal Changes If the initial and final temperatures are the same the most convenient reversible path to use to calculate the entropy is an isothermal pathway As an example consider the isothermal expansion of an ideal gas from to As was derived in Chapter So is given by and so Example Entropy Change for a Gas Expansion Calculate the entropy change for mol of an ideal gas expanding isothermally from a volume of L to L Solution Recognizing that this is an isothermal process we can use Equation refisothermS Isobaric Changes For changes in which the initial and final pressures are the same the most convenient pathway to use to calculate the entropy change is an isobaric pathway In this case it is useful to remember that So Integration from the initial to final temperature is used to calculate the change in entropy If the heat capacity is constant over the temperature range If the temperature dependence of the heat capacity is known it can be incorporated into the integral For example if can be expressed as takes the form which simplifies to or Isochoric Changes Similarly to the cast of constant pressure it is fairly simple to calculate Since is given by And so for changes over which is independent of the temperature is given by Adiabatic Changes The easiest pathway for which to calculate entropy changes is an adiabatic pathway Since for an adiabatic change then as well Phase Changes The entropy change for a phase change at constant pressure is given by Example Entropy Change for Melting Ice The enthalpy of fusion for water is kJmol Calculate the entropy change for mole of ice melting to form liquid at K Solution This is a phase transition at constant pressure assumed requiring Equation refphase Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Calorimetry Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay CalorimetryBomb CalorimetryFinding Contributors and Attributions As chemists we are concerned with chemical changes and reactions The thermodynamics of chemical reactions can be very important in terms of controlling the production of desired products and preventing safety hazards such as explosions As such measuring and understanding the thermochemistry of chemical reactions is not only useful but essential Calorimetry The techniques of calorimetry can be used to measure q for a chemical reaction directly The enthalpy change for a chemical reaction is of significant interest to chemists An exothermic reaction will release heat causing the temperature of the surrounding to increase Conversely an endothermic reaction will draw heat from the surroundings causing the temperature of the surrounding to drop Measuring the temperature change in the surroundings allows for the determination of how much heat was released or absorbed in the reaction Bomb Calorimetry Bomb calorimetry is used predominantly to measure the heat evolved in combustion reactions but can be used for a wide variety of reactions A typical bomb calorimetry set up is shown here The reaction is contained in a heavy metallic container the bomb forcing the reaction to occur at constant volume As such the heat evolved or absorbed by the reaction is equal to the change in internal energy DUrxn The bomb is then submerged in a reproducible quantity of water the temperature of which is monitored with a highprecision thermometer For combustion reactions the bomb will be loaded with a small sample of the compound to be combusted and then the bomb is filled with a high pressure typically about atm of O The reaction is initiated by supplying heat using a short piece of resistive wire carrying an electrical current Figure A Bomb Calorimeter After the temperature of the water in the insulated container has reached a constant value the combustion reaction is initiated by passing an electric current through a wire embedded in the sample Because this calorimeter operates at constant volume the heat released is not precisely the same as the enthalpy change for the reaction CC BYSANC Anonymous by request The calorimeter must be calibrated by carrying out a reaction for which is well known so that the resulting temperature change can be related to the amount of heat released or absorbed A commonly used reaction is the combustion of benzoic acid This makes a good choice since benzoic acid reacts reliably and reproducibly under normal bomb calorimetry conditions The water equivalent of the calorimeter can then be calculated from the temperature change using the following relationship where n is the number of moles of benzoic acid used is the internal energy of combustion for benzoic acid kJ mol at oC accounts for the energy released in the combustion of the fuse wire eother account for any other corrections such as heat released due to the combustion of residual nitrogen in the bomb and DT is the measured temperature change in the surrounding water bath Once the water equivalent is determined for a calorimeter the temperature change can be used to find for an unknown compound from the temperature change created upon combustion of a known quantity of the substance The experiment above is known as isothermal bomb calorimetry as the entire assembly sits in a constant temperature laboratory Another approach is to employ adiabatic bomb calorimetry in which the assembly sits inside of a water jacket the temperature of which is controlled to match the temperature of the water inside the insulated container By matching this temperature there is no thermal gradient and thus no heat leaks into or out of the assembly during an experiment and hence the experiment is effectively adiabatic Finding The enthalpy of combustion can be calculated from the internal energy change if the balanced chemical reaction is known Recall from the definition of enthalpy and if the gasphase reactants and products can be treated as ideal gases at constant temperature For the combustion of benzoic acid at oC it can be seen that is mol of gas for every mole of benzoic acid reacted Example Combustion of Naphthalene A student burned a g sample of benzoic acid in a bomb calorimeter initially at oC and saw a temperature increase of oC She then burned a g sample of naphthalene again from an initial temperature of oC and saw a temperature increase of oC From this data calculate for naphthalene assuming ewire and eother are unimportant Solution First the water equivalent Then for the sample is then given by The reaction for the combustion of naphthalene at oC is with So The literature value Balcan Arzik Altunata is kJmol So thats not too far off Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Changes in a State Function are Independent of Path Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers We can specify an equilibrium state of a physical system by giving the values of a sufficient number of the systems measurable properties We call any measurable property that can be used in this way a state function or a state variable If a system undergoes a series of changes that return it to its original state any state function must have the same value at the end as it had at the beginning The relationship between our definition of a physical state and our definition of a state function is tautological A system can return to its initial state only if every state variable returns to its original value Figure Paths between states I and II It is evident that the change in a state function when the system goes from an initial state to some other state must always be the same Consider the state functions and Suppose that functions and are sufficient to specify the state of a particular system Let their values in state be and We can express their interdependence by saying that is a function of the other state functions and In state this relationship becomes The difference depends only on the states and In particular is independent of the values of and in any intermediate states that the system passes through as it undergoes the change from state to state We say that the change in the value of a state function depends only on the initial and final states of the system the change in the value of a state function does not depend on the path along which the change is effected We can also develop this conclusion by a more explicit argument about the path Suppose that the system goes from state to state by path and then returns to state by path as sketched in Figure Let be some state function If the change in as the system traverses path is and the change in as the system traverses is we must have so that For some second path comprising followed by the same must be true and The same is true for any other path In particular in must be true for the path followed by so that and hence But this means that Since the paths and are arbitrary the change in in going from state to state must have the same value for any path Notes Since the temperature of the water increases and the process is to be reversible we must keep the temperature of the thermal reservoir just greater than that of the water throughout the process We can accomplish this by using a quantity of ideal gas as the heat reservoir By reversibly compressing the ideal gas we can reversibly deliver the required heat while maintaining the required temperature We consider this operation further in Character Tables Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah No headers C_ E A Cs E sh A xyRz xyzxy A zRxRy yzxz Ci E i Ag RxRyRz xyzxyxzyz Au xyz C E C A zRz xyzxy B xyRxRy yzxz D E Cz Cy Cx A xyz B zRz xy B yRy xz B xRx yz Charles Law Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Quantitative experiments establishing the law were first published in by GayLussac who credited Jacques Charles with having discovered the law earlier Charles law relates the volume and temperature of a gas when measurements are made at constant pressure We can imagine rediscovering Charles law by trapping a sample of gas in a tube and measuring its volume as we change the temperature while keeping the pressure constant This presumes that we have a way to measure temperature perhaps by defining it in terms of the volume of a fixed quantity of some other fluidlike liquid mercury At a fixed pressure we observe a linear relationship between the volume of a sample of gas and its temperature like that in Figure If we repeat this experiment with the same gas sample at a higher pressure we observe a second linear relationship between the volume and the temperature of the gas If we extend these lines to their intersection with the temperature axis at zero volume we make a further important discovery Both lines intersect the temperature axis at the same point Figure Gas volume versus temperature We can represent this behavior mathematically as where we recognize that both the slope and the Vaxis intercept of the graph depend on the pressure of the gas and on the number of moles of gas in the sample A little reflection shows that here too the slope and intercept must be directly proportional to the number of moles of gas so that we can rewrite our equation as When we repeat these experiments with different gaseous substances we discover an additional important fact and are the same for any gas This means that the temperature at which the volume extrapolates to zero is the same for any gas and is independent of the constant pressure we maintain as we vary the temperature Figure Chemical Change Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Experimental Probes of Chemical Change Theoretical Simulation of Chemical ChangeContributors and Attributions Experimental Probes of Chemical Change Many of the same tools that are used to determine the structures of molecules can also be used to follow the changes that the molecule undergoes as it is involved in a chemical reaction Specifically for any reaction in which one kind of molecule is converted into another kind one needs to have the ability to identify via some physical measurement the experimental signatures of both and the ability to relate the magnitude of these experimental signals to the concentrations and of these molecules and the ability to monitor these signals as functions of time so that these concentrations can be followed as time evolves The third requirement is what allows one to determine the rates at which the and molecules are reacting Many of the experimental tools used to identify molecules eg NMR allows one to identify functional groups and nearneighbor functional groups IR also allows functional groups to be seen and to determine their concentrations have restricted time scales over which they can be used For example NMR spectra require that the sample be studied for ca second or more to obtain a useable signal Likewise a mass spectroscopic analysis of a mixture of reacting species may require many second or minutes to carry out These restrictions in turn limit the rates of reactions that can be followed using these experimental tools eg one can not use NMR of mass spectroscopy to follow a reaction that occurs on a time scale of s Especially for very fast reactions and for reactions involving unstable species that can not easily be handled socalled pumpprobe experimental approaches are often used For example suppose one were interested in studying the reaction of radicals eg as formed in the decomposition of chloroflurocarbons CFCs by ultraviolet light with ozone to generate and One can not simply deposit a known amount of radicals from a vessel into a container in which gaseous of a known concentration has been prepared the radicals will recombine and react with other species making their concentrations difficult to determine So alternatively one places known concentrations of some radical precursor eg a CFC or some other XCl species and ozone into a reaction vessel One then uses for example a very short light pulse whose photons frequencies are tuned to a transition that will cause the XCl precursor to undergo rapid photodissociation hnu XCl rightarrow X Cltag Because the pump light source used to prepare the radicals is of very short duration and because the XCl dissociation is prompt one knows to within the time at which the Cl radicals begin to react with the ozone The initial concentration of the radicals can be known if the quantum yield for the hnu XCl rightarrow X Cl reaction is known This means that the intensity of photons the probability of photon absorption by XCl and the fraction of excited XCl molecules that dissociate to produce must be known Such information is available albeit from rather tedious earlier studies for a variety of XCl precursors So knowing the time at which the radicals are formed and their initial concentrations one then allows the reaction to proceed for some time duration One then at uses a second light source to probe either the concentration of the the or the to determine the extent of progress of the reaction Which species is so monitored depends on the availability of light sources whose frequencies these species absorb Such probe experiments are carried out at a series of time delays the result of which is the determination of the concentrations of some product or reactant species at various times after the initial pump event created the reactive radicals In this way one can monitor for example the concentration as a function of time after the begins to react with the If one has reason to believe that the reaction occurs in a single bimolecular event as one can then extract the rate constant k for the reaction by using the following kinetic scheme If the initial concentration of is large compared to the amount of that is formed in the pump event can be taken as constant and known If the initial concentration of is denoted and the concentration of is called this kinetic equation reduces to the solution of which is So knowing the concentration as a function of time delay and knowing the initial ozone concentration as well as the initial radical concentration one can find the rate constant Such pumpprobe experiments are necessary when one wants to study species that must be generated and allowed to react immediately This is essentially always the case when one or more of the reactants is a highly reactive species such as a radical There is another kind of experiment that can be used to probe very fast reactions if the reaction and its reverse reaction can be brought into equilibrium to the extent that reactants and products both exist in measurable concentrations For example consider the reaction of an enzyme E and a substrate S to form the enzymesubstrate complex ES At equilibrium the forward rate k_f E_eq S_eq tag and the reverse rate are equal k_f E_eq S_eq k_r ES_eq tag The idea behind so called perturbation techniques is to begin with a reaction that is in such an equilibrium condition and to then use some external means to slightly perturb the equilibrium Because both the forward and reverse rates are assumed to be very fast it is essential to use a perturbation that can alter the concentrations very quickly This usually precludes simply adding a small amount of one or more of the reacting species to the reaction vessel Instead one might employ for example a fast light source or electric field pulse to perturb the equilibrium to one side or the other For example if the reaction thermochemistry is known the equilibrium constant can be changed by rapidly heating the sample eg with a fast laser pulse that is absorbed and rapidly heats the sample and using to calculate the change in and thus the changes in concentrations caused by the sudden heating Alternatively if the polarity of the reactants and products is substantially different one may use a rapidly applied electric field to quickly change the concentrations of the reactant and product species In such experiments the concentrations of the species is shifted by a small amount as a result of the application of the perturbation so that ES ES_eq delta tag once the perturbation has been applied and then turned off Subsequently the following rate law will govern the time evolution of the concentration change d Assuming that is very small so that the term involving cam be neglected and using the fact that the forward and reverse rates balance at equilibrium this equation for the time evolution of can be reduced to So the concentration deviations from equilibrium will return to equilibrium ie will decay to zero exponentially with an effective rate coefficient that is equal to a sum of terms involving both the forward and reverse rate constants So by quickly perturbing an equilibrium reaction mixture for a short period of time and subsequently following the concentrations of the reactants or products as they return to their equilibrium values one can extract the effective rate coefficient Doing this at a variety of different initial equilibrium concentrations eg and and seeing how changes one can then determine both the forward and reverse rate constants Both the pumpprobe and the perturbation methods require that one be able to quickly create or perturb concentrations of reactive species and that one have available an experimental probe that allows one to follow the concentrations of at least some of the species as time evolves Clearly for very fast reactions this means that one must use experimental tools that can respond on a very short time scale Modern laser technology and molecular beam methods have provided some of the most widely used of such tools These experimental approaches are discussed in some detail in Chapter Theoretical Simulation of Chemical Change The most common theoretical approach to simulating a chemical reaction is to use Newtonian dynamics to follow the motion of the nuclei on a BornOppenheimer electronic energy surface If the molecule of interest contains few atoms such a surface could be computed using the methods discussed in Chapter at a large number of molecular geometries and then fit to an analytical function of the or variables denoted Knowing as a function of these variables one can then compute the forces F_J dfracpartialEpartialq_J tag along each coordinate and then use the Newton equations to follow the time evolution of these coordinates and hence the progress of the reaction The values of the coordinates at a series of discrete times constitute what is called a classical trajectory To simulate a chemical reaction one begins the trajectory with initial coordinates characteristic of the reactant species ie within one of the valleys on the reactant side of the potential surface and one follows the trajectory long enough to determine whether the collision results in a nonreactive outcome characterized by final coordinates describing reactant not product molecules or a reactive outcome that is recognized by the final coordinates describing product molecules rather than reactants One must do so for a large number of trajectories whose initial coordinates and moment are representative of the experimental conditions one is attempting to simulate Then one has to average the outcomes of these trajectories over this ensemble of initial conditions More about how one carries out such ensemble averaging is discussed in Chapters and If the molecule contains more than or atoms it is more common to not compute the BornOppenheimer energy at a set of geometries and then fit this data to an analytical form Instead one begins a trajectory at some initial coordinates and with some initial momenta and then uses the Newton equations usually in the finitedifference form q_J q_J dfracp_Jm_J dt tag to propagate the coordinates and momenta forward in time by a small amount Here denotes the gradient of the BO energy computed at the values of the coordinates The above propagation procedure is then used again but with the values of and appropriate to time as new initial coordinates and momenta to generate yet another set of and values In such direct dynamics approaches the energy gradients which produce the forces are computed only at geometries that the classical trajectory encounters along its time propagation In the earlier procedure in which the BO energy is fit to an analytical form one often computes at geometries that the trajectory never accesses In carrying out such a classical trajectory simulation of a chemical reaction there are other issues that must be addressed In particular as mentioned above one can essentially never use any single trajectory to simulate a reaction carried out in a laboratory setting One must perform a series of such trajectory calculations with a variety of different initial coordinates and momenta chosen in a manner to represent the experimental conditions of interest For example suppose one were to wish to model a molecular beam experiment in which a beam of species having a well defined kinetic energy collides with a beam of species having kinetic energy as shown in Figure Figure Crossed beam experiment in which and molecules collide in a reaction vessel Even though the and molecules all collide at right angles and with specified kinetic energies and thus specified initial momenta not all of these collisions occur head on Figure illustrates this point Figure Two A B collisions In the first the and have a small distance of closest approach in the second this distance is larger Here we show two collisions between an and a molecule both of which have identical and velocities and respectively What differs in the two events is their distance of closest approach In the collision shown on the left the and come together closely However in the left collision the A molecule is moving away from the region where would strike it before has reached it These two cases can be viewed from a different perspective that helps to clarify their differences In Figure we illustrate these two collisions viewed from a frame of reference located on the molecule Figure Same two close and distant collisions viewed from sitting on and in the case of no attractive or repulsive interactions In this figure we show the location of the molecule relative to at a series of times showing moving from right to left In the figure on the left the molecule clearly undergoes a closer collision than is the case on the right The distance of closest approach in each case is called the impact parameter and it represents the distance of closest approach if the colliding partners did not experience any attractive or repulsive interactions as the above figures would be consistent with Of course when and have forces acting between them the trajectories shown above would be modified to look more like those shown in Figure Figure Same two close and distant collisions viewed from sitting on A now in the case of repulsive interactions In both of these trajectories repulsive intermolecular forces cause the trajectory to move away from its initial path which defines the respective impact parameters So even in this molecular beam example in which both colliding molecules have well specified velocities one must carry out a number of classical trajectories each with a different impact parameter b to simulate the laboratory event In practice the impact parameters can be chosen to range from ie a head on collision to some maximum value beyond which the and molecules no longer interact and thus can no longer undergo reaction Each trajectory is followed long enough to determine whether it leads to geometries characteristic of the product molecules The fraction of such trajectories weighted by the volume element for trajectories with impact parameters in the range between and then gives the averaged fraction of trajectories that react In most simulations of chemical reactions there are more initial conditions that also must sampled ie trajectories with a variety of initial variables must be followed and properly weighted For example if there is a range of velocities for the reactants andor one must follow trajectories with velocities in this range and weigh the outcomes ie reaction or not of such trajectories appropriately eg with a MaxwellBoltzmann weighting factor and if the reactant molecules have internal bond lengths angles and orientations one must follow trajectories with different initial values of these variables and properly weigh each such trajectory eg using the vibrational states coordinate probability distribution as a weighting factor for the initial values of that coordinate As a result to properly simulate a laboratory experiment of a chemical reaction it usually requires one to follow a very large number of classical trajectories Fortunately such a task is well suited to distributed parallel computing so it is currently feasible to do so even for rather complex reactions There is a situation in which the above classical trajectory approach can be foolish to pursue even if there is reason to believe that a classical Newton description of the nuclear motions is adequate This occurs when one has a rather high barrier to surmount to evolve from reactants to products and when the fraction of trajectories whose initial conditions permit this barrier to be accessed is very small In such cases one is faced with the reactive trajectories being very rare among the full ensemble of trajectories needed to properly simulate the laboratory experiment Certainly one can apply the trajectoryfollowing technique outlined above but if one observes for example that only one trajectory in produces a reaction one may not have adequate statistics to determine the reaction probability One could subsequently run trajectories chosen again to represent the same experiment and see whether or or of these trajectories react thereby increasing the precision of your reaction probability However it may be computationally impractical to perform times as many trajectories to achieve better accuracy in the reaction probability When faced with such rareevent situations one is usually better off using an approach that breaks the problem of determining what fraction of the properly weighted initial conditions produce reaction into two parts among all of the properly weighted initial conditions what fraction can access the highenergy barrier and of those that do access the high barrier how may react This way of formulating the reaction probability question leads to the transition state theory TST method that is treated in detail in Chapter along with some of its more common variants Briefly the answer to the first question posed above involves computing the quasiequilibrium fraction of reacting species that reach the barrier region in terms of the partition functions of statistical mechanics This step becomes practical if the chemical reactants can be assumed to be in some form of thermal equilibrium which is where these kinds of models are useful In the simplest form of TST the answer to the second question posed above is taken to be all trajectories that reach the barrier react In more sophisticated variants other models are introduced to take into consideration that not all trajectories that cross over the barrier indeed proceed onward to products and that some trajectories may tunnel through the barrier near its top I will leave further discussion of the TST to Chapter In addition to the classical trajectory and TST approaches to simulating chemical reactions there are more quantum approaches These techniques should be used when the nuclei involved in the reaction include hydrogen or deuterium nuclei A discussion of the details involved in quantum propagation is beyond the level of this Chapter so I will delay it until Chapter Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Chemical Equilibrium and Predicting Chemical Change Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers When we talk about predicting chemical reactions we imagine taking quantities of various pure compounds and mixing them under some set of conditions We suppose that they react until they reach a position of equilibrium in which one or more new compounds are present We want to predict what these new compounds are and how much of each will be produced For any given set of reactants we can accomplish this predictive program in two steps First we find all of the sets of products that can be obtained from the given reactants Each such set represents a possible reaction We suppose that for each set of possible products we are able to predict the equilibrium composition Predicting which reaction will occur is equivalent to finding the reaction whose position of equilibrium lies farthest in the direction of its products From this perspective being able to predict the position of equilibrium for the reactants and any stoichiometrically consistent set of products is the same thing as being able to predict what reaction will occur If there is no single reaction whose position of equilibrium is much further in the direction of its products than that of any other reaction multiple reactions can occur simultaneously This twostep procedure corresponds to the sense in which chemical thermodynamics enables us to predict reaction products We measure values for certain characteristic thermodynamic functions for all relevant compounds Given the values of these functions for all of the compounds involved in a hypothesized reaction we calculate the position of equilibrium That we must begin by guessing the products makes this approach cumbersome and uncertain We can never be positive that the true products are among the possibilities that we consider Nevertheless as a practical matter for most combinations of reactants the number of plausible product sets is reasonably small Chemical Equilibrium as the Equality of Rates for Opposing Reactions Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics Pure Phases Suppose that the bimolecular reaction occurs as an elementary process From our conclusions about the concentration dependencies of elementary reactions the rate of the net reaction is at any time In particular this rate equation must remain true at arbitrarily long timestimes at which the reaction has reached equilibrium and at which Therefore at equilibrium we have where the concentrationterm subscripts serve to emphasize that the concentration values correspond to the reaction being in a state of equilibrium We see that the ratio of rate constants characterizes the equilibrium state This constant is so useful we give it a separate name and symbol the equilibrium constant Now let us consider the possibility that the reaction is not an elementary process but instead proceeds by a twostep mechanism involving an intermediate The sum of these elementary processes yields the same overall reaction as before This mechanism implies the following differential equations At equilibrium both and must be constant so both differential equations must be equal to zero Hence at equilibrium Multiplying these we have The concentration dependence of the equilibrium constant for the twostep mechanism Equation refeqB is the same as for case that the reaction is an elementary process Equation refeqB As far as the description of the equilibrium system is concerned the only difference is that the equilibrium constant is interpreted as a function of different rate constants Equation refeqA vs Equation refeqA For the general reaction we see that any sequence of elementary reactions will give rise to the same concentration expression for the equilibrium system Whatever the mechanism reactant must appear times more often on the left side of elementary reactions than it does on the right Product must appear times more often on the right side of elementary reactions than it does on the left Any intermediates must appear an equal number of times on the left and on the right in the various elementary reactions As a result when we form the ratio of forward to reverse rate constants for each of the elementary reactions and multiply them the concentration of reactant must appear in the product to the power the concentration of product must appear to the power and the concentrations of the intermediates must all cancel out We conclude that the condition for equilibrium in the general case is where we drop the subscripts trusting ourselves to remember that the equation is valid only when the concentration terms apply to the equilibrated system Pure Phases When the reaction involves a pure phase as a reactant or product we observe experimentally that the amount of the pure phase present in the reaction mixture does NOT affect the position of equilibrium The composition of the reaction solution is the same so long as the solution is in contact with a finite amount of the pure phase This means that we can omit the concentration of the substance that makes up the pure phase when we write the equilibriumconstant expression In writing the equilibrium constant expression we can take the concentration the substance to be an arbitrary constant Unity is usually the most convenient choice for this constant To rationalize this experimental observation within our kinetic model for equilibrium we postulate that the rate at which molecules leave the pure phase is proportional to the area of the phase that is in contact with the reaction solution that is We postulate that the rate at which molecules return to the pure phase from the reaction solution is proportional to both the area and the concentration of the substance in the reaction solution If the pure phase consists of substance we have At equilibrium we have so that and Chemical Kinetics Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Chemical kinetics is the study of how fast chemical reactions occur In Chapter we see that there is a unique way to specify what we mean by how fast We call this specification the reaction rate Chemical kinetics is the study of the factors that determine the rate of a particular reaction There are many such factors among them temperature pressure concentrations of the reactants and products nature and concentrations of spectator species like a solvent or dissolved salts isotopic substitution presence or absence of a catalyst We will look briefly at all of these but the thrust of our development will be to understand how the rate of a reaction depends on the concentrations of the reactions reactants and products Many reactions that we observe actually occur as a sequence of more simple reactions Such a sequence of simple reaction steps is called a reaction mechanism Our principal goal is to understand the relationships among concentrations reaction rates reaction mechanisms and the conditions that must be satisfied when a particular reaction reaches equilibrium We will find that two related ideas characterize equilibrium from a reactionrate perspective One is that concentrations no longer change with time The other is a fundamental postulate called the principle of microscopic reversibility about the relative rates of individual steps in an overall chemical reaction mechanism when the reacting system is at equilibrium Chemical Potential Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors and Attributions Equilibrium can be understood as accruing at the composition of a reaction mixture at which the aggregate chemical potential of the products is equal to that of the reactants Consider the simple reaction The criterion for equilibrium will be If the gases behave ideally the chemical potentials can be described in terms of the mole fractions of and where Daltons Law has been used to express the mole fractions Equation refeq can be simplified by collecting all chemical potentials terms on the left mu_Ao mu_Bo RT ln left dfracp_Bp_tot right RT lnleft dfracp_Ap_tot right labeleq Combining the logarithms terms and recognizing that mu_Ao mu_Bo Delta Go for the reaction one obtains And since for this reaction assuming perfectly ideal behavior one can write Another way to achieve this result is to consider the Gibbs function change for a reaction mixture in terms of the reaction quotient The reaction quotient can be expressed as where are the stoichiometric coefficients for the products and are those for the reactants Or if the stoichiometric coefficients are defined by expressing the reaction as a sum where refers to one of the species in the reaction and is then the stoichiometric coefficient for that species it is clear that will be negative for a reactant since its concentration or partial pressure will reduce as the reaction moves forward and positive for a product since the concentration or partial pressure will be increasing If the stoichiometric coefficients are expressed in this way the expression for the reaction quotient becomes Using this expression the Gibbs function change for the system can be calculated from And since at equilibrium and It is evident that It is in this simple way that and are related It is also of value to note that the criterion for a spontaneous chemical process is that rather than as is stated in many texts Recall that is a function of all of the reactants and products being in their standard states of unit fugacity or activity However the direction of spontaneous change for a chemical reaction is dependent on the composition of the reaction mixture Similarly the magnitude of the equilibrium constant is insufficient to determine whether a reaction will spontaneously form reactants or products as the direction the reaction will shift is also a function of not just the equilibrium constant but also the composition of the reaction mixture Example Based on the data below at K calculate the value of the equilibrium constant for the reaction kJmol Solution First calculate the value of from the data And now use the value to calculate using Equation reftriangle Note as expected for a reaction with a very large negative the equilibrium constant is very large favoring the formation of the products Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Classical Thermodynamics Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers One goal of chemical thermodynamics is to predict whether a particular chemical reaction can occur We say can not will because chemical thermodynamics is unable to make predictions about reaction rates If we learn from our study of chemical thermodynamics that a particular reaction can occur we still do not know whether it will occur in a millisecondor so slowly that no change is detectable The science of thermodynamics builds on the idea that a particular chemical system can be characterized by the values of certain thermodynamic functions These state functions include such familiar quantities as pressure temperature volume concentrations and energy as well as some that are not so well known notably enthalpy entropy Gibbs free energy Helmholtz free energy chemical potential fugacity and chemical activity We can think of a state function as a quasimathematical function whose argument is a physical system That is a state function maps a real system onto a real number When we insert a thermometer into a mixture the measurement that we make maps the state of the mixture onto the real number that we call temperature The word thermodynamics joins roots that convey the ideas of heat and motion In general motion involves kinetic energy and mechanical work The interconversion of heat and mechanical work is the core concern of the science of thermodynamics We are familiar with the idea that kinetic energy can be converted into work given a suitable arrangement of ropes and pulleys a falling object can be used to lift another object Kinetic energy can also be convertedor as we often say degradedinto heat by the effects of friction We view such processes as the conversion of the kinetic energy of a large object into increased kinetic energy of the atoms and molecules that comprise the warmed objects We can say that easily visible mechanical motions are converted into invisible mechanical motions The idea that heating an object increases the kinetic energy of its component atoms is called the kinetic theory of heat It is often convenient to use the term microscopic process to refer to an event that occurs at the atomic or molecular level We call a process that occurs on a larger scale a macroscopic process although the usual connotation is that a macroscopic process is observable in a quantity of bulk matter When friction causes the degradation of macroscopic motion to heat we can say that macroscopic motion is converted to microscopic motion While this terminology is convenient it is not very precise Changes visible under an optical microscope are macroscopic processes Of course all macroscopic changes are ultimately attributable to an accumulation of molecularlevel processes The Brownian motion of a colloidal particle suspended in a liquid medium is noteworthy because this relationship is visible Viewed with an optical microscope a suspended macroscopic colloidal particle is seen to undergo a rapid and random jiggling motion Each jiggle is the accumulated effect of otherwise invisible collisions between the particle and the molecules of the liquid Each collision imparts momentum to the particle Over long times the effects average out momentum transfer is approximately equal in every direction During the short time of a given jiggle there is an imbalance of collisions such that more momentum is transferred to the particle in the direction of the jiggle than in any other We are also familiar with the idea that heat can be converted into mechanical motion In an earlier era steam engines were the dominant means by which heat was converted to work Steam turbines remain important in large stationary facilities like power plants For applications we encounter in daily life the steam engine has been replaced by the internalcombustion engine When we want to create mechanical motion do work with a heat engine it is important to know how much heat we need in order to produce a given quantity of work Sadi Carnot was the first to analyze this problem theoretically In doing so he discovered the idea that we call the second law of thermodynamics The interconversion of heat and work involves an important asymmetry We readily appreciate that the conversion of kinetic energy to heat can be complete because we have seen countless examples of objects coming to a complete standstill as the result of frictional forces However ordinary experience leaves us less prepared to deal with the question of whether heat can be completely converted into work Possibly we remember hearing that it cannot be done and that the reason has something to do with the second law of thermodynamics If we have heard more of the story we may remember that it is slightly more complicated Under idealized circumstances heat can be converted into work completely If we confine an ideal gas in a frictionless piston and arrange to add heat to the gas while increasing the volume of the piston in a coordinated way such that the temperature of the gas remains constant the expanding piston will do work on some external entity and the amount of this work will be just equal to the thermal energy added to the gas We call this process a reversible isothermal expansion This process does not involve a cycle the volume of the gas at the end of the process is greater than its volume at the start What Carnot realized is that an engine must operate in a cyclic fashion and that no devicenot even an idealized frictionless deviceoperating around a cycle can convert heat to work with efficiency Carnot analyzed the process of converting heat into work in terms of an ideal engine that accepts thermal energy heat at a high temperature uses some of this thermal energy to do work on its surroundings and rejects the rest of its thermalenergy intake to the surroundings in the form of thermal energy at a lower temperature Carnots analysis preceded the development of our current ideas about the nature of thermal energy He expressed his ideas using a nowabandoned theory of heat In this theory heat is considered to be a fluidlike quantitycalled caloric Transfers of heat comprise the flow of caloric from one object to another Carnots ideas originated as an analogy between the flow of caloric through a steam engine and the flow of water through a water wheel In this view the temperature of the steam entering and leaving the engine is analogous to the altitude of the water entering and leaving the wheel Such considerations are obviously relevant if we are interested in building engines but we are interested in chemical reactivity How does chemical change relate to engines and the conversion of heat into work Well rather directly actually after all a chemical reaction usually liberates or absorbs heat If we can relate mechanical work to heat and we can relate the amount of heat liberated to the extent of a chemical reaction then we can imagine allowing the reaction to go to equilibrium in a machine that converts heat to work We can expect that the amount of work produced will have some relationship to the extent of the reaction The nature of this relationship is obscure at this point but we can reasonably expect that one exists Collections of Molecules at or Near Equilibrium Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah The Distribution of Energy Among LevelsBasis of the Boltzmann Population FormulaEqual a priori Probability AssumptionLagrange Multiplier MethodThe Thermodynamic LimitFluctuationsPartition Functions and Thermodynamic PropertiesSystem Partition FunctionsIndividualMolecule Partition FunctionsTranslationalRotationalVibrationalElectronicEquilibrium Constants in Terms of Partition FunctionsContributors and Attributions As introduced in Chapter the approach one takes in studying a system composed of a very large number of molecules at or near thermal equilibrium can be quite different from how one studies systems containing a few isolated molecules In principle it is possible to conceive of computing the quantum energy levels and wave functions of a collection of many molecules eg ten ions ten ions and molecules in a volume chosen to simulate a concentration of molar but doing so becomes impractical once the number of atoms in the system reaches a few thousand or if the molecules have significant intermolecular interactions as they do in condensedphase systems Also as noted in Chapter following the time evolution of such a large number of molecules can be confusing if one focuses on the shorttime behavior of any single molecule eg one sees jerky changes in its energy momentum and angular momentum By examining instead the longtime average behavior of each molecule or alternatively the average properties of a significantly large number of molecules one is often better able to understand interpret and simulate such condensedmedia systems Moreover most experiments do not probe such shorttime dynamical properties of single molecules instead their signals report on the behavior of many molecules lying within the range of their detection device eg laser beam STM tip or electrode It is when one want to describe the behavior of collections of molecules under such conditions that the power of statistical mechanics comes into play The Distribution of Energy Among Levels One of the most important concepts of statistical mechanics involves how a specified total amount of energy can be shared among a collection of molecules and within the internal rotational vibrational electronic and intermolecular translational degrees of freedom of these molecules when the molecules have a means for sharing or redistributing this energy eg by collisions The primary outcome of asking what is the most probable distribution of energy among a large number of molecules within a container of volume that is maintained in equilibrium by such energysharing at a specified temperature is the most important equation in statistical mechanics the Boltzmann population formula This equation expresses the probability of finding the system which in the case introduced above is the whole collection of interacting molecules in its quantum state where is the energy of this quantum state is the temperature in K is the degeneracy of the state and the denominator is the socalled partition function The classical mechanical equivalent of the above quantum Boltzmann population formula for a system with a total of coordinates collectively denoted they would be the internal and intermolecular coordinates of the molecules in the system and momenta denoted is where is the classical Hamiltonian is Plancks constant and the classical partition function is This probability density expression which must integrate to unity contains the factor of because as we saw in Chapter when we learned about classical action the integral of a coordinatemomentum product has units of Plancks constant Notice that the Boltzmann formula does not say that only those states of one particular energy can be populated it gives nonzero probabilities for populating all states from the lowest to the highest However it does say that states of higher energy are disfavored by the factor but if states of higher energy have larger degeneracies which they usually do the overall population of such states may not be low That is there is a competition between state degeneracy which tends to grow as the states energy grows and which decreases with increasing energy If the number of particles is huge the degeneracy grows as a high power lets denote this power as of because the degeneracy is related to the number of ways the energy can be distributed among the molecules In fact grows at least as fast as As a result of growing as the product function has the form shown in Fig for for illustrative purposes Figure Probability Weighting Factor as a Function of for By taking the derivative of this function with respect to E and finding the energy at which this derivative vanishes one can show that this probability function has a peak at and that at this energy value By then asking at what energy the function drops to of this maximum value one finds So the width of the graph measured as the change in energy needed to cause to drop to of its maximum value divided by the value of the energy at which assumes this maximum value is This width gets smaller and smaller as increases The primary conclusion is that as the number of molecules in the sample grows which as discussed earlier causes to grow the energy probability function becomes more and more sharply peaked about the most probable energy This in turn suggests that we may be able to model aside from infrequent fluctuations which we may also find a way to take account of the behavior of systems with many molecules by focusing on the most probable situation ie those having the energy and ignoring or making small corrections for deviations from this case It is for the reasons just shown that for macroscopic systems near equilibrium in which and hence is extremely large eg to only the most probable distribution of the total energy among the molecules need be considered This is the situation in which the equations of statistical mechanics are so useful Certainly there are fluctuations as evidenced by the finite width of the above graph in the energy content of the molecule system about its most probable value However these fluctuations become less and less important as the system size ie becomes larger and larger Basis of the Boltzmann Population Formula To understand how this narrow Boltzmann distribution of energies arises when the number of molecules in the sample is large we consider a system composed of identical containers each having volume V and each made out a material that allows for efficient heat transfer to its surroundings eg through collisions of the molecules inside the volume with the walls of the container but material that does not allow any of the molecules in each container to escape These containers are arranged into a regular lattice as shown in Figure in a manner that allows their thermally conducting walls to come into contact Finally the entire collection of such containers is surrounded by a perfectly insulating material that assures that the total energy of all molecules can not change So this collection of identical containers each containing molecules constitutes a closed ie with no molecules coming or going and isolated ie so total energy is constant system Figure Collection of identical cells having energyconducting walls that do not allow molecules to pass between cells Equal a priori Probability Assumption One of the fundamental assumptions of statistical mechanics is that for a closed isolated system at equilibrium all quantum states of the system having energy equal to the energy with which the system is prepared are equally likely to be occupied This is called the assumption of equal a priori probability for such energyallowed quantum states The quantum states relevant to this case are not the states of individual molecules nor are they the states of of the molecules in one of the containers of volume They are the quantum states of the entire system comprised of molecules Because our system consists of identical containers each with molecules in it we can describe the quantum states of the entire system in terms of the quantum states of each such container It may seem foolish to be discussing quantum states of the large system containing molecules given what I said earlier about the futility in trying to find such states However what I am doing at this stage is to carry out a derivation that is based upon such quantum states but whose final form and final working equations will not actually require one to know or even be able to have these states in hand Lets pretend that we know the quantum states that pertain to molecules in a container of volume as shown in Figure and lets label these states by an index That is labels the lowestenergy state of molecules in the container of volume labels the second such state and so on As I said above I understand it may seem daunting to think of how one actually finds these molecule eigenstates However we are just deriving a general framework that gives the probabilities of being in each such state In so doing we are allowed to pretend that we know these states In any actual application we will of course have to use approximate expressions for such energies Assuming that the walls that divide the containers play no role except to allow for collisional ie thermal energy transfer among the containers an energylabeling for states of the entire collection of containers can be realized by giving the number of containers that exist in each singlecontainer Jstate This is possible because under the assumption about the role of the walls just stated the energy of each container state is a sum of the energies of the singlecontainer states that comprise that container state For example if the label specifies the energy of this container state in terms of the energies of the states of the containers Notice that this container state has the same energy as several other container states for example and have the same energy although they are different individual states What differs among these distinct states is which box occupies which singlebox quantum state The above example illustrates that an energy level of the container system can have a high degree of degeneracy because its total energy can be achieved by having the various singlecontainer states appear in various orders That is which container is in which state can be permuted without altering the total energy The formula for how many ways the container states can be permuted such that there are containers appearing in singlecontainer state with a total of containers is Here denote the number of containers existing in singlecontainer states This combinatorial formula reflects the permutational degeneracy arising from placing containers into state containers into state etc If we imagine an extremely large number of containers and we view as well as the as being large numbers nb we will soon see that this is the case at least for the most probable distribution that we will eventually focus on we can ask for what choices of the variables is this degeneracy function a maximum Moreover we can examine at its maximum and compare its value at values of the parameters changed only slightly from the values that maximized As we will see is very strongly peaked at its maximum and decreases extremely rapidly for values of that differ only slightly from the optimal values It is this property that gives rise to the very narrow energy distribution discussed earlier in this Chapter So lets take a closer look at how this energy distribution formula arises We want to know what values of the variables make a maximum However all of the variables are not independent they must add up to the total number of containers so we have a constraint that the variables must obey The variables are also constrained to give the total energy of the container system when summed as We have two problems i how to maximize and ii how to impose these constraints Because takes on values greater than unity for any choice of the will experience its maximum where has its maximum so we can maximize if doing so helps Because the variables are assumed to take on large numbers when is large we can use Sterlings approximation for the natural logarithm of the factorial of a large number to approximate as follows This expression will prove useful because we can take its derivative with respect to the variables which we need to do to search for the maximum of To impose the constraints and we use the technique of Lagrange multipliers That is we seek to find values of that maximize the following function Notice that this function is exactly equal to the function we wish to maximize whenever the variables obey the two constraints So the maxima of and of are identical if the have values that obey the constraints The two Lagrange multipliers and are introduced to allow the values of that maximize to ultimately obey the two constraints That is we first find values of the variables that make maximum these values will depend on and and will not necessarily obey the constraints However we will then choose and to assure that the two constraints are obeyed This is how the Lagrange multiplier method works Lagrange Multiplier Method Taking the derivative of with respect to each independent variable and setting this derivative equal to zero gives This equation can be solved to give Substituting this result into the first constraint equation gives which allows us to solve for in terms of Doing so and substituting the result into the expression for gives where Notice that the are as we assumed earlier large numbers if is large because is proportional to Notice also that we now see the appearance of the partition function and of exponential dependence on the energy of the state that gives the Boltzmann population of that state It is possible to relate the Lagrange multiplier to the total energy of the containers by summing the number of containers in the Kth quantum state multiplied by the energy of that quantum state This shows that the average energy of a container computed as the total energy divided by the number of such containers can be computed as a derivative of the logarithm of the partition function As we show in the following Section of this Chapter all thermodynamic properties of the molecules in the container of volume can be obtained as derivatives of the natural logarithm of this function This is why the partition function plays such a central role in statistical mechanics To examine the range of energies over which each of the singlecontainer system varies with appreciable probability let us consider not just the degeneracy of that set of variables that makes maximum but also the degeneracy for values of differing by small amounts from the optimal values Expanding as a Taylor series in the parameters and evaluating the expansion in the neighborhood of the values we find We know that all of the first derivative terms vanish because has been made maximum at To evaluate the second derivative terms we first note that the first derivative of is So the second derivatives needed to complete the Taylor series through second order are Using this result we can expand in the neighborhood of in powers of as follows or equivalently This result clearly shows that the degeneracy and hence by the equal a priori probability hypothesis the probability of the container system occupying a state having falls off exponentially as the variables move away from their mostprobable values The Thermodynamic Limit As we noted earlier the are proportional to ie so when considering deviations away from the optimal we should consider deviations that are also proportional to In this way we are treating deviations of specified percentage or fractional amount which we denote Thus the ratio that appears in the above exponential has an Mdependence that allows to be written as where and are the fraction and fractional deviation of containers in state and The purpose of writing in this manner is to explicitly show that in the socalled thermodynamic limit when approaches infinity only the most probable distribution of energy need to be considered because only is important as approaches infinity Fluctuations Lets consider this very narrow distribution issue a bit further by examining fluctuations in the energy of a single container around its average energy We already know that the number of containers in a given state can be written as Alternatively we can say that the probability of a container occupying the state is Using this probability we can compute the average energy as To compute the fluctuation in energy we first note that the fluctuation is defined as the average of the square of the deviation in energy from the average The following identity is now useful for further reexpressing the fluctuations Recognizing the first factor immediately above as and the second factor as and noting that allows the fluctuation formula to be rewritten as Because the parameter can be shown to be related to the Kelvin temperature as the above expression can be rewritten as Recognizing the formula for the constantvolume heat capacity allows the fractional fluctuation in the energy around the mean energy to be expressed as What does this fractional fluctuation formula tell us On its lefthand side it gives a measure of the fractional spread of energies over which each of the containers ranges about its mean energy On the right side it contains a ratio of two quantities that are extensive properties the heat capacity and the mean energy That is both and will be proportional to the number of molecules in the container as long as is reasonably large However because the righthand side involves it is proportional to and thus will be very small for large as long as does not become large As a result except near socalled critical points where the heat capacity does indeed become extremely large the fractional fluctuation in the energy of a given container of molecules will be very small ie proportional to This finding is related to the narrow distribution in energies that we discussed earlier in this section Lets look at the expression in a bit more detail for a system that is small but still contains quite a few particlesa cluster of Ar atoms at temperature If we assume that each of the Ar atoms in the cluster has of kinetic energy and that the potential energy holding the cluster together is small and constant so it cancels in will be and will be So In a nanodroplet of diameter  with each Ar atom occupying a volume of ca there will be ca Ar atoms So the average fractional spread in the energy That is even for a very small nanodroplet the fluctuation in the energy of the system is only a fraction of a percent assuming is not large as near a critical point This example shows why it is often possible to use thermodynamic concepts and equations even for very small systems albeit realizing that fluctuations away from the most probable state are more important than in much larger systems Partition Functions and Thermodynamic Properties Let us now examine how this idea of the most probable energy distribution being dominant gives rise to equations that offer molecularlevel expressions for other thermodynamic properties The first equation is the fundamental Boltzmann population formula that we already examined which expresses the probability for finding the molecule system in its quantum state having energy Sometimes this expression is written as where now the index is used to label an energy level of the system having energy and degeneracy It is important for the student to be used to either notation a level is just a collection of those states having identical energy System Partition Functions Using this result it is possible to compute the average energy sometimes written as of the system and as we saw earlier in this Chapter to show that this quantity can be recast as To review how this proof is carried out we substitute the expressions for and for into the expression for I will use the notation labeling energy levels rather than energy states to allow the student to become used to this By noting that we can then rewrite as And then recalling that we finally obtain All other equilibrium properties can also be expressed in terms of the partition function For example if the average pressure is defined as the pressure of each quantum state defined as how the energy of that state changes if we change the volume of the container by a small amount multiplied by the probability for accessing that quantum state summed over all such states one can show realizing that only not or depend on the volume that If you wonder why the energies should depend on the volume think of the case of gasphase molecules occupying the container of volume V You know that the translational energies of each of these molecules depend on the volume through the particleinabox formula Changing can be accomplished by changing the box length This makes it clear why the energies do indeed depend on the volume Of course there are additional sources of the Vdependence of the energy levels For example as one shrinks the molecules become more crowded so their intermolecular energies also change Without belaboring the point further it is possible to express all of the usual thermodynamic quantities in terms of the partition function The average energy and average pressure are given above as is the heat capacity The average entropy is given as the Helmholtz free energy A is and the chemical potential is expressed as follows As we saw earlier it is also possible to express fluctuations in thermodynamic properties in terms of derivatives of partition functions and thus as derivatives of other properties For example the fluctuation in the energy was shown above to be given by The text Statistical Mechanics D A McQuarrie Harper and Row New York has an excellent treatment of these topics and shows how all of these expressions are derived So if one were able to evaluate the partition function for molecules in a volume at a temperature T either by summing the quantumlevel degeneracy and factors or by carrying out the phasespace integral over all of the coordinates and momenta of the system one could then use the above formulas to evaluate any thermodynamic properties and their fluctuations as derivatives of The averages discussed above derived using the probabilities associated with the most probable distribution are called ensemble averages with the set of states associated with the specified values of and constituting what is called a canonical ensemble Averages derived using the probabilities constant for all states associated with specified values of and are called ensemble averages for a microcanonical ensemble There is another kind of ensemble that is often used in statistical mechanics it is called the grand canonical ensemble and relates to systems with specified volume temperature and chemical potential rather than particle number To obtain the partition function from which all thermodynamic properties are obtained in this case one considers maximizing the same function introduced earlier but now considering each quantum labeled J as having an energy that depends on the volume and on how may particles occupy this volume The variables are now used to specify how many of the containers introduced earlier contain particles and are in the quantum state These variables have to obey the same two constraints as for the canonical ensemble but they also are required to obey which means that the sum adds up to the total number of particles in the isolated systems large container that was divided into M smaller container In this case the walls separating each small container are assumed to allow for energy transfer as in the canonical ensemble and for molecules to move from one container to another unlike the canonical ensemble Using Lagrange multipliers as before to maximize subject to the above three constraints involves maximizing and gives or Imposing the first constraint gives or where the partition function is defined by the sum in the denominator So now the probability of the system having particles and being in the quantum state is Very much as was shown earlier for the canonical ensemble one can then express thermodynamic properties eg etc in terms of derivatives of The text Statistical Mechanics D A McQuarrie Harper and Row New York goes through these derivations in good detail so I will not repeat them here because we showed how to do so when treating the canonical ensemble To summarize them briefly one again uses finds that g is related to the chemical potential as and obtains The formulas look very much like those of the canonical ensemble except for the result expressing the average number of molecules in the container Nave in terms of the derivative of the partition function with respect to the chemical potential In addition to the equal a priori probability postulate stated earlier ie that in the thermodynamic limit ie large every quantum state of an isolated system in equilibrium having fixed and is equally probable statistical mechanics makes another assumption It assumes that in the thermodynamic limit the ensemble average eg using equal probabilities for all states of an isolated system having specified and or using for states of a system having specified and or using for the grand canonical case of any quantity is equal to the longtime average of this quantity ie the value one would obtain by monitoring the dynamical evolution of this quantity over a very long time This second postulate implies that the dynamics of an isolated system spends equal amounts of time in every quantum state that has the specified and this is known as the ergodic hypothesis Lets consider a bit more what the physical meaning or information content of partition functions is Canonical ensemble partition functions represent the thermalaveraged number of quantum states that are accessible to the system at specified values of and This can be seen best by again noting that in the quantum expression the partition function is equal to a sum of the number of quantum states in the jth energy level multiplied by the Boltzmann population factor of that level So is dimensionless and is a measure of how many states the system can access at temperature Another way to think of is suggested by rewriting the Helmholtz free energy definition given above as This identity shows that can be viewed as the Boltzmann population not of a given energy but of a specified amount of free energy For the microcanonical ensemble the probability of occupying each state that has the specified values of and is equal where is the total number of such states In the microcanonical ensemble case plays the role that plays in the canonical ensemble case it gives the number of quantum states accessible to the system IndividualMolecule Partition Functions Keep in mind that the energy levels and degeneracies and discussed so far are those of the full molecule system In the special case for which the interactions among the molecules can be neglected ie in the dilute idealgas limit at least as far as expressing the state energies each of the energies can be written as a sum of the energies of each individual molecule In such a case the above partition function reduces to a product of individualmolecule partition functions where the N factor arises as a degeneracy factor having to do with the permutational indistinguishability of the molecules eg one must not count both with molecule in state and molecule in state and with molecule in state and molecule in state they are the same state and is the partition function of an individual molecule Here is the energy of the lth level of the molecule and is its degeneracy The molecular partition functions in turn can be written as products of translational rotational vibrational and electronic partition functions if the molecular energies can be approximated as sums of such energies Of course these approximations are most appropriate to gasphase molecules whose vibration and rotation states are being described at the lowest level The following equations give explicit expressions for these individual contributions to in the most usual case of a nonlinear polyatomic molecule Translational where is the mass of the molecule and is the volume to which its motion is constrained For molecules constrained to a surface of area the corresponding result is and for molecules constrained to move along a single axis over a length the result is The magnitudes these partition functions can be computed using in amu in Kelvin and or in cm cm or cm as Clearly the magnitude of depends strongly on the number of dimensions the molecule and move around in This is a result of the vast differences in translational state densities in and dimensions recall that we encountered these statedensity issues in Chapter Rotational where and are the three principal moments of inertia of the molecule ie eigenvalues of the moment of inertia tensor is the symmetry number of the molecule defined as the number of ways the molecule can be rotated into a configuration that is indistinguishable from its original configuration For example is for or for for and for The magnitudes of these partition functions can be computed using bond lengths in  and masses in amu and in using Vibrational where is the frequency of the harmonic vibration of the molecule of which there are If one wants to treat the vibrations at a level higher than harmonic this expression can be modified by replacing the harmonic energies by higherlevel expressions Electronic where and are the energies and degeneracies of the electronic state the sum is carried out for those states for which the product is numerically significant ie levels that any significant thermal population It is conventional to define the energy of a molecule or ion with respect to that of its atoms So the first term in the electronic partition function is usually written as we where we is the degeneracy of the ground electronic state and is the energy required to dissociate the molecule into its constituent atoms all in their ground electronic states Notice that the magnitude of the translational partition function is much larger than that of the rotational partition function which in turn is larger than that of the vibrational function Moreover note that the dimensional translational partition function is larger than the dimensional which is larger than the dimensional These orderings are simply reflections of the average number of quantum states that are accessible to the respective degrees of freedom at the temperature which in turn relates to the energy spacings and degeneracies of these states The above partition function and thermodynamic equations form the essence of how statistical mechanics provides the tools for connecting moleculelevel properties such as energy levels and degeneracies which ultimately determine the and the to the macroscopic properties such as etc If one has a system for which the quantum energy levels are not known it may be possible to express all of the thermodynamic properties in terms of the classical partition function if the system could be adequately described by classical dynamics This partition function is computed by evaluating the following classical phasespace integral phase space is the collection of coordinates and conjugate momenta as we discussed in Chapter In this integral one integrates over the internal eg bond lengths and angles orientational and translational coordinates and momenta of the molecules If each molecule has internal coordinates translational coordinates and orientational coordinates the total number of such coordinates per molecule is One can then compute all thermodynamic properties of the system using this in place of the quantum in the equations given above for etc The classical partition functions discussed above are especially useful when substantial intermolecular interactions are present and thus where knowing the quantum energy levels of the molecule system is highly unlikely In such cases the classical Hamiltonian is often written in terms of which contains all of the kinetic energy factors as well as all of the potential energies other than the intermolecular potentials and the intermolecular potential which depends only on a subset of the coordinates For example let us assume that depends only on the relative distances between molecules ie on the translational degrees of freedom which we denote Denoting all of the remaining coordinates as the classical partition function integral can be reexpressed as follows The factor would be the partition function if the Hamiltonian contained no intermolecular interactions The factor arises from the integration over all of the translational coordinates if is absent The other factor contains all the effects of intermolecular interactions and reduces to unity if the potential vanishes If as the example considered here assumes only depends on the positions of the centers of mass of the molecules ie not on molecular orientations or internal geometries the partition function can be written in terms of the molecular translational rotational and vibrational partition functions shown earlier Because all of the equations that relate thermodynamic properties to partition functions contain all such properties will decompose into a sum of two parts one coming from and one coming from The latter contains all the effects of the intermolecular interactions This means that in this classical mechanics case all the thermodynamic equations can be written as an ideal component plus a part that arises from the intermolecular forces Again the Statistical Mechanics text by McQuarrie is a good source for reading more details on these topics Equilibrium Constants in Terms of Partition Functions One of the most important and useful applications of statistical thermodynamics arises in the relation giving the equilibrium constant of a chemical reaction or for a physical transformation eg adsorption of molecules onto a metal surface or sublimation of molecules from a crystal in terms of molecular partition functions Specifically for any chemical or physical equilibrium eg the former could be the equilibrium the latter could be one can relate the equilibrium constant expressed in terms of numbers of molecules per unit volume or per unit area depending on whether species undergo translational motion in or dimensions in terms of the partition functions of these molecules For example in the hypothetical chemical equilibrium the equilibrium constant can be written if the species can be treated as having negligibly weak intermolecular potentials as Here is the partition function for molecules of type confined to volume at temperature As another example consider the isomerization reaction involving the normal N and zwitterionic Z forms of arginine that were discussed in Chapter Here the pertinent equilibrium constant would be So if one can evaluate the partition functions for reactant and product molecules in terms of the translational electronic vibrational and rotational energy levels of these species one can express the equilibrium constant in terms of these moleculelevel properties Notice that the above equilibrium constant expressions equate ratios of species concentrations in numbers of molecules per unit volume to ratios of corresponding partition functions per unit volume Because partition functions are a count of the number of quantum states available to the system ie the average density of quantum states this means that we equate species number densities to quantum state densities when we use the above expressions for the equilibrium constant In other words statistical mechanics produces equilibrium constants related to numbers of molecules ie number densities not molar or molal concentrations Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Colligative Properties Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Freezing Point DepressionBoiling Point ElevationVapor Pressure LoweringOsmotic PressureContributors and Attributions Colligative properties are important properties of solutions as they describe how the properties of the solvent will change as solute or solutes is are added Before discussing these important properties let us first review some definitions Solution a homogeneous mixture Solvent The component of a solution with the largest mole fraction Solute Any component of a solution that is not the solvent Solutions can exist in solid alloys of metals are an example of solidphase solutions liquid or gaseous aerosols are examples of gasphase solutions forms For the most part this discussion will focus on liquidphase solutions Freezing Point Depression In general and as will be discussed in Chapter in more detail a liquid will freeze when As such the freezing point of the solvent in a solution will be affected by anything that changes the chemical potential of the solvent As it turns out the chemical potential of the solvent is reduced by the presence of a solute In a mixture the chemical potential of component can be calculated by And because is always less than or equal to the chemical potential is always reduced by the addition of another component The condition under which the solvent will freeze is where the chemical potential of the liquid is given by Equation refchemp which rearrangement to To evaluate the temperature dependence of the chemical potential it is useful to consider the temperature derivative at constant pressure Recalling that and Equation refbigeq becomes And noting that in the case of the solvent freezing is the enthalpy of the pure solvent in solid form and is the enthalpy of the solvent in the liquid solution So Equation refbigeq then becomes or Separating the variables puts the equation into an integrable form int_ToT dfracDelta H_fusRT dT int d ln chi_A labelint where is the freezing point of the pure solvent and is the temperature at which the solvent will begin to solidify in the solution After integration of Equation refint dfracDelta H_fusR left dfracT dfracTo right ln chi_A labelint This can be simplified further by noting that where is the difference between the freezing temperature of the pure solvent and that of the solvent in the solution Also for small deviations from the pure freezing point can be replaced by the approximate value So the Equation refint becomes dfracDelta H_fusRTo Delta T ln chi_A labelint Further for dilute solutions for which the mole fraction of the solvent is very nearly then where is the mole fraction of the solute After a small bit of rearrangement this results in an expression for freezing point depression of The first factor can be replaced by which is the cryoscopic constant for the solvent gives the magnitude of the reduction of freezing point for the solution Since and are properties of the solvent the freezing point depression property is independent of the solute and is a property based solely on the nature of the solvent Further since was introduced as it represents the sum of the mole fractions of all solutes present in the solution It is important to keep in mind that for a real solution freezing of the solvent changes the composition of the solution by decreasing the mole fraction of the solvent and increasing that of the solute As such the magnitude of will change as the freezing process continually removes solvent from the liquid phase of the solution Boiling Point Elevation The derivation of an expression describing boiling point elevation is similar to that for freezing point depression In short the introduction of a solute into a liquid solvent lowers the chemical potential of the solvent cause it to favor the liquid phase over the vapor phase As sch the temperature must be increased to increase the chemical potential of the solvent in the liquid solution until it is equal to that of the vaporphase solvent The increase in the boiling point can be expressed as where is called the ebullioscopic constant and like the cryoscopic constant is a property of the solvent that is independent of the solute or solutes A very elegant derivation of the form of the models for freezing point depression and boiling point elevation has been shared by F E Schubert Schubert Cryoscopic and ebullioscopic constants are generally tabulated using molality as the unit of solute concentration rather than mole fraction In this form the equation for calculating the magnitude of the freezing point decrease or the boiling point increase is or where is the concentration of the solute in moles per kg of solvent Some values of and are shown in the table below Substance C kg mol C C kg mol C Water Benzene Ethanol CCl Example The boiling point of a solution of g of an unknown compound in g of CCl raises the boiling point to C What is the molar mass of the compound Solution The approach here is to find the number of moles of solute in the solution First find the concentration of the solution Using the number of kg of solvent one finds the number for moles of solute The ratio of mass to moles yields the final answer Vapor Pressure Lowering For much the same reason as the lowering of freezing points and the elevation of boiling points for solvents into which a solute has been introduced the vapor pressure of a volatile solvent will be decreased due to the introduction of a solute The magnitude of this decrease can be quantified by examining the effect the solute has on the chemical potential of the solvent In order to establish equilibrium between the solvent in the solution and the solvent in the vapor phase above the solution the chemical potentials of the two phases must be equal If the solute is not volatile the vapor will be pure so assuming ideal behavior Where is the vapor pressure of the solvent over the solution Similarly for the pure solvent in equilibrium with its vapor where is the standard pressure of atm and is the vapor pressure of the pure solvent Substituting Equation refeq into Equation refeq yields The terms for cancel leaving Subtracting from both side produces which rearranges to Dividing both sides by and then exponentiating yields or This last result is Raoults Law A more formal derivation would use the fugacities of the vapor phases but would look essentially the same Also as in the case of freezing point depression and boiling point elevations this derivation did not rely on the nature of the solute However unlike freezing point depression and boiling point elevation this derivation did not rely on the solute being dilute so the result should apply the entire range of concentrations of the solution Example Consider a mixture of two volatile liquids A and B The vapor pressure of pure A is Torr at some temperature and that of pure B is Torr at the same temperature What is the total vapor pressure above a mixture of these compounds with the mole fraction of B of What is the mole fraction of B in the vapor that is in equilibrium with the liquid mixture Solution Using Raoults Law Equation refRL To get the mole fractions in the gas phase one can use Daltons Law of partial pressures And of course it is also useful to note that the sum of the mole fractions is as it must be Osmotic Pressure Osmosis is a process by which solvent can pass through a semipermeable membrane a membrane through which solvent can pass but not solute from an area of low solute concentration to a region of high solute concentration The osmotic pressure is the pressure that when exerted on the region of high solute concentration will halt the process of osmosis The nature of osmosis and the magnitude of the osmotic pressure can be understood by examining the chemical potential of a pure solvent and that of the solvent in a solution The chemical potential of the solvent in the solution before any extra pressure is applied is given by And since xA the chemical potential is of the solvent in a solution is always lower than that of the pure solvent So to prevent osmosis from occurring something needs to be done to raise the chemical potential of the solvent in the solution This can be accomplished by applying pressure to the solution Specifically the process of osmosis will stop when the chemical potential solvent in the solution is increased to the point of being equal to that of the pure solvent The criterion therefore for osmosis to cease is To solve the problem to determine the magnitude of p the pressure dependence of the chemical potential is needed in addition to understanding the effect the solute has on lowering the chemical potential of the solvent in the solution The magnitude therefore of the increase in chemical potential due to the application of excess pressure p must be equal to the magnitude of the reduction of chemical potential by the reduced mole fraction of the solvent in the solution We already know that the chemical potential of the solvent in the solution is reduced by an amount given by And the increase in chemical potential due to the application of excess pressure is given by The integrals on the right can be evaluated by recognizing where is the molar volume of the substance Combining these expressions results in If the molar volume of the solvent is independent of pressure has a very small value of which is the case for most liquids the term on the right becomes Also for values of very close to So for dilute solutions Or after rearrangement pi dfracchi_B RTV again where is the molar volume of the solvent And finally since is the concentration of the solute for cases where This allows one to write a simplified version of the expression which can be used in the case of very dilute solutions When a pressure exceeding the osmotic pressure is applied to the solution the chemical potential of the solvent in the solution can be made to exceed that of the pure solvent on the other side of the membrane causing reverse osmosis to occur This is a very effective method for example for recovering pure water from a mixture such as a saltwater solution Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Collisions between Gas Molecules Relative Velocity Coordinates Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers The pressure of a gas depends on the frequency with which molecules collide with the wall of their container The rate at which gas molecules escape through a very small opening in their container is called the effusion rate The effusion rate rate also depends on the frequency of collisions with the wall See problem Other gas properties depend not on the rate of collision with the wall but on the rate with which gas molecules collide with one another We turn now to some of these properties For these considerations we need to describe the motion of one molecule relative to another We need the probability density function for the relative velocity of two particles To describe the relative velocity of two particles we introduce relative velocity coordinates Let us begin by considering a Cartesian coordinate frame with and zaxes whose origin is at a point we will use to designate this set of axes We specify the location of particle by the vector and that of particle by We let the location of the center of mass of this twoparticle system be specified by The vector from particle to particle is the vector difference When the particles are moving these vectors and their components are functions of time Using the notation we can specify the velocity of particle for example as Our goal is to find the relative velocity vector We call the components of the relative velocity coordinates Figure The center of mass frame The essential idea underlying relative velocity coordinates is that the vectors and contain the same information as the vectors and This is equivalent to saying that we can transform the locations as specified by and to the same locations as specified by and and vice versa To accomplish this we write the equation defining the component of the center of mass which we rearrange to Corresponding relationships can be written for the and components It proves to be useful to introduce the reduced mass defined by Using the reduced mass we can express the coordinates of the center of mass in terms of the coordinates of the individual particles That is Since by definition we also have we have developed the transformation from and to and The inverse transformation is readily found to be Now we can create two new Cartesian coordinate frames Which of these is more useful depends on the objective of the particular analysis we have at hand We call the first one the center of mass frame It is sketched in Figure The and axes of are parallel to the corresponding axes of but their origin is always at the point occupied by the center of mass of the twoparticle system In this reference frame the coordinates of particles and are their displacements from the center of mass The center of mass frame is particularly useful for analyzing interactions between colliding particles Figure The particleone centered frame For our purposes a third Cartesian coordinate frame which we will denote the frame is more useful It is sketched in Figure The and axes of are parallel to the corresponding axes of but their origin is always at the point occupied by particle In this reference frame the coordinates of particles and are and the coordinates of the center of mass are The frame is sometimes called the center of mass frame also To avoid confusion we call the particleone centered frame In the particleone centered frame particle is stationary at the origin With its tail at the origin the vector specifies the position of particle We are interested in the relative velocity of particles and The velocity components for particles and and for their relative velocity are obtained by finding the timederivatives of the corresponding displacement components Since the transformations of the displacement coordinates are linear the velocity components transform from one reference frame to another in exactly the same way that the displacement components do We have and The vector specifies the velocity of particle relative to a stationary particle Just as and contain the same information as the vectors and the vectors and contain the same information as and Since a parallel displacement leaves a vector unchanged each of these vectors is the same in any of the three reference frames In we find the probability density function for the magnitude of the scalar relative velocity Since the probability is independent of direction the probability that two molecules have relative velocity is the same as that they have relative velocity In spherical coordinates if then The probability and magnitude of the relative velocity are independent of which particleif eitherwe choose to view as being stationary they are independent of whether the particles are approaching or receding from one another Collisions between like Gas Molecules Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers When we consider collisions between different gas molecules of the same substance we can denote the relative velocity and the expected value of the relative velocity as and respectively By the argument we make above we can find the number of collisions between any one of these molecules and all of the others Letting this collision frequency be we find where Since we have while we have The frequency of collisions between molecules of the same substance becomes The mean time between collisions is and the mean free path When we consider the rate of collisions between all of the molecules of type in a container there is a minor complication If we multiply the collision frequency per molecule by the number of molecules available to undergo such collisions we count each collision twice because each such collision involves two type molecules To find the collision rate among like molecules we must divide this product by That is Collisions with Other Molecules Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors and Attributions A major concern in the design of many experiments is collisions of gas molecules with other molecules in the gas phase For example molecular beam experiments are often dependent on a lack of molecular collisions in the beam that could degrade the nature of the molecules in the beam through chemical reactions or simply being knocked out of the beam In order to predict the frequency of molecular collisions it is useful to first define the conditions under which collisions will occur For convenience consider all of the molecules to be spherical and in fixed in position except for one which is allowed to move through a sea of other molecules A molecular collision will occur every time the center of the moving molecule comes within one molecular diameter of the center of another molecule One can easily determine the number of molecules the moving molecule will hit by determining the number of molecules that lie within the collision cylinder Because we fixed the positions of all but one of the molecules we must use the relative speed of the moving molecule which will be given by The volume of the collision cylinder is given by The collisional cross section which determined by the size of the molecule is given by Some values of are given in the table below Table Collisional crosssection of Select Species Molecule nm He Ne N CO CH Since the number of molecules within the collision cylinder is given by and since the number density is given by the number of collisions is given by The frequency of collisions number of collisions per unit time is then given by Perhaps a more useful value is the mean free path which is the distance a molecule can travel on average before it collides with another molecule This is easily derived from the collision frequency How far something can travel between collisions is given by the ratio of how fast it is traveling and how often it hits other molecules Thus the mean free path is given by The mere fact that molecules undergo collisions represents a deviation from the kinetic molecular theory For example if molecules were infinitesimally small then the mean free path would be infinitely long The finite size of molecules represents one significant deviation from ideality Another important deviation stems from the fact that molecules do exhibit attractive and repulsive forces between one another These forces depend on a number of parameters such as the distance between molecules and the temperature or average kinetic energy of the molecules Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Combining the First and Second Laws Maxwells Relations Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Maxwell RelationsContributors and Attributions Modeling the dependence of the Gibbs and Helmholtz functions behave with varying temperature pressure and volume is fundamentally useful But in order to do that a little bit more development is necessary To see the power and utility of these functions it is useful to combine the First and Second Laws into a single mathematical statement In order to do that one notes that since for a reversible change it follows that And since for a reversible expansion in which only pV works is done it also follows that since This is an extraordinarily powerful result This differential for can be used to simplify the differentials for and But even more useful are the constraints it places on the variables T S p and V due to the mathematics of exact differentials Maxwell Relations The above result suggests that the natural variables of internal energy are and or the function can be considered as So the total differential can be expressed Also by inspection comparing the two expressions for it is apparent that and But the value doesnt stop there Since is an exact differential the Euler relation must hold that By substituting Equations refeqA and refeqB we see that or This is an example of a Maxwell Relation These are very powerful relationship that allows one to substitute partial derivatives when one is more convenient perhaps it can be expressed entirely in terms of andor for example A similar result can be derived based on the definition of Differentiating and using the chain rule on yields Making the substitution using the combined first and second laws for a reversible change involving on expansion pV work This expression can be simplified by canceling the terms And much as in the case of internal energy this suggests that the natural variables of are and Or Comparing Equations refeqA and refeqB show that and It is worth noting at this point that both Equation refeqA and Equation refeqA are equation to So they are equation to each other Morevoer the Euler Relation must also hold so This is the Maxwell relation on Maxwell relations can also be developed based on and The results of those derivations are summarized in Table Table Maxwell Relations Function Differential Natural Variables Maxwell Relation The Maxwell relations are extraordinarily useful in deriving the dependence of thermodynamic variables on the state variables of p T and V Example Show that Solution Start with the combined first and second laws Divide both sides by and constraint to constant Noting that The result is Now employ the Maxwell relation on Table to get and since It is apparent that Note How cool is that This result was given without proof in Chapter but can now be proven analytically using the Maxwell Relations Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Combining the Onedimensional Probability Density Functions Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers In Section we derive the probability density function for one Cartesian component of the velocity of a gas molecule The probability density functions for the other two Cartesian components are the same function For we have and We now want to derive the threedimensional probability density function from these relationships Given these probability density functions for the Cartesian components of we can find the probability density function in spherical coordinates Since the differential volume element in spherical coordinates is the probability that a molecule has a a velocity vector whose magnitude lies between and while its component lies between and and its component lies between and becomes We found the same result in Section of course We can find the probabilitydensity function for the scalar velocity by eliminating the dependence on the angular components To do this we need only sum up at a given value of the contributions from all possible values of and recalling that and This sum is just Since and we again obtain the MaxwellBoltzmann probabilitydensity function for the scalar velocity Unlike the distribution function for the Cartesian components of velocity the MaxwellBoltzmann distribution for scalar velocities is not a normal distribution Possible speeds lie in the interval Because of the term the MaxwellBoltzmann equation is asymmetric it has a pronounced tail at high velocities Comparing the System and the Surroundings Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay No headers It is oftentimes important for reasons that will be discussed in the next section to calculate both the entropy change of the system as well as that of the surroundings Depending on the size of the surroundings they can provide or absorb as much heat as is needed for a process without changing temperature As such it is oftentimes a very good approximation to consider the changes to the surroundings as happening isothermally even though it may not be the case for the system which is generally smaller Example Consider g mol of ice melting at K in a room that is K Calculate DS for the ice the surrounding room and of the universe DHfus kJmol Solution For the process under constant pressure For the ice For the room For the universe Note is positive which is characteristic of a spontaneous change Example A g piece of metal C Jg C initially at C is placed in g of water initially at C in an insulated container Calculate the final temperature of the metal and water once the system has reached thermal equilibrium Also calculate the entropy change for the metal the water and the entire system Solution Heat will be transferred from the hot metal to the cold water Since it has nowhere else to go the final temperature can be calculated from the expression where is the heat absorbed by the water and is the heat lost by the metal And since it follows that A bit of algebra determines the final temperature to be To get the entropy changes use the expression So for the water And for the metal beginalign Delta S_metal gJg C ln left dfracKK right pt JK endalign For the system beginalignDelta S_sys Delta S_water Delta S_metal pt JK JK JK endalign Note The total entropy change is positive suggesting that this will be a spontaneous process This should make some sense since one expects heat to flow from the hot metal to the cool water rather than the other way around Also note that the sign of the entropy change is positive for the part of the system that is absorbing the heat and negative for the part losing the heat In summary can be calculated for a number of pathways fairly conveniently Table Summary of different ways to calculate depending on the pathway Pathway Adiabatic Isothermal Isobaric Isochoric Phase Change for an ideal gas And This calculation is important as provides the criterion for spontaneity for which we were searching from the outset This also suggests a new way to state the second law The entropy of the universe increases in any spontaneous change If we think of the direction of spontaneous to be the natural direction of chance we can see that entropy and the second law are tied inexorably with the natural direction of the flow of time Basically we can expect the entropy of the universe to continue to increase as time flows into the future We can overcome this natural tendency to greater entropy by doing work on a system This is why it requires such great effort for example to straighten a messy desk but little effort for the desk to get messy over time Clausius Inequality The Second Law can be summed up in a very simple mathematical expression called the Clausius Inequality which must be true for any spontaneous process It is not the most convenient criterion for spontaneity but it will do for now In the next chapter we will derive a criterion which is more useful to us as chemists who would rather focus on the system itself rather than both the system and its surroundings Another statement of the Clausius theorem is with the only condition of the left hand side equaling zero is if the system transfers all heat reversibly Contributors Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Compressibility and Expansivity Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Isothermal Compressibility Isobaric Thermal Expansivity Contributors and Attributions Isothermal Compressibility A very important property of a substance is how compressible it is Gases are very compressible so when subjected to high pressures their volumes decrease significantly think Boyles Law Solids and liquids however are not as compressible However they are not entirely incompressible High pressure will lead to a decrease in volume even if it is only slight And of course different substances are more compressible than others To quantify just how compressible substances are it is necessary to define the property The isothermal compressibility is defined by the fractional differential change in volume due to a change in pressure The negative sign is important in order to keep the value of positive since an increase in pressure will lead to a decrease in volume The term is needed to make the property intensive so that it can be tabulated in a useful manner Isobaric Thermal Expansivity Another very important property of a substance is how its volume will respond to changes in temperature Again gases respond profoundly to changes in temperature think Charles Law whereas solids and liquid will have more modest but not negligible responses to changes in temperature For example If mercury or alcohol didnt expand with increasing temperature we wouldnt be able to use those substances in thermometers The definition of the isobaric thermal expansivity or sometimes called the expansion coefficient is As was the case with the compressibility factor the term is needed to make the property intensive and thus able to be tabulated in a useful fashion In the case of expansion volume tends to increase with increasing temperature so the partial derivative is positive Deriving an Expression for a Partial Derivative Type I The reciprocal rule Consider a system that is described by three variables and for which one can write a mathematical constraint on the variables Under these circumstances one can specify the state of the system varying only two parameters independently because the third parameter will have a fixed value As such one could define two functions and This allows one to write the total differentials for and as follows and Substituting the Equation refeq expression into Equation refeq If the system undergoes a change following a pathway where is held constant this expression simplifies to And so for changes for which This reciprocal rule is very convenient in the manipulation of partial derivatives But it can also be derived in a straightforward albeit less rigorous manner Begin by writing the total differential for Equation refeq Now divide both sides by and constrain to constant Noting that and Equation refeq becomes or This formal method of partial derivative manipulation is convenient and useful although it is not mathematically rigorous However it does work for the kind of partial derivatives encountered in thermodynamics because the variables are state variables and the differentials are exact Deriving an Expression for a Partial Derivative Type II The Cyclic Permutation Rule This alternative derivation follow the initial steps in the derivation above to Equation refeq If the system undergoes a change following a pathway where is held constant this expression simplifies to And so for and changes in which This cyclic permutation rule is very convenient in the manipulation of partial derivatives But it can also be derived in a straightforward albeit less rigorous manner As with the derivation above we wegin by writing the total differential of Now divide both sides by and constrain to constant Note that and Equation refeq becomes which is easily rearranged to This type of transformation is very convenient and will be used often in the manipulation of partial derivatives in thermodynamics Example Expanding Thermodynamic Functions Derive an expression for in terms of derivatives of thermodynamic functions using the definitions in Equations refcompress and refexpand Solution Substituting Equations refcompress and refexpand into the Equation refe Simplifying canceling the terms and using transformation Type I to invert the partial derivative in the denominator yields Applying Transformation Type II give the final result dfracalphakappa_T left dfracpartial ppartial T right_V nonumber Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Continuous Distribution Functions the Envelope Function is the Derivative of the Area Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers When we can represent the envelope curve as a continuous function the envelope curve is the derivative of the cumulative probability distribution function The cumulative distribution function is the envelope function is The envelope function is a probability density and we will refer to the envelope function as the probability density function The probability density function is the derivative with respect to the random variable of the cumulative distribution function This is an immediate consequence of the fundamental theorem of calculus If is the antiderivative of a function we have and the fundamental theorem of calculus asserts that the area under from to is In the present instance so that and The envelope function and are the same function This point is also apparent if we consider the incremental change in the area under a histogram as the variable increases from to If we let the envelope function be we have or That is the envelope function is the derivative of the area with respect to the random variable The area is so the envelope function is Calling the envelope curve the probability density function emphasizes that it is analogous to a function that expresses the density of matter That is for an incremental change in the incremental change in probability is analogous to the incremental change in mass accompanying an incremental change in volume where In this analogy we suppose that mass is distributed in space with a density that varies from point to point in the space The mass enclosed in any particular volume is given by the integral of the density function over the volume enclosed that is Conversely the density at any given point is the limit as the enclosing volume shrinks to zero of the enclosed mass divided by the magnitude of the enclosing volume Similarly for any value of the random variable the probability density is the limit as an interval spanning the value of the random variable shrinks to zero of the probability that the random variable is in the interval divided by the magnitude of the interval Cooling Curves Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors and Attributions The method that is used to map the phase boundaries on a phase diagram is to measure the rate of cooling for a sample of known composition The rate of cooling will change as the sample or some portion of it begins to undergo a phase change These breaks will appear as changes in slope in the temperaturetime curve Consider a binary mixture for which the phase diagram is as shown in Figure A cooling curve for a sample that begins at the temperature and composition given by point a is shown in Figure Figure A cooling of a twocomponent system from liquid to solid B Cooresponding cooling curve for this process As the sample cools from point a the temperature will decrease at a rate determined by the sample composition and the geometry of the experiment for example one expects more rapid cooling is the sample has more surface area exposed to the cooler surroundings and the temperature difference between the sample and the surroundings When the temperature reaches that at point b some solid compound B will begin to form This will lead to a slowing of the cooling due to the exothermic nature of solid formation But also the composition of the liquid will change becoming richer in compound A as B is removed from the liquid phase in the form of a solid This will continue until the liquid attains the composition at the eutectic point point c in the diagram When the temperature reaches that at point c both compounds A and B will solidify and the composition of the liquid phase will remain constant As such the temperature will stop changing creating what is called the eutectic halt Once all of the material has solidified at the time indicated by point c the cooling will continue at a rate determined by the heat capacities of the two solids A and B the composition and of course the geometry of the experimental set up By measuring cooling curves for samples of varying composition one can map the entire phase diagram Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Criterion for Phase Equilibrium Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Gibbs Phase RuleContributors and Attributions The thermodynamic criterion for phase equilibrium is simple It is based upon the chemical potentials of the components in a system For simplicity consider a system with only one component For the overall system to be in equilibrium the chemical potential of the compound in each phase present must be the same Otherwise there will be some mass migration from one phase to another decreasing the total chemical potential of the phase from which material is being removed and increasing the total chemical potential of the phase into which the material is being deposited So for each pair of phases present and the following must be true Gibbs Phase Rule The Gibbs phase rule describes the number of compositional and phase variables that can be varied freely for a system at equilibrium For each phase present in a system the mole fraction of all but one component can be varied independently However the relationship places a constraint on the last mole fraction As such there are compositional degrees of freedom for each phase present where is the number of components in the mixture Similarly all but one of the chemical potentials of each phase present must be equal leaving only one that can be varied independently leading to thermodynamic constraints placed on each component Finally there are two state variables that can be varied such as pressure and temperature adding two additional degrees of freedom to the system The net number of degrees of freedom is determined by adding all of the degrees of freedom and subtracting the number of thermodynamic constraints beginalign F PC CP nonumber pt PC P PC C nonumber pt CP labelPhase endalign Equation refPhase is the Gibbs phase rule Example Show that the maximum number of phases that can coexist at equilibrium for a single component system is Solution The maximum number of components will occur when the number of degrees of freedom is zero beginalign P pt P endalign Note This shows that there can never be a quadruple point for a single component system Because a system at its triple point has no degrees of freedom the triple point makes a very convenient physical condition at which to define a temperature For example the International Practical Temperature Scale of IPT uses the triple points of hydrogen neon oxygen argon mercury and water to define several low temperatures The calibration of a platinum resistance thermometer at the triple point of argon for example is described by Strouse Strouse The advantage to using a triple point is that the compound sets both the temperature and pressure rather than forcing the researcher to set a pressure and then measure the temperature of a phase change introducing an extra parameter than can introduce uncertainty into the measurement Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Deficiencies in the Single Determinant Model Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Electron CorrelationEssential Configuration Interaction To achieve reasonable chemical accuracy eg kcalmole in EAs or IPs or bond energies in electronic structure calculations one can not describe the wavefunction in terms of a single determinant The reason such a wavefunction is inadequate is because the spatial probability density functions are not correlated This means the probability of finding one electron at position r is independent of where the other electrons are which is absurd because the electrons mutual Coulomb repulsion causes them to avoid one another This mutual avoidance is what we call electron correlation because the electrons motions as reflected in their spatial probability densities are correlated ie interrelated Let us consider a simple example to illustrate this problem with single determinant functions The determinant when written as can be multiplied by itself to produce the electron spin and spatial probability density If we now integrate over the spins of the two electrons and make use of and we obtain the following spatial ie with spin absent probability density This probability being a product of the probability density for finding one electron at r times the density of finding another electron at clearly has no correlation in it That is the probability of finding one electron at r does not depend on where the other electron is This product form for is a direct result of the singledeterminant form for y so this form must be wrong if electron correlation is to be accounted for Electron Correlation Now we need to ask how should be written if electron correlation effects are to be taken into account As we now demonstrate it turns out that one can account for electron avoidance by taking to be a combination of two or more determinants that differ by the promotion of two electrons from one orbital to another orbital For example in describing the bonding electron pair of an olefin or the electron pair in alkaline earth atoms one mixes in doubly excited determinants of the form or respectively Briefly the physical importance of such doublyexcited determinants can be made clear by using the following identity involving determinants where This identity is important to understand so please make sure you can work through the algebra needed to prove it It allows one to interpret the combination of two determinants that differ from one another by a double promotion from one orbital to another as equivalent to a singlet coupling ie having spin function of two different orbitals and that comprise what are called polarized orbital pairs In the simplest embodiment of such a configuration interaction CI description of electron correlation each electron pair in the atom or molecule is correlated by mixing in a configuration state function CSF in which that electron pair is doubly excited to a correlating orbital A CSF is the minimum combination of determinants needed to express the proper spin eigenfunction for a given orbital occupation In the olefin example mentioned above the two nonorthogonal polarized orbital pairs involve mixing the p and p orbitals to produce two leftright polarized orbitals as depicted in Figure Figure Left and Right Polarized Orbitals of an Olefin In this case one says that the electron pair undergoes leftright correlation when the determinant is mixed into the CI wavefunction In the alkaline earth atom case the polarized orbital pairs are formed by mixing the and orbitals actually one must mix in equal amounts of and orbitals to preserve overall symmetry in this case and give rise to angular correlation of the electron pair Such a pair of polarized orbitals is shown in Figure Figure Angularly Polarized Orbital Pairs More specifically the following four determinants are found to have the largest amplitudes in for Be The fact that the latter three terms possess the same amplitude is a result of the requirement that a state of symmetry is desired It can be shown that this function is equivalent to psi cong frac C_ salphasbeta sap_xalphasap_xbeta sap_xbetasap_xalpha sap_yalphasap_ybeta sap_ybetasap_yalpha sap_zalphasap_zbeta sap_zbetasap_zalpha where Here two electrons occupy the orbital with opposite and spins and are thus not being treated in a correlated manner while the other pair resides in polarized orbitals in a manner that instantaneously correlates their motions These polarized orbital pairs are formed by combining the orbital with the orbital in a ratio determined by This ratio can be shown using perturbation theory to be proportional to the magnitude of the coupling matrix element between the two configurations involved and inversely proportional to the energy difference between these configurations In general configurations that have similar Hamiltonian expectation values and that are coupled strongly give rise to strongly mixed ie with large ratios polarized orbital pairs IILater in this Chapter you will learn how to evaluate Hamiltonian matrix elements between pairs of antisymmetric wavefunctions If you are anxious to learn this now go to the subsection entitled The SlaterCondon Rules and read that before returning here In each of the three equivalent terms in the alkaline earth wavefunction one of the valence electrons moves in a orbital polarized in one direction while the other valence electron moves in the orbital polarized in the opposite direction For example the first term describes one electron occupying a polarized orbital while the other electron occupies the orbital The electrons thus reduce their Coulomb repulsion by occupying different regions of space in the SCF picture both electrons reside in the same region of space In this particular example the electrons undergo angular correlation to avoid one another The use of doubly excited determinants is thus seen as a mechanism by which can place electron pairs which in the singleconfiguration picture occupy the same orbital into different regions of space ie each one into a different member of the polarized orbital pair thereby lowering their mutual Coulomb repulsion Such electron correlation effects are extremely important to include if one expects to achieve chemically meaningful accuracy ie kcalmole Essential Configuration Interaction There are occasions in which the inclusion of two or more determinants in is essential to obtaining even a qualitatively correct description of the molecules electronic structure In such cases we say that we are including essential correlation effects To illustrate let us consider the description of the two electrons in a single covalent bond between two atoms or fragments that we label X and Y The fragment orbitals from which the bonding and antibonding MOs are formed we will label and respectively Several spin and spatial symmetry adapted electron determinants ie CSFs can be formed by placing two electrons into the and orbitals For example to describe the singlet determinant corresponding to the closedshell orbital occupancy a single Slater determinant suffices An analogous expression for the determinant is given by Also the component of the triplet state having orbital occupancy can be written as a single Slater determinant as can the component of the triplet state However to describe the singlet and triplet states belonging to the occupancy two determinants are needed is the singlet and is the triplet note you can obtain this triplet by applying to the triplet In each case the spin quantum number its zaxis projection and the quantum number are given in the conventional term symbol notation As the distance between the X and Y fragments is changed from near its equilibrium value of and approaches infinity the energies of the and orbitals vary in a manner well known to chemists as depicted in Figure if X and Y are identical Figure Orbital Correlation Diagram Showing Two Type Orbitals Combining to Form a Bonding and an Antibonding Molecular Orbital If X and Y are not identical the and orbitals still combine to form a bonding and an antibonding orbital The energies of these orbitals for R values ranging from near to are depicted in Figure for the case in which X is more electronegative than Y Figure Orbital Correlation Diagram For Type Orbitals in the Heteronuclear Case The energy variation in these orbital energies gives rise to variations in the energies of the six determinants listed above As the determinants energies are difficult to intuit because the and orbitals become degenerate in the homonuclear case or nearly so in the case To pursue this point and arrive at an energy ordering for the determinants that is appropriate to the region it is useful to express each such function in terms of the fragment orbitals and that comprise and To do so the LCAOMO expressions for and and are substituted into the Slater determinant definitions given above Here and are the normalization constants The parameter is in the homonuclear case and deviates from in relation to the and orbital energy difference if lies below then if lies above Let us examine the case to keep the analysis as simple as possible The process of substituting the above expressions for and into the Slater determinants that define the singlet and triplet functions can be illustrated as follows for the case The first two of these atomicorbitalbased Slater determinants and are called ionic because they describe atomic orbital occupancies which are appropriate to the region that correspond to and valence bond structures while and are called covalent because they correspond to structures In similar fashion the remaining five determinant functions may be expressed in terms of fragmentorbitalbased Slater determinants In so doing use is made of the antisymmetry of the Slater determinants eg which implies that any determinant in which two or more spinorbitals are identical vanishes The result of decomposing the MObased determinants into their fragmentorbital components is as follows These decompositions of the six valence determinants into fragmentorbital or valence bond components allow the energies of these states to specified For example the fact that both and contain ionic and covalent structures implies that as both of their energies will approach the average of the covalent and ionic atomic energies The energy approaches the purely ionic value as The energies of and all approach the purely covalent value as The behaviors of the energies of the six valence determinants as varies are depicted in Figure for situations in which the homolytic bond cleavage is energetically favored ie for which Figure Configuration Correlation Diagram Showing How the Determinants Energies Vary With It is essential to realize that the energies of the determinants do not represent the energies of the true electronic states For values at which the determinant energies are separated widely the true state energies are rather well approximated by individual determinant energies such is the case near Re for the state However at large the situation is very different and it is in such cases that what we term essential configuration interaction occurs Specifically for the example the and determinants undergo essential CI coupling to form a pair of states of symmetry the CSF cannot partake in this CI mixing because it is of ungerade symmetry the states can not mix because they are of triplet spin symmetry The CI mixing of the and determinants is described in terms of a x secular problem leftbeginarraycc langle Sigma H Sigma rangle langle Sigma H Sigma rangle langle Sigma H Sigma rangle langle Sigma H Sigma rangle endarrayright leftbeginarraycABendarrayright EleftbeginarraycABendarrayright The diagonal entries are the determinants energies depicted in Figure The offdiagonal coupling matrix elements can be expressed in terms of an exchange integral between the and orbitals Later in this Chapter you will learn how to evaluate Hamiltonian matrix elements between pairs of antisymmetric wavefunctions and to express them in terms of one and twoelectron integrals If you are anxious to learn this now go to the subsection entitled the SlaterCondon Rules and read that before returning here At where the and determinants are degenerate the two solutions to the above CI matrix eigenvalue problem are with respective amplitudes for the and CSFs given by The first solution thus has which when decomposed into atomic orbital components yields The other root has So we see that and which both contain ionic and covalent parts combine to produce which is purely covalent and which is purely ionic The above essential CI mixing of and as qualitatively alters the energy diagrams shown above Descriptions of the resulting valence singlet and triplet S states are given in Figure for homonuclear situations in which covalent products lie below the ionic fragments Figure State Correlation Diagram Showing How the Energies of the States Comprised of Combinations of Determinants vary with Defining Enthalpy H Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Any mathematical expression that involves only state functions must itself be a state function We could define and would be a state function However it is not a useful state function We can define several state functions that have the units of energy and that turn out to be particularly useful One of them is named enthalpy and is customarily represented by the symbol We define enthalpy One reason that enthalpy is a useful state function emerges if we examine the change in when the system pressure is equal to the applied pressure and both are constant When these conditions are satisfied we usually denote the heat accepted by the system as If all of the work is pressurevolume work we have If these conditions are satisfied the enthalpy change is the same thing as the heat added to the system When we want to express the requirement that the system and applied pressures are equal and constant we often just say that the process occurs at a constant pressure This is another convenient figure of speech It also reflects our expectation that the system pressure and the applied pressure will equilibrate rapidly in most circumstances For an ideal gas the molar energy depends only on temperature Since for an ideal gas depends only on temperature Hence the molar enthalpy of an ideal gas also depends only on temperature For an ideal gas we have the parallel relationships and Earlier we asserted that while energy is a state function heat and work are not Hesss law as originally formulated in says that the heat changes for a series of chemical reactions can be summed to get the heat change for the overall process described by the sum of the chemical reactions This amounts to saying that heat is a state function As it stands this is a contradiction The resolution is of course that Hesss law was formulated for a series of chemical reactions that occur at the same constant pressure Then the heat involved in each step is the enthalpy change for that step and since enthalpy is a state function there is no contradiction Modern statements of Hesss law frequently forego historical accuracy in favor of scientific accuracy to assert that the enthalpy change for a series of reactions can be summed to get the enthalpy change for the overall process Thus revised Hesss law ceases to be a seminal but imperfect conjecture and becomes merely a special case of the principle that enthalpy is a state function Defining the Helmholtz and Gibbs Free Energies Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers The first and second laws of thermodynamics define energy and entropy Energy and entropy are fundamental state functions that we use to define other state functions In Chapter we use the energy function to define enthalpy We use the energy and entropy functions to define two more state functions that also prove to have useful properties These are the Helmholtz and Gibbs free energies The Helmholtz free energy is usually given the symbol and the Gibbs free energy is usually given the symbol We define them by and Note that and all have the units of energy The sense of the name free energy is that a constanttemperature process in which a system experiences an entropy increase is one in which the systems ability to do work in the surroundings is increased by an energy increment Then adding to the internal energy lost by the system yields the amount of energy that the process actually has available energy that is free to do work in the surroundings When we consider how and depend on the conditions under which system changes we find that this idea leads to useful results The rest of this chapter develops important equations for and that result when we require that a system change occur under particular sets of conditions Degree of Dissociation Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors and Attributions Reactions such as the one in the previous example involve the dissociation of a molecule Such reactions can be easily described in terms of the fraction of reactant molecules that actually dissociate to achieve equilibrium in a sample This fraction is called the degree of dissociation For the reaction in the previous example the degree of dissociation can be used to fill out an ICE table If the reaction is started with moles of and a is the fraction of molecules that dissociate the ICE table will look as follows Initial Change Equilibrium The mole fractions of and can then be expressed by Based on these mole fractions And so which can be expressed as is given by Example Based on the values given below find the equilibrium constant at oC and degree of dissociation for a system that is at a total pressure of atm for the reaction kJmol Solution First the value of can be determined from via an application of Hess Law beginalign Delta G_rxno left kJmol right kJmol kJmol endalign So using the relationship between thermodynamics and equilibria The degree of dissociation can then be calculated from the ICE tables at the top of the page for the dissociation of beginalign K_p dfrac alphaalpha p_tot pt atm dfrac alphaalpha atm endalign Solving for Note since a represents the fraction of NO molecules dissociated it must be a positive number between and Example Consider the gasphase reaction A reaction vessel is initially filled with mol of A and mol of B At equilibrium the vessel contains mol C and a total pressure of atm at K How many mol of A and B are present at equilibrium What is the mole fraction of A B and C at equilibrium Find values for and Solution Lets build an ICE table A B C Initial mol mol Change x x x Equilibrium mol x mol x x mol From the equilibrium measurement of the number of moles of C x mol So at equilibrium A B C Equilibrium mol mol mol The total number of moles at equilibrium is mol From these data the mole fractions can be determined beginalign chi_A dfracmolmol pt chi_B dfracmolmol pt chi_C dfracmolmol endalign So is given by And is given by Equation refoddEq so The thermodynamic equilibrium constant is unitless of course since the pressures are all divided by atm So the actual value of is This value can be used to calculate using so Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Densities of States in and dimensions Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Contributors and Attributions When a large number of neighboring orbitals overlap bands are formed However the natures of these bands their energy patterns and their densities of states are very different in different dimensions Before leaving our discussion of bands of orbitals and orbital energies in solids I want to address a bit more the issue of the density of electronic states and what determines the energy range into which orbitals of a given band will split First lets recall the energy expression for the and dimensional electron in a box case and lets generalize it to three dimensions The general result is E sum_j dfracn_j pihbarmL_jtag where the sum over runs over the number of dimensions or and is the length of the box along the jth direction For one dimension one observes a pattern of energy levels that grows with increasing and whose spacing between neighboring energy levels also grows as a result of which the state density decreases with increasing However in and dimensions the pattern of energy level spacing displays a qualitatively different character especially at high quantum number Consider first the dimensional case and for simplicity lets use a box that has equal length sides In this case the total energy is times n_x n_y n_z The latter quantity can be thought of as the square of the length of a vector having three components Now think of three Cartesian axes labeled and and view a sphere of radius in this space The volume of the th sphere having positive values of and and having radius is Because each cube having unit length along the and axes corresponds to a single quantum wave function and its energy the total number of quantum states with positive and and with energy between zero and is N_tot frac frac pi R frac biggfrac pi leftfracmELhbarpirightbiggtag The number of quantum states with energies between and is which gives the density of states near energy OmegaE fracdN_totdE frac biggfrac pi leftfracmELhbarpiright frac sqrtEbigg tag Notice that this state density increases as increases This means that in the dimensional case the number of quantum states per unit energy grows in other words the spacing between neighboring state energies decreases very unlike the dimensioal case where the spacing between neighboring states grows as and thus grows This growth in state density in the dimensional case is a result of the degeneracies and neardegeneracies that occur For example the states with and and are degenerate and those with or or or or or are degenerate and nearly degenerate to those having quantum numbers or or In the dimensional case degeneracies also occur and cause the density of states to possess an dependence that differs from the or dimensional case In this situation we think of states having energy but with The total number of states having energy between zero and is So the density of states between and is That is in this dimensional case the number of states per unit energy is constant for high values where the analysis above applies best This kind of analysis for the dimensional case gives N_rm total R sqrtfracmELhbarpi tag so the state density between and is which clearly shows the widening spacing and thus lower state density as one goes to higher energies These findings about densities of states in and dimensions are important because in various problems one encounters in studying electronic states of extended systems such as solids chains and surfaces one needs to know how the number of states available at a given total energy varies with A similar situation occurs when describing the translational states of an electron or a photo ejected from an atom or molecule into the vacuum here the dimensional density of states applies Clearly the state density depends upon the dimensionality of the problem and this fact is what I want the students reading this text to keep in mind Before closing this Section it is useful to overview how the various particleinbox models can be used as qualitative descriptions for various chemical systems a The onedimensional box model is most commonly used to model electronic orbitals in delocalized linear polyenes b The electrononacircle model is used to describe orbitals in a conjugated cyclic ring such as in benzene a The rectangular box model can be used to model electrons moving within thin layers of metal deposited on a substrate or to model electrons in aromatic sheets such as graphene shown below in Figure a Figure a Depiction of the aromatic rings of graphene extending in two dimensions b The particlewithinacircle model can describe states of electrons or other light particles requiring quantum treatment constrained within a circular corral c The particleonaspheres surface model can describe states of electrons delocalized over the surface of fullerenetype species such as shown in the upper right of Figure b Figure b Fullerene upper right and tubes of rolled up graphenes lower three a The particleinasphere model as discussed earlier is often used to treat electronic orbitals of quasispherical nanoclusters composed of metallic atoms b The particleinacube model is often used to describe the bands of electronic orbitals that arise in threedimensional crystals constructed from metallic atoms In all of these models the potential which is constant in the region where the electron is confined controls the energies of all the quantum states relative to that of a free electron ie an electron in vacuum with no kinetic energy For some dimensionalities and geometries it may be necessary to invoke more than one of these models to qualitatively describe the quantum states of systems for which the valence electrons are highly delocalized eg metallic clusters and conjugated organics For example for electrons residing on the surface of any of the three graphene tubes shown in Figure b one expects quantum states i labeled with an angular momentum quantum number and characterizing the electrons angular motions about the long axis of the tube but also ii labeled by a longaxis quantum number characterizing the electrons energy component along the tubes long axis For a threedimensional tubeshaped nanoparticle composed of metallic atoms one expects the quantum states to be i labeled with an angular momentum quantum number and a radial quantum number characterizing the electrons angular motions about the long axis of the tube and its radial Bessel function character but again also ii labeled by a longaxis quantum number characterizing the electrons energy component along the tubes long axis Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Deriving Boyles Law from Newtonian Mechanics Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers We can derive Boyles law from Newtonian mechanics This derivation assumes that gas molecules behave like point masses that do not interact with one another The pressure of the gas results from collisions of the gas molecules with the walls of the container The contribution of one collision to the force on the wall is equal to the change in the molecules momentum divided by the time between collisions The magnitude of this force depends on the molecules speed and the angle at which it strikes the wall Each such collision makes a contribution to the pressure that is equal to the force divided by the area of the wall To find the pressure from this model it is necessary to average over all possible molecular speeds and all possible collision angles In Chapter we derive Boyles law in this way We can do a simplified derivation by making a number of assumptions We assume that all of the molecules in a sample of gas have the same speed Let us call it As sketched in Figure we assume that the container is a cubic box whose edge length is If we consider all of the collisions between molecules and walls it is clear that each wall will experience of the collisions or each pair of opposing walls will experience of the collisions Instead of averaging over all of the possible angles at which a molecule could strike a wall and all of the possible times between collisions we assume that the molecules travel at constant speed back and forth between opposite faces of the box Since they are point masses they never collide with one another If we suppose that of the molecules go back and forth between each pair of opposite walls we can expect to accomplish the same kind of averaging in setting up our artificial model that we achieve by averaging over the real distribution of angles and speeds In fact this turns out to be the case the derivation below gets the same result as the rigorous treatment we develop in Chapter Figure Simplified model for velocities of gas molecules in a cubic box Since each molecule goes back and forth between opposite walls it collides with each wall once during each round trip At each collision the molecules speed remains constant but its direction changes by that is the molecules velocity changes from to Letting be the time required for a round trip the distance traversed in a round trip is The magnitude of the momentum change for a molecule in one collision is The magnitude of the force on the wall from one collision is and the pressure contribution from one collision on the wall of area is so that we have from the collision of one molecule with one wall If the number of molecules in the box is of them make collisions with this wall so that the total pressure on one wall attributable to all molecules in the box is or Since the ideal gas equation can be written as we see that so that and Thus we have found a relationship between the molecular speed and the temperature of the gas The actual speed of a molecule can have any value between zero andfor present purposesinfinity When we average the values of for many molecules we find the average value of the squared speeds In Chapter we find that That is the average speed we use in our derivation turns out to be a quantity called the rootmeansquare speed This result also gives us the average kinetic energy of a single gas molecule From this derivation we have a simple mechanical model that explains Boyles law as the logical consequence of pointmass molecules colliding with the walls of their container By combining this result with the ideal gas equation we find that the average speed of ideal gas molecules depends only on the temperature From this we have the very important result that the translational kinetic energy of an ideal gas depends only on temperature Since our noninteracting pointmass molecules have no potential energy arising from their interactions with one another their translational kinetic energy is the whole of their energy Because two such molecules neither attract nor repel one another no work is required to change the distance between them The work associated with changing the volume of a confined sample of an ideal gas arises because of the pressure the molecules exert on the walls of the container the pressure arises because of the molecules kinetic energy The energy of one mole of monatomic ideal gas molecules is When we expand our concept of ideal gases to include molecules that have rotational or vibrational energy but which neither attract nor repel one another it remains true that the energy of a macroscopic sample depends only on temperature However the molar energy of such a gas is greater than because of the energy associated with these additional motions We make extensive use of the conclusion that the energy of an ideal gas depends only on temperature As it turns out this conclusion follows rigorously from the second law of thermodynamics In Chapter we show that for a substance that obeys the ideal gas equation at constant temperature the energy of an ideal gas is independent of the volume and independent of the pressure So long as pressure volume and temperature are the only variables needed to specify its state the laws of thermodynamics imply that the energy of an ideal gas depends only on temperature While the energy of an ideal gas is independent of pressure the energy of a real gas is a function of pressure at a given temperature At ordinary pressures and temperatures this dependence is weak and can often be neglected The first experimental investigation of this issue was made by James Prescott Joule for whom the SI unit of energy is named Beginning in Joule did a long series of careful measurements of the mechanical equivalent of heat These measurements formed the original experimental basis for the kinetic theory of heat Among Joules early experiments was an attempt to measure the heat absorbed by a gas as it expanded into an evacuated container a process known as a free expansion No absorption of heat was observed which implied that the energy of the gas was unaffected by the volume change However it is difficult to do this experiment with meaningful accuracy Subsequently Joule collaborated with William Thomson Lord Kelvin on a somewhat different experimental approach to essentially the same question The JouleThomson experiment provides a much more sensitive measure of the effects of intermolecular forces of attraction and repulsion on the energy of a gas during its expansion Since our definition of an ideal gas includes the stipulation that there are no intermolecular forces the JouleThomson experiment is consistent with the conclusion that the energy of an ideal gas depends only on temperature However since intermolecular forces are not zero for any real gas our analysis reaches this conclusion in a somewhat indirect way The complication arises because the JouleThomson results are not entirely consistent with the idea that all properties of a real gas approach those of an ideal gas at a sufficiently low pressure The best of models can have limitations We discuss the JouleThomson experiment in Section Deriving the Ideal Gas Law from Boyles and Charles Laws Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers We can solve Boyles law and Charles law for the volume Equating the two we have The number of moles cancels Rearranging gives In this equation the left side is a function only of temperature the right side only of pressure Since pressure and temperature are independent of one another this can be true only if each side is in fact constant If we let this constant be we have and Since the values of and are independent of the gas being studied the value of is also the same for any gas is called the gas constant the ideal gas constant or the universal gas constant Substituting the appropriate relationship into either Boyles law or Charles law gives the ideal gas equation The product of pressure and volume has the units of work or energy so the gas constant has units of energy per mole per degree Remember that we simplified the form of Charless law by defining the Kelvin temperature scale temperature in the ideal gas equation is in degrees Kelvin Determining Whether an Expression is an Exact Differential Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Since exact differentials have these important characteristics it is valuable to know whether a given differential expression is exact or not That is given a differential expression of the form we would like to be able to determine whether is exact or inexact It turns out that there is a simple test for exactness test for exactness The differential in the form of Equation refeq is exact if and only if That is this condition is necessary and sufficient for the existence of a function for which and In we demonstrate that the condition is necessary Now we want to show that it is sufficient That is we want to demonstrate If Equation refeq hold then there exists a such that and To do this we show how to find a function that satisfies the given differential relationship If we integrate with respect to we have where is a function only of it is the arbitrary constant in the integration with respect to which we carry out with held constant To complete the proof we must find a function such that this satisfies the conditions The validity of condition in Equation refGrindEQ_ follows immediately from the facts that the order of differentiation and integration can be interchanged for a continuous function and that is a function only of so that To find such that condition in Equation refGrindEQ_ is satisfied we observe that But since this becomes Hence condition in Equation refGrindEQ_ is satisfied if and only if so that is simply an arbitrary constant Distribution Equilibria Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers A system can contain more than one phase and more than one chemical substance can be present in each phase If one of the substances is present in two phases we say that the substance is distributed between the two phases We can describe the equilibrium distribution quantitatively by specifying the concentration of the substance in each phase At constant temperature we find experimentally that the ratio of these concentrations is approximately constant Letting be the substance that is distributed we find for the distribution equilibrium the equilibrium constant where varies with temperature and pressure For example iodineiodine is slightly soluble in water and much more soluble in chloroform Since water and chloroform are essentially immiscible a system containing water chloroform and iodine will contain two liquid phases If there is not enough iodine present to make a saturated solution with both liquids the system will reach equilibrium with all of the iodine dissolved in the two immiscible solvents Experimentally the equilibrium concentration ratio is approximately constant whatever amounts of the three substances are mixed We begin our development of physical chemistry by reasoning about the effects of concentrations on the properties of chemical systems In Chapter we find that rate laws expressed using concentration variables are adequate for the analysis of reaction mechanisms Consideration of these rate laws leads us to the equilibrium constant for a chemical reaction expressed as a function of concentrations Eventually however we discover that an adequately accurate theory of chemical equilibrium must be expressed using new quantities which we call chemical activities We can think of a chemical activity as an effective concentration or a corrected concentration where the correction is for the effects of intermolecular interactions When we allow for the effects of intermolecular interactions we find that we must replace the concentration terms by chemical activities For the distribution equilibrium constant we have where denotes the chemical activity of species in phase at equilibrium Distribution Functions for Gasvelocity Components Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers In Chapter we assume that all of the molecules in a gas move with the same speed and use a simplified argument to conclude that this speed depends only on temperature We now recognize that the individual molecules in a gas sample have a wide range of speeds the velocities of gas molecules must be described by a distribution function It is true however that the average speed depends only on temperature James Clerk Maxwell was the first to derive the distribution function for gas velocities He did it about We follow Maxwells argument For a molecule moving in three dimensions there are three velocity components Maxwells argument uses only one assumption the speed of a gas molecule is independent of the direction in which it is moving Equivalently we can say that the components of the velocity of a gas molecule are independent of one another knowing the value of one component of a molecules velocity does not enable us to infer anything about the values of the other two components When we use Cartesian coordinates Maxwells assumptionMaxwells assumption means also that the same mathematical model must describe the distribution of each of the velocity components Since the velocity of a gas molecule has three components we must treat the velocity distribution as a function of three random variables To understand how this can be done let us consider how we might find probability distribution functions for velocity components We need to consider both spherical and Cartesian coordinate systems Let us suppose that we are able to measure the Cartesiancoordinate components and of the velocities of a large number of randomly selected gas molecules in a particular constanttemperature sample Then we can transform each set of Cartesian components to sphericalcoordinate velocity covelocity componentsmponents and We imagine accumulating the results of these measurements in a table like Table As a practical matter of course we cannot make the measurements to complete such a table However there is no doubt that at every instant every gas molecule can be characterized by a set of such velocity components the values exist even if we cannot measure them We imagine that we have such data only as a way to clarify the properties of the distribution functions that we need Table Molecular Velocity Components Molecule Number v These data have several important features The scalar velocity ranges from to and range from to In we see that varies from to and ranges from to Each column represents data sampled from the distribution of the corresponding random variable In Chapter we find that we can use such data to find mathematical models for such distributions Here we can find mathematical models for the cumulative distribution functions and We can approximate the graph of by plotting the rank probability of versus We expect this plot to be sigmoid at any the slope of this plot is the probabilitydensity function The probability density function for depends only on because the value measured for is independent of the values measured for and However by Maxwells assumption the functions describing the distribution of and are the same as those describing the distribution of While redundant it is convenient to introduce additional symbols to represent these probability density functions We define and When we find these onedimensional distribution functions by modeling the experimental data in this way each datum that we use in our analysis comes from an observation on a molecule and is associated with particular and values These values of and can be anything from to This is a significant point The functions and are independent of and We can also say that describes the distribution of when and are averaged over all the values it is possible for them to have To clarify this let us consider another cumulative probability distribution function which is just the fraction of all molecules whose respective Cartesian velocity components are less than Since and are the fractions whose components are less than and respectively their product is equal to We have For the velocity of a randomly selected molecule to be included in the fraction represented by the velocity must be in the particular range and However for a velocity to be included in we must have and that is the components and can have any values Since the probability that and satisfy and is the probability that is included in becomes beginaligned Pleftv_xv_xv_y infty v_z infty right f_xyz left v_x infty infty right f_x left v_x right f_y left infty right f_z left infty right f_x left v_x right endaligned For our purposes we need to be able to express the probability that the velocity lies within any range of velocities Let us use to designate a particular volume region in velocity space and use to designate the probability that the velocity of a randomly selected molecule is in this region When we let  be the region in velocity space in which components lie between and components lie between and and components lie between and denotes the probability that the velocity of a randomly chosen molecule satisfies the conditions and is an increment of probability The dependence of on and can be made explicit by introducing a new function defined by Since is the volume available in velocity space for velocities whose components are between and whose components are between and and whose components are between and we see that is a probability density function in three dimensions The value of is the probability per unit volume in velocity space that a molecule has the velocity For any velocity there is a value of this value is just a number If we want the probability of finding a velocity within some small volume of velocity space around we can find it by multiplying by this volume From the onedimensional probabilitydensity functions the probability that the component of a molecular velocity lies between and is just whatever the values of and The probability that the component lies between and is just whatever the values of and The probability that the component lies between and is just whatever the values of and When we interpret Maxwells assumption to mean that these are independent probabilities the probability that all three conditions are realized simultaneously is Evidently the product of these three onedimensional probability densities is the threedimensional probability density We have From Maxwells assumption we have derived the conclusion that can be expressed as a product of the onedimensional probability densities and Since these are probability densities we have and Moreover because the Cartesian coordinates differ from one another only in orientation and must all be the same function Figure Transformation from Cartesian to spherical coordinates To summarize the development above we define independently of and Then from Maxwells assumption that the three onedimensional probabilities are independent we find Alternatively we could take Maxwells assumption to be that the threedimensional probability density function is expressible as a product of three onedimensional probability densities In this case the relationships of and to the onedimensional cumulative probabilities etc must be deduced from the properties of As emphasized above our deduction of from experimental data uses values that are associated with all possible values of and That is what we determine in our hypothetical experiment is from which it follows that Figure The differential volume element in spherical coordinates Duhems Theorem Specifying Reversible Change in A Closed System Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers We view a chemical system as a collection of substances that occupies some volume Let us consider a closed system whose volume is variable and in which no work other than pressurevolume work is possible If this system is undergoing a reversible change it is at equilibrium and it is in contact with its surroundings Because the system is at equilibrium all points inside the system have the same pressure and the same temperature Since the change is reversible the interior pressure is arbitrarily close to the pressure applied to the system by the surroundings If the reversibly changing system can exchange heat with its surroundings the temperature of the surroundings is arbitrarily close to the temperature of the system If a process takes place in a system that cannot exchange heat with its surroundings we say that the process is adiabatic We can measure the pressure temperature and volume of such a system without knowing anything about its composition For a system composed of a known amount of a single phase of a pure substance we know from experience that any cyclic change in pressure or temperature restores the initial volume That is for a pure phase there is an equation of state that we can rearrange as meaning that specifying and is sufficient to specify uniquely For other reversible systems the function may not exist For example consider a system that consists of a known amount of water at liquidvapor equilibrium and whose pressure and temperature are known For this system the volume can have any value between that of the pure liquid and that of the pure gas Specifying the pressure and temperature of this system is not sufficient to specify its state However if we specify the temperature of this system the pressure is fixed by the equilibrium condition and if we specify the volume of the system we can find how much water is in each phase from the known molar volumes of the pure substances at the system pressure and temperature For the waterwatervapor equilibrium system we can write In each of these cases we can view one of the variables as a function of the other two and represent it as a surface in a three dimensional space The two independent variables define a plane Projecting the systems location in this independentvariable plane onto the surface establishes the value of the dependent variable The two independentvariable values determine the point on the surface that specifies the state of the system In the liquidvapor equilibrium system the pressure is a surface above the volumetemperature plane A complete description of the state of the system must also include the number of moles of liquid and the number of mole of vapor present Each of these quantities can also be described as a surface in a three dimensional space in which the other two dimensions are volume and temperature Duhems theorem asserts that these observations are special cases of a more general truth Duhems theorem For a closed reversible system in which only pressurevolume work is possible specifying how some pair of state functions changes is sufficient to specify how the state of the system changes Duhems theorem asserts that two variables are sufficient to specify the state of the system in the following sense Given the values of the systems thermodynamic variables in some initial state say specifying the change in some pair of variables say and is sufficient to determine the change in the remaining variables so that the systems thermodynamic variables in the final state are where etc The theorem does not specify which pair of variables is sufficient In fact from the discussion above of the variables that can be used to specify the state of a system containing only water it is evident that a particular pair may not remain sufficient if there is a change in the number of phases present In Chapter we see that Duhems theorem follows from the first and second laws of thermodynamics and we consider the particular pairs of variables that can be used For now let us consider a proof of Duhems theorem for a system in which the pressure temperature volume and composition can vary We consider systems in which only pressurevolume work is possible Let the number of chemical species present be and the number of phases be the number of component in the phase rule and differ by the number of stoichiometric constraints that apply to the system is less the number of stoichiometric constraints We want to know how many variables can be changed independently while the system remains at equilibrium This is similar to the question we answered when we developed Gibbs phase rule However there are important differences The phase rule is independent of the size of the system it specifies the number of intensive variables required to prescribe an equilibrium state in which specified phases are present The size of the system is not fixed we can add or remove matter to change the size of any phase without changing the number of degrees of freedom In the present problem the system cannot exchange matter with its surroundings Moreover the number of phases present can change We require only that any change be reversible and a reversible process can change the number of phases For example reversible vaporization can convert a twophase system to a gaseous onephase system We want to impose a change on an initial state of a closed system This initial state is an equilibrium state and we want to impose a change that produces a new Gibbsian equilibrium state of the same system This means that the change we impose can neither eliminate an existing chemical species nor introduce a new one A given phase can appear or disappear but a given chemical species cannot We can find the number of independent variables for this system by an argument similar to the one we used to find the phase rule To completely specify this system we must specify the pressure temperature and volume of each phase We must also specify the number of moles of each of chemical species in each phase This means that variables must be specified Every relationship that exists among these variables decreases by one the number that are independent The following relationships exist The pressure is the same in each phase There are pressure constraints The temperature is the same in each phase There are temperature constraints The volume of each phase is determined by the pressure the temperature and the number of moles of each species present in that phase In Chapter we find that the volume of a phase is given rigorously by the equation where and are the number of moles and the partial molar volume of the species in that phase The depend only on pressure temperature and composition For phases there are constraints one for the volume of each phase To completely specify the system the concentration of each species must be specified in each phase This condition creates constraints We can also reach this conclusion by a slightly different argument To specify the concentrations of species in some one phase requires constraints A distribution equilibrium relates the concentrations of each species in every pair of phases There are independent pairs of phases For chemical species there are such constraints This is equivalent to the requirement in our phase rule analysis that there are equilibrium relationships among components in P phases In the present problem the total number of concentration constraints is P Subtracting the number of constraints from the number of variables we find that there are independent variables for a reversible process in a closed system if all work is pressurevolume work The number of independent variables is constant it is independent of the species that are present and the number of phases It is important to appreciate that there is no conflict between Duhems theorem and the phaserule conclusion that degrees of freedom are required to specify an equilibrium state of a system containing specified phases When we say that specifying some pair of variables is sufficient to specify the state of a particular closed system undergoing reversible change we are describing a system that is continuously at equilibrium as it goes from a first equilibrium state to a second one Because it is closed and continuously in an equilibrium state the range of variation available to the system is circumscribed in such a way that specifying two variables is sufficient to specify its state On the other hand when we say that degrees of freedom are required to specify an equilibrium state of a system containing specified phases we mean that we must know the values of intensive variables in order to establish that the state of the system is an equilibrium state To illustrate the compatibility of these ideas and the distinction between them let us consider a closed system that contains nitrogen hydrogen and ammonia gasammonia gases In the presence of a catalyst the reaction occurs For simplicity let us assume that these gases behave ideally If the gases do not behave ideally the argument remains the same but more complex equations are required to express the equilibrium constant and the system pressure as functions of the molar composition This system has two components and three degrees of freedom When we say that the system is closed we mean that the total number of moles of the elements nitrogen and hydrogen are known and constant Let these be and respectively Letting the moles of ammonia present be the number of moles of dihydrogen and dinitrogen are and respectively If we know that this system is at equilibrium we know that the equilibrium constant relationship is satisfied We have where is the volume of the system The idealgas equilibrium constant is a function only of temperature We assume that we know this function therefore if we know the temperature we know the value of the equilibrium constant The pressure of the system can also be expressed as a function of and We have If we know the system pressure and we know that the system is at equilibrium we can solve the equations for and simultaneously to find the unknowns and From these we can calculate the molar composition of the system and the partial pressure of each of the gases We discuss idealgas equilibrium calculations in detail in Chapter Thus if we know that the system is at equilibrium knowledge of the pressure and temperature is sufficient to determine its composition and all of its other properties If we do not know that this system is at equilibrium but instead want to collect sufficient experimental data to prove that it is the phase rule asserts that we must find the values of some set of three intensive variables Two are not sufficient From the perspective provided by the equations developed above we can no longer use the equilibrium constant relationship to find and Instead our problem is to find the composition of the system by other means so that we can test for equilibrium by comparing the value of the quantity to the value of the equilibrium constant We could accomplish this goal by measuring the values of several different combinations of three intensive variables A convenient combination is pressure temperature and ammonia concentration When we rearrange the equation for the system pressure to it is easy to see that knowing P T and enables us to find the volume of the system Given the volume we can find the molar composition of the system and the partial pressure of each of the gases With these quantities in hand we can determine whether the equilibrium condition is satisfied Electron Tunneling Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Contributors and Attributions As we have seen several times already solutions to the Schrdinger equation display several properties that are very different from what one experiences in Newtonian dynamics One of the most unusual and important is that the particles one describes using quantum mechanics can move into regions of space where they would not be allowed to go if they obeyed classical equations We call these classically forbidden regions Let us consider an example to illustrate this socalled tunneling phenomenon Specifically we think of an electron a particle that we likely would use quantum mechanics to describe moving in a direction we will call under the influence of a potential that is Infinite for this could for example represent a region of space within a solid material where the electron experiences very repulsive interactions with other electrons Constant and negative for some range of between and this could represent the attractive interaction of the electrons with those atoms or molecules in a finite region or surface of a solid Constant and repulsive ie positive by an amount for another finite region from to this could represent the repulsive interactions between the electrons and a layer of molecules of thickness d lying on the surface of the solid at Constant and equal to from to infinity this could represent the electron being removed from the solid but with a work function energy cost of and moving freely in the vacuum above the surface and the adlayer Such a potential is shown in Figure Figure Onedimensional potential showing a well a barrier and the asymptotic region The piecewise nature of this potential allows the onedimensional Schrdinger equation to be solved analytically For energies lying in the range an especially interesting class of solutions exists These socalled resonance states occur at energies that are determined by the condition that the amplitude of the wave function within the barrier ie for be large Let us now turn our attention to this specific energy regime which also serves to introduce the tunneling phenomenon The piecewise solutions to the Schrdinger equation appropriate to the resonance case are easily written down in terms of sin and cos or exponential functions using the following three definitions The combination of and that solve the Schrdinger equation in the inner region and that vanish at because the function must vanish within the region where is infinite and because it must be continuous it must vanish at is psi AsinkR hspacecm textfor le R le R_rm max Between and there are two solutions that obey the Schrdiger equation so the most general solution is a combination of these two psi B expkappaR B expkappaR hspacecm textfor R_rm max le R le R_rm max delta Finally in the region beyond we can use a combination of either and or and to express the solution Unlike the region near where it was most convenient to use the sin and cos functions because one of them could be thrown away since it could not meet the boundary condition of vanishing at in this large region either set is acceptable We choose to use the and set because each of these functions is an eigenfunction of the momentum operator This allows us to discuss amplitudes for electrons moving with positive momentum and with negative momentum So in this region the most general solution is psi C expikR D expikR hspacecm textfor R_rm max delta le R infty There are four amplitudes and that can be expressed in terms of the specified amplitude of the incoming flux eg pretend that we know the flux of electrons that our experimental apparatus shoots at the surface Four equations that can be used to achieve this goal result when and are matched at and at one of the essential properties of solutions to the Schrdinger equation is that they and their first derivative are continuous these properties relate to y being a probability and the momentum being continuous These four equations are C expikR_rm max delta D expikR_rm max delta ikC expikR_rm max delta ik D expikR_rm max delta It is especially instructive to consider the value of that results from solving this set of four equations in four unknowns because the modulus of this ratio provides information about the relative amount of amplitude that exists inside the barrier in the attractive region of the potential compared to that existing in the asymptotic region as incoming flux The result of solving for is To simplify this result in a manner that focuses on conditions where tunneling plays a key role in creating the resonance states it is instructive to consider this result under conditions of a high large and thick large barrier In such a case the factor will be very small compared to its counterpart and so The factor in causes the magnitude of the wave function inside the barrier to be small in most circumstances we say that incident flux must tunnel through the barrier to reach the inner region and that governs the probability of this tunneling Keep in mind that in the energy range we are considering a classical particle could not even enter the region this is why we call this the classically forbidden or tunneling region A classical particle starting in the large region can not enter let alone penetrate this region so such a particle could never end up in the inner region Likewise a classical particle that begins in the inner region can never penetrate the tunneling region and escape into the large region Were it not for the fact that electrons obey a Schrdinger equation rather than Newtonian dynamics tunneling would not occur and for example scanning tunneling microscopy STM which has proven to be a wonderful and powerful tool for imaging molecules on and near surfaces would not exist Likewise many of the devices that appear in our modern electronic tools and games which depend on currents induced by tunneling through various junctions would not be available But or course tunneling does occur and it can have remarkable effects Let us examine an especially important in chemistry phenomenon that takes place because of tunneling and that occurs when the energy E assumes very special values The magnitude of the factor in the above solutions of the Schrdinger equation can become large if the energy E is such that the denominator in the above expression for approaches zero This happens when or if It can be shown that the above condition is similar to the energy quantization condition that arises when bound states of a finite potential well similar to that shown above but with the barrier between and missing and with below There is however a difference In the boundstate situation two energyrelated parameters occur and In the case we are now considering is the same but k sqrtdfracmu D_edelta VEhbar rather than occurs so the two equations involving are not identical but they are quite similar Another observation that is useful to make about the situations in which becomes very large can be made by considering the case of a very high barrier so that is much larger than In this case the denominator that appears in can become small at energies satisfying This condition is nothing but the energy quantization condition that occurs for the particleinabox potential shown in Figure Figure Onedimensional potential similar to the tunneling potential but without the barrier and asymptotic region This potential is identical to the potential that we were examining for but extends to infinity beyond the barrier and the dissociation asymptote displayed by our potential are absent Lets consider what this tunneling problemhbaras taught us First it showed us that quantum particles penetrate into classically forbidden regions It showed that at certain socalled resonance energies tunneling is much more likely than at energies that are offresonance In our model problem this means that electrons impinging on the surface with resonance kinetic energies will have a very high probability of tunneling to produce an electron that is highly localized ie trapped in the region Likewise it means that an electron prepared eg perhaps by photoexcitation from a lowerenergy electronic state within the region will remain trapped in this region for a long time ie will have a low probability of tunneling outward In the case just mentioned it would make sense to solve the four equations for the amplitude C of the outgoing wave in the region in terms of the A amplitude If we were to solve for and then examine under what conditions the amplitude of this ratio would become small so the electron cannot escape we would find the same resonance condition as we found from the other point of view This means that the resonance energies tell us for what collision energies the electron will tunnel inward and produce a trapped electron and at these same energies an electron that is trapped will not escape quickly Whenever one has a barrier on a potential energy surface at energies above the dissociation asymptote but below the top of the barrier here one can expect resonance states to occur at special scattering energies As we illustrated with the model problem these socalled resonance energies can often be approximated by the boundstate energies of a potential that is identical to the potential of interest in the inner region but that extends to infinity beyond the top of the barrier ie beyond the barrier it does not fall back to values below The chemical significance of resonances is great Highly rotationally excited molecules may have more than enough total energy to dissociate but this energy may be stored in the rotational motion and the vibrational energy may be less than In terms of the above model high rotational angular momentum may produce a significant centrifugal barrier in the effective potential that characterizes the molecules vibration but the systems vibrational energy may lie significantly below In such a case and when viewed in terms of motion on an angularmomentummodified effective potential such as I show in Figure the lifetime of the molecule with respect to dissociation is determined by the rate of tunneling through the barrier Figure Radial potential for nonrotating molecule and for rotating molecule In this case one speaks of rotational predissociation of the molecule The lifetime t can be estimated by computing the frequency n at which flux that exists inside strikes the barrier at nu frachbar kmu R_rm max hspacecm rm sec and then multiplying by the probability that flux tunnels through the barrier from to The result is that tau frachbar kmu R_rm max expkappadelta with the energy entering into and being determined by the resonance condition kappasinkR_rm maxkcoskR_rm max minimum We note that the probability of tunneling falls of exponentially with a factor depending on the width d of the barrier through which the particle must tunnel multiplied by which depends on the height of the barrier above the energy available This exponential dependence on thickness and height of the barriers is something you should keep in mind because it appears in all tunneling rate expressions Another important case in which tunneling occurs is in electronically metastable states of anions In socalled shape resonance states the anions extra electron experiences an attractive potential due to its interaction with the underlying neutral molecules dipole quadrupole and induced electrostatic moments as well as a centrifugal potential of the form whose magnitude depends on the angular character of the orbital the extra electron occupies When combined the above attractive and centrifugal potentials produce an effective radial potential of the form shown in Figure for the case in which the added electron occupies the orbital which has character when viewed from the center of the NN bond Again tunneling through the barrier in this potential determines the lifetimes of such shape resonance states Figure Effective radial potential for the excess electron in occupying the orbital which has a dominant component Although the examples treated above analytically involved piecewise constant potentials so the Schrdinger equation and the boundary matching conditions could be solved exactly many of the characteristics observed carry over to more chemically realistic situations In fact one can often model chemical reaction processes in terms of motion along a reaction coordinate s from a region characteristic of reactant materials where the potential surface is positively curved in all direction and all forces ie gradients of the potential along all internal coordinates vanish to a transition state at which the potential surfaces curvature along s is negative while all other curvatures are positive and all forces vanish onward to product materials where again all curvatures are positive and all forces vanish A prototypical trace of the energy variation along such a reaction coordinate is in Figure Figure Energy profile along a reaction path showing the barrier through which tunneling may occur Near the transition state at the top of the barrier on this surface tunneling through the barrier plays an important role if the masses of the particles moving in this region are sufficiently light Specifically if or atoms are involved in the bond breaking and forming in this region of the energy surface tunneling must usually be considered in treating the dynamics Within the above reaction path point of view motion transverse to the reaction coordinate is often modeled in terms of local harmonic motion although more sophisticated treatments of the dynamics is possible This picture leads one to consider motion along a single degree of freedom with respect to which much of the above treatment can be carried over coupled to transverse motion along all other internal degrees of freedom taking place under an entirely positively curved potential which therefore produces restoring forces to movement away from the streambed traced out by the reaction path This point of view constitutes one of the most widely used and successful models of molecular reaction dynamics and is treated in more detail in Chapters and of this text Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Enthalpy Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers In Chapter we introduce the enthalpy function which we define as When the only form of work possible is pressurevolume work and a system change occurs at constant pressure the enthalpy change is synonymous with the heat added to the system only PV work Since we define it follows that Recalling our earlier discovery that we have the important parallel relationships and We can find the enthalpy change for heating a substance at constant pressure by integrating its constantpressure heat capacity over the change in temperature That is implies that Similarly we have for a process in which a substance is heated at constant volume One reason that the enthalpy function is useful in chemistry is that many processes are carried out at conditions constant pressure only work where the enthalpy change is synonymous with the heat exchanged The heat exchanged in a process is frequently an important consideration If we want to carry out an endothermic process we must provide means to add sufficient heat If we want to carry out an exothermic process we may have to make special arrangements to safely transfer the heat evolved from the system to its surroundings One of our principal objectives is to predict whether a given process can occur spontaneously We will see that the heat evolved in a process is not a generally valid predictor of whether or not the process can occur spontaneously however it is true that a very exothermic process is usually one that can occur spontaneously We will see that is a rigorous criterion for whether the process can occur spontaneously if and only if the process is one for which both the entropy and the pressure remain constant Entropy Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors and Attributions In addition to learning that the efficiency of a Carnot engine depends only on the high and low temperatures more interesting things can be derived through the exploration of this system For example consider the total heat transferred in the cycle Making the substitution the total heat flow can be seen to be given by It is clear that the two terms do not have the same magnitude unless This is sufficient to show that is not a state function since its net change around a closed cycle is not zero as any value of a state function must be However consider what happens when the sum of is considered This is the behavior expected for a state function It leads to the definition of entropy in differential form In general will be larger than since the reversible pathway defines the maximum heat flow So it is easy to calculate entropy changes as one needs only to define a reversible pathway that connects the initial and final states and then integrate over that pathway And since is defined using for a reversible pathway is independent of the actual path a system follows to undergo a change Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Entropy and Disorder Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors and Attributions A common interpretation of entropy is that it is somehow a measure of chaos or randomness There is some utility in that concept Given that entropy is a measure of the dispersal of energy in a system the more chaotic a system is the greater the dispersal of energy will be and thus the greater the entropy will be Ludwig Boltzmann OConnor Robertson understood this concept well and used it to derive a statistical approach to calculating entropy Boltzmann proposed a method for calculating the entropy of a system based on the number of energetically equivalent ways a system can be constructed Boltzmann proposed an expression which in its modern form is This rather famous equation is etched on Boltzmanns grave marker in commemoration of his profound contributions to the science of thermodynamics Figure Figure Ludwig Boltzmann Example Calculate the entropy of a carbon monoxide crystal containing mol of and assuming that the molecules are randomly oriented in one of two equivalent orientations Solution Using the Boltzmann formula Equation refBoltz And using the calculation is straightforward Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Entropy and Predicting Change Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers The entropybased criteria that we develop in Section through Section are of central importance If we are able to evaluate the change in the entropy of the universe for a prospective process and find that it is greater than zero we can conclude that the process can occur spontaneously The reverse of a spontaneous process cannot occur it is an impossible process and the change in the entropy of the universe for such a process must be less than zero Since an equilibrium process is a reversible process the entropy of the universe must remain unchanged when a system goes from an initial state to a final state along a path whose every point is an equilibrium state Using another figure of speech we often say that a change that occurs along a reversible path is a change that occurs at equilibrium These conclusions are what make the entropy function useful If we can calculate for a prospective process we know whether the system is at equilibrium with respect to that process whether the process is possible or whether the process cannot occur If we find for a process we can conclude that the process is possible however we cannot conclude that the process will occur Indeed many processes can occur spontaneously but do not do so For example hydrocarbons can react spontaneously with oxygen most do so only at elevated temperatures or in the presence of a catalyst The criteria are completely general They apply to any process occurring under any conditions To apply them we must determine both and By definition the system comprises the part of the universe that is of interest to us the need to determine would appear to be a nuisance This proves not to be the case So long as the surroundings have a welldefined temperature we can develop additional criteria for equilibrium and spontaneous change in which does not occur explicitly In we develop criteria that apply to reversible processes In we find a general relationship for that enables us to develop criteria for spontaneous processes To develop the criteria for spontaneous change we must define what we mean by spontaneous change more precisely To define a spontaneous process in an isolated system as one that can take place on its own is reasonably unambiguous However when a system is in contact with its surroundings the properties of the surroundings affect the change that occurs in the system To specify a particular spontaneous process we must specify some properties of the surroundings ormore preciselyproperties of the system that the surroundings act to establish The ideas that we develop in lead to criteria for changes that occur while one or more thermodynamic functions remain constant These criteria supplement the secondlaw criteria In using these criteria we can say that the change occurs subject to one or more constraints Some of these criteria depend on the magnitudes of and in the prospective process We also find criteria that are expressed using new state functions that we call the Helmholtz and Gibbs free energies In the next section we introduce these functions Entropy and Spontaneous Change Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers In a reversible process the changes that occur in the system are imposed by the surroundings reversible change occurs only because the system responds to changes in the conditions imposed on it by its surroundings A reversible process is driven by the surroundings In contrast a spontaneous process is driven by the system Nevertheless when a spontaneous process occurs under some specific set of imposed conditions specific values of the temperature and pressure for example the systems equilibrium state depends on these conditions To specify a particular spontaneous change we must specify enough constraints to fix the final state of the system To see these points from a slightly different perspective let us consider a closed reversible system in which only pressurevolume work is possible Duhems theorem asserts that a change in the state of this system can be specified by specifying the changes in some pair of state functions say and If the imposed values of and are constant at their eventual equilibrium values but the system is changing the system cannot be on a Gibbsian equilibrium manifold We say that the system is undergoing a spontaneous change at constant and This description is a figure of speech in that the systems and values do not necessarily attain the imposed values and become constant until equilibrium is reached An example is in order A system whose original pressure and temperature are and can undergo a spontaneous change while the surroundings impose a constant pressure and the system is immersed in constant temperature bath at The pressure and temperature of the system may be indeterminate as the process occurs but the equilibrium pressure and temperature must be and If the surroundings operate to impose particular values of and on the system then the position at which the system eventually reaches equilibrium is determined by these values The same equilibrium state is reached for any choice of surroundings that imposes the same values of and on the system at the time that the system reaches equilibrium For every additional form of nonpressurevolume work that affects the system we must specify the value of one additional variable in order to specify a unique equilibrium state The entropy changes that occur in the system and its surroundings during a spontaneous process have predictive value However our definitions do not enable us to find the entropy change for a spontaneous process and the temperature of the system may not have a meaningful value On the other hand we can always carry out the process so that the temperature of the surroundings is known at every point in the process Indeed if the system is in thermal contact with its surroundings as the process occurs we cannot specify the conditions under which the process occurs without specifying the temperature of the surroundings along this path Figure describes a spontaneous process whose path can be specified by the values of thermodynamic variable and the temperature of the surroundings as a function of time Let us denote the curve that describes this path as We can divide this path into short intervals Let denote a short segment of this path along which the temperature of the surroundings is approximately constant For our present purposes the temperature of the system is irrelevant since the process is spontaneous the temperature of the system may have no meaningful value within the interval As the system traverses segment it accepts a quantity of heat from the surroundings which are at temperature The heat exchanged by the surroundings within is Below we show that it is always possible to carry out the process in such a way that the change in the surroundings occurs reversibly Then and since it follows that This is the Clausius inequality It plays a central role in the thermodynamics of spontaneous processes When we make the intervals arbitrarily short we have To demonstrate that we can measure the entropy change in the surroundings during a spontaneous process let us use a conceptual device to transfer the heat that must be exchanged from the surroundings at temperature to the system As sketched in Figure we imagine a very small reversible idealgas Carnot engine whose hightemperature reservoir is also very small We suppose that the Carnot engine delivers a very small heat increment to the high temperature reservoir in every cycle While the system is within we maintain the Carnot engines high temperature reservoir at and allow heat to pass from the high temperature reservoir to the system The high temperature reservoir is the only part of the surroundings that is in thermal contact with the system is the only heat exchanged by the system while it is within Figure Using a reversible Carnot engine to exchange heat with a spontaneously changing system To maintain the high temperature reservoir at we operate the Carnot engine for a large integral number of cycles such that and do so at a rate that just matches the rate at which heat passes from the hightemperature reservoir to the system When the system passes from pathsegment to pathsegment we alter the steps in the reversible Carnot cycle to maintain the hightemperature reservoir at the new surroundings temperature The lowtemperature heat reservoir for this Carnot engine is always at the constant temperature Let the heat delivered from the hightemperature reservoir to the Carnot engine within be We have Let the heat delivered from the lowtemperature reservoir to the Carnot engine within be Let the heat delivered to the lowtemperature reservoir within be We have Since the Carnot engine is reversible we have and so that While the system is within it receives an increment of heat from the high temperature reservoir Simultaneously three components in the surroundings also exchange heat Let the entropy changes in the hightemperature reservoir the Carnot engine and the lowtemperature reservoir be and respectively The high temperature reservoir receives heat from the Carnot engine and delivers the same quantity of heat to the system The net heat accepted by the high temperature reservoir is zero No change occurs in the hightemperature reservoir We have The reversible Carnot engine completes an integral number of cycles so that The low temperature reservoir accepts heat at the fixed temperature during the reversible operation of the Carnot engine so that The entropy change in the surroundings as the system passes through is so that as we observed above Since can be any part of path C and can be made arbitrarily short we have for every increment of any spontaneous process occurring in a closed system that can exchange heat with its surroundings and If the temperature of the surroundings is constant between any two points A and B on curve C we can integrate over this interval to obtain and For an adiabatic process For any arbitrarily small increment of an adiabatic process It follows that and for any spontaneous adiabatic process Entropy Changes for A Reversible Process Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Let us consider a closed system that undergoes a reversible change while in contact with its surroundings Since the change is reversible the portion of the surroundings that exchanges heat with the system is at the same temperature as the system From and the definition the entropy changes are and Evidently for any reversible process we have Note that these ideas are not sufficient to prove that the converse is true From only these ideas we cannot prove that for a process means that the process is reversible it remains possible that there could be a spontaneous process for which However our entropybased statement of the second law does assert that the converse is true that is necessary and sufficient for a process to be reversible In the next section we use the machinebased statement of the second law to show that for any spontaneous process in an isolated system We introduce heuristic arguments to infer that is not possible for a spontaneous process in an isolated system From this we show that for any spontaneous process and hence that is not possible for any spontaneous process We conclude that is sufficient to establish that the corresponding process is reversible Entropy Changes for A Spontaneous Process in An Isolated System Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers In Section we consider the entropy changes in a system and its surroundings when the process is reversible We consider now the diametrically opposite situation in which an isolated system undergoes a spontaneous change From the entropybased statement of the second law we know how the entropy of this system and its surroundings change Since the system is isolated no change occurs in the surroundings Thus and since we have Let us attempt to develop these conclusions from the machinebased statement of the second law Since the process occurs irreversibly we cannot use the heat of the process to find the entropy change for the system We can calculate the entropy change for a process from the defining equation only if the process is reversible However entropy is a state function using the figure of speech that we introduce in Section we can find the entropy change for the spontaneous process by evaluating along a second and reversible path that connects the same initial and final states Figure A cycle that includes a spontaneous process in an isolated system In Figure these paths are diagrammed in temperatureentropy space The transition from state A to state B occurs irreversibly and therefore it does not necessarily correspond to a path that we can specify on this diagram The dashed line drawn for this transition is supposed to remind us of this fact We can readily devise a reversible path from B back to A First we reversibly and adiabatically return the temperature of the system to its original value In this step the system does work on the surroundings or vice versa The system reaches point C on the diagram Then we reversibly and isothermally add or remove heat from the system to return to the original state at point A For the transfer of heat to be reversible we must have for this step Hence the final and original temperature of the system at point A is equal to the temperature of the surroundings The reversible path must exist because the tiling theorem asserts that adiabats vertical lines and isotherms horizontal lines tile the plane arbitrarily densely Taken literally this description of state A is inconsistent We suppose that the initial state A is capable of spontaneous change therefore it cannot be an equilibrium state We suppose that the final state A is reached by a reversible process therefore it must be an equilibrium state We bridge this contradiction by refining our definition of the initial state The final state A is an equilibrium state with welldefined state functions What we have in mind is that these final equilibriumstate values also characterize the initial nonequilibrium state Evidently the initial state A that we have in mind is a hypothetical state This hypothetical state approximates the state of a real system that undergoes spontaneous change By invoking this hypothetical initial state we eliminate the contradiction between our descriptions of initial state A and final state A Given a real system that undergoes spontaneous change we must find approximate values for the real systems state functions by finding an equilibriumor quasiequilibriumsystem that adequately models the initial state of the spontaneously changing system In the development below we place no constraints on the nature of the system or the spontaneous process We assume that the state functions of any hypothetical initial state A can be adequately approximated by some equilibriumstate model However before we consider the general argument let us show how these conditions can be met for another specific system Consider a vessel whose interior is divided by a partition The real gas of a pure substance occupies the space on one side of the partition The space on the other side of the partition is evacuated We suppose that this vessel is isolated The real gas is at equilibrium We can measure its state functions including its pressure volume and temperature Now suppose that we puncture the partition As soon as we do so the gas expands spontaneously to fill the entire vessel reaching a new equilibrium position at a new pressure volume and temperature The gas undergoes a free expansion as defined in Section At the instant the partition is punctured the system becomes able to undergo spontaneous change In this hypothetical initial state before any significant quantity of gas passes through the opening neither the actual condition of the gas nor the values of its state functions have changed After the expansion to the new equilibrium state the original state can be restored by reversible processes of adiabatic compression and isothermal volume adjustment Problems and in Chapter deal with the energy and entropy changes for ideal and real gases around a cycle in which spontaneous expansion in an isolated system is followed by reversible restoration of the initial state Returning to the general cycle depicted in Figure we see that there are some important conditions on the heat and work terms in the individual steps Since the system is isolated while it undergoes the transition from A to B it exchanges no heat or work with the surroundings in this step For the reversible adiabatic transition from B to C in every incremental part of the path The transition from C to A occurs reversibly and isothermally letting the heat of this step be the entropy changes for these reversible steps are from the defining equation and The energy and entropy changes around this cycle must be zero whether the individual steps occur reversibly or irreversibly We have and We want to analyze this cycle using the machinebased statement of the second law We have and Let us assume that the system does net work on the surroundings as this cycle is traversed so that Then and it follows that The system exchanges heat with the surroundings in only one step of this process In this step the system extracts a quantity of heat from a reservoir in the surroundings The temperature of this reservoir remains constant at throughout the process The heat extracted by the system is converted entirely into work This result contradicts the machinebased statement of the second law Hence is false it follows that and that For the entropy change in the spontaneous process in the isolated system we have Now we introduce the premise that If this is true the entropy change in the spontaneous process in the isolated system becomes The converse is also true that is implies that The premise that is independent of the machinebased statement of the second law which requires only that as we just demonstrated It is also independent of the first law which requires only that If we can conclude that for a spontaneous process in an isolated system we must have and These conditions correspond to doing work on the system and finding that heat is liberated by the system There is no objection to this it is possible to convert mechanical energy into heat quantitatively The conclusions that and have important consequences we consider them below First however we consider a line of thought that leads us to infer that and hence that must be true Because and we have The system can be taken from state A to state B by the reversible process A Above we see that if we have In we introduce Duhems theorem which asserts that two thermodynamic variables are sufficient to specify the state of a closed reversible system in which only pressurevolume work is possible We gave a proof of Duhems theorem when the two variables are chosen from among the pressure temperature and composition variables that describe the system We avoided specifying whether other pairs of variables can be used If we assume now that specifying the variables energy and entropy is always sufficient to specify the state of such a system it follows that states A and B must in fact be the same state In and in greater detail in Chapter we see that the first law and our entropybased statement of the second law do indeed imply that specifying the energy and entropy specifies the state of a closed reversible system in which only pressurevolume work is possible If state A and state B are the same state that is if the state functions of state A are the same as those of state B it is meaningless to say that there is a spontaneous process that converts state A to state B Therefore if A can be converted to B in a spontaneous process in an isolated system it must be that That is From the machinebased statement of the second law we find When we supplement this conclusion with our Duhems theorembased inference that we can conclude that for any spontaneous process in any isolated system Because the system is isolated we have and For any spontaneous process in any isolated system we have We can also conclude that the converse is true that is if for a process in which an isolated system goes from state A to state B the process must be spontaneous Since any process that occurs in an isolated system must be a spontaneous process it is only necessary to show that implies that state B is different from state A This is trivial Because entropy is a state function requires that state B be different from state A None of our arguments depends on the magnitude of the change that occurs Evidently the same inequality must describe every incremental portion of any spontaneous process otherwise we could define an incremental spontaneous change for which the machinebased statement of the second law would be violated For every incremental part of any spontaneous change in any isolated system we have and These are pivotally important results we explore their ramifications below Before doing so however let us again consider a system in which only pressurevolume work is possible There is an alternative way to express the idea that such a system is isolated Since an isolated system cannot interact with its surroundings in any way it cannot exchange energy with its surroundings Its energy must be constant Since it cannot exchange pressurevolume work its volume must be constant Hence isolation implies constant and If only pressurevolume work is possible the converse must be true that is if only pressurevolume work is possible constant energy and volume imply that there are no interactions between the system and its surroundings Therefore constant and imply that the system is isolated and it must be true that In this case a spontaneous process in which and are constant must be accompanied by an increase in the entropy of the system If is constant and only pressurevolume work is possible the process involves no work We have a criterion for spontaneous change spontaneous process only pressurevolume work where the subscripts indicate that the energy and volume of the system are constant In Section we arrive at this conclusion by a different argument Equilibria and Reversible Processes Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers The distinction between a system at equilibrium and a system undergoing reversible change is razorthin What we have in mind goes to the way we choose to define the system and centers on the origin of the forces that affect its energy For a system at equilibrium the forces are fixed For a system undergoing reversible change some of the forces originate in the surroundings and those that do are potentially variable To raise a bowling ball reversibly we apply an upward force exactly equal and opposite to the downward force due to gravity At any point in this reversible motion the ball is stationary which is the reason we say that a reversible process is a hypothetical change If we were to change the system slightly by adding a shelf to support the ball at exactly the same height the forces on the ball would be the same however the forces would be fixed and we would say that the ball is at equilibrium We can further illustrate this distinction by returning to the waterwatervapor system If an unchanging waterwatervapor mixture is enclosed in a container whose dimensions are fixed like a sealed glass bulb we say that the system is at equilibrium If a piston encloses the same collection of matter and the surroundings apply a force on the piston that balances the pressure exerted by the mixture we can say that the system is changing reversibly In Section we used the term primitive equilibrium to refer to an equilibrium state in which all of the state functions are fixed A system that can undergo reversible change without changing the number or kinds of phases present can be in an infinite number of such states Since the set of such primitive equilibrium states encompasses the accessible equilibrium conditions in the sense of Gibbs phase rule we can call this set a Gibbsian equilibrium manifold Equilibria in Chemical Reactions Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Equilibria involving chemical reactions share important characteristics with phase and distribution equilibria In Chapter we develop the equilibrium constant expression from ideas about reaction rates For the present comparison let us consider the equilibrium between the gases nitrogen dioxide and dinitrogen tetroxide Suppose that we trap a quantity of pure in a cylinder closed with a piston If we fix the temperature and volume of this system the dissociation reaction occurs until equilibrium is achieved at some system pressure For present purposes let us assume that both and behave as ideal gases The equilibrium system pressure will be equal to the sum of the partial pressures If we now do a series of experiments in which we hold the volume constant while allowing the temperature to change we find a continuous series of pressuretemperature combinations at which the system is at equilibrium This curve is sketched in Figure It is much like the curve describing the dependence of the waterwatervapor equilibrium on pressure and temperature Figure System pressure versus temperature for dissociation If we hold the temperature constant and allow the volume to vary we can change the force on the piston to keep the total pressure constant at a new value The position of the chemical equilibrium will change At the new equilibrium position the new and partial pressures will satisfy the total pressure relationship When we repeat this experiment we find that whatever the total pressure the equilibrium partial pressures are related to one another as sketched in Figure Figure Equilibrium compositions for dissociation at a fixed temperature We find that the experimental data fit the equation where is the equilibrium constant for the reaction Pressure is a measure of gas concentration Later we see that the equilibrium constant can be expressed more rigorously as a ratio of fugacitiesor activities Equilibrium and Classical Thermodynamics Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers We develop classical thermodynamics by reasoning about reversible processesprocesses in which a system passes through a series of equilibrium states Any such process corresponds to a path on one or more of the Gibbsian manifolds that are available to the system The resulting theory consists of equations that relate the changes in the values of the systems state functions as the system undergoes a reversible change For this reason the body of theory that we are calling classical thermodynamics is often called equilibrium thermodynamics or reversible thermodynamics As we discuss further in Chapter any change that we can actually observe in a real system must be the result of a spontaneous process In a reversible process both the initial and the final states are equilibrium states In a spontaneous process the initial state of the system is not an equilibrium state A spontaneous process begins with the system in a nonequilibrium state and proceeds until an equilibrium state is reached The domain of classical thermodynamicsreversible processesis distinct from the domain of real observations because real observations can be made only for spontaneous processes We bridge this gap by careful selection of realworld systems to serve as models for the reversible systems that inhabit our theory That is we find that we can make measurements on nonequilibrium systems and irreversible processes from which we can estimate the properties of equilibrium systems and reversible processes Saying almost the same thing from another perspective we find that the classical thermodynamic equations that apply to equilibrium states can also be approximately valid for nonequilibrium states For many nonequilibrium states notably those whose individual phases are homogenous the approximations can be very good For other nonequilibrium states notably those whose individual phases are markedly inhomogeneous these approximations may be very poor Equilibrium and Reversibility Phase Equilibria Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers To review the general characteristics of phase equilibria let us consider a familiar system Suppose that we have a transparent but very strong cylinder sealed with a frictionless piston within which we have trapped a quantity of pure liquid water at some high pressure We can fix the pressure of the liquid water at any value we choose by applying an appropriate force to the piston Suppose that we hold the temperature constant and force the volume to increase by withdrawing the piston in very small increments Because pure water is not compressed easily we find initially that the pressure of the water decreases and does so in very large increments However after some small increase in the volume we find that imposing a further volume increase changes the systems behavior abruptly The system undergoes a profound change What was formerly pure liquid becomes a mixture of liquid and gas As we impose still further volume increases the pressure of the system remains constant additional liquid passes from the liquid to the gas phase and we find that we must supply substantial amounts of heat in order to keep the temperature of the system constant If we continue to force volume increases in this manner vaporization continues until all of the liquid evaporates If we impose a decrease in the volume of the twophase system we see the process reverse The pressure of the system remains constant some of the gas condenses to liquid and the system gives up heat to the surroundings For any given temperature these conversions are precisely balanced at some particular pressure and these conditions characterize a state of liquidvapor equilibrium At any given pressure the equilibrium temperature is called the boiling point of the liquid The equilibrium pressure and temperature completely specify the state of the system except for the exact amounts of liquid and gaseous water present If we begin with this system in a state of liquidvapor equilibrium we can increase the amount of vapor by imposing a small volume increase Conversely we can decrease the amount of vapor by imposing a very small volume decrease At the equilibrium temperature and pressure changing the imposed volume by an arbitrarily small amount from to is sufficient to reverse the direction of the change that occurs in the system We call any process whose direction can be reversed by an arbitrarily small change in a thermodynamic state function a reversible process Evidently there is a close connection between reversible processes and equilibrium states If a process is to occur reversibly the system must pass continuously from one equilibrium state to another In this description the reversible constanttemperature vaporization of water is driven by arbitrarily small volume changes The system responds to these imposed volume changes so as to maintain a constant equilibrium vapor pressure at the specified temperature We say that the reversible process takes place at constant pressure and temperature We can also describe this process as being driven by arbitrarily small changes in the applied pressure If the applied pressure exceeds the equilibrium vapor pressure by an arbitrarily small increment condensation occurs if the applied pressure is less than the equilibrium vapor pressure by an arbitrarily small increment vaporization occurs To describe this tersely we introduce a figure of speech and say that the reversible process occurs while the system pressure and the applied pressure are equal Literally of course there can be no change when these pressures are equal To cause water to vaporize at a constant temperature and pressure we must add heat energy to the system This heat is called the latent heat of vaporization or the enthalpy of vaporization and it must be supplied from some entity in the surroundings When water vapor condenses this latent heat must be removed from the system and taken up by the surroundings The enthalpy change for vaporizing one mole of a substance is usually denoted It varies with temperature and pressure Tables usually give experimental values of the equilibrium boiling temperature at a pressure of bar or atm then they give the enthalpy of vaporization at this temperature and pressure We discuss the enthalpy function in Chapter Four conditions are sufficient to exactly specify either the initial or the final state the number of moles of liquid the number of moles of gas the pressure and the temperature The change is a conversion of some liquid to gas or vice versa We can represent this change as a transition from an initial state to a final state where and are the initial numbers of moles of liquid and gas respectively and is the incremental number of moles vaporized The initial pressure and temperature are the same as the final pressure and temperature Effecting this change requires that a quantity of heat be added to the system without changing the temperature of the system This introduces another requirement that a reversible process must satisfy If the reversibly vaporizing water is to take up an arbitrarily small amount of heat the system must be in contact with surroundings that are hotter than the system The temperature difference between the system and its surroundings must be arbitrarily small because we can describe exactly the same process as being driven by contacting the system at temperature with surroundings at temperature If we keep the applied pressure constant at the temperature equilibrium vapor pressure the system volume increases We can reverse the direction of change by changing the temperature of the surroundings from to If the process is to satisfy our criterion for reversibility the difference between these two temperatures must be arbitrarily small To describe this requirement tersely we again introduce a figure of speech and say that the reversible process occurs while the system temperature and the surroundings temperature are equal If we repeat the waterincylinder experiment with the temperature held constant at a slightly different value we get similar results There is again a pressure at which the process of converting liquid to vapor is at equilibrium At this temperature and pressure both liquid and gaseous water can be present in the system and so long as no heat is added or removed from the system the amount of each remains constant When we hold the pressure of the system constant at the equilibrium value and supply a quantity of heat to the system a quantity of liquid is again converted to gaseous water The quantity of heat required to convert one mole of liquid to gaseous water phase equilibria is slightly different from the quantity required in the previous experiment This is what we mean when we say that the enthalpy of vaporization varies with temperature This experiment can be repeated for many temperatures So long as the temperature is in the range mathrm we find a pressure at which liquid and gaseous water are in equilibrium If we plot the results they lie on a smooth curve which is sketched in Figure This curve represents the combinations of pressure and temperature at which liquid water and gaseous water are in equilibrium Figure Water liquidvapor equilibrium Below an equilibrium system containing only liquid and gaseous water cannot exist At high pressures a twophase equilibrium system contains solid and liquid at sufficiently low pressures it contains solid and gas Above the distinction between liquid and gaseous water vanishes The water exists as a single dense phase This is the critical temperature Above the critical temperature there is a single fluid phase at any pressure If we keep the pressure constant and remove heat from a quantity of liquid water the temperature decreases until we eventually reach a temperature at which the water begins to freeze to ice At this point water and ice are in equilibrium Further removal of heat does not decrease the temperature of the waterice system rather the temperature remains constant and additional water freezes into ice Only when all of the liquid has frozen does further removal of heat cause a further decrease in the temperature of the system When we repeat this experiment at a series of temperatures we find a continuous line of pressuretemperature points that are liquidice equilibrium points Figure The phase diagram for water Note that the ordinate values for the solid liquid and liquid gas equilibria are severely compressed As sketched in Figure the liquidice equilibrium line intersects the liquidvapor equilibrium line At this intersection liquid water ice and water vapor are all in equilibrium with one another There is only one such point It is called the triple point of water The ice point or melting point of water is the temperature at which solid and liquid water are in equilibrium at one atmosphere in the presence of air The water contains dissolved air The triple point occurs in a purewater system it is the temperature and pressure at which gaseous liquid and solid water are in equilibrium By definition the triple point temperature is K Experimentally the pressure at the triple point is Pa Experimentally the melting point is K To freeze a liquid we must remove heat To fuse melt the same amount of the solid at the same temperature and pressure we must add the same amount of heat This heat is called the latent heat of fusion or the enthalpy of fusion The enthalpy of fusion for one mole of a substance is usually denoted It varies slightly with temperature and pressure Tables usually give experimental values of the equilibrium melting temperature at a pressure of bar or atm then they give the enthalpy of fusion at this temperature and pressure At low pressures and temperatures ice is in equilibrium with gaseous water A continuous line of pressuretemperature points represents the conditions under which the system contains only ice and water vapor As the temperature increases the icevapor equilibrium line ends at the triple point The conversion of a solid directly into its vapor is called sublimation To sublime a solid to its vapor requires the addition of heat This heat is called the latent heat of sublimation or the enthalpy of sublimation The enthalpy of sublimation for one mole of a substance is usually denoted It varies slightly with temperature and pressure Exact Differentials and State Functions Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Now let us consider the general case of a continuous function for which the exact differential is We want to integrate the exact differential over very short paths like paths a and b in Section Let us evaluate the integral between and over the paths a and b sketched in Figure Figure Alternative paths from to Path a has two linear segments The first segment is the portion of the line as goes from to Along the first segment The second segment is the portion of the line as goes from to Along the second segment Path b has two linear segments also The first segment is the portion of the line as goes from to Along the first segment The second segment is the portion of the line as goes from to Along the second segment Along path a we have Along path b In the limit as and become arbitrarily small we must have so that Rearranging this equation so that terms in are on one side and terms in are on the other side dividing both sides by and taking the limit as and we have These limits are the partial derivative of with respect to and of with respect to That is and This shows that if is a continuous function of and whose partial derivatives exist then The mixed second partial derivative of is independent of the order of differentiation We also write these second partial derivatives as and To summarize these points if is a continuous function of and all of the following are true represents a surface in a threedimensional space is a state function The total differential is The total differential is exact The line integral of between two points is independent of the path of integration The line integral of around any closed path is zero The mixed secondpartial derivatives are equal that is Experimental Determination of Rate Laws Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics Method of Initial Rates The determination of a rate law is a matter of finding an empirical equation that adequately describes reactionrate data We can distinguish two general approaches to this task One approach is to measure reaction rate directly That is for we measure the reaction rate in experiments where the concentrations and of reactants and products are known The other is to measure a concentration at frequent time intervals as a batch reaction goes nearly to completion We then seek a differential equation that is consistent with this concentrationversustime data If the reaction is the only process that affects direct measurement of the reaction rate can be effected by measuring over a short time interval in which the concentrations and do not change appreciably This is often difficult to implement experimentally primarily because it is difficult to measure small values of with the necessary accuracy at known values of and Method of Initial Rates The method of initial rates is an experimentally simple method in which the reaction rate is measured directly Initialrate measurements are extensively used in the study of enzymecatalyzed reactions Direct measurement of reaction rate can also be accomplished using a flow reactor We discuss the method of initial rates a particular kind of flow reactor known as a CSTR and enzyme catalysis in Sections and respectively The most common reactionrate experiment is a batch reaction in which we mix the reactants as rapidly as possible and then monitor the concentration vs time of one or more of the reactants or products as the reaction proceeds We do the mixing so that the initially mixed reactants are at a known temperature which can be maintained constant for the remainder of the experiment The data from such an experiment are a set of concentrations and the times at which they are measured To find the rate law corresponding to these concentrationversustime data we employ a trialanderror procedure We guess what the rate law is likely to be We then obtain a general solution for this differential equation This solution predicts the dependence of concentrations versus time as a function of one or more rate constants If we can obtain a satisfactory fit of experimental concentrationversustime data to the concentrationversustime equation predicted by the rate law we conclude that the rate law is a satisfactory representation of the experimental data For a reaction in a closed constantvolume system we would want to test a firstorder rate law rate law which we can express in several alternative ways Using the changing concentration of A to express the rate separating variables and integrating between the initial concentration at and concentration at time gives so that or Frequently it is convenient to introduce the extent of reaction or the concentration of a product as a parameter In the present instance if the initial concentration of is zero Then at any time t we have and the firstorder rate equation can be written as which we rearrange and integrate between the limits and as To give It is easy to test whether concentration versus time data conform to the firstorder decay model If they do a plot of or versus time is a straight line For a reaction we would want to test a rate law rate of the form If the initial concentration of is zero and at any time The rate law can be written as and rearranged and integrated as to give or If concentrationversustime data conform to this secondorder rate law a plot of versus time is a straight line For a reaction we would want to test a rate law of the form If the initial concentration of is again zero and at any time The rate law can be written as If this can be integrated by partial fractions to give If experimental data conform to this equation a plot of versus time is linear In practice this often has disadvantages and experiments to study reactions like this typically exploit the technique of flooding Flooding is a widely used experimental technique that enables us to simplify a complex rate law in a way that makes it more convenient to test experimentally In the case we are considering we can often arrange to carry out the reaction with the initial concentration of much greater than the initial concentration of Then the change that occurs in the concentration of during the reaction has much less effect on the reaction rate than the change that occurs in the concentration of in the rate equation it becomes a good approximation to let at all times For a fuller consideration of this point see problem The secondorder rate equation simplifies to where Since the simplified rate equation is approximately first order the observed rate constant is the slope of a plot of versus is called a pseudofirstorder rate constant Of course one such experiment tests only whether the true rate law is first order in It tells nothing about the dependence on If we do several such experiments at different initial concentrations of the resulting set of values must be directly proportional to the corresponding values This can be tested graphically by plotting versus If the rate law is first order in the resulting plot is linear with an intercept of zero The slope of this plot is the secondorder rate constant Flooding works by simplifying the rate law that is observed in a given experiment Similar simplification can be achieved by designing the experiment so that the initial concentrations of two or more reactants are proportional to their stoichiometric coefficients For the reaction and the expected rate law we would initiate the experiment with equal concentration of reactants and Letting and the concentrations of and at longer times become The rate law becomes effectively second order Experimental Probes of Electronic Structure Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Visible and Ultraviolet Spectroscopy The Electronic Transition Dipole and Use of Point Group Symmetry The FranckCondon Factors Time Correlation Function Expressions for Transition Rates Line Broadening Mechanismsa Doppler Broadeningb Pressure Broadeningc Rotational Diffusion Broadeningd Lifetime or Heisenberg Homogeneous Broadeninge Site Inhomogeneous Broadening Photoelectron Spectroscopy Probing Continuum OrbitalsContributors and Attributions Visible and Ultraviolet Spectroscopy Visible and ultraviolet spectroscopies are used to study transitions between states of a molecule or ion in which the electrons orbital occupancy changes We call these electronic transitions and they usually require light in the cm to cm regime When such transitions occur the initial and final states generally differ in their electronic vibrational and rotational energies because any change to the electrons orbital occupancy will induce changes in the BornOppenheimer energy surface which in turn governs the vibrational and rotational character Excitations of innershell and core orbital electrons may require even higher energy photons as would excitations that eject an electron The interpretation of all such spectroscopic data relies heavily on theory as this Section is designed to illustrate The Electronic Transition Dipole and Use of Point Group Symmetry The interaction of electromagnetic radiation with a molecules electrons and nuclei can be treated using perturbation theory as we discussed in Chapter The result is a standard expression that we derived in Chapter R_if fracpihbar fomega_fi textbfE_ langle Phi_f boldsymbolmu Phi_irangle for the rate of photon absorption between initial and final states In this equation is the intensity of the photon source at the frequency is the frequency corresponding to the transition under study and is the electric field vector of the photon field The vector is the electric dipole moment of the electrons and nuclei in the molecule Because each of these wave functions is a product of an electronic ye a vibrational and a rotational function we realize that the electronic integral appearing in this rate expression involves a transition dipole matrix element between the initial and final electronic wave functions This element is a function of the internal vibrational coordinates of the molecule and is a vector locked to the molecules internal axis frame Molecular pointgroup symmetry can often be used to determine whether a particular transitions dipole matrix element will vanish and as a result the electronic transition will be forbidden and thus predicted to have zero intensity If the direct product of the symmetries of the initial and final electronic states and do not match the symmetry of the electric dipole operator which has the symmetry of its and components these symmetries can be read off the right most column of the character tables the matrix element will vanish For example the formaldehyde molecule has a ground electronic state that has symmetry in the point group Its singlet excited state also has symmetry because both the and orbitals are of symmetry In contrast the lowest these orbitals are shown in Figure singlet excited state is of symmetry because the highest energy oxygen centered nonbonding orbital is of symmetry and the orbital is of symmetry so the Slater determinant in which both the and orbitals are singly occupied has its symmetry dictated by the direct product which is Figure Electronic Transition From the Nonbonding orbital to the antibonding Orbital of Formaldehyde The transition thus involves ground and excited states whose direct product is of symmetry This transition thus requires that the electric dipole operator possess a component of symmetry A glance at the point groups character table shows that the molecular axis is of symmetry Thus if the lights electric field has a nonzero component along the symmetry axis the molecules axis the transition is predicted to be allowed Light polarized along either of the molecules other two axes cannot induce this transition In contrast the transition has a groundexcited state direct product of symmetry The s point group character table shows that the electric dipole operator ie its and components in the moleculefixed frame has no component of symmetry thus light of no electric field orientation can induce this transition We thus say that the transition is forbidden The above examples illustrate one of the most important applications of visibleUV spectroscopy The information gained in such experiments can be used to infer the symmetries of the electronic states and hence of the orbitals occupied in these states It is in this manner that this kind of experiment probes electronic structures The FranckCondon Factors Beyond such electronic symmetry analysis it is also possible to derive vibrational selection rules for electronic transitions that are allowed It is conventional to expand the transition dipole matrix element in a power series about the equilibrium geometry of the initial electronic state since this geometry is characteristic of the molecular structure prior to photon absorption and because the photon absorption takes place quickly the nuclei dont have time to move far from there The first term in this expansion when substituted into the integral over the vibrational coordinates gives which has the form of the electronic transition dipole multiplied by the overlap integral between the initial and final vibrational wave functions The factor was discussed above it is the electronic transition integral evaluated at the equilibrium geometry of the absorbing state Symmetry can often be used to determine whether this integral vanishes as a result of which the transition will be forbidden The vibrational overlap integrals do not necessarily vanish because and are eigenfunctions of different vibrational Hamiltonians because they belong to different BornOppenheimer energy surfaces is an eigenfunction whose potential energy is the final electronic states energy surface has the initial electronic states energy surface as its potential The squares of these integrals which are what eventually enter into the transition rate expression R_if fracpihbar fomega_fi textbfE_ langle Phi_f boldsymbolmu Phi_irangle are called FranckCondon factors Their relative magnitudes play strong roles in determining the relative intensities of various vibrational bands ie series of peaks within a particular electronic transitions spectrum In Figure I show two potential energy curves and illustrate the kinds of absorption and emission transitions that can occur when the two electronic states have significantly different geometries Figure Absorption From One Initial State to One Final State Followed by Relaxation and Then Emission From the Lowest State of the Upper Surface Whenever an electronic transition causes a large change in the geometry bond lengths or angles of the molecule the FranckCondon factors tend to display the characteristic broad progression shown in Figure when considered for one initialstate vibrational level and various finalstate vibrational levels Figure Broad FranckCondon Progression Characteristic of Large Geometry Change Notice that as one moves to higher values the energy spacing between the states Evf Evf decreases this of course reflects the anharmonicity in the excitedstate vibrational potential For the above example the transition to the state has the largest FranckCondon factor This means that the overlap of the initial states vibrational wave function is largest for the final states function with As a qualitative rule of thumb the larger the geometry difference between the initial and final state potentials the broader will be the FranckCondon profile as shown in Figure and the larger the value for which this profile peaks Differences in harmonic frequencies between the two states can also broaden the FranckCondon profile If the initial and final states have very similar geometries and frequencies along the mode that is excited when the particular electronic excitation is realized the type of FranckCondon profile shown in Figure may result Figure FranckCondon Profile Characteristic of Small Geometry Change Another feature that is important to emphasize is the relation between absorption and emission when the two states energy surfaces have different equilibrium geometries or frequencies Subsequent to photon absorption to form an excited electronic state but prior to photon emission the molecule can undergoe collisions with other nearby molecules This of course is especially true in condensedphase experiments These collisions cause the excited molecule to lose some of its vibrational and rotational energy thereby relaxing it to lower levels on the excited electronic surface This relaxation process is illustrated in Figure Figure Absorption Followed by Relaxation to Lower Vibrational Levels of the Upper State Subsequently the electronically excited molecule can undergo photon emission also called fluorescence to return to its ground electronic state as shown in Figure Figure Fluorescence From Lower Levels of the Upper Surface The FranckCondon principle discussed earlier also governs the relative intensities of the various vibrational transitions arising in such emission processes Thus one again observes a set of peaks in the emission spectrum as shown in Figure Figure Absorption and Emission Spectra With the Latter Red Shifted There are two differences between the lines that occur in emission and in absorption First the emission lines are shifted to the red ie to lower energy or longer wavelength because they occur at transition energies connecting the lowest vibrational level of the upper electronic state to various levels of the lower state In contrast the absorption lines connect the lowest vibrational level of the ground state to various levels of the upper state These relationships are shown in Figure Figure Absorption to High States on the Upper Surface Relaxation and Emission From Lower States of the Upper Surface The second difference relates to the spacings among the vibrational lines In emission these spacings reflect the energy spacings between vibrational levels of the ground state whereas in absorption they reflect spacings between vibrational levels of the upper state The above examples illustrate how vibrationallyresolved visibleUV absorption and emission spectra can be used to gain valuable information about athe vibrational energy level spacings of the upper and ground electronic states these spacings in turn reflect the strengths of the bonds existing in these states bthe change in geometry accompanying the groundtoexcited state electronic transition as reflected in the breadth of the FranckCondon profiles these changes also tell us about the bonding changes that occur as the electronic transition occurs So again we see how visibleUV spectroscopy can be used to learn about the electronic structure of molecules in various electronic states Time Correlation Function Expressions for Transition Rates The above socalled goldenrule expression for the rates of photoninduced transitions are written in terms of the initial and final electronicvibrationalrotational states of the molecule There are situations in which these states simply cannot be reliably known For example the higher vibrational states of a large polyatomic molecule or the states of a molecule that strongly interacts with surrounding solvent molecules are such cases In such circumstances it is possible to recast the golden rule formula into a form that is more amenable to introducing specific physical models that lead to additional insights Specifically by using socalled equilibrium averaged time correlation functions it is possible to obtain rate expressions appropriate to a large number of molecules that exist in a distribution of initial states eg for molecules that occupy many possible rotational and perhaps several vibrational levels at room temperature As we will soon see taking this route to expressing spectroscopic transition rates also allows us to avoid having to know each vibrationalrotational wave function of the two electronic states involved as noted above this is especially useful for large molecules or molecules in condensed media where such knowledge is likely not available To begin reexpressing the spectroscopic transition rates the expression obtained earlier R_if fracpihbar fomega_fi textbfE_ langle Phi_f boldsymbolmu Phi_irangle appropriate to transitions between a particular initial state and a specific final state is rewritten as R_if fracpihbar int fomegatextbfE_ cdot langle Phi_f boldsymbolmu Phi_i rangle deltaomega_fiomegadomega Here the function is used to specifically enforce the resonance condition which states that the photons frequency must be resonant with the transition frequency The following integral identity can be used to replace the function by a form that is more amenable to further development Then the statetostate rate of transition becomes If this expression is then multiplied by the equilibrium probability that the molecule is found in the state and summed over all such initial states and summed over all final states that can be reached from with photons of energy the equilibrium averaged rate of photon absorption by the molecular sample is obtained This expression is appropriate for an ensemble of molecules that can be in various initial states with probabilities The corresponding result for transitions that originate in a particular state but end up in any of the allowed by energy and selection rules final states reads R_i frachbarsum_f rho_i int fomega textbfE_ cdot langle Phi_f boldsymbolmu Phi_i rangle int_inftyinfty expiomega_fiomegat dt domega As we discuss in Chapter for an ensemble in which the number of molecules the temperature and the system volume are specified takes the form where is the partition function of the molecules and is the degeneracy of the state whose energy is If you are unfamiliar with partition functions and do not want to simply trust me in the analysis of time correlation functions that we am about to undertake I suggest you interrupt your study of Chapter and read up through Section of Chapter at this time In the above expression for a double sum occurs Writing out the elements that appear in this sum in detail one finds sum_if rho_i textbfE_ langle Phi_i boldsymbolmu Phi_frangle textbfE_ langle Phi_f boldsymbolmu Phi_irangle expiomega_fit In situations in which one is interested in developing an expression for the intensity arising from transitions to all allowed final states the sum over the final states can be carried out explicitly by first writing and then using the fact that the set of states are complete and hence obey The result of using these identities as well as the Heisenberg definition of the timedependence of the dipole operator is sum_irho_i langle Phi_i textbfE_ boldsymbolmu textbfE_ boldsymbolmu t Phi_irangle In this form one says that the time dependence has been reduce to that of an equilibrium averaged ie as reflected in the sum_i rho_i langle Phi_i Phi_irangle expression time correlation function involving the component of the dipole operator along the external electric field at and this component at a different time If is positive ie in the photon absorption case the above expression will yield a nonzero contribution when multiplied by and integrated over positive values If is negative as for stimulated photon emission this expression will contribute when multiplied by for negative values In the latter situation is the equilibrium probability of finding the molecule in the excited state from which emission will occur this probability can be related to that of the lower state by rho_rm excited rho_rm lower exp E_rm excited E_rm lowerkT The absorption and emission cases can be combined into a single expression for the net rate of photon absorption by recognizing that the latter process leads to photon production and thus must be entered with a negative sign The resultant expression for the net rate of decrease of photons is int int fomega langle Phi_i textbfE_ boldsymbolmu textbfE_ boldsymbolmu t Phi_irangle exp hbaromegakT expiomega t domega dt It is convention to introduce the socalled line shape function I omega sum_i rho_i expiomega t dt in terms of which the net photon absorption rate is R_rm eqavenet frachbar exp hbaromegakT The function C t sum_i rho_i langle Phi_i textbfE_ boldsymbolmu textbfE_ boldsymbolmu t Phi_irangle is called the equilibrium averaged time correlation function of the component of the electric dipole operator along the direction of the external electric field Its Fourier transform is the spectral line shape function The convolution of with the light sources function multiplied by the correction for stimulated photon emission gives the net rate of photon absorption Although the correlation function expression for the photon absorption rate is equivalent to the statetostate expression from which it was derived we notice that does not contain explicit reference to the finalstate wave functions instead requires us to describe how the dipole operator changes with time That is in the time correlation framework one is allowed to use models of the time evolution of the system to describe the spectra This is especially appealing for large complex molecules and molecules in condensed media because for such systems it would be hopeless to attempt to find the finalstate wave functions but it may be reasonable albeit challenging to model the systems time evolution Prof Eric Heller at Harvard has pioneered the use of timedomain methods for treating molecular spectroscopy his web site offers access to further information and insight into this subject It turns out that a very wide variety of spectroscopic and thermodynamic properties eg light scattering intensities diffusion coefficients and thermal conductivity can be expressed in terms of molecular time correlation functions The text Statistical Mechanics D A McQuarrie Harper and Row New York has a good treatment of many of these cases Lets now examine how such time evolution issues are used within the correlation function framework for the specific photon absorption case Line Broadening Mechanisms If the rotational motion of the systems molecules is assumed to be entirely unhindered eg by any environment or by collisions with other molecules it is appropriate to express the time dependence of each of the dipole time correlation functions listed above in terms of a free rotation model For example when dealing with diatomic molecules the electronicvibrationalrotational appropriate to a specific electronicvibrational transition becomes Ct q_r q_v q_e q_t sum_J J expbigg frachbarJJpiIkTbigg expBig frachbarnu_rm vibv_ikTBig g_ie langle phi_J textbfE_ boldsymbolmu_ifR_e textbfE_ boldsymbolmu_ifR_et phi_Jrangle langle chi_iv chi_fvrangle Here is the rotational partition function I being the molecules moment of inertia and being the molecules rotational energy for the state with quantum number and degeneracy is the vibrational partition function being the vibrational frequency is the degeneracy of the initial electronic state is the translational partition function for the molecules of mass moving in volume and is the adiabatic electronic energy spacing The origins of such partition functions are treated in Chapter of this text The functions describe the time evolution of the electronic transition dipole vector for the rotational state In a freerotation model this function is taken to be of the form where is the rotational frequency in cycles per second for rotation of the molecule in the state labeled by This oscillatory time dependence combined with the time dependence arising from the electronic and vibrational factors produce when this function is Fourier transformed to generate a series of function peaks The intensities of these peaks are governed by the quantities Boltzmann population factors as well as by the FranckCondon factors and the terms This same analysis can be applied to the pure rotation and vibrationrotation time dependences with analogous results In the former function peaks are predicted to occur at and in the latter at omega omega_fviv omega_J with the intensities governed by the time independent factors in the corresponding expressions for In experimental measurements such sharp function peaks are of course not observed Even when very narrow bandwidth laser light sources are used ie for which is an extremely narrowly peaked function spectral lines are found to possess finite widths Let us now discuss several sources of line broadening some of which will relate to deviations from the unhindered rotational motion model introduced above a Doppler Broadening In the above expressions for the averaging over initial rotational vibrational and electronic states is explicitly shown There is also an average over the translational motion implicit in all of these expressions Its role has not yet been emphasized because the molecular energy levels whose spacings yield the characteristic frequencies at which light can be absorbed or emitted do not depend on translational motion However the frequency of the electromagnetic field experienced by moving molecules does depend on the velocities of the molecules so this issue must now be addressed Elementary physics classes express the socalled Doppler shift of a waves frequency induced by relative movement of the light source and the molecule as follows Here is the frequency of the unmoving light source seen by unmoving molecules is the velocity of relative motion of the light source and molecules is the speed of light and wobserved is the Dopplershifted frequency ie the frequency seen by the molecules The second identity is obtained by expanding in a power series the factor and is valid in truncated form when the molecules are moving with speeds significantly below the speed of light For all of the cases considered earlier a function is subjected to Fourier transformation to obtain a spectral line shape function which then provides the essential ingredient for computing the net rate of photon absorption In this Fourier transform process the variable is assumed to be the frequency of the electromagnetic field experienced by the molecules The above considerations of Doppler shifting then lead one to realize that the correct functional form to use in converting to is where is the nominal frequency of the light source As stated earlier within there is also an equilibrium average over translational motion of the molecules For a gasphase sample undergoing random collisions and at thermal equilibrium this average is characterized by the wellknown MaxwellBoltzmann velocity distribution Here is the mass of the molecules and and label the velocities along the labfixed Cartesian coordinates Defining the axis as the direction of propagation of the lights photons and carrying out the averaging of the Doppler factor over such a velocity distribution one obtains int_inftyinfty explefti t omegaBigdfracv_zcBigright leftfracmpi kTrightexpbiggfracm v_xv_yv_zkTbigg dv_x dv_y dv_z expiomega tint_inftyinfty leftfracmpi kTright expleftitomega dfracv_zcrightexpBigdfracmv_zkTBigdv_z This result when substituted into the expressions for yields expressions identical to those given for the three cases treated above but with one modification The translational motion average need no longer be considered in each instead the earlier expressions for must each be multiplied by a factor that embodies the translationaly averaged Doppler shift The spectral line shape function can then be obtained for each by simply Fourier transforming When applied to the rotation vibrationrotation or electronicvibrationrotation cases within the unhindered rotation model treated earlier the Fourier transform involves integrals of the form This integral would arise in the electronicvibrationrotation case the other two cases would involve integrals of the same form but with the absent in the vibrationrotation situation and with missing for pure rotation transitions All such integrals can be carried out analytically and yield The result is a series of Gaussian peaks in space centered at with widths determined by given the temperature and the mass of the molecules The hotter the sample the faster the molecules are moving on average and the broader is the distribution of Doppler shifted frequencies experienced by these molecules The net result then of the Doppler effect is to produce a line shape function that is similar to the unhindered rotation models series of functions but with each function peak broadened into a Gaussian shape If spectra can be obtained to accuracy sufficient to determine the Doppler width of the spectral lines such knowledge can be used to estimate the temperature of the system This can be useful when dealing with systems that cannot be subjected to alternative temperature measurements For example the temperatures of stars can be estimated if their velocity relative to the earth is known by determining the Doppler shifts of emission lines from them Alternatively the relative speed of a star from the earth may be determined if its temperature is known As another example the temperature of hot gases produced in an explosion can be probed by measuring Doppler widths of absorption or emission lines arising from molecules in these gases b Pressure Broadening To include the effects of collisions on the rotational motion part of any of the above functions one must introduce a model for how such collisions change the dipolerelated vectors that enter into The most elementary model used to address collisions applies to gaseous samples which are assumed to undergo unhindered rotational motion until struck by another molecule at which time a kick is applied to the dipole vector and after which the molecule returns to its unhindered rotational movement The effects of such infrequent collisioninduced kicks are treated within the socalled pressure broadening sometimes called collisional broadening model by modifying the freerotation correlation function through the introduction of an exponential damping factor This damping functions time scale parameter is assumed to characterize the average time between collisions and thus should be inversely proportional to the collision frequency Its magnitude is also related to the effectiveness with which collisions cause the dipole function to deviate from its unhindered rotational motion ie related to the collision strength In effect the exponential damping causes the time correlation function to lose its memory and to decay to zero This memory point of view is based on viewing as the projection of along its value as a function of time t Introducing this additional time dependence into produces when is Fourier transformed to generate integrals of the form In the limit of very small Doppler broadening the factor can be ignored ie set equal to unity and results This integral can be performed analytically and generates a pair of Lorentzian peaks in space centered again at The full width at half height of these Lorentzian peaks is One says that the individual peaks have been pressure or collisionally broadened When the Doppler broadening can not be neglected relative to the collisional broadening the above integral is more difficult to perform Nevertheless it can be carried out and again produces a series of peaks centered at but whose widths are determined both by Doppler and pressure broadening effects The resultant line shapes are thus no longer purely Lorentzian nor Gaussian which are compared in Figure for both functions having the same full width at half height and the same integrated area but have a shape that is called a Voight shape Figure Typical Forms of Gaussian and Lorentzian Peaks having identical widths and areas Experimental measurements of line widths that allow one to extract widths originating from collisional broadening provide information through on the frequency of collisions and the strength of these collisions By determining at a series of gas densities one can separate the collisionfrequency dependence and determine the strength of the individual collisions meaning how effective each collision is in reorienting the molecules dipole vector c Rotational Diffusion Broadening Molecules in liquids and very dense gases undergo such frequent collisions with the other molecules that the mean time between collisions is short compared to the rotational period for their unhindered rotation As a result the time dependence of the dipolerelated correlation functions can no longer be modeled in terms of free rotation that is interrupted by infrequent collisions and Doppler shifted Instead a model that describes the incessant buffeting of the molecules dipole by surrounding molecules becomes appropriate For liquid samples in which these frequent collisions cause the dipole to undergo angular motions that cover all angles ie in contrast to a frozen glass or solid in which the molecules dipole would undergo strongly perturbed pendular motion about some favored orientation the socalled rotational diffusion model is often used In this picture the rotationdependent part of is expressed as langle phi_J textbfE_ boldsymbolmu_ifR_e textbfE_ boldsymbolmu_ifR_e phi_Jrangle exp D_rm rott where is the rotational diffusion constant whose magnitude details the time decay in the averaged value of at time with respect to its value at time the larger the faster is this decay As with pressure broadening this exponential time dependence when subjected to Fourier transformation yields int_inftyinfty expiomega t exp D_rm rott expbigg fracomegatkTmcbigg explefti Bigomega_fviv dfracDelta E_ifhbar pm omega_JBig t right Again in the limit of very small Doppler broadening the factor can be ignored ie set equal to unity and int_inftyinfty expiomega t exp D_rm rott explefti Bigomega_fviv dfracDelta E_ifhbar pm omega_JBig t right results This integral can be evaluated analytically and generates a pair of Lorentzian peaks in space centered again at The full width at half height of these Lorentzian peaks is In this case one says that the individual peaks have been broadened via rotational diffusion In such cases experimental measurement of line widths yield valuable information about how fast the molecule is rotationally diffusing in its condensed environment d Lifetime or Heisenberg Homogeneous Broadening Whenever the absorbing species undergoes one or more processes that depletes its numbers we say that it has a finite lifetime For example a species that undergoes unimolecular dissociation has a finite lifetime as does an excited state of a molecule that decays by spontaneous emission of a photon Any process that depletes the absorbing species contributes another source of time dependence for the dipole time correlation functions discussed above This time dependence is usually modeled by appending in a multiplicative manner a factor This in turn modifies the line shape function in a manner much like that discussed when treating the rotational diffusion case Not surprisingly when the Doppler contribution is small one obtains In these Lorentzian lines the parameter describes the kinetic decay lifetime of the molecule One says that the spectral lines have been lifetime or Heisenberg broadened by an amount proportional to The latter terminology arises because the finite lifetime of the molecular states can be viewed as producing via the Heisenberg uncertainty relation states whose energy is uncertain to within an amount e Site Inhomogeneous Broadening Among the above line broadening mechanisms the pressure rotational diffusion and lifetime broadenings are all of the homogeneous variety This means that each and every molecule in the sample is affected in exactly the same manner by the broadening process For example one does not find some molecules with short lifetimes and others with long lifetimes in the Heisenberg case the entire ensemble of molecules is characterized by a single lifetime In contrast Doppler broadening is inhomogeneous in nature because each molecule experiences a broadening that is characteristic of its particular velocity That is the fast molecules have their lines broadened more than do the slower molecules Another important example of inhomogeneous broadening is provided by socalled site broadening Molecules imbedded in a liquid solid or glass do not at the instant of their photon absorption all experience exactly the same interactions with their surroundings The distribution of instantaneous solvation environments may be rather narrow eg in a highly ordered solid matrix or quite broad eg in a liquid at high temperature or in a supercritical liquid Different environments produce different energy level splittings because the initial and final states are solvated differently by the surroundings and thus different frequencies at which photon absorption can occur The distribution of energy level splittings causes the sample to absorb at a range of frequencies as illustrated in Figure where homogeneous and inhomogeneous line shapes are compared Figure Illustration of homogeneous band showing absorption at several concentrations of the absorbing species left and of inhomogeneous band showing absorption at one concentration by numerous subpopulations The spectral line shape function is therefore further broadened when site inhomogeneity is present and significant These effects can be modeled by convolving the kind of function that results from Doppler lifetime rotational diffusion and pressure broadening with a Gaussian distribution that describes the inhomogeneous distribution of energy level splittings Here is a line shape function such as those described earlier each of which contains a set of frequencies eg omega_fvivDelta E_ifhbar omega_J Delta E hbar omegaDelta E hbar at which absorption or emission occurs and is a Gaussian probability function describing the inhomogeneous broadening of the energy splitting A common experimental test to determine whether inhomogeneous broadening is significant involves hole burning In such experiments an intense light source often a laser is tuned to a frequency that lies within the spectral line being probed for inhomogeneous broadening Then with the intense light source constantly turned on a second tunable light source is used to scan through the profile of the spectral line and an absorption spectrum is recorded Given an absorption profile as shown in Figure in the absence of the intense burning light source Figure Absorption Profile in the Absence of Hole Burning one expects to see a profile such as that shown in Figure if inhomogeneous broadening is operative Figure Absorption Profile With Laser Turned On to Burn a Hole The interpretation of the change in the absorption profile caused by the bright light source proceeds as follows In the ensemble of molecules contained in the sample some molecules will absorb at or near the frequency of the bright light source other molecules those whose environments do not produce energy level splittings that match will not absorb at this frequency Those molecules that do absorb at will have their transition saturated by the intense light source thereby rendering this frequency region of the line profile transparent to further absorption When the probe light source is scanned over the line profile it will induce absorptions for those molecules whose local environments did not allow them to be saturated by the light The absorption profile recorded by this probe light sources detector thus will match that of the original line profile until The probe light sources frequency matches upon which no absorption of the probe sources photons will be recorded because molecules that absorb in this frequency regime have had their transition saturated Hence a hole will appear in the absorption spectrum recorded by the probe light sources detector in the region of Unfortunately the technique of hole burning does not provide a fully reliable method for identifying inhomogeneously broadened lines If a hole is observed in such a burning experiment this provides ample evidence but if one is not seen the result is not definitive In the latter case the transition may not be strong enough ie may not have a large enough rate of photon absorption for the intense light source to saturate the transition to the extent needed to form a hole Photoelectron Spectroscopy Photoelectron spectroscopy PES is a special kind of electronic spectroscopy It uses visible or UV light to excite a molecule or ion to a final state in which an electron is ejected In effect it induces transitions to final states in which an electron has been promoted to an unbound socalled continuum orbital Most PES experiments are carried out using a fixedfrequency light source usually a laser This sources photons when absorbed eject electrons whose intensity and kinetic energies are then measured Subtracting the electrons from the photons energy gives the binding energy of the electron If the sample subjected to the PES experiment has molecules in a variety of initial states eg two electronic states or various vibrationalrotational levels of the ground electronic state having various binding energies one will observe a series of peaks corresponding to electrons ejected with a variety of kinetic energies as Figure illustrates and as the energybalance condition requires The peak of electrons detected with the highest kinetic energy came from the highestlying state of the parent while those with low kinetic energy came from the lowestenergy state of the parent Figure Photoelectron spectrum showing absorption from two states of the parent By examining the spacings between these peaks one learns about the spacings between the energy levels of the parent species that has been subjected to electron loss Alternatively if the parent species exists primarily in its lowest state but the daughter species produced when an electron is removed from the parent has excited electronic vibrationrotation states that can be accessed one can observe a different progression of peaks In this case the electrons with highest kinetic energy arise from transitions leading to the lowestenergy state of the daughter as Figure illustrates In that figure the lower energy surface belongs to the parent and the upper curve to the daughter Figure Photoelectron events showing detachment from one state of the parent to several states of the daughter An example of experimental photodetachment data is provided in Figure showing the intensity of electrons detected when anion loses an electron vs the kinetic energy of the ejected electrons Figure Photoelectron spectrum of Cu The peaks belong to a FranckCondon vibrational progression of neutral Cu The peak at a kinetic energy of ca eV corresponding to a binding energy of eV arises from in losing an electron to produce in The most intense peak corresponds to a to transition As in the visibleUV spectroscopy case FranckCondon factors involving the overlap of the anion and neutral vibrational wave functions govern the relative intensities of the PES peaks Another example is given in Figure where the photodetachment spectrum of the anion of the carbene vinylidene appears Figure Photoelectron spectrum of showing detachments to two electronic states of the neutral In this spectrum the peaks having electron binding energies near eV correspond to transitions in which groundstate in is detached to produce groundstate in various v levels The spacings between this group of peaks relate to the spacings in vibrational states of this electronic state The series of peaks with binding energies near eV correspond to transitions in which is detached to produce in its excited electronic state The spacings between peaks in this range relate to spacings in vibrational states of this state The spacing between the peaks near eV and those near eV relate to the energy difference between the and electronic states of the neutral Because PES offers a direct way to measure energy differences between anion and neutral or neutral and cation state energies it is a powerful and widely used means of determining molecular electron affinities EAs and ionization potentials IPs Because IPs and EAs relate via Koopmans theorem to orbital energies PES is thus seen to be a way to measure orbital energies Its vibrational envelopes also offer a good way to probe vibrational energy level spacings and hence the bonding strengths Probing Continuum Orbitals There is another type of spectroscopy that can be used to directly probe the orbitals of a molecule that lie in the continuum ie at energies higher than that of the parent neutral I ask that you reflect back on our discussion in Chapter of tunneling and of resonance states that can occur when an electron experiences both attractive and repulsive potentials In such cases there exists a special energy at which the electron can be trapped by the attractive potential and have to tunnel through the repulsive barrier to eventually escape It is these kinds of situations that this spectroscopy probes This experiment is called electrontransmission spectroscopy ETS In such an experiment a beam of electrons having a known intensity and narrowly defined range of kinetic energies is allowed to pass through a sample usually gaseous of thickness The intensity of electrons observed to pass through the sample and arrive at a detector lying along the incident beams direction is monitored as are the kinetic energies of these electrons Such an experiment is described in qualitative form in Figure Figure Qualitative depiction of a prototypical electron transmission spectrum setup If the molecules in the sample have a resonance orbital whose energy is close to the kinetic energy of the colliding electrons it is possible for an electron from the beam to be captured into such an orbital and to exist in this orbital for a considerable time Of course in the absence of any collisions or other processes to carry away excess energy this anion will reemit an electron at a later time Hence such anions are called metastable and their electronic states are called resonance states If the captured electron remains in this orbital for a length of time comparable to or longer than the time it takes for the nascent molecular anion to undergo vibrational or rotational motion various events can take place before the electron is reemitted isome bond lengths or angles can change this will happen if the orbital occupied by the beams electron has bonding or antibonding character so when the electron is subsequently emitted the neutral molecule is left with a change in vibrational energy iithe molecule may rotate so when the electron is ejected it is not emitted in the same direction as the incident beam In the former case one observes electrons emitted with energies that differ from that of the incident beam by amounts related to the internal vibrational energy levels of the anion In the latter one sees a reduction in the intensity of the beam that is transmitted directly through the sample and electrons that are scattered away from this direction Such an ETS spectrum is shown in Figure for a gaseous sample of molecules In this spectrum the energy of the transmitted beams electrons is plotted on the horizontal axis and the derivative of the intensity of the transmitted beam is plotted on the vertical axis It is common to plot such derivatives in ETStype experiments to allow the variation of the signal with energy to be more clearly identified Figure ETS Spectrum plotted in derivative form as described in the text of In this ETS spectrum of the oscillations that appear within the major spectral feature displayed whose center is near eV correspond to stretching and bending vibrational levels of the metastable anion It is the bending vibration that is primarily excited because the beam electron enters the LUMO of which is an orbital of the form shown in Figure Figure Antibonding orbital of holding the excess electron in Occupancy of this antibonding orbital causes both CO bonds to lengthen and the OCO angle to bend away from deg The bending allows the antibonding nature of this orbital to be reduced Other examples of ETS spectra are shown in Figure Figure ETS spectra of several DNA bases Here again a derivative spectrum is shown and the vertical lines have been added to show where the derivative passes through zero which is where the ETS absorption signal would have a peak These maxima correspond to electrons entering various virtual orbitals of the uracil and DNA base molecules It is by finding these peaks in the ETS spectrum that one can determine the energies of such continuum orbitals Before closing this section it is important to describe how one uses theory to simulate the metastable states that arise in such ETS experiments Such calculations are not at all straightforward and require the introduction of special tools designed to properly model the resonant continuum orbital For metastable anions it is difficult to approximate the potential experienced by the excess electron For example singly charged anions in which the excess electron occupies a molecular orbital that possesses nonzero angular momentum have effective potentials as shown in Figure which depend on the angular momentum value of the orbital Figure Radial potentials and shape resonance energy levels for two values For example the orbital of shown in Figure produces two counteracting contributions to the effective radial potential experienced by an electron occupying it Figure Antibonding orbital of showing its character First the two nitrogen centers exert attractive potentials on the electron in this orbital These attractions are strongest when the excess electron is near the nuclei but decay rapidly at larger distances because the other electrons Coulomb repulsions screen the nuclear attractions Secondly because the molecular orbital is comprised of atomic basis functions of etc symmetry it possesses nonzero angular momentum Because the orbital has gerade symmetry its larger character is dominated by angular momentum As a result the excess electron has a centrifugal radial potential derived largely from its character The attractive shortrange valence potentials and the centrifugal potential combine to produce a net effective potential as illustrated in Figure The energy of an electron experiencing such a potential may or may not lie below the asymptote If the attractive potential is sufficiently strong as it is for the electron in the orbital will be bound and its energy will lie below this asymptote On the other hand if the attractive potential is not as strong as is the case for the lesselectronegative nitrogen atoms in the energy of the orbital can lie above the asymptote In the latter cases we speak of metastable shaperesonance states They are metastable because their energies lie above the asymptote so they can decay by tunneling through the centrifugal barrier They are called shaperesonances because their metastability arises from the shape of their repulsive centrifugal barrier If one had inhand a reasonable approximation to the attractive shortrange potential and if one knew the Lsymmetry of the orbital occupied by the excess electron one could form as above However to compute the lifetime of the shape resonance one has to know the energy of this state The most common and powerful tool for studying such metastable states theoretically is the stabilization method SM that Prof Howard Taylor at USC pioneered This method involves embedding the system of interest eg the anion within a finite radial box in order to convert the continuum of states corresponding for example to into discrete states that can be handled using more conventional methods By then varying the size of the box one can vary the energies of the discrete states that correspond to ie one varies the kinetic energy of the orbital containing the excess electron As the box size is varied one eventually notices eg by plotting the orbitals that one of the states possesses a significant amount of valence ie shortrange character That is one such state has significant amplitude not only at larger but also in the region of the two nitrogen centers It is this state that corresponds to the metastable shaperesonance state and it is the energy where significant valence components develop that provides the stabilization estimate of the state energy Let us continue using as an example for how the SM would be employed especially how one usually varies the box within which the anion is constrained One would use a conventional atomic orbital basis set that would likely include s and functions on each atom perhaps some polarization d functions and some conventional diffuse s and orbitals on each atom These basis orbitals serve primarily to describe the motions of the electrons within the usual valence regions of space To this basis one would append extra sets of diffuse symmetry orbitals These orbitals could be and maybe functions centered on each nitrogen atom or they could be and maybe orbitals centered at the midpoint of the NN bond One usually would not add just one such function rather several such functions each with an orbital exponent that characterizes its radial extent would be used Let us assume for example that such functions have been used Next using the conventional atomic orbital basis as well as the extra basis functions one carries out a calculation most often a variational calculation in which one computes many energy levels on the anion In this calculation one tabulates the energies of many say M of the electronic states of Of course because a finite atomic orbital basis set must be used one finds a discrete spectrum of orbital energies and thus of electronic state energies There are occupied orbitals having negative energy that represent via Koopmans theorem the bound states of the There are also socalled virtual orbitals ie those orbitals that are not occupied whose energies lie above zero ie do not describe bound states The latter orbitals offer a discrete approximation to the continuum within which the resonance state of interest lies One then scales the orbital exponents of the extra basis orbitals by a factor alpha_J rightarrow eta alpha_J and repeats the calculation of the energies of the M lowest energies of This scaling causes the extra basis orbitals to contract radially if or to expand radially if It is this basis orbital expansion and contraction that produces expansion and contraction of the box discussed above That is one does not employ a box directly instead one varies the radial extent of the most diffuse basis orbitals to simulate the box variation If the conventional orbital basis is adequate one finds that the extra orbitals whose exponents are being scaled do not affect appreciably the energy of the neutral molecule This can be probed by plotting the energy as a function of the scaling parameter h if the energy varies little with the conventional basis is adequate In contrast to plots of the neutral energy vs plots of the energies of the M states show significant hdependence as Figure illustrates Figure Typical stabilization plot showing several levels of the metastable anion and their avoided Crossings What does such a stabilization plot tell us and what do the various branches of the plot mean First one should notice that each of the plots of the energy of an anion state relative to the neutral molecules energy which is independent of grows with increasing h This hdependence arises from the hscaling of the extra diffuse basis orbitals Because most of the amplitude of such basis orbitals lies outside the valence region the kinetic energy is the dominant contributor to such orbitals energy Because enters into each orbital as and because the kinetic energy operator involves the second derivative with respect to r the kinetic energies of orbitals dominated by the diffuse basis functions vary as For small all of the diffuse basis functions have their amplitudes concentrated at large r and have low kinetic energy This is because for small all of these orbitals are very diffuse and concentrate electron density at large distances As grows these functions become more radially compact and their kinetic energies grow For example note the three lowest energies shown above increasing from near zero as grows As further increases one reaches a point at which the third and fourth anionstate energies undergo an avoided crossing At this value if one examines the nature of the two wave functions whose energies avoid one another one finds that one of them contains substantial amounts of both valence and extradiffuse function character Just to the left of the avoided crossing the lowerenergy state the third state for small contains predominantly extra diffuse orbital character while the higherenergy state the fourth state contains largely valence orbital character However at the special value of where these two states nearly cross the kinetic energy of the third state as well as its radial size and its de Broglie wavelength are appropriate to connect properly with the fourth state By connect properly we mean that the two states have wave function amplitudes phases and slopes that match So at this special value one can achieve a description of the shaperesonance state that correctly describes this state both in the valence region and in the larger region Only by tuning the energy of the larger states using the scaling can one obtain this proper boundary condition matching In summary by carrying out a series of anionstate energy calculations for several states and plotting them vs one obtains a stabilization graph By examining this graph and looking for avoided crossings one can identify the energies at which metastable resonances occur It is also possible to use the shapes ie the magnitude of the energy splitting between the two states and the slopes of the two avoiding curves of the avoided crossings in a stabilization graph to compute the lifetimes of the metastable states Basically the larger the avoided crossing energy splitting between the two states the shorter is the lifetime of the resonance state So the ETS and PES experiments offer wonderful probes of the bound and continuum states of molecules and ions that tell us a lot about the electronic nature and chemical bonding of these species The theoretical study of these phenomena is complicated by the need to properly identify and describe any continuum orbitals and states that are involved The stabilization technique allows us to achieve a good approximation to resonance states that lie in such continua Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Experimental Probes of Reaction Dynamics Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Spectroscopic Methods Beam Methods Other MethodsContributors and Attributions Spectroscopic Methods To follow the rate of any chemical reaction one must have a means of monitoring the concentrations of reactant or product molecules as time evolves In the majority of current experiments that relate to reaction dynamics one uses some form of spectroscopic or alternative physical probe eg an electrochemical signature or a mass spectrometric detection of product ions to monitor these concentrations as functions of time Of course in all such measurements one must know how the intensity of the signal detected relates to the concentration of the molecules that cause the signal For example in many absorption experiments as illustrated in Figure light is passed through a sample of thickness and the intensity of the light beam in the absence of the sample and with the sample present are measured Figure Typical Beerslaw experiment in which a light beam of intensity is passed through a sample of thickness The BeerLambert law then allows the concentration A of the absorbing molecules to be determined given the path length over which absorption occurs and given the extinction coefficient of the absorbing molecules These extinction coefficients which relate to the electric dipole matrix elements as discussed in Chapter are usually determined empirically by preparing a known concentration of the absorbing molecules and measuring the ratio that this concentration produces in a cell of length For molecules and ions that are extremely reactive this calibration approach to determining is often not feasible because one cannot prepare a sample with a known concentration that remains constant in time long enough for the experiment to be carried out In such cases one often must resort to using the theoretical expressions given in Chapter and discussed in most textbooks on molecular spectroscopy to compute in terms of the wave functions of the absorbing species In any event one must know how the strength of the signal relates to the concentrations of the species if one wishes to monitor chemical reaction or energy transfer rates Because modern experimental techniques are capable of detecting molecules in particular electronic and vibrationrotation states it has become common to use such tools to examine chemical reaction dynamics on a statetostate level and to follow energy transfer processes which clearly require such statespecific data In such experiments one seeks to learn the rate at which reactants in a specific state react to produce products in some specific state One of the most common ways to monitor such statespecific rates is through a socalled pumpprobe experiment in which i A shortduration light pulse is used to excite reactant molecules to some specified initial state Usually a tunable laser is used because its narrow frequency spread allows specific states to be pumped The time at which this pump laser thus prepares the excited reactant molecules in state defines ii After a delay time of duration t a second light source is used to probe the product molecules that have been formed in various final states Often the frequency of this probe source is scanned so that one can examine populations of many such final states The concentrations of reactant and products molecules in the initial and final states and are determined by the BeerLambert relation assuming that the extinction coefficients and for these species and states absorption are known In the former case the extinction coefficient relates to absorption of the pump photons to prepare reactant molecules in the specified initial state In the latter refers to absorption of the product molecules that are created in the state Carrying out a series of such finalstate absorption measurements at various delay times t allows one to determine the concentration of these states as a function of time This kind of laser pumpprobe experiment is used not only to probe specific electronic or vibrationrotation states of the reactants and products but also when the reaction is fast ie complete in s or less In these cases one is not using the high frequency resolution of the laser but its fast time response Because laser pulses of quite short duration can be generated these tools are well suited in such fast chemical reaction studies The reactions can be in the gas phase eg fast radical reactions in the atmosphere or in explosions or in solution eg photoinduced electron transfer reactions in biological systems Beam Methods Another approach to probing chemical reaction dynamics is to use a beam of reactant molecules A that collides with other reactants B that may also in a beam or in a bulb in equilibrium at some temperature T Such crossedbeam and beambulb experiments are illustrated in Figure Figure Typical crossedbeam and beambulb experimental setups Almost always these beam and bulb samples contain molecules radicals or ions in the gas phase so these techniques are most prevalent in gasphase dynamics studies The advantages of the crossedbeam type experiments are that one can control the velocities and hence the collision energies of both reagents one can examine the product yield as a function of the angle through which the products are scattered one can probe the velocity of the products and by using spectroscopic methods one can determine the fraction of products generated in various internal electronicvibrationalrotational states Such measurements allow one to gain very detailed information about how the reaction rate coefficient depends on collisional kinetic energy and where the total energy available to the products is deposited ie into product translational energy or product internal energy The angular distribution of product molecules can also give information about the nature of the reaction process For example if the A B collision forms a longlived ie on rotational time scales collision complex the product C molecules display a very isotropic angular distribution In contrast reactions that proceed more impulsively show product angular distributions that are either strongly backscattered or strongly forwardscattered rather than isotropic In beambulb experiments one is not able to gain as much detailed information because one of the reactant molecules B is not constrained to be moving with a known fixed velocity in a specified direction when the collisions occur Instead the B molecules collide with A molecules in a variety of orientations and with a distribution of collision energies whose range depends on the MaxwellBoltzmann distribution of kinetic energies of the B molecules in the bulb The advantage of beambulb experiments is that one can achieve much higher collision densities than in crossedbeam experiments because the density of B molecules inside the bulb can be much higher than the densities achievable in a beam of B molecules There are cases in which the beambulb experiments can be used to determine how the reaction rate depends on collision energy even though the molecules in the bulb have a distribution of kinetic energies That is if the species in the beam have much higher kinetic energies than most of the B molecules then the A B collision energy is primarily determined by the beam energy An example of this situation is provided by socalled guidedion beam experiments in which a beam of ions having wellspecified kinetic energy E impinges on molecules in a bulb having a temperature for which Figure illustrates data that can be extracted from such an experiment Figure Collisioninduced dissociation data showing crosssection as a function of collision energy In Figure we illustrate the crosssection related to the bimolecular rate constant by where v is the relative collision speed for production of ions when a beam of uracil complexes having energy E the horizontal axis collides with a bulb containing Xe atoms at room temperature In this case the reaction is simply the collisioninduced dissociation CID process in which the complex undergoes unimolecular decomposition after gaining internal energy in collisions with Xe atoms Narm uracil rightarrow Na rm uracil The primary knowledge gained in this CID experiment is the threshold energy that is the minimum collision energy needed to effect dissociation of the complex This kind of data has proven to offer some of the most useful information about bond dissociation energies of a wide variety of species In addition the magnitude of the reaction crosssection as a function of collision energy is a valuable product of such experiments These kind of CID beambulb experiments offer one of the most powerful and widely used means of determining such bondrupture energies and reaction rate constants Other Methods Of course not all chemical reactions occur so quickly that they require the use of fast lasers to follow concentrations of reacting species or pumpprobe techniques to generate and probe these molecules For slower chemical reactions one can use other methods for monitoring the relevant concentrations These methods include electrochemistry where the redox potential is the species signature and NMR spectroscopy where the chemical shifts of functional groups are the signatures both of whose instrumental response times are too slow for probing fast reactions In addition when the reactions under study do not proceed to completion but exist in equilibrium with a back reaction alternative approaches can be used The example discussed in Chapter is one such case Let us briefly review it here and again consider the reaction of an enzyme E and a substrate S to form the enzymesubstrate complex ES In the perturbationtype experiments the equilibrium concentrations of the species are shifted by a small amount by application of the perturbation so that Subsequently the following rate law will govern the time evolution of the concentration change d Assuming that is very small so that the term involving cam be neglected and using the fact that the forward and reverse rates balance at equilibrium this equation for the time evolution of can be reduced to So the concentration deviations from equilibrium will return to equilibrium exponentially with an effective rate coefficient that is equal to a sum of terms So by following the concentrations of the reactants or products as they return to their equilibrium values one can extract the effective rate coefficient Doing this at a variety of different initial equilibrium concentrations eg and and seeing how changes one can then determine both the forward and reverse rate constants Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Experimental Test of the MaxwellBoltzmann Probability Density Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers There are numerous applications of the MaxwellBoltzmann equation These include predictions of collision frequencies meanfree paths effusion and diffusion rates the thermal conductivity of gases and gas viscosities These applications are important but none of them is a direct test of the validity of the MaxwellBoltzmann equation The validity of the equation has been demonstrated directly in experiments in which a gas of metal atoms is produced in an oven at a very high temperature As sketched in Figure the gas is allowed to escape into a vacuum chamber through a very small hole in the side of the oven The escaping atoms impinge on one or more metal plates Narrow slits cut in these plates stop any metal atoms whose flight paths do not pass though the slits This produces a beambeamof metal atoms of metal atoms whose velocity distribution is the same as that of the metalatom gas inside the oven The rate at which metal atoms arrive at a detector is measured Various methods are used to translate the atomarrival rate into a measurement of their speed Figure Producing a beam of metal atoms One device uses a solid cylindrical drum which rotates on its cylindrical axis As sketched in Figure a spiral groove is cut into the cylindrical face of this drum This groove is cut with a constant pitch When the drum rotates at a constant rate an atom traveling at a constant velocity parallel to the cylindrical axis can traverse the length of the drum while remaining within the groove That is for a given rotation rate there is one critical velocity at which an atom can travel in a straight line while remaining in the middle of the groove all the way from one end of the drum to the other If the atom moves significantly faster or slower than this critical velocity it collides withand sticks toone side or the other of the groove Figure Device to select metal atoms having a specified velocity Since the groove has a finite width atoms whose velocities lie in a narrow range about the critical velocity can traverse the groove without hitting one of the sides Let us assume that the groove is cut so that the spiral travels half way around the cylinder That is if we project the spiral onto one of the circular faces of the drum the projection traverses an angle of on the face In order to remain in the middle of this groove all the way from one end of the drum to the other the atom must travel the length of the cylindrical drum in exactly the same time that it takes the drum to make a halfrotation Let the critical velocity be Then the time required for the atom to traverse the length d of the drum is If the drum rotates at u cyclessec the time required for the drum to make onehalf rotation is Thus the atom will remain in the middle of the groove all the way through the drum if By varying the rotation rate we can vary the critical velocity Because the groove has a finite width atoms whose velocities are in a range can successfully traverse the groove Whether or not a particular atom can do so depends on its velocity where it enters the groove and the width of the groove Let the width of the groove be and the radius of the drum be where the drum is constructed with A slower atom that enters the groove at the earliest possible timewhen the leading edge of the groove first encounters the beam of atomscan traverse the length of the groove in a longer time A point on the circumference of the drum travels with speed The slowest atom traverses the length of the drum while a point on the circumference of the drum travels a distance To intercept the slowest atom the trailing edge of the groove must travel a distance equal to half the circumference of the drum plus the width of the groove The time required for this rotation is the maximum time a particle can take to traverse the length so and A fast atom that enters the groove at the last possible momentwhen the trailing edge of the grove just leaves the beam of atomscan still traverse the groove if it does so in the time that it takes the trailing edge of the groove to travel a distance So and At a given rotation rate the drum will pass atoms whose speeds are in the range So that The fraction of the incident atoms that successfully traverse the groove is equal to the fraction that have velocities in the interval centered on the critical velocity Finding Avogadros Number Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers This use of Avogadros number raises the question of how we know its value There are numerous ways to measure Avogadros number One such method is to divide the charge of one mole of electrons by the charge of a single electron We can obtain the charge of a mole of electrons from electrolysis experiments The charge of one electron can be determined in a famous experiment devised by Robert Millikan the Millikan oildrop experiment The charge on a mole of electrons is called the faraday Experimentally it has the value coulombs per mole As determined by Millikans experiment the charge on one electron is Then Firstorder Rate Processes Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Firstorder rate processes are ubiquitous in natureand commerce In chemistry we are usually interested in firstorder decay processes in other subjects firstorder growth is common We can develop our appreciation for the dynamicsand mathematicsof firstorder processes by considering the closely related subject of compound interest Compound Interest When a bank says that it pays annual interest compounded annually on a deposit it means that for every we deposit at the beginning of a year the bank will add or to our account at the end of the year making our deposit worth If we let the value of our deposit at the end of year be and the interest rate expressed as a fraction be with we can write where we represent the first years interest by If we leave all of the money in the account for an additional year we will have and after t years we will have Sometimes a bank will say that it pays annual interest compounded monthly Then the bank means that it will compute a new balance every month based on After one month and after months If we want the value of the account after years we have since If the bank were to say that it pays interest at the rate compounded daily the balance at the end of years would be For any number of compoundings at rate during a year the balance at the end of years would be Sometimes banks speak of continuous compounding which means that they compute the value of the account at time as the limit of this equation as becomes arbitrarily large That is for continuous compounding we have Fortunately we can think about the continuous compounding of interestinterestcontinuous compounding in another way What we mean is that the change in the value of the account over a short time interval is given by where is the initial value of the account for the interval and is the fractional change in during one unit of time So we can write Separating variables to obtain and integrating between the limits at and at we obtain or Comparing the two equations we have derived for continuous compounding we see that Continuous compounding of interest is an example of firstorder or exponential growth Other examples are found in nature the growth of bacteria normally follows such an equation Reflection suggests that such behavior should not be considered remarkable It requires only that the increase per unit time in some quantity be proportional to the amount of that is already present Since measures the number of items dollars molecules bacteria present this is equivalent to our observation in Section that a firstorder process corresponds to a constant probability that a given individual item will disappear firstorder decay or reproduce firstorder growth in unit time For a firstorder decay we have keeping In the limit as which has solution Firstorder growth and firstorder decay both depend exponentially on The difference is in the sign of the exponential term For exponential growth becomes arbitrarily large as for exponential decay goes to zero If the concentration of a chemical species decreases according to a firstorder rate law we have The units of the rate constant are The halflife of a chemical reaction is the time required for onehalf of the stoichiometrically possible change to occur For a firstorder decay the halflife is the time required for the concentration of the reacting species to decrease to onehalf of its value at time zero that is when the time is the concentration is Substituting into the integrated rate law we find that the halflife of a firstorder decay is independent of concentration the halflife is Free Electron Model of Polyenes Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Contributors and Attributions The particleinabox type problems provide important models for several relevant chemical situations The particleinabox model for motion in one or two dimensions discussed earlier can obviously be extended to three dimensions For two and three dimensions it provides a crude but useful picture for electronic states on surfaces ie when the electron can move freely on the surface but cannot escape to the vacuum or penetrate deeply into the solid or in metallic crystals respectively I say metallic crystals because it is in such systems that the outermost valence electrons are reasonably well treated as moving freely rather than being tightly bound to a valence orbital on one of the constituent atoms or within chemical bonds localized to neighboring atoms Free motion within a spherical volume such as we discussed in Chapter gives rise to eigenfunctions that are also used in nuclear physics to describe the motions of neutrons and protons in nuclei In the socalled shell model of nuclei the neutrons and protons fill separate etc orbitals refer back to Chapter to recall how these orbitals are expressed in terms of spherical Bessel functions and what their energies are with each type of nucleon forced to obey the Pauli exclusion principle ie to have no more than two nucleons in each orbital because protons and neutrons are Fermions For example has two protons in orbitals and neutrons in orbitals whereas has two protons and one neutron To remind you I display in Figure the angular shapes that characterize and orbitals Figure The angular shapes of and functions This same spherical box model has also been used to describe the valence electrons in quasispherical nanoclusters of metal atoms such as and their positive and negative ions Because of the metallic nature of these species their valence electrons are essentially free to roam over the entire spherical volume of the cluster which renders this simple model rather effective In this model one thinks of each valence electron being free to roam within a sphere of radius ie having a potential that is uniform within the sphere and infinite outside the sphere The orbitals that solve the Schrdinger equation inside such a spherical box are not the same in their radial shapes as the etc orbitals of atoms because in atoms there is an additional attractive Coulomb radial potential present In Chapter we showed how the particleinasphere radial functions can be expressed in terms of spherical Bessel functions In addition the pattern of energy levels which was shown in Chapter to be related to the values of x at which the spherical Bessel functions vanish are not the same as in atoms again because the radial potentials differ However the angular shapes of the spherical box problem are the same as in atomic structure because in both cases the potential is independent of and As the orbital plots shown above indicate the angular shapes of s p and orbitals display varying number of nodal surfaces The orbitals have none orbitals have one and orbitals have two Analogous to how the number of nodes related to the total energy of the particle constrained to the plane the number of nodes in the angular wave functions indicates the amount of angular or orbital rotational energy Orbitals of shape have no angular energy those of shape have less then do orbitals etc It turns out that the pattern of energy levels derived from this particleinasphericalbox model can offer reasonably accurate descriptions of what is observed experimentally In particular when a cluster or cluster ion has a closedshell electronic configuration in which for a given radial quantum number all of the orbitals associated with that are doubly occupied nanoscopic metal clusters are observed to display special stability eg lack of chemical reactivity large electron detachment energy Clusters that produce such closedshell electronic configurations are sometimes said to have magicnumber sizes The energy level expression given in Chapter for an electron moving inside a sphere of radius and having a potential relative to the vacuum of can be used to model the energies of electron within metallic nanoclusters Each electron occupies an orbital having quantum numbers and with the energies of the orbitals given above in terms of the zeros of the spherical Bessel functions Spectral features of the nanoclusters are then determined by the energy gap between the highest occupied and lowest unoccupied orbital and can be tuned by changing the radius of the cluster or the charge ie number of electrons of the cluster Another very useful application of the model problems treated in Chapter is the onedimensional particleinabox which provides a qualitatively correct picture for electron motion along the orbitals of delocalized polyenes The one Cartesian dimension corresponds to motion along the delocalized chain In such a model the box length is related to the carboncarbon bond length and the number of carbon centers involved in the delocalized network In Figure such a conjugated network involving nine centers is depicted In this example the box length would be eight times the CC bond length Figure The atomic orbitals of a conjugated chain of nine carbon atoms so the box length is eight times the CC bond length The eigenstates and their energies represent orbitals into which electrons are placed In the example case if nine electrons are present eg as in the nonatetraene radical the ground electronic state would be represented by a total wave function consisting of a product in which the lowest four s are doubly occupied and the fifth is singly occupied The component spin angular momentum states of the electrons are labeled and as discussed earlier We write the total wave function above as a product wave function because the total Hamiltonian involves the kinetic plus potential energies of nine electrons To the extent that this total energy can be represented as the sum of nine separate energies one for each electron the Hamiltonian allows a separation of variables in which each Hj describes the kinetic and potential energy of an individual electron Of course the full Hamiltonian contains electronelectron Coulomb interaction potentials that cannot be written in this additive form However as we will treat in detail in Chapter it is often possible to approximate these electronelectron interactions in a form that is additive Recall that when a partial differential equation has no operators that couple its different independent variables ie when it is separable one can use separation of variables methods to decompose its solutions into products Thus the approximate additivity of implies that solutions of are products of solutions to The two lowest excited states would correspond to states of the form and where the spinorbitals orbitals multiplied by or appearing in the above products depend on the coordinates of the various electrons For example denotes The electronic excitation energies from the ground state to each of the above excited states within this model would be DeltaE dfrac pi hbarm left dfracL dfracLright taga and It turns out that this simple model of electron energies provides a qualitatively correct picture of such excitation energies Its simplicity allows one for example to easily suggest how a molecules color as reflected in the complementary color of the light the molecule absorbs varies as the conjugation length of the molecule varies That is longer conjugated molecules have lowerenergy orbitals because appears in the denominator of the energy expression As a result longer conjugated molecules absorb light of lower energy than do shorter molecules This simple particleinabox model does not yield orbital energies that relate to ionization energies unless the potential inside the box is specified Choosing the value of this potential that exists within the box such that is equal to minus the lowest ionization energy of the nonatetraene radical gives energy levels as which can then be used as approximations to ionization energies The individual molecular orbitals are depicted in Figure for a model of the hexatriene orbital system for which the box length is five times the distance between neighboring pairs of carbon atoms The magnitude of the Catom centered atomic orbital in the molecular orbital is given by Figure The phases of the six molecular orbitals of a chain containing six atoms In this figure positive amplitude is denoted by the clear spheres and negative amplitude is shown by the darkened spheres Where two spheres of like shading overlap the wave function has enhanced amplitude ie there is a bonding interaction where two spheres of different shading overlap a node occurs ie there is antibonding interaction Once again we note that the number of nodes increases as one ranges from the lowestenergy orbital to higher energy orbitals The reader is once again encouraged to keep in mind this ubiquitous characteristic of quantum mechanical wave functions This simple model allows one to estimate spin densities at each carbon center and provides insight into which centers should be most amenable to electrophilic or nucleophilic attack For example radical attack at the carbon of the nineatom nonatetraene system described earlier would be more facile for the ground state than for either or In the former the unpaired spin density resides in which varies as so is nonzero at which has nonzero amplitude at the site In and the unpaired density is in and respectively both of which have zero density at because sinnpxRCC vanishes for or at Plots of the wave functions for ranging from to are shown in another format in Figure where the nodal pattern is emphasized Figure The nodal pattern for a chain containing seven atoms I hope that by now the student is not tempted to ask how the electron gets from one region of high amplitude through a node to another highamplitude region Remember such questions are cast in classical Newtonian language and are not appropriate when addressing the wavelike properties of quantum mechanics Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Free Energy Functions Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay The Gibbs and Helmholtz FunctionsCalculating for ReactionsContributors and Attributions In the previous chapter we saw that for a spontaneous process While this is a useful criterion for determining whether or not a process is spontaneous it is rather cumbersome as it requires one to calculate not only the entropy change for the system but also that of the surroundings It would be much more convenient if there was a single criterion that would do the job and focus only on the system As it turns out there is Since we know that for any natural process and all we need to do is to find an expression for that can be determined by the changes in the system itself Fortunately we have already done that Recalling that at constant temperature and at constant pressure it follows that at constant temperature and pressure Substitution into the above equations yields an expression for the criterion of spontaneity that depends only on variables describing the changes in the system Delta S_univ ge Delta S_sys dfracDelta H_sysT so Multiplying both sides by yields A similar derivation for constant volume processes results in the expression at constant volume and temperature Equation refchem is of great use to chemists as most of chemistry occurs at constant pressure For geologists however who are interested in processes that occur at very high pressures say under the weight of an entire mountain and expansion is not a possibility the constant volume expression of Equation refchem may be of greater interest All of the above arguments can be made for systems in which the temperature is not constant by considering infinitesimal changes The resulting expressions are and The Gibbs and Helmholtz Functions Equation refchem suggests a very convenient thermodynamic function to help keep track of both the effects of entropy and enthalpy changes This function the Gibbs function or Gibbs Free Energy is defined by A change in the Gibbs function can be expressed Or at constant temperature And the criterion for a process to be spontaneous is the DG As such it should be clear spontaneity is not merely a function the enthalpy change although exothermic processes tend to be spontaneous but also a function of the entropy change weighted by the temperature Going back to an earlier example with and with It is easy to see why both processes are spontaneous In the first case the process is exothermic favorable and proceeds with an increase in entropy also favorable due to the formation of fragments in the liquid phase more chaotic from a very ordered solid more ordered The second reaction is endothermic unfavorable but proceeds with an increase in entropy favorable So so long as the temperature is high enough the entropy term will overwhelm the enthalpy term and cause the process to be spontaneous The conditions for spontaneous processes at constant temperature and pressure can be summarized in Table Table Spontaneity Conditions for a Process under Constant Temperature and Pressure Spontaneous At high T At no T At all T At low T Similarly to the Gibbs function the Helmholtz function is defined by and provides another important criterion for spontaneous processes at constant value and temperature At constant temperature the Helmholtz function can be expressed by Based on similar arguments used for the Gibbs function the Helmholtz function also can be used to predict which processes will be spontaneous at constant volume and temperature according to Table Table Spontaneity Conditions for a Process under Constant Temperature and Volume Spontaneous At high T At no T At all T At low T Calculating for Reactions Much like in the case of enthalpy and unlike entropy free energy functions do not have an unambiguous zero to the energy scale So just like in the case of enthalpies of formation by convention the standard free energy of formation for elements in their standard states is defined as zero This allows for two important things to happen First can be measured and tabulated for any substance in principle at least is determined to be for the reaction that forms one mole of a compound from elements in their standard states similarly to how is defined Secondly tabulated can be used to calculate standard reaction free energies in much the same way as is used for reaction enthalpies Example Given the following data at K calculate at K for the following reaction Substance kJmol CHg CHg Solution The values can be used to calculate for the reaction in exactly the same method as can be used to calculate a reaction enthalpy Note is not included in the calculation since for is since it is an element in its standard state Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Free Expansion of a Gas Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers To develop the theory of thermodynamics we must be able to model the thermodynamic properties of gases as functions of pressure temperature and volume To do so we consider processes in which the volume of a gas changes For the expansion or compression of a gas to be a reproducible process the exchange of heat between the system and its surroundings must be controlled There are two straightforward ways to do this We can immerse the system in a constant temperature bath whose temperature is the same as that of the system in this case and we can say that the process is isothermal Alternatively we can isolate the system so that it cannot exchange heat with the surroundings in this case and the process is said to be adiabatic In we find that the work done on a system when its volume changes by under the influence of an applied pressure is Any expansion of a system in which the applied pressure is less than the system pressure can be called a free expansion In Section we consider the adiabatic expansion of a real gas against a constant applied pressurea process known as a JouleThomson expansion We find that we must introduce a new parameterthe JouleThomson coefficientin order to describe the behavior of a real gas in a free expansion The JouleThomson coefficient varies with pressure and temperature Literally an isothermal process is one in which the temperature of the system remains the same throughout the process However we often use the term to mean merely that the process occurs while the system is in thermal contact with constanttemperature surroundings The free expansion of a gas is an irreversible process in principle the temperature of a gas undergoing a free expansion is not a meaningful quantity When we talk about an isothermal free expansion of a gas we mean that the final temperature is the same as the initial temperature Here we consider the behavior of ideal gases and we begin by considering the limiting case of a free expansion in which the applied pressure is zero Physically this corresponds to the expansion of a system into a very large evacuated container Under this condition and the energy change is For one mole of any substance If only pressurevolume work is possible and the applied pressure is zero we have and where and are the temperatures of the substance before and after the expansion respectively At ordinary temperatures changes only slowly as the temperature changes Over a short temperature range it is usually a good approximation to assume that is constant We have one mole of any gas or other substance For a monatomic ideal gas the energy change is exactly one mole of a monatomic ideal gas The enthalpy change for any process is If the system is one mole of an ideal gas we have because one mole of any ideal gas For an isothermal free expansion against an applied pressure of zero we have and so neither the energy nor the enthalpy of the gas changes Since also there can be no exchange of heat with the surroundings We have free expansion ideal gas For an adiabatic free expansion we have and and it follows again that We see that the isothermal and adiabatic expansions of an ideal gas into a vacuum are equivalent processes If the expansion is opposed by a nonzero applied pressure the two processes cease to be equivalent Free Particle Motions in More Dimensions Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah The Schrdinger EquationBoundary ConditionsEnergies and Wave Functions for Bound StatesQuantized Action Can Also be Used to Derive Energy Levels Action Can Also be Used to Generate Wave FunctionsContributors and Attributions The number of dimensions depends on the number of particles and the number of spatial and other dimensions needed to characterize the position and motion of each particle The number of dimensions also affects the number of quantum numbers that may be used to label eigenstates of the Hamiltonian The Schrdinger Equation Consider an electron of mass m and charge moving on a twodimensional surface that defines the plane eg perhaps an electron is constrained to the surface of a solid by a potential that binds it tightly to a narrow region in the direction but allows it to roam freely over a rectangular area in the plane and assume that the electron experiences a constant and not timevarying potential at all points in this plane For example if is negative it could reflect the binding energy of the electron relative to its energy in vacuum The pertinent time independent Schrdinger equation is The task at hand is to solve the above eigenvalue equation to determine the allowed energy states for this electron Because there are no terms in this equation that couple motion in the and directions eg no terms of the form or or separation of variables can be used to write as a product Substitution of this form into the Schrdinger equation followed by collecting together all dependent and all ydependent terms gives Since the first term contains no dependence and the second contains no dependence and because the right side of the equation is independent of both and both terms on the left must actually be constant these two constants are denoted and respectively realizing that they have units of energy This observation allows two separate Schrdinger equations to be written and The total energy can then be expressed in terms of these separate energies and from Solutions to the and Schrdinger equations are easily seen to be Two independent solutions are obtained for each equation because the and space Schrdinger equations are both second order differential equations ie a second order differential equation has two independent solutions Boundary Conditions The boundary conditions not the Schrdinger equation determine whether the eigenvalues will be discrete or continuous If the electron is entirely unconstrained within the plane the energies and can assume any values this means that the experimenter can inject the electron onto the plane with any total energy and any components and along the two axes as long as In such a situation one speaks of the energies along both coordinates as being in the continuum or not quantized In contrast if the electron is constrained to remain within a fixed area in the plane eg a rectangular or circular region then the situation is qualitatively different Constraining the electron to any such specified area gives rise to boundary conditions that impose additional requirements on the above and functions These constraints can arise for example if the potential becomes very large for values outside the region in which case the probability of finding the electron outside the region is very small Such a case might represent for example a situation in which the molecular structure of the solid surface changes outside the enclosed region in a way that is highly repulsive to the electron eg as in the case of molecular corrals on metal surfaces This case could then represent a simple model of socalled corrals in which the particle is constrained to a finite region of space For example if motion is constrained to take place within a rectangular region defined by then the continuity property that all wave functions must obey because of their interpretation as probability densities which must be continuous causes to vanish at and at That is because must vanish for and must vanish for and because is continuous it must vanish at and at Likewise must vanish at and at To implement these constraints for one must linearly combine the above two solutions and to achieve a function that vanishes at One is allowed to linearly combine solutions of the Schrdinger equation that have the same energy ie are degenerate because Schrdinger equations are linear differential equations An analogous process must be applied to to achieve a function that vanishes at Further requiring and to vanish respectively at and respectively gives equations that can be obeyed only if and assume particular values These equations are equivalent ie using to Knowing that vanishes at for although the function vanishes for this function vanishes for all or and is therefore unacceptable because it represents zero probability density at all points in space one concludes that the energies and can assume only values that obey or and and It is important to stress that it is the imposition of boundary conditions expressing the fact that the electron is spatially constrained that gives rise to quantized energies In the absence of spatial confinement or with confinement only at or or only at or quantized energies would not be realized In this example confinement of the electron to a finite interval along both the and coordinates yields energies that are quantized along both axes If the electron were confined along one coordinate eg between but not along the other ie is either restricted to vanish only at or at or at neither point then the total energy lies in the continuum its component is quantized but is not Analogs of such cases arise for example for a triatomic molecule containing one strong and one weak bond If the bond with the higher dissociation energy is excited to a level that is not enough to break it but that is in excess of the dissociation energy of the weaker bond one has a situation that is especially interesting In this case one has two degenerate states one with the strong bond having high internal energy and the weak bond having low energy and a second with the strong bond having little energy and the weak bond having more than enough energy to rupture it Although an experiment may prepare the molecule in a state that contains only the former component ie with coupling between the two degenerate functions induced by terms in the Hamiltonian H that have been ignored in defining and can cause the true wave function to acquire a component of the second function as time evolves In such a case one speaks of internal vibrational energy relaxation IVR giving rise to unimolecular decomposition of the molecule Energies and Wave Functions for Bound States For discrete energy levels the energies are specified functions that depend on quantum numbers one for each degree of freedom that is quantized Returning to the situation in which motion is constrained along both axes the resultant total energies and wave functions obtained by inserting the quantum energy levels into the expressions for and are as follows and with and The two factors are included to guarantee that is normalized Normalization allows to be properly identified as a probability density for finding the electron at a point Shown in Figure are plots of four such two dimensional wave functions for and values of and respectively Figure Plots of the and wave functions Note that the functions vanish on the boundaries of the box and notice how the number of nodes ie zeroes encountered as the wave function oscillates from positive to negative is related to the and quantum numbers and to the energy This pattern of more nodes signifying higher energy is one that we encounter again and again in quantum mechanics and is something the student should be able to use to guess the relative energies of wave functions when their plots are at hand Finally you should also notice that as in the onedimensional box case any attempt to classically interpret the probabilities corresponding to the above quantum wave functions will result in failure As in the onedimensional case the classical would be constant along slices of fixed and varying or slices of fixed and varying within the box because the speed is constant there However the quantum plots at least for small quantum numbers are not constant For large and ny values the quantum plots will again via the quantumclassical correspondence principle approach the constant classical form except near the classical turning points ie near the edges of the twodimensional box If instead of being confined to a rectangular corral the electron were constrained to lie within a circle of radius R the Schrdinger equation is more favorably expressed in polar coordinates Transforming the partial derivatives appearing in the Schrdinger equation into polar coordinates and realizing that the potential depends on but not on gives Again using separation of variables to substitute into the Schrdinger equation and dividing by we obtain where is the value of the potential inside the circular region The first two terms on the left and the on the right side contain no reference to so the quantity must be independent of Moreover because the coordinates and describe the same point in space must obey The solutions to the above differential equation for subject to the periodicity condition are This means that the equation for the radial part of the wave function is or This differential equation is probably not familiar to you but it turns out this is the equation obeyed by socalled Bessel functions The Bessel functions labeled obey so our function is The full wave functions are then where is a normalization constant The energy eigenvalues cannot be expressed analytically as in the particleina box system where we used knowledge of the zeros of the sin function to determine However knowing that must vanish at we can use tables for example see Kreyszig E Advanced Engineering Mathematics th ed John Wiley and Sons Inc New York that give the values of at which vanishes to determine the set of eigenvalues associated with each value of the angular momentum quantum number In the table shown below we list the first five values at which and vanish Values of at which vanish for and If we call the values at which vanishes then the energies are given as From the ordering of the values shown in the table above we can see that the ordering of the energy levels will be and so forth regardless of the size of the circle or the mass of the particle The state with has the same energy as that with likewise has the same energy as So all but the states are doubly degenerate the only difference between such pairs of states is the sense of the angular momentum terms These energy levels depend on both the angular momentum quantum number as well as the radial quantum number and they depend upon much like the particleinabox energies depend on the box length In Figure a we show plots of the probability densities for and and for and to illustrate how the number of radial nodes increases as increases Figure a Plots of for top middle and bottom Taken from Ellison M D J Chem Educ The character of also changes with For there is high amplitude for the particle being in the center of the circle but for there is no amplitude in the center This is analogous to what one finds for atomic orbitals orbitals have nonzero amplitude at the nucleus but p d and higher orbitals do not Lets examine a few more easy problems that can be solved analytically to some degree This will help illustrate how boundary conditions generate quantization and how the number of quantum numbers depends on the dimensionality of the problem When considering a particle of mass moving in three dimensions but constrained to remain within a sphere of radius R we replace the three Cartesian coordinates and by the spherical coordinates and Doing so changes the Schrdinger equations kinetic energy terms into what we show below Taking the potential to be a constant for and infinite for we can again use separation of variables to progress in solving this three dimensional differential equation We substitute into the Schrdinger equation and taking into account that the socalled spherical harmonic functions obey the following This reduces the Schrdinger equation to an equation for the radial function Again this equation is probably not familiar to you but it can be recast in a way that makes it equivalent to the equation obeyed by socalled spherical Bessel functions by taking The result is that the wave functions for this problem reduce to where is a normalization constant The energies are determined by requiring to vanish at which is analogous to insisting that the spherical Bessel function vanish at in the earlier problem we studied The values of at which vanish again can be found in various tabulations including that cited earlier Several of these values are tabulated below for illustration Values of at which vanish for and n n n n L L L L L From the values of one finds the energies from Again we see how the energy depends on the size of the constraining region characterized by very much in the same way as in the earlier systems We also see that depends on the angular momentum quantum number much as it did in the preceding example and on the mass of the particle However the energy ordering of these levels is different from what we have seen earlier as reflected in the ordering of the values shown in the above table The energies appear in the order and so on and this is true for any size sphere and any particle mass m If instead of being constrained to move within a spherical volume the particle is constrained to move on the surface of a sphere or radius the variable is fixed at and the Schrdinger equation becomes Using we can see that the wave functions are the spherical harmonics and the energies are given by Note that the energies depend on but not on the quantum number So each state belonging to level is fold degenerate because ranges from to Finally if instead of being constrained to move within a circle of radius R the particle were constrained to move on the surface of the circle the twodimensional Schrdinger equation treated earlier would reduce to The solutions are the familiar functions with and the energies are Note that the quantization of energy arises because the angular momentum is quantized to be this condition arose in turn by the condition that As with the case of a particle moving within the circular region the states with are doubly degenerate the difference between pairs of such states reflecting the sense of their angular momentum These model problems will be seen in Chapter to be very useful representations of situations that arise when an electron is constrained within or on the surface of various nanoscopic particles For now they were discussed to illustrate how separations of variables can sometimes be used to decompose the Schrdinger equation into onedimensional ordinary differential equations and to show how it is the boundary conditions either constraining to vanish at certain distances or insisting that be periodic when appropriate that produce the quantization It is important to note that it is when a particle is spatially constrained eg when its wave function was forced to vanish at two locations and that quantized energy levels result When the particle is not so spatially trapped its energy will not be quantized You will see this behavior over and over as we explore other models for electronic vibrational and rotational motions in molecules Quantized Action Can Also be Used to Derive Energy Levels There is another approach that can be used to find energy levels and is especially straightforward to use for systems whose Schrdinger equations are separable The socalled classical action denoted of a particle moving with momentum p along a path leading from initial coordinate at initial time to a final coordinate at time is defined by Here the momentum vector p contains the momenta along all coordinates of the system and the coordinate vector likewise contains the coordinates along all such degrees of freedom For example in the twodimensional particleinabox problem considered above has two components as does and the action integral is In computing such actions it is essential to keep in mind the sign of the momentum as the particle moves from its initial to its final positions The examples given below will help clarify these matters and will show how to apply the idea For systems for which the Hamiltonian is separable the action integral decomposes into a sum of such integrals one for each degree of freedom In the twodimensional example the additivity of H means that and can be independently solved for in terms of the potentials and as well as the energies and associated with each separate degree of freedom the signs on and must be chosen to properly reflect the motion that the particle is actually undergoing at any instant of time Substituting these expressions into the action integral yields The relationship between these classical action integrals and the existence of quantized energy levels has been shown to involve equating the classical action for motion that is periodic between a left and right turning point as for a classical particle undergoing periodic vibrational motion to the following multiple of Plancks constant where the quantization index ranges from to in steps of unity Alternatively for motion in a closed angular path as for a particle moving on a circular or elliptical path the action quantization condition reads where again ranges from to in steps of unity When actionquantization as described above is applied to the socalled harmonic oscillator problem this serves as the simplest reasonable model for vibration of a diatomic molecule AB that we will study in quantum form later one expresses the total energy as the sum of kinetic and potential energies where is the reduced mass of the AB diatomic molecule is the force constant describing the bond between A and B is the bondlength displacement and p is the momentum associated with the bond length The quantized action requirement then reads This integral is carried out between and the left and right turning points of the oscillatory motion and back again to form a closed path Carrying out this integral and equating it to gives the following expression for the energy If the quantum number is allowed to assume integer values ranging from to infinity these energy levels agree with the full quantum treatments results that we will obtain later For an example of applying this approach to a problem involving motion along a closed loop lets consider the free ie with no potential affecting its angular motion rotation of a diatomic molecule AB having fixed bond length R The rotational energy can be written as where is the momentum associated with rotation and is the reduced mass of the AB molecule Solving for and inserting this into the actionquantization equation appropriate for motion along a closed loop gives Solving for the energy then gives which is exactly the same result as we obtained earlier when solving the Schrdinger equation for the motion of a particle moving on a circle Now lets apply action quantization to each of the independent coordinates of the twodimensional particle in a box problem The two separate action quantization conditions read Notice that the sign of the momenta are positive in each of the first integrals appearing above because the particle is moving from to and analogously for motion and thus has positive momentum and negative in each of the second integrals because the motion is from to and analogously for motion and thus the particle has negative momentum Within the region bounded by the potential is constant and can be taken as zero this just gives our reference point for total energy Using this fact and reversing the upper and lower limits and thus the sign in the second integrals above one obtains Solving for and one finds These are not the same quantized energy levels that arose when the wave function boundary conditions were matched at and In the Schrdinger equation approach the energy expressions did not have the factor that appears in the above actionbased result It turns out that for potentials that are defined in a piecewise manner as the particleinabox potential is ie the potential undergoes an infinite jump at and the action quantization condition has to be modified An example of how and why one has to make this modification is given in a paper from Prof Bill Millers group J E Adams and W H Miller J Chem Phys but I will not discuss it further here because its details are beyond the level of this text Suffice it to say that for periodic motion between two turning points on a smooth ie nonpiecewise potential is the correct action quantization value For angular motion on a closed loop nh is the proper value But for periodic motion between turning points on a piecewise potential the modifications discussed in the above reference must be applied to cause action quantization to reproduce the correct quantum result The use of action quantization as illustrated above has become a very important tool It has allowed scientists to make great progress toward bridging the gap between classical and quantum descriptions of molecular dynamics In particular by using classical concepts such as trajectories and then imposing quantizedaction conditions people have been able to develop socalled semiclassical models of molecular dynamics In such models one is able to retain a great deal of classical understanding while building in quantum effects such as energy quantization zeropoint energies and interferences Both at my Theory Page web site and from papers accessed on the web site of Professor William H Miller one of the pioneers of semiclassical theory as applied to chemistry you can learn more about this subject Before leaving this section it is worth discussing a bit more the energy and angular momentum quantization that occurs when treating free onedimensional rotational motion of a particle on a circle or a linear rigid molecule constrained to lie on a plane When we used action quantization to address this kind of problem we obtained quantized energies which through the energy expression given in terms of angular momentum implies that the angular momentum itself is quantized This is the same result we obtain when we seek eigenfunctions and eigenvalues the quantum mechanics angular momentum operator As we showed earlier this operator when computed as the component of can be written in polar coordinates as The eigenfunctions of this operator have the form and the eigenvalues are a h Because geometries with azimuthal angles equal to or equal to are exactly the same geometries the function should be exactly the same as This can only be the case if a is an integer Thus one concludes that only integral multiples of h can be allowed values of the component of angular momentum Experimentally one measures the component of an angular momentum by placing the system possessing the angular momentum in a magnetic field of strength B and observing how many component energy states arise This splitting in energy levels is termed the Zeeman effect For example a boron atom with one unpaired electron its orbital has one unit of orbital angular momentum so one finds three separate component values which are usually denoted and Another example is offered by the scandium atom with one unpaired electron in a d orbital this atoms states split into five component states In each case one finds values of the quantum number and because L is an integer is an odd integer Both of these observations are consistent with the expectation that only integer values can occur for eigenvalues as obtained from action quantization and from the boundary condition However it has been observed that some species do not possess or or or component states but an even number of such states In particular electrons protons or neutrons are observed to have only two component eigenvalues This also is observed in for example the Boron atom mentioned above if one examines the further splittings of the m and levels caused by the magnetic fields action on the unpaired electrons spin Because as we discuss later in this text all angular momenta have component eigenvalues that are separated from one another by unit multiples of h one is forced to conclude that these three fundamental buildingblock particles electrons protons and neutrons have component eigenvalues of and The appearance of halfintegral angular momenta is not consistent with the actionquantization result or the observation made earlier that and correspond to exactly the same physical point in coordinate space which in turn implies that only fullinteger angular momenta are possible The resolution of the above paradox ie how can halfinteger angular momenta exist involves realizing that some angular momenta correspond not to the angular momenta of a physical mass rotating but instead are intrinsic properties of certain particles That is the intrinsic angular momenta of electrons protons and neutrons can not be viewed as arising from rotation of some mass that comprises these particles Instead such intrinsic angular momenta are fundamental built in characteristics of these particles For example the two and angular momentum states of an electron usually denoted a and b respectively are two internal states of the electron that are degenerate in the absence of a magnetic field but which represent two distinct states of the electron Analogously a proton has and states as do neutrons All such halfintegral angular momentum states cannot be accounted for using classical mechanics but are known to arise in quantum mechanics This means that when we teach introductory chemistry to young students it is not correct to say that the up and down a and b spin states of an electron can be viewed in terms of the electrons mass spinning clockwise or counterclockwise around some axis Such spinningmass angular momenta can only possess integer values halfinteger angular momenta cannot and should not be described in terms of spinning masses Action Can Also be Used to Generate Wave Functions Action integrals computed from classical descriptions of motion on potential energy surfaces can also be used to generate approximate quantum wave functions So doing offers yet another avenue for making connection between the classical and quantum worlds To see how such a connection can arise directly from the Schrdinger equation we begin with the timeindependent Schrdinger equation for a single particle of mass moving on a potential that depends on the particles position coordinates Then we express the complex wave function as a constant real amplitude A multiplied by a complex phase which we write as Substituting this expression for into the Schrdinger equation gives an equation for This equation contains both real and imaginary components nb itself is complex It is usually solved by assuming can be expanded in a power series in the variable This expansion is motivated by noting that if the factor in the above equation is neglected the resulting equation would make sense if were equal to the classical momentum of the particle So taking the limit of the equation for appears to reduce this quantum mechanics equation to a classical result in which So substituting into the above equation for and gathering together all terms of a given power in produces equations for the various the first two of which read and To simplify further discussion of this socalled semiclassical wave function theory let us restrict attention to the case in which there is only one spatial coordinate For the two or threedimensional cases and are vector quantities and the solution of these equations is considerably more complicated especially if the potential can not be separated into additive contributions from each of the variables When there is only one spatial coordinate and are scalar quantities The first equation can be solved for and gives two independent solutions ie those corresponding to the sign each of which will be real when ie in classically allowed regions of space and imaginary when ie in classically forbidden regions Notice that contains an integrand equal to the classical momentum The equation for can also be solved So through firstorder in the semiclassical wave functions are These pairs of wave functions are often expressed as in regions of space where and in the classically forbidden regions where Notice that the wave functions in the classically allowed regions have probability densities given by which is exactly the classical probability density we discussed earlier in this Chapter The probability is inversely proportional to the speed of the particle at location r and has the same singularity as the classical probability at turning points where In contrast the probability densities in regions where either grow or decay exponentially within these classically forbidden regions Lets see how these semiclassical wave functions can be applied to some of the model problems we discussed earlier For the one dimensional particleinabox problem the two exponentially growing and decaying functions are not needed because in the regions and the wave function can be taken to vanish Within the region there are two independent wave functions and the potential is constant lets call the potential in this region So the integration appearing in these two wave functions can be carried out to give We can combine these two functions to generate a function that will vanish at as it must for this particleinabox problem We can then use the condition that must also vanish at to obtain an equation that specifies the energies that are allowed which means that These energies are exactly the same as we found when we solved the Schrdinger equation for this model problem It is informative to note that these semiclassical wave functions which are not exact because they were obtained by retaining only terms up to the first power of were able to generate quantum nodal patterns ie interferences and quantized energy levels even though they contained classical concepts such as the momentum at various positions in space It was by superimposing two functions having the same energy that nodal patterns were obtained Lets now consider what happens when we apply the semiclassical wave function to the harmonic oscillator problem also discussed earlier In this case there are two classical turning points and at which The semiclassical wave functions appropriate to the three regions two classically forbidden and one classically allowed are The first two decay exponentially within the two classically forbidden regions The third is a combination of the two independent solutions within the classically allowed region with the amplitudes of the two solutions defined by the coefficients and The amplitudes and multiply the wave functions in the two classically forbidden regions and all four amplitudes as well as the energy must be determined by i normalizing the total wave function to obey and by matching the wave functions and and their first derivatives at and the wave functions and and their first derivatives at Before addressing how this wave function matching might be accomplished let me point out an interesting property of the factor entering into the exponential of the semiclassical wave function We first use the two expressions and given above for the first two components of and then make use of the harmonic form of Next we evaluate the integral of for a closed classical path in which the system moves from the left turning point to the right turning point and back again to the left turning point The contribution from integrating along this closed path is nb the sign is used for the first part of the path because the particle has positive momentum and the sign applies to the return part of the path when the particle has negative momentum which is exactly the action integral we treated earlier in this Chapter when we computed for the classical harmonic oscillator The contribution from integrating along this closed path can be evaluated by first writing The integral from to of this quantity can be carried out using the substitution as The evaluation of the integral remaining on the righthand side can be done using contour integration undergraduate students may not have encountered this subject within complex variable theory I refer them to pp Methods of Theoretical Physics P M Morse and H Feshabach McGrawHill New York or p Applied Complex Variables J W Dettman Macmillan Co New York The basic equation from contour integration says that an integral of the form where is a singularity is equal to Our integral has singularities at and at so there are two such contributions The net result is that our integral reduces to So the contribution to the integral of arising from to is equal to The integral from back to gives another factor or Combining the integral of and the integral of multiplied by because gives the following final result If the original Bohr quantization is applied to the integral of along a closed classical path our result above then says that which is the same as This means that the factor that arises in the action quantization condition for periodic motions between two turning points can be viewed as arising from the first quantum correction ie the term first order in to the semiclassical wave function Recall that equating this classical action integral to gave the correct ie quantum energies for this harmonic oscillator problem We have seen how a semiclassical wave function can be defined what its spatial probability density is how it can build in interference to achieve proper nodal patterns and how quantizing its action can give the correct allowed energy levels However there is one issue we have not fully addressed To solve for the coefficients multiplying the semiclassical wave functions in the classically allowed and forbidden regions the wave functions and and their first derivatives must be matched at and the wave functions and and their first derivatives must be matched at Unfortunately the details of this matching process are rather complicated and require examining in more detail the nature of the wave functions near the classical turning points where each of and contain factors of the form in their denominators It should be clear that matching functions and their derivatives that contain such singularities pose special challenges I will not go further into this matter here rather I refer the interested reader to pp of Quantum Mechanics rd Ed L I Schiff McGrawHill New York for a good treatment of this socalled WKB approach to the matching issue Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Gas Mixtures Amagats Law of Partial Volums Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Amagats law of partial volumes asserts that the volume of a mixture is equal to the sum of the partial volumes of its components For a mixture of components etc Amagats law gives the volume as For real gases Amagats law is usually an even better approximation than Daltons law Again for mixtures of ideal gases it is exact For an ideal gas the partial volume is Since we have for a mixture of ideal gases Applied to the mixture the idealgas equation yields Amagats law Also we have Gas Mixtures Daltons Law of Partial Pressures Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Thus far our discussion of the properties of a gas has implicitly assumed that the gas is pure We turn our attention now to mixtures of gasesgas samples that contain molecules of more than one compound Mixtures of gases are common and it is important to understand their behavior in terms of the properties of the individual gases that make it up The idealgas laws we have for mixtures are approximations Fortunately these approximations are often very good When we think about it this is not surprising After all the distinguishing feature of a gas is that its molecules do not interact with one another very much Even if the gas is composed of molecules of different kinds the unimportance of moleculemolecule interactions means that the properties of one kind of molecules should be nearly independent of the properties of the other kinds Consider a sample of gas that contains a fixed number of moles of each of two or more compounds This sample has a pressure a volume a temperature and a specified composition Evidently the challenge here is to describe the pressure volume and temperature of the mixture in terms of measurable properties of the component compounds There is no ambiguity about what we mean by the pressure volume and temperature of the mixture we can measure these properties without difficulty Given the nature of temperature it is both reasonable and unambiguous to say that the temperature of the sample and the temperature of its components are the same However we cannot measure the pressure or volume of an individual component in the mixture If we hope to describe the properties of the mixture in terms of properties of the components we must first define some related quantities that we can measure The concepts of a component partial pressure and a component partial volume meet this need We define the partial pressure of a component of a gas mixture as the pressure exerted by the same number of moles of the pure component when present in the volume occupied by the mixture at the temperature of the mixture In a mixture of moles of component moles of component etc it is customary to designate the partial pressure of component as It is important to appreciate that the partial pressure of a real gas can only be determined by experiment We define the partial volume of a component of a gas mixture as the volume occupied by the same number of moles of the pure component when the pressure is the same as the pressure of the mixture at the temperature of the mixture In a mixture of components etc it is customary to designate the partial volume of component as The partial volume of a real gas can only be determined by experiment Daltons law of partial pressures asserts that the pressure of a mixture is equal to the sum of the partial pressures of its components That is for a mixture of components A B C etc the pressure of the mixture is Under conditions in which the ideal gas law is a good approximation to the behavior of the individual components Daltons law is usually a good approximation to the behavior of real gas mixtures For mixtures of ideal gases it is exact To see this we recognize that for an ideal gas the definition of partial pressure becomes The idealgas mixture contains so that Applied to the mixture the idealgas equation yields Daltons law Equation refDalton When is the mole fraction of A in a mixture of ideal gases Gibbs Phase Rule Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Gibbs found an important relationship among the number of chemical constituents the number of phases present and the number of intensive variables that must be specified in order to characterize an equilibrium system This number is called the number of degrees of freedom available to the system and is given the symbol By specifying intensive variables we can specify the state of the systemexcept for the amount of each phase The number of chemical constituents is called the number of components and is given the symbol The number of components is the smallest number of pure chemical compounds that we can use to prepare the equilibrium system so that it contains an arbitrary amount of each phase The number of phases is given the symbol The relationship that Gibbs found between and is called Gibbs phase rule or just the phase rule The phase rule applies to equilibrium systems in which any component can move freely between any two phases in which that component is present We suppose that the state of the system is a continuous function of its state functions If intensive independent variables are sufficient to specify the state of an equilibrium system then specify an incrementally different equilibrium state of the same system This means that the number of degrees of freedom is also the number of intensive variables that can be varied independently while the system changes reversiblysubject to the condition that there is no change in either the number or kinds of phases present Moreover if we keep the systems intensive variables constant we can change the size of any phase without changing the nature of the system This means that Gibbs phase rule applies to any equilibrium system whether it is open or closed A system containing only liquid water contains one component and one phase By adjusting the temperature and pressure of this system we can arrive at a state in which both liquid and solid are present For present purposes we think of this as a second system Since the second system can be prepared using only liquid water or for that matter only ice it too contains only one component However since it contains both liquid and solid phases the second system contains two phases We see that the number of components required to prepare a system in such a way that it contains an arbitrary amount of each phase is not affected by phase equilibria However the number of componentsnumber of components is affected by chemical equilibria and by any other stoichiometric constraints that we impose on the system The number of components is equal to the number of chemical substances present in the system less the number of stoichiometric relationship among these substances Let us consider an aqueous system containing dissolved acetic acid ethanol and ethyl acetate For this system to be at equilibrium the esterification reaction must be at equilibrium In general we can prepare a system like this by mixing any three substances chosen from the set acetic acid ethanol ethyl acetate and water Hence there are three components The esterification reaction or its reverse then produces an equilibrium concentration of the fourth substance However there is a special case with only two components Suppose that we require that the equilibrium concentrations of ethanol and acetic acid be exactly equal In this case we can prepare the system by mixing ethyl acetate and water Then the stoichiometry of the reaction assures that the concentration condition will be met indeed this is the only way that the equalconcentration condition can be met exactly In this example there are four chemical substances The esterification reaction places one stoichiometric constraint on the amounts of these substances that can be present at equilibrium which means that we can change only three concentrations independently The existence of this constraint reduces the number of components from four to three An additional stipulation that the product concentrations be equal is a second stoichiometric constraint that reduces the number of independent components to two If we have a onephase system at equilibrium we see that the pressure the temperature and the componentconcentrations constitute a set of variables that must be related by an equation of state If we specify all but one of these variables the remaining variable is determined and can be calculated from the equation of state There are variables but the existence of the equation of state means that only of them can be changed independently Evidently the number of degrees of freedom for a onephase system is To find the number of degrees of freedom when such phases are in equilibrium with one another requires a similar but more extensive analysis We first consider the number of intensive variables that are required to describe completely a system that contains components and phases if the phases are not at equilibrium with one another Remember that the description we seek is complete except for a specification of the absolute amount of each phase present For the characterization of equilibrium that we seek these amounts are arbitrary In this case each phase is a subsystem in its own right Each phase can have a pressure a temperature and a concentration for each component Each of these properties can have a value that is independent of its value in any other phase There are variables for each phase or variables for all phases Table displays these variables Pressure Temperature Component Component Component C If the system is at equilibrium there are numerous relationships among these variables We want to know how many independent relationships there are among them Each such relationship decreases by one the number of independent intensive variables that are needed to specify the state of the system when all of the phases are at equilibrium Let us count these relationships The pressure must be the same in each phase That is etc Since and implies that etc there are only independent equations that relate these pressures to one another The temperature must be the same in each phase As for the pressure there are independent relationships among the temperature values The concentration of species in phase must be in equilibrium with the concentration of species in phase and so forth We can write an equation for phase equilibrium involving the concentration of in any two phases for example In Chapter we will find that this requirement can be stated more rigorously using a thermodynamic function that we call the chemical potential At equilibrium the chemical potential of species must be the same in each phase For the phases there are again independent relationships among the component concentration values This is true for each of the components so the total number of independent relationships among the concentrations is While every component need not be present in each phase there must be a finite amount of each phase present Each phase must have a nonzero volume To express this requirement using intensive variables we can say that the sum of the concentrations in each phase must be greater than zero For phase we must have and so on for each of the phases There are such relationships that are independent of one another If we subtract from the total number of relevant relationships the number of independent relationships that must be satisfied at equilibrium we find Gibbs phase rule There are independent relationships or degrees of freedom needed to describe the equilibrium system containing components and phases A component may not be present in some particular phase If this is the case the total number of relationships is one less than the number that we used above to derive the phase rule The number of equilibrium constraints is also one less than the number we used Consequently the absence of a component from any particular phase has no effect on the number of degrees of freedom available to the system at equilibrium Grahams Law of Effusion Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributor An important consequence of the kinetic molecular theory is what it predicts in terms of effusion and diffusion effects Effusion is defined as a loss of material across a boundary A common example of effusion is the loss of gas inside of a balloon over time The rate at which gases will effuse from a balloon is affected by a number of factors But one of the most important is the frequency with which molecules collide with the interior surface of the balloon Since this is a function of the average molecular speed it has an inverse dependence on the square root of the molecular weight This can be used to compare the relative rates of effusion for gases of different molar masses The Knudsen Cell Experiment A Knudsen cell is a chamber in which a thermalized sample of gas is kept but allowed to effuse through a small orifice in the wall The gas sample can be modeled using the Kinetic Molecular Theory model as a collection of particles traveling throughout the cell colliding with one another and also with the wall If a small orifice is present any molecules that would collide with that portion of the wall will be lost through the orifice Figure Effusion of gas particles through an orifice CC BYSA Astrang This makes a convenient arrangement to measure the vapor pressure of the material inside the cell as the total mass lost by effusion through the orifice will be proportional to the vapor pressure of the substance The vapor pressure can be related to the mass lost by the expression where is the mass lost is the area of the orifice is the time the effusion is allowed to proceed is the temperature and is the molar mass of the compound in the vapor phase The pressure is then given by A schematic of what a Knudsen cell might look like is given below Contributor Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Heat Capacities for Gases Cv Cp Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers If we heat or do work on any gasreal or idealthe energy change is When we investigate the energy change that accompanies a temperature change we can obtain reproducible results by holding either the pressure or the volume constant With volume held constant we measure With pressure held constant the energy change we measure depends on both and the relationship among the pressure volume and temperature of the gas If we know an equation of state for the gas and the values of both and we can find the energy change between any two states of the gas because the same change of state can be achieved in two steps one at constant pressure and one at constant volume To see this we recognize that the state of any pure gas is completely specified by specifying its pressure temperature and volume Any change of state necessarily involves changing at least two of these state functions Any change of state that changes all three of them can be achieved in an alternate way that involves two changes each of which occurs with one variable held constant For example the change can be achieved by the constantpressure sequence followed by the constantvolume sequence where is some intermediate temperature Note that this sequence has to be possible with held constant specifying a change in is sufficient to determine the change in with held constant specifying a change in is sufficient to determine the change in Let us consider how the energy of one mole of any pure substance changes with temperature at constant volume The rate of change of with is where we use the definition of For any system and hence for any substance the pressurevolume work is zero for any process in which the volume remains constant throughout therefore we have and one mole of any substance only PV work possible When we develop the properties of ideal gases by treating them as point mass molecules we find that their average translational kinetic energy is per mole or per molecule which clearly depends only on temperature Translational kinetic energy is the only form of energy available to a pointmass molecule so these relationships describe all of the energy of any pointmass molecule In particular they describe all of the energy of a monatomic ideal gas Since the energy of a monatomic ideal gas is independent of pressure and volume the temperature derivative must be independent of pressure and volume The ordinary derivative and the partial derivatives at constant pressure and constant volume all describe the same thing which we have just seen is one mole of a monatomic ideal gas It is useful to extend the idea of an ideal gas to molecules that are not monatomic When we do so we have in mind molecules that do not interact significantly with one another Another way of saying this is that the energy of the collection of molecules is not affected by any interactions among the molecules we can get the energy of the collection by adding up the energies that the individual molecules would have if they were isolated from one another In our development of statistical thermodynamics we find that the energy of a collection of noninteracting molecules depends only on the molecules energy levels and the temperature The molecules energy levels are fixed This means that if we extend our idea of ideal gases to include noninteracting polyatomic compounds the energies of such gases still depend only on temperature For any ideal gas we have one mole of any ideal gas However for polyatomic molecules it will no longer be true that Let us see why Recall that we construct our absolute temperature scale by extrapolating the Charles law graph of volume versus temperature to zero volume Figure By experiment we find that this graph is the same for one mole of a polyatomic ideal gas as it is for one mole of a monatomic ideal gas Evidently our definition of temperature depends only on the translational energy of ideal gas molecules and viceversa At a fixed temperature the average translational kinetic energy is the same for any ideal gas it is independent of the mass of the molecule and of the kinds of atoms in it To increase the temperature by one degree requires that the translational kinetic energy increase by and vice versa Consider what happens when we add energy to a polyatomic ideal gas Polyatomic gas molecules have energy in rotational and vibrational modes of motion When we add energy to such molecules some of the added energy goes into these rotational and vibrational modes To achieve the same increase in translational kinetic energy the total amount of energy added must be greater We find that we need a larger to achieve the same which means that the heat capacity either or of the polyatomic ideal gas is greater than that of a monatomic ideal gas Now let us consider the rate of change of with at constant pressure For one mole of any substance we have This equation is as far as we can go unless we can focus on a particular situation for which we know how work varies with temperature at constant pressure For one mole of an ideal gas we have this information From at constant we have If reversible work is done on the ideal gas and any ideal gas That is when enough heat is added to increase the temperature of one mole of ideal gas by one degree kelvin at constant pressure units of work are done on the gas This is the energy change that occurs because of the increase in volume that accompanies the onedegree temperature increase Since for any ideal gas we have one mole of any ideal gas For a monatomic ideal gas one mole of a monatomic ideal gas The heat capacity functions have a pivotal role in thermodynamics We consider many of their properties further in the next section and in later chapters particularly and Because we want to use these properties before we get around to justifying them all let us summarize them now For monatomic ideal gases and are independent of temperature For polyatomic gases real or ideal and are functions of temperature is always greater than but as the temperature decreases their values converge and both vanish at absolute zero At ordinary temperatures and increase only slowly as temperature increases For many purposes they can be taken to be constant over rather wide temperature ranges For real substances is a weak function of volume and is a weak function of pressure These dependencies are so small that they can be neglected for many purposes For ideal gases is independent of volume and is independent of pressure Heat Capacities of Solids the Law of Dulong and Petit Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers It is easy to maintain a constant pressure on a solid while varying its temperature To keep its volume rigorously constant over a range of temperatures is difficult Because the direct measurement of is straightforward most heatcapacity experiments on solids measure In Section we derive a general relationship between and other measurable properties of a substance This relationship makes it possible to evaluate indirectly For a solid this relationship shows that and are usually about the same Heat capacities of solids have been investigated over wide temperature ranges For most solids is approximately constant at room temperature and above For any of the heavier elements this constant has about the same value This observation was first made in It is called the law of Dulong and Petit in honor of the discoverers It played an important role in the establishment of correct atomic weights for the elements The value of the constant found by Dulong and Petit is about Remarkably the law can be extended to polyatomic molecules containing only the heavier elements Often the solidstate heat capacity of such molecules is about per mole of atoms in the molecule Correlations that are more detailed have been developed These relate the heat capacity of a mole of a molecular solid to its molecular formula In such correlations the heat capacity per mole increases by a fixed increment for each atom of say carbon in the molecule by a different fixed increment for each atom of nitrogen in the molecule etc For the lighter elements the increments are less than For the heavier elements the increment is approximately as observed by Dulong and Petit Figure Heat capacity of solid rhombohedral mercury Data from D R Linde Editor The Handbook of Chemistry and Physics CRC Press th edition p As the temperature of any solid decreases its heat capacity eventually begins to decrease At temperatures near absolute zero the heat capacity approaches zero The graph in Figure shows the shape of the heat capacity versus temperature curve for solid mercury The shape of this curve can be predicted from a very simple model for the energy modes available to the atoms in a solid Albert Einstein developed this model in Einsteins model for the heat capacity of a solid was an important milestone in the development of quantum mechanics Since then the basic ideas have been extended and refined to create more detailed theories that achieve good quantitative agreement with the experimental results for particular substances We discuss Einsteins treatment in Section Heat Engines and the Carnot Cycle Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Heat EnginesThe Carnot Cycle Heat Engines Sadi Carnot Mendoza a French physicist and engineer was very interested in the improvement of steam engines to perform the tasks needed by modern society Figure Sadi Carnot To simplify his analysis of the inner workings of an engine Carnot devised a useful construct for examining what affect engine efficiency His construct is the heat engine The idea behind a heat engine is that it will take energy in the form of heat and transform it into an equivalent amount of work Unfortunately such a device is impractical As it turns out nature prevents the complete conversion of energy into work with perfect efficiency This leads to an important statement of the Second Law of Thermodynamics It is impossible to convert heat into an equivalent amount of work without some other changes occurring in the universe As such a more reasonable picture of the heat engine is one which will allow for losses of energy to the surroundings The fraction of energy supplied to the engine that can be converted to work defines the efficiency of the engine The Carnot Cycle The Carnot cycle is a theoretical cyclic heat engine that can used to examine what is possible for an engine for which the job is convert heat into work For simplicity all energy provided to the engine occurs isothermally and reversibly at a temperature and all of the energy lost to the surroundings also occurs isothermally and reversibly at temperature In order to insure this the system must change between the two temperatures adiabatically Thus the cycle consists of four reversible legs two of which are isothermal and two of which are adiabatic Isothermal expansion from p and V to p and V at Th Adiabatic expansion from p V Th to p V Tl Isothermal compression from p and V to p and V at Tl Adiabatic compression from p V Tl to p V Th Plotted on a pressurevolume diagram the Carnot cycle looks as follows Because this is a closed cycle the ending state is identical initial state any state function must have a net change of zero as the system moves around the cycle Furthermore the efficiency of the engine can be expressed by the net amount of work the engine produces per unit of heat supplied to power the engine In order to examine this expression it is useful to write down expressions fo the heat and work flow in each of the four legs of the engine cycle Leg Heat Work I qh nRTh lnVV nRTh lnVV II CVTl Th III ql nRTl lnVV nRTl lnVV IV CVTh Tl The total amount of work done is given by the sum of terms in the thirst column Clearly the terms for the two adiabatic legs cancel as they have the same magnitude but opposite signs So the total work done is given by The efficiency of the engine can be defined as the total work produced per unit of energy provided by the high temperature reservoir or That expression has a lot of variables but it turns out that it can be simplified dramatically It turns out that by the choice of pathways connecting the states places a very important restriction on the relative values of V V V and V To understand this we must consider how the work of adiabatic expansion is related to the initial and final temperatures and volumes In Chapter it was shown that the initial and final temperatures and volumes of an adiabatic expansion are related by or Using the adiabatic expansion and compression legs II and IV this requires that and Since the second terms are reciprocals of one another the first terms must be as well A simple rearrangement shows that This is very convenient It is what allows for the simplification of the efficiency expression Equation refeff becomes Canceling terms in the numerator and denominator yields This expression gives the maximum efficiency and depends only on the high and low temperatures Also it should be noted that the heat engine can be run backwards By providing work to the engine it can be forces to draw heat from the low temperature reservoir and dissipate it into the high temperature reservoir This is how a refrigerator or heat pump works The limiting efficiency of such a device can also be calculated using the temperatures of the hot can cold reservoirs Example What is the maximum efficiency of a freezer set to keep ice cream at a cool oC which it is operating in a room that is oC What is the minimum amount of energy needed to remove J from the freezer and dissipate it into the room Solution The efficiency is given by Equation refeff and converting the temperatures to an absolute scale the efficiency can be calculated as This value can be used in the following manner So or It is interesting to note that any arbitrary closed cyclical process can be described as a sum of infinitesimally small Carnot cycles and so all of the conclusions reached for the Carnot cycle apply to any cyclical process Contributors Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Heat Transfer in Practical Devices Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers The amount of heat transferred to or from a system undergoing change is an important thermodynamic variable In practical devices the rate at which heat can be transferred to or from a system plays a very important role also Consider again the work produced by heating a gas that is confined in a cylinder that is closed by a piston Clearly the rate at which heat can be transferred from the outside to the gas determines the rate at which the piston moves outward and thus the rate at which work is done on the environment Does it matter whether the heattransfer process is fast or slow If the heat cost nothing would we care if our engine produced work only very slowly After all if we want more work and the heat is free we need only build more engines eventually we will have enough of them to produce any required amount of work Of course heat is not free more significantly for our present considerations the engines are not free either Engineers and accountants call the cost of heat an operating costcostoperating There are many other operating costs like labor supplies insurance and taxes The cost of the engine is called a capital costcostcapital To find the total cost of a unit of work we need to add up the various operating costs and a part of the cost of the engine The difference between an operating cost and a capital cost is that an operating cost is incurred at about the same time that the product in this case a unit of work is created In contrast a capital cost is incurred well before the product is created The purchase of a machine is a typical capital expense The cost of the machine is incurred long before the machine makes its last product This occurs because the machine must be paid for when it is acquired but it continues to function over a useful lifetime that is typically many years For example if an engine that costs can produce a maximum of units of work before it wears out the minimum contribution that the cost of the engine makes to the cost of the work it produces is per unit The life of the engine also enters into the estimation of capital cost If some of the work done by the engine will be produced ten years in the future we will be foregoing the interest that we could otherwise have earned on the money that we invested in the engine while we wait around to get the future work Operating costs are well defined because they are incurred here and now Capital costs are more problematic because they depend upon assumptions about things like the life of the machine and the variation in interest rates during that life Suppose that we are developing a new engine All else being equal we can decrease the capitalcost component of the work our engine produces by decreasing the time it needs to produce a unit of work The savings occurs because we can get the same amount of work from a smaller and hence lesscostly engine Since each unit of work requires that the same amount of heat be moved we can make the engine smaller only if we can move heat around more quickly In internal combustion engines we get heat into the engineinternal combustion with a combustion reaction an explosion and take most of it out again by venting the combustion products the exhaust gas So internal combustion engines have the great advantage that both of these steps can be fast Steam engines are successful because we can get heat into the engine quickly by allowing steam to flow from a boiler into the engine We can remove heat from the steam engine quickly by venting the spent steam which is feasible because the working fluid is water The Stirling engine is a type of external combustion engine that works by alternately heating expanding and cooling compressing an enclosed working fluid Stirling engines have theoretical advantages but they are not economically competitive essentially because heat transfer to and from the working fluid cannot be made fast enough Why does anyone care about capital cost Well we can be sure that the owner of an engine will be keenly interested in minimizing the dollars that come out of his pocket But capital cost is also a measure of the consumption of resourcesresources that may have more valuable alternative uses So if any segment of an economy uses resources inefficiently other segments of that economy must give up other goals that could have been achieved using the wasted resources Economic activity benefits many people besides the owners of capital If capital is used inefficiently society as a whole is poorer as a result Heat transfer has a profound effect also on the design of the machines that manufacture chemicals This occurs most conspicuously in processes that involve very exothermic reactions If heat cannot be removed from the reacting material fast enough the temperature of the material rises The higher temperature may cause side reactions that decrease the yield of the product If the temperature rises enough there may be an explosion For such reactions the equipment needed to achieve rapid heat transfer and to manage the rate of heat production and dissipation may account for a large fraction of the cost of the whole plant In some cases chemical reactions used for the production of chemicals produce enough heat that it is practical to use this waste heat for the production of electricity Heat Transfer in Reversible Processes Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers If a system is in thermal contact with its surroundings a reversible change can involve the exchange of heat between the system and the surroundings In Chapter we make a number of important observations about the nature of any heat transfer that occurs during a reversible process Let us review these ideas A system can undergo a change in which it accepts or liberates heat while its temperature remains constant If we boil a liquid at constant pressure a thermometer immersed in the liquid continues to show the same temperature even though we add more and more heat energy The added heat is used within the system to convert the liquid to its vapor If the liquid is stirred well any localized temperature excursions away from the equilibrium temperature are small it is a good approximation to say that the temperature of the system is homogenous throughout the system and that it has a constant value Nevertheless for a finite boiling rate we recognize that the idea of an isothermal process is indeed an approximation For heat transfer to occur from the surroundings to the system the surroundings must be at a higher temperature than the system The portion of the system in immediate contact with the wall of the vessel must be at a higher temperature than the portion in the interior of the vessel When we think about a constanttemperature system undergoing a reversible change while in thermal contact with its surroundings we imagine that heat can be transferred in either direction with equal facility If the system is taking up heat as the process proceeds we imagine that we can reverse the direction of the change simply by changing the direction of heat transfer Heat will flow from the system to the surroundings and the process will run backwards We can reverse the direction of heat flow by changing the temperature of the surroundings Initially the surroundings must be hotter than the system To reverse the direction of heat flow we must make the temperature of the surroundings less than that of the system Since a reversible process is one whose direction can be reversed by an arbitrarily small change in some state function the original temperatures must be arbitrarily close to one another For a system that exchanges heat with its surroundings a process can be reversible only if the temperatures of the system and the surroundings are arbitrarily close to one another In a reversible process net heat transfer occurs between two entitiesthe system and its surroundingsthat are arbitrarily close to thermal equilibrium Such a process is an idealization As we have noted several times a reversible process is a creature of theory that is merely approximated in real systems A reversible process does not have to be a constanttemperature process If the temperatures of system and surroundings change simultaneously they can remain arbitrarily close to one another throughout the process Nor must a system undergoing reversible change be in thermal contact with its surroundings A system can undergo a reversible change adiabatically Finally we have noted that the term isothermal process is often intended to mean a constanttemperature thermallyreversible process However the same words are frequently intended to indicate only that the final temperature of the system is the same as the initial temperature This is the case whenever the isothermal process is a spontaneous process The intended meaning is usually clear from the context HighEnd Methods for Treating Electron Correlation Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Quantum MonteCarloThe Method Although their detailed treatment is beyond the scope of this text it is important to appreciate that new approaches are always under development in all areas of theoretical chemistry In this Section I want to introduce you to two tools that are proving to offer high precision in the treatment of electron correlation energies These are the socalled quantum Quantum MonteCarlo and r approaches to this problem Both methods currently are used when one wishes to obtain the absolute highest precision in an electronic structure calculation The computational requirements of both of these methods are very high so at present they can only be used on species containing fewer than ca electrons However with the power and speed of computers growing as fast as they are it is likely that these highend methods will be more and more widely used as time goes by Quantum MonteCarlo In this method one first rewrites the time dependent Schrdinger equation for negative imaginary values of the time variable ie one simply replaces by This gives which is analogous to the wellknown diffusion equation The rewritten Schrdinger equation can be viewed as a diffusion equation in the spatial coordinates of the electrons with a diffusion coefficient that is related to the electrons mass me by The socalled source and sink term in the diffusion equation is related to the electronnuclear and electronelectron Coulomb potential energies denoted V In regions of space where is large and negative ie where the potential is highly attractive is large and negative so is large and positive This causes the concentration of the diffusing material to accumulate in such regions Likewise where is positive will decrease Clearly by recognizing as the concentration variable in this analogy one understands that will accumulate where is negative and will decay where is positive as one expects So far we see that the trick of taking to be negative and imaginary causes the electronic Schrdinger equation to look like a dimensional diffusion equation Why is this useful and why does this trick work It is useful because as we see in Chapter of this text MonteCarlo methods are highly efficient tools for solving certain equations it turns out that the diffusion equation is one such case So the Quantum MonteCarlo approach can be used to solve the imaginarytime Schrdinger equation even for systems containing many electrons But what does this imaginary time mean To understand the imaginary time trick let us recall that any wave function eg the trial wave function with which one begins to use MonteCarlo methods to propagate the diffusing function can be written in terms of the exact eigenfunctions of the Hamiltonian as follows If the MonteCarlo method can in fact be used to propagate forward in time such a function but with then it will in principle generate the following function at such an imaginary time As increases the relative amplitudes of all states but the lowest state ie that with smallest will decay compared to the amplitude of the lowest state So the timepropagated wave function will at long enough t be dominated by its lowestenergy component In this way the quantum MonteCarlo propagation method can generate a wave function in dimensions that approaches the groundstate wave function It has turned out that this approach which tackles the electron correlation problem headon has proven to yield highly accurate energies and wave functions that display the proper cusps near nuclei as well as the negative cusps ie the wave function vanishes whenever two electrons coordinates approach one another Finally it turns out that by using a starting function of a given symmetry and nodal structure this method can be extended to converge to the lowestenergy state of the chosen symmetry and nodal structure So the method can be used on excited states also In Chapter of this text you will learn how the MonteCarlo tools can be used to simulate the behavior of manybody systems eg the electron system we just discussed in a highly efficient and easily parallellized manner The Method In this approach to electron correlation one employs a trial variational wave function that contains components that depend explicitly on the interelectron distances By so doing one does not rely on the polarized orbital pair approach introduced earlier in this Chapter to represent all of the correlations among the electrons An example of such an explicitly correlated wave function is which consists of an antisymmetrized product of spinorbitals multiplied by a factor that is symmetric under interchange of any pair of electrons and contains the electronelectron distances in addition to a single variational parameter Such a trial function is said to contain linear correlation factors Of course it is possible to write many other forms for such an explicitly correlated trial function For example one could use as a trial function Both the linear and the exponential forms have been used in developing this tool of quantum chemistry Because the integrals that must be evaluated when one computes the Hamiltonian expectation value are most computationally feasible albeit still very taxing when the linear form is used this particular parameterization is currently the most widely used How Enthalpy Depends on Pressure Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Let us look briefly at the approximations and that we used in Section In these steps the pressure changes while the temperature remains constant In Chapter we find a general relationship for the pressuredependence of a systems enthalpy This evaluates to zero for an ideal gas and to a negligible quantity for many other systems For liquids and solids information on the variation of volume with temperature is collected in tables as the coefficient of thermal expansion where Consequently the dependence of enthalpy on pressure is given by For ice and the molar volume near C is The enthalpy change for compressing one mole of ice from the sublimation pressure to atm is To find the enthalpy change for expanding one mole of water vapor at C from atm to the sublimation pressure we use the virial equation and tabulated coefficients for water vapor to calculate We find See problem How The Enthalpy Change for a Reaction Depends on Temperature Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers In Section we see how to use tabulated enthalpies of formation to calculate the enthalpy change for a particular chemical reaction Such tables typically give enthalpies of formation at a number of different temperatures so that the enthalpy change for a given reaction can also be calculated at these different temperatures it is just a matter of repeating the same calculation at each temperature We often need to find the enthalpy change associated with increasing the temperature of a substance at constant pressure As we observe in this enthalpy change is readily calculated by integrating the heat capacity over the temperature change We may want to know for example the enthalpy change for increasing the temperature of one mole of methane from K to K with the pressure held constant at one bar In Table we find We might be tempted to think that the difference represents the enthalpy change associated with heating the methane This is not so The reason becomes immediately apparent if we consider a cycle in which we go from the elements to a compound at two different temperatures For methane this cycle is shown in Figure Figure A thermochemical cycle relating at two temperatures The difference between the standard enthalpies of formation of methane at K and K reflects the enthalpy change for increasing the temperatures of all of the reactants and products from K to K That is Over the temperature range from K to K the heat capacities of carbon hydrogen and methane are approximated by with values of and given in Table From this information we calculate the enthalpy change for increasing the temperature of one mole of each substance from K to K at bar and Thus from the cycle we calculate The tabulated value is The two values differ by or about This difference arises from the limitations of the twoparameter heatcapacity equations As another example of a thermochemical cycle let us consider the selective oxidation of methane to methanol at K and K From the enthalpies of formation in Table we calculate the enthalpies for the reaction to be and As in the previous example we use the tabulated heatcapacity parameters to calculate the enthalpy change for increasing the temperature of one mole of each of these gases from K to K at bar We find and Figure A thermochemical cycle relating at two temperatures The cycle is shown in Figure Inspecting this cycle we see that we can calculate the enthalpy change for warming one mole of methanol from K to K by summing the enthalpy changes around the bottom left side and top of the cycle that is This is J or about larger than the value obtained by integrating the heat capacity for methanol Hckel or Tight Binding Theory Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Contributors and Attributions Now lets examine what determines the energy range into which orbitals eg orbitals in polyenes metal semiconductor or insulator or orbitals in a solid or or atomic orbitals in a molecule split I know that in our earlier discussion we talked about the degree of overlap between orbitals on neighboring atoms relating to the energy splitting but now it is time to make this concept more quantitative To begin consider two orbitals one on an atom labeled A and another on a neighboring atom labeled B these orbitals could be for example the orbitals of two hydrogen atoms such as Figure illustrates Figure Two orbitals combine to produce a bonding and a antibonding molecular orbital However the two orbitals could instead be two orbitals on neighboring carbon atoms such as are shown in Figure as they form bonding and antibonding orbitals Figure Two atomic orbitals form a bonding and antibonding molecular orbital In both of these cases we think of forming the molecular orbitals MOs as linear combinations of the atomic orbitals AOs ca on the constituent atoms and we express this mathematically as follows where the are called linear combination of atomic orbital to form molecular orbital LCAOMO coefficients The MOs are supposed to be solutions to the Schrdinger equation in which the Hamiltonian H involves the kinetic energy of the electron as well as the potentials and detailing its attraction to the left and right atomic centers this oneelectron Hamiltonian is only an approximation for describing molecular orbitals more rigorous Nelectron treatments will be discussed in Chapter In contrast the AOs centered on the left atom A are supposed to be solutions of the Schrdinger equation whose Hamiltonian is and the AOs on the right atom B have Substituting into the MOs Schrdinger equation and then multiplying on the left by the complex conjugate of and integrating over the and coordinates of the electron produces Recall that the Dirac notation denotes the integral of and and denotes the integral of and the operator op acting on b In what is known as the Hckel model in chemistry or the tightbinding model in solidstate theory one approximates the integrals entering into the above set of linear equations as follows The diagonal integral involving the AO centered on the right atom and labeled is assumed to be equivalent to which means that net attraction of this orbital to the left atomic center is neglected Moreover this integral is approximated in terms of the binding energy denoted not to be confused with the electron spin function a for an electron that occupies the orbital The physical meaning of is the kinetic energy of the electron in plus the attraction of this electron to the right atomic center while it resides in Of course an analogous approximation is made for the diagonal integral involving These values are negative quantities because as is convention in electronic structure theory energies are measured relative to the energy of the electron when it is removed from the orbital and possesses zero kinetic energy The offdiagonal integrals are expressed in terms of a parameter which relates to the kinetic and potential energy of the electron while it resides in the overlap region in which both and are nonvanishing This region is shown pictorially above as the region where the left and right orbitals touch or overlap The magnitude of is assumed to be proportional to the overlap between the two AOs It turns out that is usually a negative quantity which can be seen by writing it as Since is an eigenfunction of having the eigenvalue the first term is equal to a negative quantity times the overlap The second quantity is equal to the integral of the overlap density multiplied by the negative Coulomb potential for attractive interaction of the electron with the left atomic center So whenever and have positive overlap b will turn out negative iii Finally in the most elementary Hckel or tightbinding model the offdiagonal overlap integrals are neglected and set equal to zero on the right side of the matrix eigenvalue equation However in some Hckel models overlap between neighboring orbitals is explicitly treated so in some of the discussion below we will retain With these Hckel approximations the set of equations that determine the orbital energies and the corresponding LCAOMO coefficients are written for the twoorbital case at hand as in the first matrix equations shown below left beginarraycc alpha beta beta alpha endarray right leftbeginarrayc C_L C_R endarray right varepsilon left beginarraycc S S endarray right leftbeginarrayc C_L C_R endarray right which is sometimes written a left beginarraycc alphavarepsilon betavarepsilon S betavarepsilon S alphavarepsilon endarray right leftbeginarrayc C_L C_R endarray right leftbeginarrayc endarray right These equations reduce with the assumption of zero overlap to left beginarraycc alpha beta beta alpha endarray right leftbeginarrayc C_L C_R endarray right varepsilon left beginarraycc endarray right leftbeginarrayc C_L C_R endarray right The a parameters are identical if the two AOs ca and are identical as would be the case for bonding between the two orbitals of two H atoms or two orbitals of two C atoms or two s orbitals of two Na atoms If the left and right orbitals were not identical eg for bonding in HeH or for the bonding in a CO group their a values would be different and the Hckel matrix problem would look like left beginarraycc alpha beta beta alpha endarray right leftbeginarrayc C_L C_R endarray right varepsilon left beginarraycc S S endarray right leftbeginarrayc C_L C_R endarray right To find the MO energies that result from combining the AOs one must find the values of e for which the above equations are valid Taking the matrix consisting of e times the overlap matrix to the left hand side the above set of equations reduces to the third set displayed earlier It is known from matrix algebra that such a set of linear homogeneous equations ie having zeros on the right hand sides can have nontrivial solutions ie values of that are not simply zero only if the determinant of the matrix on the left side vanishes Setting this determinant equal to zero gives a quadratic equation in which the e values are the unknowns This quadratic equation can be factored into a product which has two solutions As discussed earlier it turns out that the b values are usually negative so the lowest energy such solution is the solution which gives the energy of the bonding MO Notice that the energies of the bonding and antibonding MOs are not symmetrically displaced from the value a within this version of the Hckel model that retains orbital overlap In fact the bonding orbital lies less than b below a and the antibonding MO lies more than b above a because of the and factors in the respective denominators This asymmetric lowering and raising of the MOs relative to the energies of the constituent AOs is commonly observed in chemical bonds that is the antibonding orbital is more antibonding than the bonding orbital i bonding This is another important thing to keep in mind because its effects pervade chemical bonding and spectroscopy Having noted the effect of inclusion of AO overlap effects in the Hckel model I should admit that it is far more common to utilize the simplified version of the Hckel model in which the S factors are ignored In so doing one obtains patterns of MO orbital energies that do not reflect the asymmetric splitting in bonding and antibonding orbitals noted above However this simplified approach is easier to use and offers qualitatively correct MO energy orderings So lets proceed with our discussion of the Hckel model in its simplified version To obtain the LCAOMO coefficients corresponding to the bonding and antibonding MOs one substitutes the corresponding a values into the linear equations left beginarraycc alphavarepsilon beta beta alphavarepsilon endarray right leftbeginarrayc C_L C_R endarray right leftbeginarrayc endarray right and solves for the coefficients actually one can solve for all but one and then use normalization of the MO to determine the final Ca For example for the bonding MO we substitute into the above matrix equation and obtain two equations for and These two equations are clearly not independent either one can be solved for one C in terms of the other C to give which means that the bonding MO is The final unknown C_L is obtained by noting that f is supposed to be a normalized function Within this version of the Hckel model in which the overlap S is neglected the normalization of f leads to the following condition with the final result depending on assuming that each c is itself also normalized So finally we know that and hence the bonding MO is Actually the solution of could also have yielded and then we would have These two solutions are not independent one is just times the other so only one should be included in the list of MOs However either one is just as good as the other because as shown very early in this text all of the physical properties that one computes from a wave function depend not on but on So two wave functions that differ from one another by an overall sign factor as we have here have exactly the same and thus are equivalent In like fashion we can substitute into the matrix equation and solve for the can values that are appropriate for the antibonding MO Doing so gives us or alternatively Again the fact that either expression for is acceptable shows a property of all solutions to any Schrdinger equations any multiple of a solution is also a solution In the above example the two answers for differ by a multiplicative factor of Lets try another example to practice using Hckel or tightbinding theory In particular Id like you to imagine two possible structures for a cluster of three Na atoms ie pretend that someone came to you and asked what geometry you think such a cluster would assume in its ground electronic state one linear and one an equilateral triangle Further assume that the NaNa distances in both such clusters are equal ie that the person asking for your theoretical help is willing to assume that variations in bond lengths are not the crucial factor in determining which structure is favored In Figure I shown the two candidate clusters and their s orbitals Figure Linear and equilateral triangle structures of sodium trimer Numbering the three Na atoms valence s orbitals and we then set up the x Hckel matrix appropriate to the two candidate structures left beginarrayccc alpha beta beta alpha beta beta alpha endarray right for the linear structure nb the zeros arise because and do not overlap and thus have no coupling matrix element Alternatively for the triangular structure we find left beginarrayccc alpha beta beta beta alpha beta beta beta alpha endarray right as the Hckel matrix Each of these x matrices will have three eigenvalues that we obtain by subtracting e from their diagonals and setting the determinants of the resulting matrices to zero For the linear case doing so generates and for the triangle case it produces The first cubic equation has three solutions that give the MO energies for the bonding nonbonding and antibonding MOs respectively The second cubic equation also has three solutions So for the linear and triangular structures the MO energy patterns are as shown in Figure Figure Energy orderings of molecular orbitals of linear and triangular sodium trimer For the neutral cluster about which you were asked you have three valence electrons to distribute among the lowest available orbitals In the linear case we place two electrons into the lowest orbital and one into the second orbital Doing so produces a electron state with a total energy of Alternatively for the triangular species we put two electrons into the lowest MO and one into either of the degenerate MOs resulting in a electron state with total energy Because b is a negative quantity the total energy of the triangular structure is lower than that of the linear structure since The above example illustrates how we can use Hckel or tightbinding theory to make qualitative predictions eg which of two shapes is likely to be of lower energy Notice that all one needs to know to apply such a model to any set of atomic orbitals that overlap to form MOs is the individual AO energies a which relate to the electronegativity of the AOs the degree to which the AOs couple the b parameters which relate to AO overlaps an assumed geometrical structure whose energy one wants to estimate This example and the earlier example pertinent to or the bond in ethylene also introduce the idea of symmetry Knowing for example that ethylene and linear have a leftright plane of symmetry allows us to solve the Hckel problem in terms of symmetryadapted atomic orbitals rather than in terms of primitive atomic orbitals as we did earlier For example for linear we could use the following symmetryadapted functions both of which are even under reflection through the symmetry plane and which is odd under reflection The x Hckel matrix would then have the form left beginarrayccc alpha sqrtbeta sqrtbeta alpha alpha endarray right For example and are evaluated as follows The three eigenvalues of the above Hckel matrix are easily seen to be and exactly as we found earlier So it is not necessary to go through the process of forming symmetryadapted functions the primitive Hckel matrix will give the correct answers even if you do not However using symmetry allows us to break the full x in this case Hckel problem into separate Hckel problems for each symmetry component one odd function and two even functions in this case so a x and a sub matrix While we are discussing the issue of symmetry let me briefly explain the concept of approximate symmetry again using the above Hckel problem as it applies to ethylene as an illustrative example Figure a Ethylene molecules and orbitals showing the reflection plane that is a symmetry property of this molecule Clearly as illustrated in Figure a at its equilibrium geometry the ethylene molecule has a plane of symmetry denoted that maps nuclei and electrons from its left to its right and vice versa This is the symmetry element that could used to decompose the Hckel matrix describing the and orbitals into two x matrices However if any of the four CH bond lengths or HCH angles is displaced from its equilibrium value in a manner that destroys the perfect symmetry of this molecule or if one of the CH units were replaced by a CCH unit it might appear that symmetry would no longer be a useful tool in analyzing the properties of this molecules molecular orbitals Fortunately this is not the case Even if there is not perfect symmetry in the nuclear framework of this molecule the two atomic orbitals will combine to produce a bonding and antibonding orbital Moreover these two molecular orbitals will still possess nodal properties similar to those shown in Figure a even though they will not possess perfect even and odd character relative to the plane The bonding orbital will still have the same sign to the left of the plane as it does to the right and the antibonding orbital will have the opposite sign to the left as it does to the right but the magnitudes of these two orbitals will not be leftright equal This is an example of the concept of approximate symmetry It shows that one can use symmetry even when it is not perfect to predict the nodal patterns of molecular orbitals and it is the nodal patterns that govern the relative energies of orbitals as we have seen time and again Lets see if you can do some of this on your own Using the above results would you expect the cation to be linear or triangular What about the anion Next I want you to substitute the MO energies back into the x matrix and find the and coefficients appropriate to each of the MOs of the linear and of the triangular structure See if doing so leads you to solutions that can be depicted as shown in Figure and see if you can place each set of MOs in the proper energy ordering Figure The molecular orbitals of linear and triangular sodium trimer note they are not energy ordered in this figure Now I want to show you how to broaden your horizons and use tightbinding theory to describe all of the bonds in a more complicated molecule such as ethylene shown in Figure What is different about this kind of molecule when compared with metallic or conjugated species is that the bonding can be described in terms of several pairs of valence orbitals that couple to form twocenter bonding and antibonding molecular orbitals Within the Hckel model described above each pair of orbitals that touch or overlap gives rise to a x matrix More correctly all n of the constituent valence orbitals form an nxn matrix but this matrix is broken up into x blocks Notice that this did not happen in the triangular Na case where each AO touched two other AOs For the ethlyene case the valence orbitals consist of a four equivalent C orbitals that are directed toward the four H atoms b four H orbitals c two C orbitals directed toward one another to form the CC bond and d two C orbitals that will form the CC bond This total of orbitals generates Hckel matrices as shown below the ethylene molecule Figure Ethylene molecule with four CH bonds one CC bond and one CC bond We obtain one matrix for the CC bond of the form left beginarraycc alpha_sp beta_spsp beta_spsp alpha_sp endarray right and one matrix for the CC bond of the form left beginarraycc alpha_p_pi beta_p_pip_pi beta_p_pip_pi alpha_p_pi endarray right Finally we also obtain four identical matrices for the CH bonds left beginarraycc alpha_sp beta_spH beta_spH alpha_H endarray right The above matrices produce four identical CH bonding MOs having energies four identical CH antibonding MOs having energies one bonding CC orbital with a partner antibonding CC orbital with a CC bonding MO with and phi its antibonding partner with In all of these expressions the parameter is supposed to be that appropriate to the specific orbitals that overlap as shown in the matrices If you wish to practice this exercise of breaking a large molecule down into sets of interacting valence try to see what Hckel matrices you obtain and what bonding and antibonding MO energies you obtain for the valence orbitals of methane shown in Figure Figure Methane molecule with four CH bonds Before leaving this discussion of the Hckeltightbinding model I need to stress that it has its flaws because it is based on approximations and involves neglecting certain terms in the Schrdinger equation For example it predicts see above that ethylene has four energetically identical CH bonding MOs and four degenerate CH antibonding MOs However this is not what is seen when photoelectron spectra are used to probe the energies of these MOs Likewise it suggests that methane has four equivalent CH bonding and antibonding orbitals which again is not true It turns out that in each of these two cases ethylene and methane the experiments indicate a grouping of four nearly isoenergetic bonding MOs and four nearly isoenergetic antibonding MOs However there is some splitting among these clusters of four MOs The splittings can be interpreted within the Hckel model as arising from couplings or interactions among for example one sp or orbital on a given C atom and another such orbital on the same atom Such couplings cause the nxn Hckel matrix to not blockpartition into groups of sub matrices because now there exist offdiagonal b factors that couple one pair of directed valence to another When such couplings are included in the analysis one finds that the clusters of MOs expected to be degenerate are not but are split just as the photoelectron data suggest Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Hydrogenic Orbitals Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah The Equation The Equation The Equation SummaryContributors and Attributions The Hydrogenic atom problem forms the basis of much of our thinking about atomic structure To solve the corresponding Schrdinger equation requires separation of the and variables The Schrdinger equation for a single particle of mass moving in a central potential one that depends only on the radial coordinate can be written as or introducing the shorthand notation frachbarmu nabla psi V psi Epsi This equation is not separable in Cartesian coordinates because of the way and appear together in the square root However it is separable in spherical coordinates where it has the form Subtracting from both sides of the equation and multiplying by then moving the derivatives with respect to to the righthand side one obtains fracsinthetafracpartialpartial theta leftsinthetafracpartial psipartialtheta right fracsinthetafracpartial psipartialphi fracmu rhbarEVr psi leftfracpartialpartial rleftrfracpartialpsipartial rrightright Notice that except for itself the righthand side of this equation is a function of only it contains no or dependence Lets call the entire right hand side to emphasize this fact To further separate the and dependence we multiply by and subtract the derivative terms from both sides to obtain Now we have separated the dependence from the and r dependence We now introduce the procedure used to separate variables in differential equations and assume y can be written as a function of times a function of and Dividing by we obtain Now all of the dependence is isolated on the left hand side the right hand side contains only and dependence Whenever one has isolated the entire dependence on one variable as we have done above for the dependence one can easily see that the left and right hand sides of the equation must equal a constant For the above example the left hand side contains no or dependence and the right hand side contains no dependence Because the two sides are equal for all values of and they both must actually be independent of and dependence that is they are constant This again is what is done when one employs the separations of variables method in partial differential equations For the above example we therefore can set both sides equal to a socalled separation constant that we call It will become clear shortly why we have chosen to express the constant in the form of minus the square of an integer You may recall that we studied this same equation earlier and learned how the integer arises via the boundary condition that and represent identical geometries The Equation The resulting equation reads the symbol is used to represent second derivative This equation should be familiar because it is the equation that we treated much earlier when we discussed zcomponent of angular momentum So its further analysis should also be familiar but for completeness I repeat much of it The above equation has as its most general solution Because the wave functions of quantum mechanics represent probability densities they must be continuous and singlevalued The latter condition applied to our function means nb we used this in our earlier discussion of zcomponent of angular momentum that or This condition is satisfied only when the separation constant is equal to an integer This provides another example of the rule that quantization comes from the boundary conditions on the wave function Here is restricted to certain discrete values because the wave function must be such that when you rotate through about the zaxis you must get back what you started with The Equation Now returning to the equation in which the dependence was isolated from the and dependence and rearranging the terms to the lefthand side we have fracsinthetafracpartial partial theta leftsinthetafracpartial Qpartialtheta right fracmQsintheta FrQ In this equation we have separated the and terms so we can further decompose the wave function by introducing which yields fracThetasinthetafracpartial partial theta leftsinthetafracpartial Thetapartialtheta right fracmsintheta fracFrQRlambda where a second separation constant has been introduced once the and dependent terms have been separated onto the right and left hand sides respectively We now can write the equation as fracsinthetafracpartial partial theta leftsinthetafracpartial Thetapartialtheta right fracmThetasintheta lambdaTheta where is the integer introduced earlier To solve this equation for we make the substitutions and so and fracpartial partial theta fracpartial zpartial thetafracpartial partial z sintheta fracpartial partial z The range of values for was le theta pi so the range for is The equation for when expressed in terms of and becomes fracddzleftzfracdPdzright fracmPz lambda P Now we can look for polynomial solutions for because is restricted to be less than unity in magnitude If we first let P sum_ka_kzk and substitute into the differential equation to obtain Equating like powers of gives Note that for large values of Since the coefficients do not decrease with for large this series will diverge for unless it truncates at finite order This truncation only happens if the separation constant obeys where is an integer you can see this from the recursion relation giving in terms of only for certain values of will the numerator vanish So once again we see that a boundary condition ie that the wave function not diverge and thus be normalizable in this case give rise to quantization In this case the values of are restricted to before we saw that is restricted to Since the above recursion relation links every other coefficient we can choose to solve for the even and odd functions separately Choosing and then determining all of the even in terms of this followed by rescaling all of these to make the function normalized generates an even solution Choosing and determining all of the odd in like manner generates an odd solution For the series truncates after one term and results in For the same thing applies and For so one obtains and so on These polynomials are called Legendre polynomials and are denoted For the more general case where one can proceed as above to generate a polynomial solution for the function Doing so results in the following solutions These functions are called Associated Legendre polynomials and they constitute the solutions to the problem for nonzero values The above and functions when reexpressed in terms of and yield the full angular part of the wave function for any centrosymmetric potential These solutions are usually written as and are called spherical harmonics They provide the angular solution of the Schrdinger equation for any problem in which the potential depends only on the radial coordinate Such situations include all oneelectron atoms and ions eg etc the rotational motion of a diatomic molecule where the potential depends only on bond length the motion of a nucleon in a spherically symmetrical box as occurs in the shell model of nuclei and the scattering of two atoms where the potential depends only on interatomic distance The functions possess varying number of angular nodes which as noted earlier give clear signatures of the angular or rotational energy content of the wave function These angular nodes originate in the oscillatory nature of the Legendre and associated Legendre polynomials the higher is the more sign changes occur within the polynomial The Equation Let us now turn our attention to the radial equation which is the only place that the explicit form of the potential appears Using our earlier results for the equation obeyed by the function and specifying to be the Coulomb potential appropriate for an electron in the field of a nucleus of charge yields We can simplify things considerably if we choose rescaled length and energy units because doing so removes the factors that depend on and We introduce a new radial coordinate and quantity as follows Notice that if is negative as it will be for bound states ie those states with energy below that of a free electron infinitely far from the nucleus and with zero kinetic energy and are real On the other hand if is positive as it will be for states that lie in the continuum and will be imaginary These two cases will give rise to qualitatively different behavior in the solutions of the radial equation developed below We now define a function such that and substitute for to obtain fracrhofracddrholeftrhofracdSdrhoright leftfracfracLLrhodfracsigmarhoright S The differential operator terms can be recast in several ways using The strategy that we now follow is characteristic of solving second order differential equations We will examine the equation for at large and small values Having found solutions at these limits we will use a power series in to interpolate between these two limits Let us begin by examining the solution of the above equation at small values of to see how the radial functions behave at small As the term will dominate over Neglecting these other two terms we find that for small values of or the solution should behave like and because the function must be normalizable we must have Since can be any nonnegative integer this suggests the following more general form for Srho approx rhoL earho This form will insure that the function is normalizable since as for all as long as is a real quantity If is imaginary such a form may not be normalized see below for further consequences Turning now to the behavior of for large we make the substitution of into the above equation and keep only the terms with the largest power of ie the term and we allow the derivatives in the above differential equation to act on Upon so doing we obtain the equation which leads us to conclude that the exponent in the large behavior of S is Having found the small and large behaviors of we can take to have the following form to interpolate between large and small rvalues where the function is expanded in an infinite power series in as Again substituting this expression for into the above equation we obtain and then substituting the power series expansion of and solving for the aks we arrive at a recursion relation for the ak coefficients For large the ratio of expansion coefficients reaches the limit which when substituted into gives the same behavior as the power series expansion of Because the power series expansion of describes a function that behaves like for large the resulting function would not be normalizable because the efactor would be overwhelmed by this dependence Hence the series expansion of must truncate in order to achieve a normalizable function Notice that if is imaginary as it will be if is in the continuum the argument that the series must truncate to avoid an exponentially diverging function no longer applies Thus we see a key difference between bound with real and continuum with r imaginary states In the former case the boundary condition of nondivergence arises in the latter it does not because does not diverge if is imaginary To truncate at a polynomial of order we must have This implies that the quantity s introduced previously is restricted to which is certainly an integer let us call this integer If we label states in order of increasing we see that doing so is consistent with specifying a maximum order in the polynomial after which the value can run from in steps of unity up to Substituting the integer for we find that the energy levels are quantized because is quantized equal to and the scaled distance turns out to be Here the length is the socalled Bohr radius which turns out to be  it appears once the above Eexpression is substituted into the equation for Using the recursion equation to solve for the polynomials coefficients for any choice of and quantum numbers generates a socalled Laguerre polynomial They contain powers of from zero through and they have sign changes as the radial coordinate ranges from zero to infinity It is these sign changes in the Laguerre polynomials that cause the radial parts of the hydrogenic wave functions to have nodes For example orbitals have no radial nodes but d orbitals have one and as shown in Figure orbitals have one while orbitals have two Once again the higher the number of nodes the higher the energy in the radial direction Figure Plots of the probability densities of the radial parts of the and orbitals Let me again remind you about the danger of trying to understand quantum wave functions or probabilities in terms of classical dynamics What kind of potential would give rise to for example the plot shown above Classical mechanics suggests that should be large where the particle moves slowly and small where it moves quickly So the plot suggests that the radial speed of the electron has three regions where it is low ie where the peaks in are and two regions where it is very large ie where the nodes are This in turn suggests that the radial potential experienced by the electron is high in three regions near peaks in P and low in two regions Of course this conclusion about the form of is nonsense and again illustrates how one must not be drawn into trying to think of the classical motion of the particle especially for quantum states with small quantum number In fact the low quantum number states of such oneelectron atoms and ions have their radial plots focused in regions of rspace where the potential is most attractive ie largest in magnitude Finally we note that the energy quantization does not arise for states lying in the continuum because the condition that the expansion of terminate does not arise The solutions of the radial equation appropriate to these scattering states which relate to the scattering motion of an electron in the field of a nucleus of charge are a bit outside the scope of this text so we will not treat them further here To review separation of variables has been used to solve the full Schrdinger equation for one electron moving about a nucleus of charge The and solutions are the spherical harmonics The boundstate radial solutions depend on the and quantum numbers and are given in terms of the Laguerre polynomials Summary To summarize the quantum numbers and arise through boundary conditions requiring that be normalizable ie not diverge and The radial equation which is the only place the potential energy enters is found to possess both boundstates ie states whose energies lie below the asymptote at which the potential vanishes and the kinetic energy is zero and continuum states lying energetically above this asymptote The former states are spatially confined by the potential but the latter are not The resulting hydrogenic wave functions angular and radial and energies are summarized on pp in the text by L Pauling and E B Wilson for up to and including and up to ie for and orbitals There are both bound and continuum solutions to the radial Schrdinger equation for the attractive coulomb potential because at energies below the asymptote the potential confines the particle between and an outer classical turning point whereas at energies above the asymptote the particle is no longer confined by an outer turning point see Figure This provides yet another example of how quantized states arise when the potential spatially confines the particle but continuum states arise when the particle is not spatially confined Figure Radial Potential for Hydrogenic Atoms and Bound and Continuum Orbital Energies The solutions of this oneelectron problem form the qualitative basis for much of atomic and molecular orbital theory For this reason the reader is encouraged to gain a firmer understanding of the nature of the radial and angular parts of these wave functions The orbitals that result are labeled by and quantum numbers for the bound states and by and quantum numbers and the energy for the continuum states Much as the particleinabox orbitals are used to qualitatively describe p electrons in conjugated polyenes these socalled hydrogenlike orbitals provide qualitative descriptions of orbitals of atoms with more than a single electron By introducing the concept of screening as a way to represent the repulsive interactions among the electrons of an atom an effective nuclear charge can be used in place of in the and to generate approximate atomic orbitals to be filled by electrons in a manyelectron atom For example in the crudest approximation of a carbon atom the two electrons experience the full nuclear attraction so for them whereas the and electrons are screened by the two electrons so for them Within this approximation one then occupies two orbitals with two orbitals with and two orbitals with in forming the full sixelectron wave function of the lowestenergy state of carbon It should be noted that the use of screened nuclear charges as just discussed is different from the use of a quantum defect parameter d as discussed regarding Rydberg orbitals in Chapter The screened charge for carbons and orbitals is attempting to represent the effect of the innershell electrons on the and orbitals The modification of the principal quantum number made by replacing by represents the penetration of the orbital with nominal quantum number inside its innershells Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Internal Entropy and the Second Law Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers For every incremental part of any process we have Let us define a new quantity the external entropy change as The change criteria become Now let us define the internal entropy change as The entropy change for a system is the sum of its internal and external entropy changes We use and to represent incremental changes To represent macroscopic changes we use and Since two processes can effect different changes in the surroundings while the change that occurs in the system is the same and are not completely determined by the change in the state of the system Neither the internal nor the external entropy change depends solely on the change in the state of the system Nevertheless we see that or is an alternative expression of the thermodynamic criteria The external entropy change is that part of the entropy change that results from the interaction between the system and its surroundings The internal entropy is that part of the entropy change that results from processes occurring entirely within the system We also use the term internal energy The fact that the word internal appears in both of these terms does not reflect any underlying relationship of material significance The criterion makes it explicit that a process is spontaneous if and only if the events occurring within the system act to increase the entropy of the system In one common figure of speech we say entropy is produced in the system in a spontaneous process It is of course possible for a spontaneous process to have while and In Section we introduce a quantity that we can think of as a change in the chemical potential energy of a system The internal entropy change is closely related to this quantity We find As required by the properties of we find that is an expression of the thermodynamic criteria for change Internal entropy is a useful concept that is applied to particular advantage in the analysis of many different kinds of spontaneous processes in nonhomogeneous systems Intrinsic Reaction Paths Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Contributors and Attributions As we will discuss in more detail in Chapter there is a special path connecting reactants transition states and products that is especially useful to characterize in terms of energy surface gradients and Hessians This is the Intrinsic Reaction Path IRP To construct an IRP one proceeds as follows Step Once a transition state TS has been located its massweighted Hessian matrix is formed and diagonalized The normalized eigenvector belonging to the one negative eigenvalue of this matrix defines the initial directions leading from the TS to either reactants or products a unit vector along is one direction a unit vector along is the second Step One takes a small step ie a displacement of the Cartesian coordinates of the nuclei having a total length along the direction and this direction is taken to define the first step along the intrinsic reaction coordinate IRC that will eventually lead to the IRP When is expressed in terms of the its components along the Cartesian coordinates the displacements can be expressed as deltaq_j L s_jlabelb Step One reevaluates the gradient and Hessian at this new geometry call it forms the massweighted Hessian at and identifies the eigenmode having negative curvature The gradient along this direction will no longer vanish as it did at the TS and the normalized eigenvector of this mode is now used to define the continuation of the direction along the IRC Step One then minimizes the energy along the or coordinates transverse to This can be done by expressing the energy in terms of the corresponding eigenmodes of the massweighted Hessian where is the component of the gradient of the energy along the eigenmode and is the eigenvalue of the massweighted Hessian for this mode This energy minimization transverse to is designed to constrain the walk downhill from the TS at or near the minimum in the streambed along which the IRC is evolving After this energy minimization step the Cartesian coordinates will be defined as Step At one reevaluates the gradient and Hessian and proceeds as in step c above This process is continued generating a series of geometries that define points on the IRC At each of these geometries the gradient will have its largest component excluding at the TS where all components vanish along the direction of because the energy minimization process will cause its components transverse to to at least approximately vanish Step Eventually a geometry will be reached at which all or of the eigenvalues of the massweighted Hessian are positive here one is evolving into a region where the curvature along the IRC is positive and suggests one may be approaching a minimum However at this point there will be one eigemode the one whose eigenvalue just changed from negative to positive along which the gradient has its largest component This eigenmode will continue to define the IRCs direction Step One continues by taking a small step along downhill in energy after which the energy is minimized along the modes transverse to This process is continued until the magnitude of the gradient which always points along s becomes small enough that one can claim to have reached a minimum Step The process described above will lead from the TS to either the reactants or products and will define one branch of the IRP To find the other branch one returns to step b and begins the entire process again but now taking the first small step in the opposite direction ie along the negative of the eigenvector of the massweighted Hessian at the TS Proceeding along this path one generates the other branch of the IRP the series of geometries leading from reactants through the TS to products defines the full IRP At any point along this path the direction is the direction of the IRC This process for generating the IRP can be viewed as generating a series of Cartesian coordinates lying along a continuous path that is the solution of the following differential equation where is the Cartesian coordinate is the energy gradient along this Cartesian coordinate is the norm of the total energy gradient and is the continuous parameter describing movement along the IRC The initial condition appropriate to solving this differential equation is that the initial step ie at is to be directed along for one branch of the IRP or opposed to for the other branch the eigenmode of the massweighted Hessian having negative eigenvalue at the TS Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Introduction to the Second Law Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay No headers Rudolph Clausius is kind enough in his work The Mechanical Theory of Heat Clausius to indicate where we have been in our discussion of thermodynamics as well as where we are going The fundamental laws of the universe which correspond to the two fundamental theorems of the mechanical theory of heat The energy of the universe is constant The entropy of the universe tends to a maximum Rudolf Clausius The Mechanical Theory Of Heat The second law of thermodynamics which introduces us to the topic of entropy is amazing in how it constrains what we can experience and what we can do in the universe As Sean M Carroll a CalTech Theoretical physicist suggests in a interview with Wired Magazine Biba Im trying to understand how time works And thats a huge question that has lots of different aspects to it A lot of them go back to Einstein and spacetime and how we measure time using clocks But the particular aspect of time that Im interested in is the arrow of time the fact that the past is different from the future We remember the past but we dont remember the future There are irreversible processes There are things that happen like you turn an egg into an omelet but you cant turn an omelet into an egg We as observers of nature are time travelers And the constraints on what we can observe as we move through time step from the second law of thermodynamics But more than just understanding what the second law says we are interested in what sorts of processes are possible And even more to the point what sorts of processes are spontaneous A spontaneous process is one that will occur without external forces pushing it A process can be spontaneous even if it happens very slowly Unfortunately Thermodynamics is silent on the topic of how fast processes will occur but is provides us with a powerful toolbox for predicting which processes will be spontaneous But in order to make these predictions a new thermodynamic law and variable is needed since the first law which defined and is insufficient Consider the following processes with with Both reactions will occur spontaneously but one is exothermic and the other endothermic So while it is intuitive to think that an exothermic process will be spontaneous there is clearly more to the picture than simply the release of energy as heat when it comes to making a process spontaneous The Carnot cycle because a useful thought experiment to explore to help to answer the question of why a process is spontaneous Contributors Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Isothermal Expansions of An Ideal Gas Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers For an isothermal reversible expansion of an ideal gas we have by definition that Since the energy of an ideal gas depends only on the temperature a constant temperature implies constant energy so that Using the equation we find for in the previous section we have qrevwrevRT ln fracV_V_ ideal gas isothermal reversible expansion where and are the initial and final volumes respectively Since enthalpy is defined as we have For the spontaneous isothermal expansion of an ideal gas from to against a constant applied pressure we again have These are state functions and the amounts by which they change in this spontaneous process must be the same as those for the reversible process between the same two states The heat and work exchanged in the spontaneous process are different demonstrating that heat and work are not state functions We have one mole ideal gas isothermal free expansion Kinetic Energy Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay The Ideal Gas LawCollisions with the WallContributors and Attributions Using expressions for or it is fairly simple to derive expressions for kinetic energy from the expression It is important to remember that there will be a full distribution of molecular speeds in a thermalized sample of gas Some molecules will be traveling faster and some more slowly It is also important to recognize that the most probable average and RMS kinetic energy terms that can be derived from the Kinetic Molecular Theory do not depend on the mass of the molecules Table As such it can be concluded that the average kinetic energy of the molecules in a thermalized sample of gas depends only on the temperature However the average speed depends on the molecular mass So for a given temperature light molecules will travel faster on average than heavier molecules Table Kinetic Properties of a Thermalized Ensemble ie follows MaxwellBoltzmann Distribution Property Speed Kinetic Energy Most probable Average Rootmeansquare The Ideal Gas Law The expression for the rootmeansquare molecular speed can be used to show that the Kinetic Molecular model of gases is consistent with the ideal gas law Consider the expression for pressure Replacing with the square of the RMS speed expression yields which simplifies to Noting that Ntot nNA where n is the number of moles and NA is Avogadros number or Finally noting that Thats kind of cool no The only assumptions beyond the postulates of the Kinetic Molecular Theory is that the distribution of velocities for a thermalized sample of gas is described by the MaxwellBoltzmann distribution law The next development will be to use the Kinetic Molecular Theory to describe molecular collisions which are essential events in many chemical reactions Collisions with the Wall In the derivation of an expression for the pressure of a gas it is useful to consider the frequency with which gas molecules collide with the walls of the container To derive this expression consider the expression for the collision volume All of the molecules within this volume and with a velocity such that the xcomponent exceeds vx and is positive will collide with the wall That fraction of molecules is given by and the frequency of collisions with the wall per unit area per unit time is given by In order to expand this model into a more useful form one must consider motion in all three dimensions Considering that and that it can be shown that or and so The factor of NV is often referred to as the number density as it gives the number of molecules per unit volume At atm pressure and K the number density for an ideal gas is approximately x moleculecm This value is easily calculated using the ideal gas law By comparison the average number density for the universe is approximately moleculecm Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Lattice Energy and the BornHaber Cycle Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay The BornHaber CycleContributors and Attributions An important enthalpy change is the Lattice Energy which is the energy required to take one mole of a crystalline solid to ions in the gas phase For the lattice energy is defined as the enthalpy of the reaction ce NaCls rightarrow Nag Clg with called the lattice energy The BornHaber Cycle A very handy construct in thermodynamics is that of the thermodynamic cycle This can be represented graphically to help to visualize how all of the pieces of the cycle add together A very good example of this is the BornHaber cycle describing the formation of an ionic solid Two pathways can be envisioned for the formation Added together the two pathways form a cycle In one pathway the ionic solid if formed directly from elements in their standard states with The other pathway involves a series of steps that take the elements from neutral species in their standard states to ions in the gas phase with with with with with It should be clear that when added after proper manipulation if needed the second set of reactions yield the first reaction Because of this the total enthalpy changes must all add This can be depicted graphically the advantage being that arrows can be used to indicate endothermic or exothermic changes An example of the BornHaber Cycle for NaCl is shown below Figure the BornHaber Cycle for NaCl In many applications all but one leg of the cycle is known and the job is to determine the magnitude of the missing leg Exercise Potassium Bromide Find for KBr given the following data with with with with ceBrg e rightarrow Brg nonumber with with Answer Note This cycle required the extra leg of the vaporization of Br Many cycles involve ions with greater than unit charge and may require extra ionization steps as well Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Le Chateliers Principle Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics Vaporliquid equilibriumIcewater equilibriumChemical reaction between gases In Chapter we describe a very general goal given that we create a system in some arbitrary initial state by some change of conditions or removal of some constraint we want to predict how the system will respond as it changes on its own spontaneously to some new equilibrium state Under these circumstances we need a lot of information about the system before we can make any useful prediction about the spontaneous change In this case we have said nothing about the condition of the system before we effect the change of conditions that creates the arbitrary initial state Our ability to make useful predictions is much greater if the system and the change of conditions have a particular character If we start with a system that is at equilibrium and we impose a change in conditions on it the initial state of the system after the imposed change of conditions will generally not be an equilibrium state Experience shows that the system will undergo some spontaneous change to arrive at a new equilibrium state In these particular circumstances Le Chateliers principle enables us to predict the spontaneous change that occurs Definition Le Chateliers principle If a change is imposed on the state of a system at equilibrium the system adjusts to reach a new equilibrium state In doing so the system undergoes a spontaneous change that opposes the imposed change Le Chateliers principle is useful and it is worthwhile to learn to apply it The principle places no limitations on the nature of the imposed change or on the number of thermodynamic variables that might change as the system responds However since our reasoning based on the principle is qualitative it is frequently useful to suppose that the imposed change is made in just one variable and that the opposing change involves just one other variable That is we ask how changing one of the variables that characterizes the equilibrated system changes a second such variable all else being equal Successful use of the principle often requires careful thinking about the variable on which change is imposed and the one whose value changes in response Let us consider some applications Vaporliquid equilibrium Vaporliquid equilibrium Suppose that we have a sealed vial that contains only the liquid and vapor phases of a pure compound We suppose that the vial and its contents are at a single temperature and that the liquid and the vapor are in equilibrium with one another at this temperature What will happen if we now thermostat the vial at some new and greater temperature We see that the imposed change is an increase in temperature or equivalently an addition of heat to the system The system cannot respond by decreasing its temperature because the temperature change is the imposed change Similarly it cannot respond by changing its volume because the system volume is fixed Evidently the observable consequence of increasing temperatureadding heat must be a change in the pressure of the system The principle asserts that the system will respond so as to consume heat Converting liquid to vapor consumes the latent heat of vaporization so the system can oppose the imposed addition of heat by converting liquid to vapor This increases the pressure of the vapor We can conclude from Le Chateliers principle that increasing the temperature of a system at liquidvapor equilibrium increases the equilibrium vapor pressure Now suppose that we have the liquid and vapor phases of the same pure compound in a thermally isolated cylinder that is closed by a piston We ask what will happen if we decrease the volume That is the imposed change is a step decrease in volume accompanied by an increase in pressure The new volume is fixed but the pressure is free to adjust to a new value at the new equilibrium position The principle asserts that the system will respond so as to decrease its pressure Decreasing the system pressure is accomplished by condensing vapor to liquid which is accompanied by the release of the latent heat of vaporization Since we suppose that the system is thermally isolated during this process the heat released must result in an increase in the temperature of the system While the pressure can decrease from the initial nonequilibrium value it cannot decrease to its originalequilibrium value evidently the new equilibrium pressure must be greater than the original pressure We again conclude that an increase in the equilibrium vapor pressure requires an increase in the temperature of the system If the volume decrease were imposed with the system immersed in a constant temperature bath the heat evolved would be transferred from the system to the bath The system would return to its original pressure and original temperature albeit with fewer moles of the substance present in the gas phase Icewater equilibrium Suppose that we have a closed system consisting of ice in equilibrium with liquid water at some temperature and pressure What will happen if we impose an increase in the temperature this system We suppose that the system occupies a container of fixed volume Initially it is at equilibrium with a constanttemperature bath We impose the change by moving the container to a new bath whose temperature is higherbut not high enough to melt all of the ice The imposed change is a temperature increase or equivalently an addition of heat The principle asserts that the system will respond by consuming heat which it can do by converting ice to liquid Since liquid water occupies less volume than the same mass of ice the system pressure will decrease We conclude that the pressure at which ice and water are at equilibrium decreases when the temperature increases That is the melting point increases as the pressure decreases Again we can imagine that the equilibrium mixture of ice and water is contained in a thermally isolated cylinder that is closed by a piston and ask how the system must respond if we impose a step decrease in its volume We impose the volume decrease by applying additional force to the piston The imposed step change in the volume is accompanied by an increase in the system pressure the new volume is fixed but the system pressure can adjust The principle asserts that the system will respond by decreasing its pressure The system pressure will decrease if some of the ice melts Melting ice consumes heat Since we are now assuming that the system is thermally isolated this heat cannot come from outside the system which means that the temperature of the system must decrease While the pressure can decrease from its initial nonequilibrium value it cannot decrease to the value that it had in the original equilibrium position We again conclude that increasing the pressure results in a decrease in temperature that is the melting point of ice increases as the pressure decreases Chemical reaction between gases Chemical reaction between gases Finally suppose that we have a chemical equilibrium involving gaseous reagents To be specific let us again consider the reaction We suppose that this system is initially at equilibrium at some temperature and that we seek to increase the pressure while maintaining the temperature constant We can imagine that the system is contained in a cylinder that is closed by a piston The cylinder is immersed in a constanttemperature bath We increase the pressure by applying additional force to the piston As in the examples above we view this as a step change in volume that is accompanied by an increase of the pressure to a transitory nonequilibrium value The principle asserts that the system will respond by undergoing a change that opposes this pressure increase The system can reduce its pressure by decreasing the number of moles of gas present and it can do this by converting molecules to molecules We conclude that there will be less present at equilibrium at the higher pressure When we first encounter it Le Chateliers principle seems to embody a remarkable insight As indeed it does However as we think about it we come to see it as a logical necessity Suppose that the response of an equilibrium system to an imposed change were to augment the change rather than oppose it Then an imposed change would reinforce itself The slightest perturbation of any equilibrium system would cause the system to run away from that original position Since no real system can be maintained at a perfectly constant set of conditions any real system could undergo spontaneous change Equilibrium would be unattainable If we assume that a system must behave oppositely to the way that is predicted by Le Chateliers principle we arrive at a prediction that contradicts our experience Le Chateliers principle is inherently qualitative We will discuss it further after we develop the thermodynamic criteria for equilibrium We will find that the thermodynamic criteria for equilibrium tell us quantitatively how two or more thermodynamic variables must change in concert if a system is to remain at equilibrium while also undergoing some change of condition Linear Variational Method Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Contributors and Attributions A widely used example of Variational Methods is provided by the socalled linear variational method Here one expresses the trial wave function a linear combination of socalled basis functions Substituting this expansion into and then making this quantity stationary with respect to variations in the subject to the constraint that remains normalized gives This is a generalized matrix eigenvalue problem that we can write in matrix notation as It is called a generalized eigenvalue problem because of the appearance of the overlap matrix on its right hand side This set of equations for the coefficients can be made into a conventional eigenvalue problem as follows The eigenvectors and eigenvalues of the overlap matrix are found by solving All of the eigenvalues are positive because is a positivedefinite matrix Next one forms the matrix whose elements are another matrix can be formed in a similar way replacing with One then multiplies the generalized eigenvalue equation on the left by to obtain This equation is then rewritten using and as This is a conventional eigenvalue problem in which the matrix is and the eigenvectors are The net result is that one can form and then find its eigenvalues and eigenvectors Its eigenvalues will be the same as those of the original generalized eigenvalue problem Its eigenvectors can be used to determine the eigenvectors of the original problem by multiplying by Although the derivation of the matrix eigenvalue equations resulting from the linear variational method was carried out as a means of minimizing it turns out that the solutions offer more than just an upper bound to the lowest true energy of the Hamiltonian It can be shown that the nth eigenvalue of the matrix is an upper bound to the true energy of the nth state of the Hamiltonian A consequence of this is that between any two eigenvalues of the matrix there is at least one true energy of the Hamiltonian This observation is often called the bracketing condition The ability of linear variational methods to provide estimates to the ground and excitedstate energies from a single calculation is one of the main strengths of this approach Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Line Integrals Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers The significance of the distinction between exact and inexact differential expressions comes into focus when we use the differential to find how the quantity changes when the system passes from the state defined by to the state defined by We suppose that the system undergoes this change along some continuous path in the plane We can specify such a path as a function where is a constant or as Whether the differential is exact or inexact we can sum up increments of change along short segments of the path to find the change in between and Let and be two neighboring points on the curve As the system traverses between these points the change in is If we sum up such increments of along the curve from to the sum approximates the change in along this path In the limit that all of the incremental and become arbitrarily small the approximation becomes exact The limit of this sum is called the line integral of along the path between and Whether is exact or inexact the line integral of is defined along any continuous path in the plane If the path is and it connects the points and in the plane we designate the value of the line integral as any differential expression However if is exact we know that In this case the line integral of along curve between these points has the value for exact differential Because the value of the line integral depends only on the values of at the end points of the integration path the line integral of the total differential is independent of the path It follows that the line integral of an exact differential around any closed path must be zero A circle in the middle of the integral sign is often used to indicate that the line integral is being taken around a closed path In this notation writing indicates that is exact and is a state function In concept the evaluation of line integrals is straightforward Since the path of integration is a line the integrand involves only one dimension A line integral can always be expressed using a single variable of integration Three approaches to the evaluation of line integrals are noteworthy If we are free to choose an arbitrary path we can choose the twosegment path Along the first segment is constant at so we can evaluate the change in as Along the second segment is constant at so we can evaluate the change in as Then If the path is readily solved for as a function of say substitution converts the differential expression into a function of only Integration of this expression from to gives The path can always be expressed as a parametric function of a dummy variable That is we can always find functions and such that and Then substitution converts the differential expression into a function of Integration of this expression from to gives While the line integral of an exact differential between two points is independent of the path of integration this not the case for an inexact differential For an inexact differential the integral between two points depends on the path of integration To illustrate these ideas let us consider some examples These examples illustrate methods for finding the integral of a differential along a particular path They illustrate also the pathindependence of the integral of an exact differential and the pathdependence of the integral of an inexact differential Example An exact Differential We begin by considering the function for which Since exists must be exact Let us integrate between the points and along four different paths sketched in Figure that we denote as paths a b c and d Figure Paths a b c and d Path a has two linear segments The first segment is the portion of the line from to Along this segment The second segment is portion of the line from to Along the second segment Path b has two linear segments also The first segment is the portion of the line from to Along the first segment The second segment is portion of the line from to Along the second segment Path c is the line from to and for which Path d is the line which we can express in parametric form as and At At Also and The integrals along these paths are Path a Path b Path c Path d beginalign int_d dfintt_t leftt t t t right dt pt intt_t leftt t t t rightdt pt lefttttttright_ endalign The integrals along all four paths are the same The value is which as required is the difference Example An inexact Differential Now let us consider the differential expression This expression has the form of a total differential but we will see that there is no function for which this expression is the total differential That is is an inexact differential If we integrate over the same four paths we find Path a beginalign int_adhintx_x leftrightdxinty_y y dy pt leftxright_leftyright_ pt endalign Path b beginalign int_bdhintx_xleftrightdxinty_yleftrightleftrighty dy pt leftxright_leftyright_ pt endalign Path c beginalign int_cdhintx_xleftxxright dx ptleftfracxfracxright_ ptfrac endalign Path d beginalign int_ddhintt_t lefttt ttrightdt ptintt_tleftt t t t right dt pt leftt t t t tright_ pt frac endalign For the value of the integral depends on the path of integration confirming that is an inexact differential Since the value of the integral depends on path there can be no for which That is cannot have four different values LiquidVapor Systems Raoults Law Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Raoults LawContributors and Attributions Liquids tend to be volatile and as such will enter the vapor phase when the temperature is increased to a high enough value provided they do not decompose first A volatile liquid is one that has an appreciable vapor pressure at the specified temperature An ideal mixture continuing at least one volatile liquid can be described using Raoults Law Raoults Law Raoults law can be used to predict the total vapor pressure above a mixture of two volatile liquids As it turns out the composition of the vapor will be different than that of the two liquids with the more volatile compound having a larger mole fraction in the vapor phase than in the liquid phase This is summarized in the following theoretical diagram for an ideal mixture of two compounds one having a pure vapor pressure of and the other having a pure vapor pressure of In Figure the liquid phase is represented at the top of the graph where the pressure is higher Figure The liquid phase is represented at the top of the graph where the pressure is higher Oftentimes it is desirable to depict the phase diagram at a single pressure so that temperature and composition are the variables included in the graphical representation In such a diagram the vapor which exists at higher temperatures is indicated at the top of the diagram while the liquid is at the bottom A typical temperature vs composition diagram is depicted in Figure for an ideal mixture of two volatile liquids Figure A typical temperature vs composition diagram In this diagram and represent the boiling points of pure compounds and If a system having the composition indicated by has its temperature increased to that indicated by point c The system will consist of two phases a liquid phase with a composition indicated by and a vapor phase indicated with a composition indicated by The relative amounts of material in each phase can be described by the lever rule as described previously Further if the vapor with composition is condensed the temperature is lowered to that indicated by point b and revaporized the new vapor will have the composition consistent with This demonstrates how the more volatile liquid the one with the lower boiling temperature which is A in the case of the above diagram can be purified from the mixture by collecting and reevaporating fractions of the vapor If the liquid was the desired product one would collect fractions of the residual liquid to achieve the desired result This process is known as distillation Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Maxwells Derivation of the Gasvelocity Probabilitydensity Function Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers To this point we have been developing our ability to characterize the gasvelocity distribution functions We now want to use Maxwells argument to find them We have already introduced the first step which is the recognition that threedimensional probabilitydensity functions can be expressed as products of independent onedimensional functions and that and are the constants and Now because the probability density associated with any given velocity is just a number that is independent of the coordinate system we can equate the threedimensional probabilitydensity functions for Cartesian and spherical coordinates so that We take the partial derivative of this last equation with respect to The probability densities and are independent of However is a function of because We find Since and Making this substitution and dividing by the original equation gives Cancellation and rearrangement of the result leads to an equation in which the independent variables and are separated This means that each term must be equal to a constant which we take to be We find so that and From the first of these equations we obtain the probability density function for the distributions of onedimensional velocities See Section The threedimensional probability density function can be deduced from the onedimensional function See Section From the second equation we obtain the threedimensional probabilitydensity function directly Integrating from where has a fixed value to an arbitrary scalar velocity where the scalarvelocity function is we have or The probabilitydensity function for the scalar velocity becomes This is the result we want except that it contains the unknown parameters and The value of must be such as to make the integral over all velocities equal to unity We require so that where we use the definite integral See Appendix D The scalarvelocity function in the threedimensional probabilitydensity function becomes The probabilitydensity function for the scalar velocity becomes The threedimensional probability density in spherical coordinates becomes The probability that an arbitrarily selected molecule has a velocity vector whose magnitude lies between and while its component lies between and and its component lies between and becomes In Section we again derive Boyles law and use the ideal gas equation to show that Measuring Heat Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers As the idea of heat as a form of transferring energy was first being developed a unit amount of heat was taken to be the amount that was needed to increase the temperature of a reference material by one degree Water was the reference material of choice and the calorie was defined as the quantity of heat that raised the temperature of one gram of water one degree kelvin The amount of heat exchanged by a known amount of water could then be calculated from the amount by which the temperature of the water changed If for example introducing g mole of copper metal initially at K into g of water initially at K resulted in thermal equilibrium at K the water surrendered This amount of heat was taken up by the copper so that cal was required to increase the temperature of one gram of copper by one degree K Given this information the amount of heat gained or lost by a known mass of copper in any subsequent experiment can be calculated from the change in its temperature Joule developed the idea that mechanical work can be converted entirely into heat The quantity of heat that could be produced from one unit of mechanical work was called the mechanical equivalent of heat Today we define the unit of heat in mechanical units That is we define the unit of energy the joule in terms of the mechanical units mass distance and time One joule is one newtonmeter or one One calorie is now defined as exactly This definition assumes that heat and work are both forms of energy This assumption is an intrinsic element of the first law of thermodynamics This aspect of the first law is of course just a restatement of Joules original idea When we want to measure the heat added to a system measuring the temperature increase that occurs is often the most convenient method If we know the temperature increase in the system and we know the temperature increase that accompanies the addition of one unit of heat we can calculate the heat input to the system Evidently it is useful to know how much the temperature increases when one unit of heat is added to various substances Let us consider a general procedure for accumulating such information Figure Heat capacity is the slope of versus First we need to choose some standard amount of the substance in question After all if we double the amount it takes twice as much heat to effect the same temperature change One mole is a natural choice for this standard amount If we add small increments of heat to one mole of a pure substance we can measure the temperature after each addition and plot heat versus temperature Figure shows such a plot In experiments like this it is often convenient to introduce the heat by passing a known electrical current through a known resistance immersed in the substance The rate at which heat is produced is Except for the usually negligible amount that goes into warming the resistor all of it is transferred to the substance At any particular temperature the slope of the graph is the increment of heat input divided by the incremental temperature increase This slope is so useful it is given a name it is the molar heat capacity of the substance Since this slope is also the derivative of the versus curve we have The temperature increase accompanying a given heat input varies with the particular conditions under which the experiment is done In particular the temperature increase will be less if some of the added heat is converted to work as is the case if the volume of the system increases If the volume increases the system does work on the surroundings For a given will be less when the system is allowed to expand which means that will be greater Heat capacity measurements are most conveniently done with the system at a constant pressure However the heat capacity at constant volume plays an important role in our theoretical development The heat capacity is denoted when the pressure is constant and when the volume is constant We have the important definitions and Since no pressurevolume work can be done when the volume is constant less heat is required to effect a given temperature change and we have as a general result In we consider this point further If the system contains a gas the effect of the volume increase can be substantial For a monatomic ideal gas the temperature increase at constant pressure is only of the temperature increase at constant volume for the same input of heat Measuring PressureVolume Work Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers By definition the energy of a system can be exploited to produce a mechanical change in the surroundings The energy of the surroundings increases the energy of the system decreases Raising a weight against the earths gravitational force is the classical example of a mechanical change in the surroundings When we say that work is done on a system we mean that the energy of the system increases because of some nonthermal interaction between the system and its surroundings The amount of work done on a system is determined by the nonthermal energy change in its surroundings We define work as the scalar product of a vector representing an applied force and a second vector representing the displacement of the object to which the force is applied The definition is independent of whether the process is reversible or not If the force is a function of the displacement we have Pressurevolume work is done whenever a force in the surroundings applies pressure on the system while the volume of the system changes Because chemical changes typically do involve volume changes pressurevolume work often plays a significant role Perhaps the most typical chemical experiment is one in which we carry out a chemical reaction at the constant pressure imposed by the earths atmosphere When the volume of such a system increases the system pushes aside the surrounding atmosphere and thereby does work on the surroundings When a pressure is applied to a surface of area the force normal to the area is For a displacement normal to the area the work is We can find the general relationship between work and the change in the volume of a system by supposing that the system is confined within a cylinder closed by a piston See Figure The surroundings apply pressure to the system by applying force to the piston We suppose that the motion of the piston is frictionless Figure Pressurevolume work The system occupies the volume enclosed by the piston If the crosssectional area of the cylinder is and the system occupies a length the magnitude of the systems volume is If an applied pressure moves the piston a distance the volume of the system changes by The magnitude of the work done in this process is therefore work is positive if it is done on the system We are using the convention that work is positive if it is done on the system This means that a compression of the system for which and does a positive quantity of work on the system Therefore the work done on the system is or using our convention that unlabeled variables always characterize the system Measuring Work NonPressureVolume Work Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers For chemical systems pressurevolume work is usually important Many other kinds of work are possible From our vector definition of work any force that originates in the surroundings can do work on a system The force drives a displacement in space of the system or some part of the system Stretching a strip of rubber is a onedimensional analog of pressurevolume work Changing the surface area of a liquid is a twodimensional analog of pressurevolume work When only internal forces act a liquid system minimizes its surface area We can model this property by attributing a surfacearea minimizing force which we call the surface tension to the surface of the liquid We can think of the layer of molecules at the surface as a film that separates the bulk liquid from its surroundings To increase the area of a liquid system requires an expenditure of work by the surroundings against the surface tension of the film Gravitational electrical and magnetic forces can all do work on particular systems In this book we give little attention to the details of the various kinds of nonpressurevolume work that can be important There are two exceptions Electrical work is important in electrochemistry which we discuss in Chapter We discuss gravitational work in examples that illustrate reversible processes and some aspects of the criteria for change Nevertheless no development of the basic concepts can be complete without including the effects of nonpressurevolume work For this reason we include nonpressurevolume work in our discussions frequently For the most part however we do so in a generalized or abstract way To do so we must identify some essential features of any process that does work on a system Whenever a particular kind of work is done on a system some change occurs in a thermodynamic variable that is characteristic of that kind of work For pressurevolume work this is the volume change For stretching a strip of rubber it is the change in length For gravitational work it is the displacement of a mass in a gravitational field For changing the shape of a liquid it is the change in surface area For electrical work it is the displacement of a charge in an electrical field For magnetic work it is the displacement of a magnetic moment in a magnetic field For an arbitrary form of nonpressurevolume work let us use to represent this variable We can think of as a generalized displacement When there is an incremental change in this variable there is a corresponding change in the energy of the system For a displacement let the increase in the energy of the system be The energy increase also depends on the magnitude of the force that must be applied to the system parallel to the displacement Let this force be Then for this arbitrary abstract process we have or Since is the contribution to the incremental change in the energy of the system associated with the displacement we can also write this as We can generalize this perspective need not be a vector and need not be a mechanical force So long as determines the energy change we have We call a potential If we let the energy increment becomes If multiple forms of work are possible we can distinguish them by their characteristic variables which we label For each of these characteristic variables there is a corresponding potential The total energy increment which we also call the nonpressurevolume work becomes For pressurevolume work The characteristic variable is volume and the potential is the negative of the pressure For gravitational work the characteristic variable is elevation for a given system the potential depends on the gravitational acceleration and the mass of the system When a process changes the composition of a system it is often important to relate the work done on the system to the composition change Formally we express the incremental work resulting from the th generalized displacement as where and are the incremental changes in the work done on the system and the number of moles of the substance in the system To see how this works out in practice let us consider the particular case of electrical work The electrodes of an electrochemical cell can be at different electric potentials We usually designate the potential difference between the electrodes as We can also write when we want to keep our notation uniform The unit of electrical potential is the volt V One volt is one joule per coulomb We are usually interested in cases in which we can assume that is constant Whenever a current flows in an electrochemical cell electrons flow through an external circuit from one electrode to the other By our definition of electrical potential the energy change that occurs when a charge passes through a potential difference is We have Evidently charge is the characteristic variable for electrical work we have and Letting the magnitude of the electron charge be electrons carry charge Then The magnitude of the charge carried by one mole of electrons is the faraday That is See Letting be the number of moles of electrons we have and so that The work done when moles of electrons pass through the potential difference becomes We find the work done when ions pass through a potential difference by essentially the same argument If ions of species carry charge then ions carry charge and the electrical work is If different species pass through the potential difference the total electrical work becomes Mechanisms and Elementary Processes Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers To see what we mean by an elementary process let us consider some possible mechanisms for the base hydrolysis of methyl iodide In this reaction a carboniodide bond is broken and a carbonoxygen bond is formed While any number of reaction sequences sum to this overall equation we can write down three that are reasonably simple and plausible The could be broken first and the bond formed thereafter Alternatively the bond could be formed first and the bond broken thereafter In the first case we have an intermediate species of reduced coordination number and in the second we have an intermediate of increased coordination number Finally we can suppose that the bondforming and bondbreaking steps occur simultaneously so that no intermediate species is formed at all Heterolytic bondbreaking precedes bondmaking Bondmaking precedes bondbreaking Bondbreaking and bondmaking are simultaneous The distinction between mechanism b and mechanism c is that an intermediate is formed in the former but not in the latter Nevertheless mechanism c clearly involves an intermediate structure in which both the incoming and the leaving group are bonded to the central carbon atom The distinction between mechanisms b and c depends on the nature of the intermediate structure In mechanism b we suppose that the intermediate is a bona fide chemical entity once a molecule of it is formed that molecule has a finite lifetime In c we suppose that the intermediate structure is transitory it does not correspond to a molecule with an independent existence For this distinction to be meaningful we must have a criterion that establishes the shortest lifetime we are willing to associate with real molecules It might seem that any minimum lifetime we pick must be wholly arbitrary Fortunately this is not the case there is a natural definition for a minimum molecular lifetime The definition arises from the fact that molecules undergo vibrational motions If a collection of atoms retains a particular relative orientation for such a short time that it never undergoes a motion that we would recognize as a vibration it lacks an essential characteristic of a normal molecule This means that the period of a highfrequency molecular vibration roughly s is the shortest time that a collection of atoms can remain together and still have all of the characteristics of a molecule If a structure persists for more than a few vibrations it is reasonable to call it a molecule albeit a possibly very unstable one In mechanism c the structure designated depicts a transitory arrangement of the constituent atoms The atomic arrangement does not persist long enough for the bond or the bond to undergo vibrational motion A structure with these characteristics is called an activated complex or a transition state for the reaction and a superscript double dagger is conventionally used to signal that a structure has this character The distinction between a bona fide intermediate and a transition state is clear enough in principle but it can be very difficult to establish experimentally These considerations justify our earlier definition An elementary reaction is one in which there are no intermediates Any atomic arrangement that occurs during an elementary reaction does not persist long enough to vibrate before the arrangement goes on to become products or reverts to reactants An elementary reaction is one in which there are no intermediates We can distinguish a small number of possible kinds of elementary reaction termolecular elementary reactions bimolecular elementary reactions and unimolecular reactions A single molecule can spontaneously rearrange to a new structure or break into smaller pieces Two molecules can react to form one or more products Three molecules can react to produce products Or we can imagine that some larger number of molecules reacts We refer to these possibilities as unimolecular bimolecular termolecular and highermolecularity processes The stoichiometry of many reactions is so complicated as to preclude the possibility that they could occur as a single elementary process For example the reaction can not plausibly occur in a single collision of three ferrous ions one chromate ion and seven hydronium ions It is just too unlikely that all of these species could find themselves in the same place at the same time in the proper orientation and with sufficient energy to react In such cases the stoichiometric mechanism must be a series of elementary steps For this reaction a skeletal representation of one plausible series is Microscopic Reversibility and the Second Law Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers The principle of microscopic reversibility requires that parallel mechanisms give rise to the same expression for the concentrationdependence of the equilibrium constant That is the function that characterizes the equilibrium composition must be the same for each mechanism If for the reaction the equilibrium composition for mechanism is and that for mechanism is microscopic reversibility asserts that and In and of itself microscopic reversibility makes no assertion about the value of compared to that of While microscopic reversibility asserts that the same function characterizes the concentration relationships for parallel mechanisms it does not assert that the numerical value of this function is necessarily the same for each of the mechanisms However that these numerical values must be equal follows directly when we introduce another of our most basic observations No matter how many mechanisms may be available to a reaction in a particular system the concentration of any reagent can have only one value in an equilibrium state At equilibrium etc therefore the numerical values of the equilibrium constants must be the same The uniqueness of the equilibrium composition is a fundamental feature of our ideas about what chemical equilibrium means Nevertheless it is of interest to show that we can arrive at this conclusion from a different perspective We can use an idealized machine to show that the second law of thermodynamics requires that parallel mechanisms must produce the same the equilibrium composition Our argument is a proof by contradiction Let us suppose that and are gases Suppose that the reaction occurs in the absence of a catalyst but that reaction occurs in the opposite direction when a catalyst is present More precisely we assume that the position of equilibrium lies to the right in the absence of the catalyst and to the left in its presence while all other reaction conditions are maintained constant These assumptions mean that the equilibrium composition for the catalyzed mechanism is different from that of the mechanism that does not involve the catalyst We can show that these assumptions imply that the second law of thermodynamics is false If we accept the validity of the second law this violation means that the assumptions cannot in fact describe any real system We are getting a bit ahead of ourselves here inasmuch as our detailed consideration of the laws of thermodynamics begins in Chapter Given our assumptions we can build a machine consisting of a large cylinder closed by a frictionless piston The cylinder contains a mixture of and and a quantity of the catalyst We provide a container for the catalyst and construct the device so that the catalyst container can be opened and closed from outside the cylinder Finally we immerse the entire cylinder in a fluid which we maintain at a constant temperature When the catalyst container is sealed so that the gaseous contents of the cylinder are not in contact with the catalyst reaction occurs according to and the piston moves outward doing work on the surroundings When the catalyst container is open reaction occurs according to and the piston moves inward Figure shows these changes schematically At the end of a cycle the machine is in exactly the same state as it was in the beginning and the temperature of the reaction mixture is the same at the end of a cycle as it was at the beginning By connecting the piston to a load we can do net work on the load as the machine goes through a cycle For example if we connect the piston to a mechanical device that converts the reciprocating motion of the piston into rotary motion we can wind a rope around an axle and thereby lift an attached weight Figure A machine that violates the second law We can operate this machine as an engine by alternately opening and closing the catalyst container We can make the cylinder as large as we want so the energy we expend in opening and closing the catalyst container can be made arbitrarily small compared to the amount of work we get out of the machine in a given cycle All of this occurs with the machine maintained at a constant temperature If energy is conserved the machine must absorb heat from the bath during the cycle otherwise the machine would be doing work with no offsetting consumption of energy This would be a violation of the first law of thermodynamics See Sections From experience we know that this machine cannot function in the manner we have described This experience is embodied in the second law of thermodynamics we know that it is impossible to construct a machine that operates in a cycle exchanges heat with its surroundings at only one temperature and produces work in the surroundings Section Our argument assumes that two reaction mechanisms are available in a particular physical system that they consume the same reactants that they produce the same products and that the equilibrium compositions are different These assumptions imply that the second law is false Since we are confident that it is possible for some system to satisfy the first three of these assumptions the second law requires that the last one be false the equilibrium compositions must be the same We see that there is a complementary relationship between microscopic reversibility and this statement of the second law Microscopic reversibility asserts that a unique function of concentrations characterizes the equilibrium state for any reaction mechanism but does not require that every mechanism reach the same state at equilibrium This statement of the second law implies that a reactions equilibrium composition unique but it does not specify a law relating the equilibrium concentrations of the reacting species In Chapters and we see that by augmenting this statement of the second law with some additional ideas we are led to a more rigorous statement from which we are eventually able to infer the same functional form for the equilibrium constant Microscopic reversibility asserts that a unique function of concentrations characterizes the equilibrium state for any reaction mechanism but does not require that every mechanism reach the same state at equilibrium G N Lewis gave an early statement of the principle of microscopic reversibility He called it the law of entire equilibrium and observed that it is a law which in its general form is not deducible from thermodynamics but proves to be compatible with the laws of thermodynamics in all cases where a comparison is possible It is worth noting that we have not shown that the existence of a unique equilibrium state implies either microscopic reversibility or the second law Also even though the principle of microscopic reversibility is inferred from the laws of mechanics our development of the equilibrium constant relationshipwhich we do view as a law of thermodynamicsdepends on our equations for the rates of elementary reactions Our rate equations are not logical consequences of the laws of motion Rather they follow from assumptions we make about the average behavior of systems that contain many molecules Consequently we should not suppose that we have deduced a thermodynamic result the condition for chemical equilibrium solely from the laws of mechanics In Section we give brief additional consideration to the relationship between the theories of mechanics and thermodynamics Beginning in Chapter we develop thermodynamic equations by applying statistical models to the distribution of molecular energy levels Molecular Dynamics Simulations Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Trajectory PropagationForce FieldsCoarse GrainingContributors and Attributions One thing that the MC process does not address directly is the time evolution of the system That is the steps one examines in the MC algorithm are not straightforward to associate with a timeduration so it is not designed to compute the rates at which events take place If one is interested in simulating such dynamical processes even when the Nmolecule system is at or near equilibrium it is more appropriate to carry out a classical molecular dynamics MD simulation In such an MD calculation one has to assign initial values for each of the internal and external coordinates of each of the molecules and an initial value of the kinetic energy or momentum for each coordinate after which a timepropagation algorithm generates values for the coordinates and momenta at later times For example the initial coordinates could be chosen close to those of a local minimum on the energy surface and the initial momenta associated with each coordinate could be assigned values chosen from a MaxwellBoltzmann distribution characteristic of a specified temperature T In such cases it is common to then allow the MD trajectory to be propagated for a length of time long enough to allow further equilibration of the energy among all degrees of freedom before extracting any numerical data to use in evaluating average values or creating interparticle distance histograms for example One usually does not choose just one set of such initial coordinates and momenta to generate a single trajectory Rather one creates an ensemble of initial coordinates and momenta designed to represent the experimental conditions the MD calculation is to simulate The time evolution of the system for each set of initial conditions is then followed using MD and various outcomes eg reactive events barrier crossings folding or unfolding events chemisorption ocurrences etc are monitored throughout each MD simulation An average over the ensemble of trajectories is then used in computing averages and creating histograms for the MD simulation It is the purpose of this Section to describe how MD is used to follow the time evolution for such simulations Trajectory Propagation With each coordinate having its initial velocity and its initial value specified one then uses Newtons equations written for a time step of duration to propagate and forward in time according for example to the following firstorder propagation formula Here m_q is the mass factor connecting the velocity and the momentum pq conjugate to the coordinate q and is the force along the coordinate at the earlier geometry In most modern MD simulations more sophisticated numerical methods can be used to propagate the coordinates and momenta For example the widely used Verlet algorithm is derived as follows One expands the value of the coordinate at the and time steps in Taylor series in terms of values at the st time step One adds these two expansions to obtain which allows one to compute in terms of and and the force at the step while not requiring knowledge of velocities If the two Taylor expansions are subtracted one obtains as the expression for the velocity at the time step in terms of the coordinates at the and steps There are many other such propagation schemes that can be used in MD each has strengths and weaknesses In the present Section I will focus on describing the basic idea of how MD simulations are performed while leaving treatment of details about propagation schemes to more advanced sources such as Computer Simulations of Liquids M P Allen and D J Tildesley Oxford U Press New York The forces appearing in the MD propagation algorithms can be obtained as gradients of a BornOppenheimer electronic energy surface if this is computationally feasible Following this path involves performing what is called directdynamics MD Alternatively the forces can be computed from derivatives of an empirical force field In the latter case the systems potential energy is expressed in terms of analytical functions of intramolecular bond lengths bond angles and torsional angles as well as intermolecular distances and orientations The parameters appearing in such force fields have usually been determined from electronic structure calculations on molecular fragments spectroscopic determination of vibrational force constants and experimental measurements of intermolecular forces Force Fields Lets interrupt our discussion of MD propagation of coordinates and velocities to examine the ingredients that usually appear in the force fields mentioned above In Figure c we see a molecule in which various intramolecular and intermolecular interactions are introduced Figure c Depiction of a molecule in which bondstretching bondbending intramolecular van der Waals and intermolecular solvation potentials are illustrated The total potential of a system containing one or more such molecules in the presence of a solvent eg water it typically written as a sum of intramolecular potentials one for each molecule in the system and itermolecular potentials The former are usually decomposed into a sum of covalent interactions describing how the energy varies with bond stretching bond bending and dihedral angle distortion as depicted in Figure d Figure d Depiction of bond stretching and bending top left and dihedral angle distortion top right within a molecule and equations describing how the energy varies with these geometry changes and noncovalent interactions describing electrostatic and van der Waals interactions among the atoms in the molecule a These functional forms would be used to describe how the energy changes with the bond lengths and angles within for example each of the molecules shown in Figure c lets call them solute molecules as well as for any water molecules that may be present if these molecules are explicitly included in the MD simulation The interactions among the solute and solvent moleulues are also often expressed in a form involving electrostatic and van der Waals interations between pairs of atoms one on one molecule solute or solvent and the other on another molecule solute or solvent The Cartesian forces on any atom within a solute or solvent molecule are then computed for use in the MD simulation by using the chain rule to relate derivatives with respect to Cartesian coordinates to derivatives of the above intramolecular and intermolecular potentials with respect to the interatomic distances and the angles appearing in them Because water is such a ubiquitous component in condensedphase chemistry much effort has been devoted to generating highly accurate intermolecular potentials to describe the interactions among water molecules In the popular TIPP and TIPP models the waterwater interaction is given by where rOO is the distance between the oxygen atoms of the two water molecules in  and indices and run over or sites respectively for TIPP or TIPP with labeling sites on one water molecule and labeling sites on the second water molecule The parameter is  kcal mol A and B are conventional LennardJones parameters for oxygen atoms and qi is the magnitude of the partial charge on the ith site In Figure d we show how the or sites are defined for these two models Figure d Location of the or sites used in the TIPP and TIPP models Typical values for the parameters are given in the table below rOH HOH angle degrees rOM A  kcalmol B  kcalmol qOor qM qH TIPP x TIPP x In the TIPP model the three sites reside on the oxygen and two hydrogen centers For TIPP the fourth site is called the Msite and it resides off the oxygen center a distance of along the bisector of the two OH bonds as shown in Figure d In using either the TIPP or TIPP model the intramolecular bond lengths and angles are often constrained to remain fixed when doing so one is said to be using a rigid water model There are variants to these two site and site models that for example include van der Waals interactions between atoms on different water molecules and there are models including more than sites and models that allow for the polarization of each water molecule induced by the dipole fields as represented by the partial charges of the other water molecules and of solute molecules The more detail and complexity one introduces the more computational effort is needed to perform MD simulations In particular water molecules that allow for polarization are considerably more computationally demanding because they often involve solving selfconsistently for the polarization of each molecule by the charge and dipole potentials of all the other molecules with each dipole potential including both the permanent and induced dipoles of that molecule Professor John Wampler has created a web page in which the details about molecular mechanics force fields introduced above are summarized This web page provides links to numerous software packages that use these kinds of force fields to carry out MD simulations These links also offer more detailed information about the performance of various force fields as well as giving values for the parameters used in those force fields The parameter values are usually obtained by fitting the intramolecular or intermolecular functional form eg as shown above to energies obtained in electronic structure calculations at a large number of geometries or adjusting them to cause MD or MC simulations employing the force field to reproduce certain thermodynamic properties eg radial distribution functions solvation energies vaporization energies diffusion constants or some combination of both It is important to observe that the kind of force fields discussed above have limitations beyond issues of accuracy In particular they are not designed to allow for bond breaking and bond forming and they represent the BornOppenheimer energy of one most often the ground electronic state There are force fields explicitly designed to include chemical bonding changes but most MD packages do not include them When one is interested in treating a problem that involves transitions from one electronic state to another eg in spectroscopy or when the system undergoes a surface hop near a conical intersection it is most common to use a combined QMMM approach like we talked about in Section of Chapter A QM treatment of the portion of the system that undergoes the electronic transition is combined with a forcefield MM treatment of the rest of the system to carry out the MD simulation Lets now return to the issue of propagating trajectories given a force field and a set of initial conditions appropriate to describing the system to be simulated By applying one of the timepropagation algorithms to all of the coordinates and momenta of the molecules at time t one generates a set of new coordinates and new velocities appropriate to the system at time Using these new coordinates and momenta as and and evaluating the forces at these new coordinates one can again use the propagation equations to generate another finitetimestep set of new coordinates and velocities Through the sequential application of this process one generates a sequence of coordinates and velocities that simulate the systems behavior By following these coordinates and momenta one can interrogate any dynamical properties that one is interested in For example one could monitor oxygenoxygen distances throughout an MD simulation of liquid water with initial conditions chosen to represent water at a given temperature T would determine the initial momenta to generate a histogram of OO distances This would allow one to construct the kind of radial distribution function shown in Figure using MD simulation rather than MC The radial distribution function obtained in such an MD simulation should be identical to that obtained from MC because statistical mechanics assumes the ensemble average MC is equal to the longtime average MD of any property for a system at equilibrium Of course one could also monitor quantities that depend on time such as how often two oxygen atoms come within a certain distance throughout the MD simulation This kind of interrogation could not be achieved using MC because there is no sense of time in MC simulations In Chapter I again discuss using classical molecular dynamics to follow the time evolution of a chemical system However there is a fundamental difference between the kind of simulations described above and the case I treat in Chapter In the former one allows the Nmolecule system to reach equilibrium ie either by carefully choosing initial coordinates and momenta or by waiting until the dynamics has randomized the energy before monitoring the subsequent time evolution In the problem discussed in Chapter we use MD to follow the time progress of a system representing a single bimolecular collision in two crossed beams of molecules Each such beam contains molecules whose initial translational velocities are narrowly defined rather than MaxwellBoltzmann distributed In this case we do not allow the system to equilibrate because we are not trying to model an equilibrium system Instead we select an ensemble of initial conditions that represent the molecules in the two beams and we then follow the Newton dynamics to monitor the outcome eg reaction or nonreactive collision Unlike the MC method which is very amenable to parallel computation MD simulations are more difficult to carry out in a parallel manner One can certainly execute many different classical trajectories on many different computer nodes however to distribute one trajectory over many nodes is difficult The primary difficulty is that for each time step all of the molecules undergo moves to new coordinates and momenta To compute the forces on all molecules requires of the order of calculations eg when pairwise additive potentials are used In contrast each MC step requires that one evaluate the potential energy change accompanying the displacement of only one molecule This uses only of the order of computational steps again for pair wise additive potentials Another factor that complicates MD simulations has to do with the wide range of times scales that may be involved For example for one to use a time step dt short enough to follow highfrequency motions eg OH stretching in a simulation of an ion or polymer in water solvent dt must be of the order of s To then simulate the diffusion of an ion or the folding of a polymer in the liquid state which might require s or longer one would have to carry out MD steps This likely would render the simulation not feasible In the table below we illustrate the wide range of time scales that characterize various events that one might want to simulate using some form of MD and we give a sense of what is practical using MD simulations in the year Examples of dynamical processes taking place over timescales ranging from s through hundreds of seconds each of which one may wish to simulate using MD s s s s s s CH NH OH bond vibration Rotation of small molecule Routinely accessible time duration for atomistic MD simulation Time duration for heroic atomistic MD simulation Time duration achievable using coarsegraining techniquesa Time needed for protein folding a These techniques are discussed in Section Because one can not afford to carry out simulations covering s using time steps needed to follow bond vibrations s it is necessary to devise strategies to focus on motions whose time frame is of primary interest while ignoring or approximating faster motions For example when carrying out longtime MD simulations one can ignore the highfrequency intramolecular motions by simply not including these coordinates and momenta in the Netwonian dynamics eg as one does when using a rigidwater model discussed earlier In other words one simply freezes certain bond lengths and angles Of course this is an approximation whose consequences must be tested and justified and would certainly not be a wise step to take if those coordinates played a key role in the dynamical process being simulated Another approach called coarse graining involves replacing the fully atomistic description of selected components of the system by a muchsimplified description involving significantly fewer spatial coordinates and momenta Coarse Graining The goal of coarse graining is to bring the computational cost of a simulation into the realm of reality This is done by replacing the fully atomistic description of the system in which coordinates sufficient to specify the positions and in MD the velocities of every atom by a description in terms of fewer functional groups often referred to as beads The TIPP and TIPP models for the waterwater interaction potential discussed above are not coarsegrained models because they contain as many or more centers as atoms An example of a coarsegrained model for the waterwater interaction is provided by the StillingerWeber model that was originally introduced to treat tetrahedral Si of water introduced in V Molinero and E B Moore J Phys Chem B Here each water molecule is described only by the location of its oxygen nucleus labeled ri for the ith water molecule and the interaction potential is given as a sum of twobody and threebody terms where is the distance between the ith and jth oxygen atom deg and is the angle between the ith at the center jth and kth oxygen atom The parameters and are used to characterize various characteristics of the potential different values are needed to describe the behavior of Si Ge diamond or water even though they all can adopt tetrahedral coordination The form of the threebody part of this potential is designed to guide the orientations among oxygen atoms to adopt tetrahedral character Although the above potential seems more complicated than for example the form used in the TIPP or TIPP potential it has three important advantages when it comes to carrying out MD simulations Because the SW potential contains no terms varying with distance as ie no Coulomb interactions among partial charges it is of qualitatively shorter range than the other two potentials This allows spatial cutoffs to be used ie to ignore interactions beyond much shorter distances efficiently For a system containing water molecules the TIPP or TIPP models require one to evaluate functions of the distances between or centers whereas the SWs twobody component involves only interactions and the threebody component need only be evaluated for molecules and that are nearby molecule If for the atomistic models one wishes to treat the OH stretching and HOH bending motions MD time steps of ca s must be employed For the SW model the fastest motions involve relative movements of the oxygen centers which occur on time scales ca times longer This means that one can use longer MD steps The net result is that this coarsegrained model of the waterwater interaction allows MD simulations to be carried out for qualitatively longer time durations Of course this is only an advantage if the simulations provide accurate results In the Table shown below taken from the above reference we see MD simulation results as well as experimental results obtained with the above mW model with various TIPnP models and with two other popular waterwater potentials SPC and SPCE from which it is clear that the coarsegrained mW model is capable of yielding reliable results on a range of thermodynamic properties Figure e we see a coarsegrained representation of the DNA double helix taken from this reference as well as a depiction of how the beads are defined in terms of base sugar and phosphate units Figure e Depiction of cytosine base sugar and phosphate units constituting blue yellow and brown beads respectively a bead description of the double helix d locations of the beads relative to the atomic positions for the phosphate sugar and bases and definition of various beadbead interaction distances c In the Table shown below the reference cited above specifies the locations and masses of the phosphate sugar and base beads in the B form of the DNA helix The masses need to be chosen so that the coarsegrained dynamical motions of these units replicate within reasonable tolerances the center of mass motions of the phosphate sugar and base moieties when atomistic MD simulations are carried out on smaller test systems containing these nucleotide units The potential used to carry out the coarsegrained MD simulations is given by the equations shown below taken from the above reference In addition to the usual bond stretching bending and dihedral terms nb now the bonds relate to linkages between beads rather than between atoms that are similar to what we saw earlier in our discussion of force fields there are additional terms describes the interactions among pstacked base pairs describes the hydrogen bonding interactions between bases and describes excludedvolume effects where V_rm exsum_ijN_rm ex leftbeginarraycc varepsilonleftleftdfracsigma_ijr_ijrightleftdfracsigma_ijr_ijrightrightvarepsilon textif r_ijd_rm cut textif r_ijge d_rm cut endarrayright is the screened Coulombic interactions among phosphate units with its exponential decay constant given in terms of a socalled Debye screening length as detailed in the above reference The values of the parameters used in this force field potential given in the above reference are reproduced in the two Tables shown below Although there are numerous parameters in this potential the key to the success of this coarse graining is that there are only six kinds of sites whose positions and velocities must be propagated in the MD simulation phosphate sites sugar sites and four kinds of base sites This is far fewer coordinates that would arise in a fully atomistic MD simulation I will refer the reader to the reference cited above for details about how successful coarse graining was in this case but I will not go further into it at this time I think the two examples we discussed in this Section suffice for introducing the subject of coarse graining to the readers of this textIn summary for this Section MD classical simulations are not difficult to implement if one has available a proper representation of the intramolecular and intermolecular potential energy V Such calculations are routinely carried out on large biomolecules or condensedmedia systems containing thousands to millions of atomic centers There are however difficulties primarily connected to the time scales over which molecular motions and over which the process being simulated change that limit the success of this method and which often require one to employ reduced representations of the system such as in coarse graining In contrast quantum MD simulations such as we describe in the following Section are considerably more difficult to carry out Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Molecular Orbitals Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah a Shapes Sizes and Energies of Orbitalsb Bonding Antibonding Nonbonding and Rydberg Orbitals Before moving on to discuss methods that go beyond the HF model it is appropriate to examine some of the computational effort that goes into carrying out a HF SCF calculation on a molecule The primary differences that appear when molecules rather than atoms are considered are The electronic Hamiltonian contains not only one nuclearattraction Coulomb potential but a sum of such terms one for each nucleus in the molecule whose locations are denoted One has AO basis functions of the type discussed above located on each nucleus of the molecule These functions are still denoted but their radial and angular dependences involve the distance and orientation of the electron relative to the particular nucleus on which the AO is located Other than these two changes performing a SCF calculation on a molecule or molecular ion proceeds just as in the atomic case detailed earlier Let us briefly review how this iterative process occurs Once atomic basis sets have been chosen for each atom the one and twoelectron integrals appearing in the and overlap matrices must be evaluated There are numerous highly efficient computer codes that allow such integrals to be computed for and even and basis functions After executing one of these socalled integral packages for a basis with a total of functions one has available usually on the computers hard disk of the order of oneelectron and and twoelectron integrals When treating extremely large atomic orbital basis sets eg or more basis functions modern computer programs calculate the requisite integrals but never store them on the disk Instead their contributions to the matrix elements are accumulated on the fly after which the integrals are discarded This is usually referred to as the direct integraldriven approach a Shapes Sizes and Energies of Orbitals Each molecular spinorbital MO that results from solving the HF SCF equations for a molecule or molecular ion consists of a sum of components involving all of the basis AOs In this expression the are referred to as LCAOMO coefficients because they tell us how to linearly combine AOs to form the MOs Because the AOs have various angular shapes eg or shapes and radial extents ie different orbital exponents the MOs constructed from them can be of different shapes and radial sizes Lets look at a few examples to see what I mean The first example is rather simple and pertains to two H atoms combining to form the molecule The valence AOs on each H atom are the AOs they combine to form the two valence MOs and depicted in Figure Figure Two Hydrogen Atomic Orbitals Combine to Form a Bonding and Antibonding Molecular Orbital The bonding MO labeled s has LCAOMO coefficients of equal sign for the two AOs as a result of which this MO has the same sign near the left H nucleus A as near the right H nucleus B In contrast the antibonding MO labeled has LCAOMO coefficients of different sign for the A and B AOs As was the case in the Hckel or tightbinding model outlined in Chapter the energy splitting between the two MOs depends on the overlap between the two AOs which in turn depends on the distance between the two nuclei An analogous pair of bonding and antibonding MOs arises when two orbitals overlap sideways as in ethylene to form and MOs which are illustrated in Figure Figure Two Atomic Orbitals on Carbon Atoms Combine to Form a Bonding and Antibonding Molecular Orbital The shapes of these MOs clearly are dictated by the shapes of the AOs that comprise them and the relative signs of the LCAOMO coefficients that relate the MOs to AOs For the MO these coefficients have the same sign on the left and right atoms for the MO they have opposite signs I should stress that the signs and magnitudes of the LCAOMO coefficients arise as eigenvectors of the HF SCF matrix eigenvalue equation It is a characteristic of such eigenvalue problems for the lower energy eigenfunctions to have fewer nodes than the higher energy solutions as we learned from several examples that we solved in Part of this text Another thing to note about the MOs shown above is that they will differ in their quantitative details but not in their overall shapes when various functional groups are attached to the ethylene molecules C atoms For example if electronwithdrawing groups such as Cl OH or Br are attached to one of the C atoms the attractive potential experienced by a electron near that C atom will be enhanced relative to the potential near the other C atom As a result the bonding MO will have larger LCAOMO coefficients Ckm belonging to tighter basis AOs on this C atom This will make the bonding MO more radially compact in this region of space although its nodal character and gross shape will not change Alternatively an electron donating group such as HC or tbutyl attached to one of the C centers will cause the MO to be more diffuse by making its LCAOMO coefficients for more diffuse basis AOs larger In addition to MOs formed primarily of AOs of one type ie for it is primarily stype orbitals that form the and MOs for ethylenes bond it is primarily the C AOs that contribute there are bonding and antibonding MOs formed by combining several AOs For example the four equivalent CH bonding MOs in shown in Figure each involve C and as well as H basis AOs Figure The Four CH Bonds in Methane The energies of the MOs depend on two primary factors the energies of the AOs from which the MOs are constructed and the overlap between these AOs The pattern in energies for valence MOs formed by combining pairs of firstrow atoms to form homonuclear diatomic molecules is shown in Figure Figure Energies of the Valence Molecular Orbitals in Homonuclear Diatomics Involving FirstRow Atoms In this figure the core MOs formed from the AOs are not shown only those MOs formed from and AOs appear The clear trend toward lower orbital energies as one moves from left to right is due primarily to the trends in orbital energies of the constituent AOs That is F being more electronegative than has a lowerenergy orbital than does b Bonding Antibonding Nonbonding and Rydberg Orbitals As noted above when valence AOs combine to form MOs the relative signs of the combination coefficients determine along with the AO overlap magnitudes the MOs energy and nodal properties In addition to the bonding and antibonding MOs discussed and illustrated earlier two other kinds of MOs are important to know about Nonbonding MOs arise for example when an orbital on one atom is not directed toward and overlapping with an orbital on a neighboring atom For example the lone pair orbitals on or on the oxygen atom of are nonbonding orbitals They still are described in the LCAOMO manner but their coefficients do not contain dominant contributions from more than one atomic center Finally there is a type of orbital that all molecules possess but that is ignored in most elementary discussions of electronic structure All molecules have socalled Rydberg orbitals These orbitals can be thought of as large diffuse orbitals that describe the regions of space an electron would occupy if it were in the presence of the corresponding closedshell molecular cation Two examples of such Rydberg orbitals are shown in Figure On the left we see the Rydberg orbital of and on the right that of The former species can be thought of as a closedshell ammonium cation around which a Rydberg orbital resides The latter is protonated methyl amine with its Rydberg orbital Figure Rydberg Orbitals of and of Protonated Methyl Amine Molecular Structure Theory and Experiment Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Experimental Probes of Molecular Shapes Rotational Spectroscopy Vibrational Spectroscopy XRay Crystallography NMR Spectroscopy Theoretical Simulation of StructuresContributors and Attributions Experimental Probes of Molecular Shapes I expect you are wondering why I want to discuss how experiments measure molecular shapes in this text whose aim is to introduce you to the field of theoretical chemistry In fact theory and experimental measurement are very connected and it is these connections that I wish to emphasize in the following discussion In particular I want to make it clear that experimental data can only be interpreted and thus used to extract molecular properties through the application of theory So theory does not replace experiment but serves both as a complementary component of chemical research via simulation of molecular properties and as the means by which we connect laboratory data to molecular properties Rotational Spectroscopy Most of us use rotational excitation of molecules in our everyday life In particular when we cook in a microwave oven the microwave radiation which has a frequency in the range inputs energy into the rotational motions of the primarily water molecules contained in the food These rotationally hot water molecules then collide with neighboring molecules ie other water as well as proteins and other molecules in the food and in the cooking vessel to transfer some of their motional energy to them Through this means the translational kinetic energy of all the molecules inside the cooker gains energy This process of rotationtotranslation energy transfer is how the microwave radiation ultimately heats the food which cooks it What happens when you put the food into the microwave oven in a metal container or with some other metal material As shown in Chapter the electrons in metals exist in very delocalized partially filled orbitals called bands These band orbitals are spread out throughout the entire piece of metal The application of any external electric field eg that belonging to the microwave radiation causes these metal electrons to move throughout the metal As these electrons accumulate more and more energy from the microwave radiation they eventually have enough kinetic energy to be ejected into the surrounding air forming a discharge This causes the sparking that we see when we make the mistake of putting anything metal into our microwave oven Lets now learn more about how the microwave photons cause the molecules to become rotationally excited Using microwave radiation molecules having dipole moment vectors can be made to undergo rotational excitation In such processes the timevarying electric field of the microwave electromagnetic radiation interacts with the molecules via a potential energy of the form This potential can cause energy to flow from the microwave energy source into the molecules rotational motions when the energy of the former matches the energy spacing between two rotational energy levels This idea of matching the energy of the photons to the energy spacings of the molecule illustrates the concept of resonance and is something that is ubiquitous in spectroscopy as we learned in mathematical detail in Chapter Upon first hearing that the photons energy must match an energylevel spacing in the molecule if photon absorption is to occur it appears obvious and even trivial However upon further reflection there is more to such resonance requirements than one might think Allow me to illustrate using this microwaveinduced rotational excitation example by asking you to consider why photons whose energies considerably exceed the energy spacing will not be absorbed in this transition That is why is more than enough energy not good enough The reason is that for two systems in this case the photons electric field and the molecules rotation which causes its dipole moment to also rotate to interact and thus exchange energy this is what photon absorption is they must have very nearly the same frequencies If the photons frequency exceeds the rotational frequency of the molecule by a significant amount the molecule will experience an electric field that oscillates too quickly to induce a torque on the molecules dipole that is always in the same direction and that lasts over a significant length of time As a result the rapidly oscillating electric field will not provide a coherent twisting of the dipole and hence will not induce rotational excitation One simple example from every day life can further illustrate this issue When you try to push your friend spouse or child on a swing you move your arms in resonance with the swinging persons movement frequency Each time the person returns to you your arms are waiting to give a push in the direction that gives energy to the swinging individual This happens over and over again each time they return your arms have returned to be ready to give another push in the same direction In this case we say that your arms move in resonance with the swings motion and offer a coherent excitation of the swinger If you were to increase greatly the rate at which your arms are moving in their up and down pattern the swinging person would not always experience a push in the correct direction when they return to meet your arms Sometimes they would feel a strong inphase push but other times they would feel an outofphase push in the opposite direction The net result is that over a long period of time they would feel random jerks from your arms and thus would not undergo smooth energy transfer from you This is why too high a frequency and hence too high an energy does not induce excitation Let us now return to the case of rotational excitation by microwave photons As we saw in Chapter for a rigid diatomic molecule the rotational energy spacings are given by where is the moment of inertia of the molecule given in terms of its equilibrium bond length and its reduced mass as Thus in principle measuring the rotational energy level spacings via microwave spectroscopy allows one to determine The second identity above simply defines what is called the rotational constant in terms of the moment of inertia The rotational energy levels described above give rise to a manifold of levels of nonuniform spacing as shown in the Figure Figure Rotational energy levels vs rotational quantum number The nonuniformity in spacings is a result of the quadratic dependence of the rotational energy levels on the rotational quantum number E_J JJ biggdfrachbarIbiggtag Moreover the level with quantum number is fold degenerate that is there are distinct energy states and wave functions that have energy and that are distinguished by a quantum number These states have identical energy but differ among one another by the orientation of their angular momentum in space ie the orientation of how they are spinning For polyatomic molecules we know from Chapter that things are more complicated because the rotational energy levels depend on three socalled principal moments of inertia which in turn contain information about the molecules geometry These three principle moments are found by forming a x moment of inertia matrix having elements and expressed in terms of the Cartesian coordinates of the nuclei a and of the center of mass in an arbitrary moleculefixed coordinate system analogous definitions hold for and The principle moments are then obtained as the eigenvalues of this x matrix For molecules with all three principle moments equal the rotational energy levels are given by E_JK dfrachbarJJI and are independent of the quantum number and on the quantum number that again describes the orientation of how the molecule is spinning in space Such molecules are called spherical tops For molecules called symmetric tops with two principle moments equal and one unique moment the energies depend on two quantum numbers and and are given by E_JK dfrachbarJJI_a hbarK biggdfracI_c dfracI_abigg tag Species having all three principal moments of inertia unique termed asymmetric tops have rotational energy levels for which no analytic formula is yet known The HO molecule shown in Figure is such an asymmetric top molecule More details about the rotational energies and wave functions were given in Chapter Figure Water molecule showing its three distinct principal moment of inertia The moments of inertia that occur in the expressions for the rotational energy levels involve positions of atomic nuclei relative to the center of mass of the molecule So a microwave spectrum can in principle determine the moments of inertia and hence the geometry of a molecule In the discussion given above we treated these positions and thus the moments of inertia as fixed ie not varying with time Of course these distances are not unchanging with time in a real molecule because the molecules atomic nuclei undergo vibrational motions Because of this it is the vibrationallyaveraged moments of inertia that must be incorporated into the rotational energy level formulas Specifically because the rotationally energies depend on the inverses of moments of inertia one must vibrationally average over the vibrational motion that characterizes the molecules movement For species containing stiff bonds the vibrational average of the inverse squares of atomic distances relative to the center of mass does not differ significantly from the equilibrium values of the same distances However for molecules such as weak van der Waals complexes eg HO or ArHCl that undergo floppy largeamplitude vibrational motions there may be large differences between the equilibrium and the vibrationally averaged values The proper treatment of the rotational energy level patterns in such floppy molecules is still very much under active study by theoretical and experimental chemists For this reason it is a very challenging task to use microwave data on rotational energies to determine geometries equilibrium or vibrationally averaged for these kinds of molecules So in the area of rotational spectroscopy theory plays several important roles It provides the basic equations in terms of which the rotational line spacings relate to moments of inertia It allows one given the distribution of geometrical bond lengths and angles characteristic of the vibrational state the molecule exists in to compute the proper vibrationallyaveraged moment of inertia It can be used to treat large amplitude floppy motions eg by simulating the nuclear motions on a BornOppenheimer energy surface thereby allowing rotationally resolved spectra of such species to provide proper moment of inertia and thus geometry information Vibrational Spectroscopy The ability of molecules to absorb and emit infrared radiation as they undergo transitions among their vibrational energy levels is critical to our planets health It turns out that water and molecules have bonds that vibrate in the frequency range which is within the infrared spectrum As solar radiation primarily visible and ultraviolet impacts the earths surface it is absorbed by molecules with electronic transitions in this energy range eg colored molecules such as those contained in plant leaves and other dark material These molecules are thereby promoted to excited electronic states Some such molecules reemit the photons that excited them but most undergo socalled radiationless relaxation that allows them to return to their ground electronic state but with a substantial amount of internal vibrational energy That is these molecules become vibrationally very hot Subsequently these hot molecules as they undergo transitions from highenergy vibrational levels to lowerenergy levels emit infrared IR photons If our atmosphere were devoid of water vapor and these IR photons would travel through the atmosphere and be lost into space The result would be that much of the energy provided by the suns visible and ultraviolet photons would be lost via IR emission However the water vapor and do not allow so much IR radiation to escape These greenhouse gases absorb the emitted IR photons to generate vibrationally hot water and molecules in the atmosphere These vibrationally excited molecules undergo collisions with other molecules in the atmosphere and at the earths surface In such collisions some of their vibrational energy can be transferred to translational kinetic energy of the collisionpartner molecules In this manner the temperature which is measure of the average translational energy increases Of course the vibrationally hot molecules can also reemit their IR photons but there is a thick layer of such molecules forming a blanket around the earth and all of these molecules are available to continually absorb and reemit the IR energy In this manner the blanket keeps the IR radiation from escaping and thus keeps our atmosphere warm Those of us who live in dry desert climates are keenly aware of such effects Clear cloudless nights in the desert can become very cold primarily because much of the days IR energy production is lost to radiative emission through the atmosphere and into space Lets now learn more about molecular vibrations how IR radiation excites them and what theory has to do with this When infrared IR radiation is used to excite a molecule it is the vibrations of the molecule that are in resonance with the oscillating electric field Molecules that have dipole moments that vary as its vibrations occur interact with the IR electric field via a potential energy of the form Here denotes the change in the molecules dipole moment associated with motion along the vibrational normal mode labeled As the IR radiation is scanned it comes into resonance with various vibrations of the molecule under study and radiation can be absorbed Knowing the frequencies at which radiation is absorbed provides knowledge of the vibrational energy level spacings in the molecule Absorptions associated with transitions from the lowest vibrational level to the first excited lever are called fundamental transitions Those connecting the lowest level to the second excited state are called first overtone transitions Excitations from excited levels to even higher levels are named hotband absorptions Fundamental vibrational transitions occur at frequencies that characterize various functional groups in molecules eg OH stretching HNH bending NH stretching CC stretching etc As such a vibrational spectrum offers an important fingerprint that allows the chemist to infer which functional groups are present in the molecule However when the molecule contains soft floppy vibrational modes it is often more difficult to use information about the absorption frequency to extract quantitative information about the molecules energy surface and its bonding structure As was the case for rotational levels of such floppy molecules the accurate treatment of largeamplitude vibrational motions of such species remains an area of intense research interest within the theory community In a polyatomic molecule with atoms there are many vibrational modes The total vibrational energy of such a molecule can be approximated as a sum of terms one for each of the or for a linear molecule vibrations Ev_ v_Ntext or hbaromega_j bigv_j dfracbig tag Here is the harmonic frequency of the mode and is the vibrational quantum number associated with that mode As we discussed in Chapter the vibrational wave functions are products of harmonic vibrational functions for each mode psi prod_jNtext or psi_v_j x jtag and the spacings between energy levels in which one of the normalmode quantum numbers increases by unity are expressed as Delta E_v_j Ev_j E v_j hbaromega_j That is the spacings between successive vibrational levels of a given mode are predicted to be independent of the quantum number v within this harmonic model as shown in Figure Figure Harmonic vibrational energy levels vs vibrational quantum number In Chapter the details connecting the local curvature ie Hessian matrix elements in a polyatomic molecules potential energy surface to its normal modes of vibration are presented Experimental evidence clearly indicates that significant deviations from the harmonic oscillator energy expression occur as the quantum number grows These deviations are explained in terms of the molecules true potential deviating strongly from the harmonic potential at higher energy as shown in the Figure Figure Harmonic parabola and anharmonic potentials At larger bond lengths the true potential is softer than the harmonic potential and eventually reaches its asymptote which lies at the dissociation energy above its minimum This deviation of the true from causes the true vibrational energy levels to lie below the harmonic predictions It is convention to express the experimentally observed vibrational energy levels along each of the or independent modes in terms of an anharmonic formula similar to what we discussed for the Morse potential in Chapter Ev_j hbiggomega_j bigv_j dfracbig omega_x_j bigv_j dfracbig omega_y_j bigv_j dfracbig omega_z_j bigv_j dfracbig bigg The first term is the harmonic expression The next is termed the first anharmonicity it usually produces a negative contribution to that varies as Subsequent terms are called higher anharmonicity corrections The spacings between successive energy levels are then given by DeltaEv_j Ev_j Ev_jtag A plot of the spacing between neighboring energy levels versus should be linear for values of where the harmonic and first anharmonicity terms dominate The slope of such a plot is expected to be and the small intercept should be Such a plot of experimental data which clearly can be used to determine the and parameters of the vibrational mode of study is shown in Figure Figure BirgeSponer plot of vibrational energy spacings vs quantum number These socalled BirgeSponer plots can also be used to determine dissociation energies of molecules if the vibration whose spacings are plotted corresponds to a bondstretching mode By linearly extrapolating such a plot of experimental values to large values one can find the value of at which the spacing between neighboring vibrational levels goes to zero This value max specifies the quantum number of the last bound vibrational level for the particular bondstretching mode of interest The dissociation energy can then be computed by adding to the zero point energy along this mode the sum of the spacings between neighboring vibrational energy levels from to So in the case of vibrational spectroscopy theory allows us to interpret observed infrared lines in terms of absorptions arising in localized functional groups extract dissociation energies if a long progression of lines is observed in a bondstretching transition and treat highly nonharmonic floppy vibrations by carrying out dynamical simulations on a BornOppenheimer energy surface XRay Crystallography In xray crystallography experiments one employs crystalline samples of the molecules of interest and makes use of the diffraction patterns produced by scattered xrays to determine positions of the atoms in the molecule relative to one another using the famous Bragg formula In this equation is the wavelength of the xrays is a spacing between layers planes of atoms in the crystal is the angle through which the xray beam is scattered and is an integer that labels the order of the scattered beam Because the xrays scatter most strongly from the innershell electrons of each atom the interatomic distances obtained from such diffraction experiments are more precisely measures of distances between high electron densities in the neighborhoods of various atoms The xrays interact most strongly with the innershell electrons because it is these electrons whose characteristic Bohr frequencies of motion are nearly in resonance with the high frequency of such radiation For this reason xrays can be viewed as being scattered from the core electrons that reside near the nuclear centers within a molecule Hence xray diffraction data offers a very precise and reliable way to probe interatomic distances in molecules The primary difficulties with xray measurements are That one needs to have crystalline samples often materials simply cannot be grown as crystals That one learns about interatomic spacings as they occur in the crystalline state not as they exist for example in solution or in gasphase samples This is especially problematic for biological systems where one would like to know the structure of the biomolecule as it exists within the living organism Nevertheless xray diffraction data and its interpretation through the Bragg formula provide one of the most widely used and reliable ways for probing molecular structure NMR Spectroscopy NMR spectroscopy probes the absorption of radiofrequency RF radiation by the nuclear spins of the molecule The most commonly occurring spins in natural samples are protons deuterons and nuclei In the presence of an external magnetic field along the axis each such nucleus has its spin states split in energy by an amount given by where is the component of the nucleus spin angular momentum along the axis is the strength of the external magnetic field and is a socalled gyromagnetic factor ie a constant that is characteristic of the nucleus This splitting of magnetic spin levels by a magnetic field is called the Zeeman effect and it is illustrated in Figure Figure Zeeman splitting of magnetic nucleuss two levels caused by magnetic field The factor is introduced to describe the screening of the external field at the nucleus caused by the electron cloud that surrounds this nucleus In effect is the magnetic field experienced local to the nucleus It is this screening that gives rise to the phenomenon of chemical shifts in NMR spectroscopy and it is this factor that allows NMR measurements of shielding factors to be related by theory to the electronic environment of a nucleus In Figure we display the chemical shifts of proton and nuclei in a variety of chemical bonding environments Figure Chemical shifts characterizing various electronic environments for protons and for carbon nuclei Because the quantum number changes in steps of unity and because each photon possesses one unit of angular momentum the RF energy that will be in resonance with the nucleus Zeemansplit levels is given by In most NMR experiments a fixed RF frequency is employed and the external magnetic field is scanned until the above resonance condition is met Determining at what value a given nucleus absorbs RF radiation allows one to determine the local shielding for that nucleus This in turn provides information about the electronic environment local to that nucleus as illustrated in the above figure This data tells the chemist a great deal about the molecules structure because it suggests what kinds of functional groups occur within the molecule To extract even more geometrical information from NMR experiments one makes use of another feature of nuclear spin states In particular it is known that the energy levels of a given nucleus eg the one are altered by the presence of other nearby nuclear spins These spinspin coupling interactions give rise to splittings in the energy levels of the nucleus that alter the above energy expression as follows Where is the component of the nuclear spin angular momentum is the corresponding component of a nearby nucleus causing the splitting and is called the spinspin coupling constant between the two nuclei Examples of how spins on neighboring centers split the NMR absorption lines of a given nucleus are shown in Figs for three common cases The first involves a nucleus labeled A that is close enough to one other magnetically active nucleus labeled X the second involves a nucleus A that is close to two equivalent nuclei X and the third describes a nucleus A close to three equivalent nuclei X Figure Splitting pattern characteristic of AX case In Figure are illustrated the splitting in the X nucleus absorption due to the presence of a single A neighbor nucleus right and the splitting in the A nucleus absorption left caused by the X nucleus In both of these examples the X and A nuclei have only two values so they must be spin nuclei This kind of splitting pattern would for example arise for a group in the benzene molecule where A and X Figure Splitting pattern characteristic of case The splitting pattern shown if Figure would for example arise in the spectrum of a group and illustrates the splitting of the A nucleus absorption line by the four spin states that the two equivalent X spins can occupy Again the lines shown would be consistent with X and A both having spin because they each assume only two values Figure Splitting pattern characteristic of case In Figure is the kind of splitting pattern that would apply to the NMR absorptions for a group In this case the spin A line is split by the eight spin states that the three equivalent spin H nuclei can occupy The magnitudes of these coupling constants depend on the distances R between the two nuclei to the inverse sixth power ie as They also depend on the values of the two interacting nuclei In the presence of splitting caused by nearby usually covalently bonded nuclei the NMR spectrum of a molecule consists of sets of absorptions each belonging to a specific nuclear type in a particular chemical environment and thus have a specific chemical shift that are split by their couplings to the other nuclei Because of the spinspin couplings strong decay with internuclear distance the magnitude and pattern of the splitting induced on one nucleus by its neighbors provides a clear signature of what the neighboring nuclei are ie through the number of values associated with the peak pattern and how far these nuclei are through the magnitude of the constant knowing it is proportional to This nearneighbor data combined with the chemical shift functional group data offer powerful information about molecular structure An example of a full NMR spectrum is given in Figure where the spectrum ie only the proton absorptions are shown of appears along with plots of the integrated intensities under each set of peaks The latter data suggests the total number of nuclei corresponding to that group of peaks Notice how the protons absorption the absorption of the two equivalent protons on the group and that of the three equivalent protons in the group occur at different field strengths ie have different chemical shifts Also note how the peak is split only slightly because this proton is distant from any others but the protons peak is split by the neighboring groups protons in an pattern Finally the protons peak is split by the neighboring groups three protons in an pattern Figure Proton NMR of ethanol showing splitting of three distinct protons as well as integrated intensities of the three sets of peaks In summary NMR spectroscopy is a very powerful tool that allows us to extract internuclear distances or at least tell how many nearneighbor nuclei there are and thus geometrical information by measuring coupling constants and subsequently using the theoretical expressions that relate values to values allows us to probe the local electronic environment of nuclei inside molecules by measuring chemical shifts or shielding and then using the theoretical equations relating the two quantities Knowledge about the electronic environment tells one for example about the degree of polarity in bonds connected to that nuclear center tells us through the splitting patterns associated with various nuclei the number and nature of the neighbor nuclei again providing a wealth of molecular structure information Theoretical Simulation of Structures We have seen how microwave infrared and NMR spectroscopy as well as xray diffraction data when subjected to proper interpretation using the appropriate theoretical equations can be used to obtain a great deal of structural information about a molecule As discussed in Part of this text theory is also used to probe molecular structure in another manner That is not only does theory offer the equations that connect the experimental data to the molecular properties but it also allows one to simulate a molecule This simulation is done by solving the Schrdinger equation for the motions of the electrons to generate a potential energy surface after which this energy landscape can be searched for points where the gradients along all directions vanish An example of such a PES is shown in Figure for a simple case in which the energy depends on only two geometrical parameters Even in such a case one can find several local minima and transition state structures connecting them Figure Potential energy surface in two dimensions showing reactant and product minima transition states and paths connecting them As we discussed in Chapter among the stationary points on the potential energy surface PES those at which all eigenvalues of the second derivative Hessian matrix are positive represent geometrically stable isomers of the molecule Those stationary points on the PES at which all but one Hessian eigenvalue are positive and one is negative represent transition state structures that connect pairs of stable isomers Once the stable isomers of a molecule lying within some energy interval above the lowest such isomer have been identified the vibrational motions of the molecule within the neighborhood of each such isomer can be described either by solving the Schrdinger equation for the vibrational wave functions belonging to each normal mode or by solving the classical Newton equations of motion using the gradient of the PES to compute the forces along each molecular distortion direction The decision about whether to use the Schrdinger or Newtonian equations to treat the vibrational motion depends on whether one wishes needs to properly include quantum effects eg zeropoint motion and wave function nodal patterns in the simulation Once the vibrational motions have been described for a particular isomer and given knowledge of the geometry of that isomer one can evaluate the moments of inertia one can properly vibrationally average all of the quantities that enter into these moments and hence one can simulate the microwave spectrum of the molecule Also given the Hessian matrix for this isomer one can form its massweighted variant whose nonzero eigenvalues give the normalmode harmonic frequencies of vibration of that isomer and whose eigenvectors describe the atomic motions that correspond to these vibrations Moreover the solution of the electronic Schrdinger equation allows one to compute the NMR shielding values at each nucleus as well as the spinspin coupling constants between pairs of nuclei the treatment of these subjects is beyond the level of this text you can find it in Molecular Electronic Structure Theory by Helgaker et al Again using the vibrational motion knowledge one can average the and values over this motion to gain vibrationally averaged and values that best simulate the experimental parameters One carries out such a theoretical simulation of a molecule for various reasons Especially in the early days of developing theoretical tools to solve the electronic Schrdinger equation or the vibrational motion problem one would do so for molecules whose structures and IR and NMR spectra were well known The purpose in such cases was to calibrate the accuracy of the theoretical methods against established experimental data Now that theoretical tools have been reasonably well tested and can be trusted within known limits of accuracy one often uses theoretically simulated structural and spectroscopic properties to identify spectral features whose molecular origin is not known That is one compares the theoretical spectra of a variety of test molecules to the observed spectral features to attempt to identify the molecule that produced the spectra It is also common to use simulations to examine species that are especially difficult to generate in reasonable quantities in the laboratory and species that do not persist for long times Reactive radicals cations and anions are often difficult to generate in the laboratory and may be impossible to retain in sufficient concentrations and for a sufficient duration to permit experimental characterization In such cases theoretical simulation of the properties of these molecules may be the most reliable way to access such data Moreover one might use simulations to examine the behavior of molecules under extreme conditions such as high pressure confinement to nanoscopic spaces high temperature or very low temperatures for which experiments could be very difficult or expensive to carry out Let me tell you about an example of how such theoretical simulation has proven useful probably even essential for interpreting experimental data the data is reported in N I Hammer JW Shin J M Headrick E G Diken J R Roscioli G H Weddle and M A Johnson Science In the group of Prof Mark Johnson at Yale infrared spectroscopy is carried out on gasphase ions In this particular experiment water cluster anions with one or more Ar atoms attached to them were formed and using a mass spectrometer the ions of one specific mass were selected for subsequent study In the example illustrated here the cluster containing four water molecules was studied When infrared IR radiation impinges on the ions it can be absorbed if its frequency matches the frequency of one of the vibrational modes of this cluster If for example IR radiation in the cm frequency range is absorbed this range corresponds to frequencies of HOH bending vibrations this excess internal energy can cause one or more of the weakly bound Ar atoms to be ejected from the cluster thus decreasing the number of intact ions in the mass spectrometer The decrease in the number of intact ions is a direct measure then of the absorption of the IR light By monitoring the number of ie the strength of the mass spectrometers signal at this particular masstocharge ratio as the IR radiation is tuned through the cm frequency range the experimentalists obtain spectral signatures ie the ion intensity loss of the IR absorption by the cluster ions When they carry out this kind of experiment using and scan the IR radiation in the cm frequency range they obtained the spectrum labeled A in Figure a When they performed the same kind of experiment on and scanned in the cm frequency range which is where OD stretching vibrations are known to occur they obtained the spectrum labeled B in Figure a Figure a Infrared spectra of and respectively in the cm and cm frequency ranges What the experimentalists did not know however is what the geometrical structure of the underlying ion was Nor did they know exactly which HOH bending or OH or OD stretching vibrations were causing the various peaks shown in Figure a A and B By carrying out electronic structure calculations on a large number of geometries for and searching for local minima on the ground electronic state of this ion there are a very large number of such local minima and then using the massweighted Hessian matrix at each local minima to calculate the structures vibrational energies the experimentalists were able to figure out what structure for was most consistent with their observed IR spectrum For example for the rather extended structure of they computed the IR spectrum shown in panel E and for in panel F of Figure a Alternatively for the cyclic structure of they computed the IR spectrum shown in panel C and for in panel D of Figure a Clearly the spectrum of panels C and D agrees much better with their experimental spectrum in panels A and B than does the spectrum of panels E and F Based on these comparisons these scientists concluded that the ions in their and have the cyclic geometry not the extended quasilinear geometry Moreover by looking at which particular vibrational modes of the cyclic produced which peaks in panels C and D they were able to assign each of the IR peaks seen in their data of panels A and B This is a good example of how theoretical simulation can help interpret experimental data without the theory these scientists would not know the geometry of Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Molecules Embedded in Condensed Media Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah No headers Often one wants to model the behavior of a molecule or ion that is not isolated as it might be in a gasphase experiment When one attempts to describe a system that is embedded for example in a crystal lattice in a liquid or a glass one has to have some way to treat both the effects of the surrounding medium on the molecule of interest and the motions of the mediums constituents In socalled quantum mechanics molecular mechanics QMMM approaches to this problem one treats the molecule or ion of interest using the electronic structure methods outlined earlier in this Chapter but with one modification The oneelectron component of the Hamiltonian which contains the electronnuclei Coulomb potential is modified to also contain a term that describes the potential energy of interaction of the electrons and nuclei with the surrounding medium In the simplest such models this solvation potential depends only on the dielectric constant of the surroundings In more sophisticated models the surroundings are represented by a collection of fractional point charges that may also be attributed with local dipole moments and polarizabilities that allow them to respond to changes in the internal charge distribution of the molecule or ion The locations of such partial charges and the magnitudes of their dipoles and polarizabilities are determined to make the resultant solvation potential reproduce known from experiment or other simulations solvation characteristics eg solvation energy radial distribution functions in a variety of calibration cases The book Molecular Modeling nd ed A R Leach Prentice Hall Englewood Cliffs offers a good source of information about how these terms are added into the oneelectron component of the Hamiltonian to account for solvation effects In addition to describing how the surroundings affect the Hamiltonian of the molecule or ion of interest one needs to describe the motions or spatial distributions of the mediums constituent atoms or molecules This is usually done within a purely classical treatment of these degrees of freedom That is if equilibrium properties of the solvated system are to be simulated then MonteCarlo MC sampling this subject is treated in Chapter of this text of the surrounding mediums coordinates is used Within such a MC sampling the potential energy of the entire system is calculated as a sum of two parts i the electronic energy of the solute molecule or ion which contains the interaction energy of the molecules electrons and nuclei with the surrounding medium plus ii the intramedium potential energy which is taken to be of a simple molecular mechanics MM force field character ie to depend on interatomic distances and internal angles in an analytical and easily computed manner Again the book Molecular Modeling nd ed A R Leach Prentice Hall Englewood Cliffs offers a good source of information about these matters If alternatively dynamical characteristics of the solvated species are to be simulated a classical molecular dynamics MD treatment is used In this approach the solutemedium and internalmedium potential energies are handled in the same way as in the MC case but where the time evolution of the mediums coordinates are computed using the MD techniques discussed in Chapter of this text Monte Carlo Evaluation of Properties Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Metropolis Monte CarloUmbrella SamplingContributors and Attributions A tool that has proven extremely powerful in statistical mechanics since computers became fast enough to permit simulations of complex systems is the Monte Carlo MC method This method allows one to evaluate the integrations appearing in the classical partition function described above by generating a sequence of configurations ie locations of all of the molecules in the system as well as of all the internal coordinates of these molecules and assigning a weighting factor to these configurations By introducing an especially efficient way to generate configurations that have high weighting the MC method allows us to simulate extremely complex systems that may contain millions of molecules To appreciate why it is useful to have a tool such as MC lets consider how one might write a computer program to evaluate the classical partition function For a system consisting of Ar atoms in a box of volume at temperature T The classical Hamiltonian consists of a sum of kinetic and interatomic potential energies The integration over the momentum variables can be carried out analytically and allows to be written as The contribution to provided by the integral over the coordinates is often called the configurational partition function If the density of the Ar atoms is high as in a liquid or solid state the potential will depend on the coordinates of the Ar atoms in a manner that would not allow substantial further approximations to be made One would thus be faced with evaluating an integral over spatial coordinates of a function that depends on all of these coordinates If one were to discretize each of the coordinate axes using say points along each axis the numerical evaluation of this integral as a sum over the coordinates would require computational effort scaling as KN Even for Ar atoms with each axis having points this is of the order of computer operations Clearly such a straightforward evaluation of this classical integral would be foolish to undertake The MC procedure allows one to evaluate such highdimensional integrals by not dividing each of the axes into discrete points but rather selecting values of for which the integrand is nonnegligible while also avoiding values of for which the integrand is small enough to neglect By then summing over only values of that meet these criteria the MC process can estimate the integral Of course the magic lies in how one designs a rigorous and computationally efficient algorithm for selecting those that meet the criteria To illustrate how the MC process works let us consider carrying out a MC simulation representative of liquid water at some density r and temperature T One begins by placing water molecules in a box of volume chosen such that reproduces the specified density To effect the MC process we must assume that the total intramolecular and intermolecular potential energy of these water molecules can be computed for any arrangement of the molecules within the box and for any values of the internal bond lengths and angles of the water molecules Notice that as we showed above when considering the Ar example does not include the kinetic energy of the molecules it is only the potential energy Often this energy is expressed as a sum of intramolecular bondstretching and bending contributions one for each molecule plus a pairwise additive intermolecular potential although the MC process does not require that one employ such a decomposition the energy could be computed in other ways if appropriate For example might be evaluated as the BornOppenheimer energy if an ab initio electronic structure calculation on the full molecule system were feasible The MC process does not depend on how is computed but most commonly it is evaluated as shown above Metropolis Monte Carlo In each step of the MC process this potential energy is evaluated for the current positions of the water molecules In its most common and straightforward implementation known as the Metropolis MonteCarlo process a single water molecule is then chosen at random and one of its internal bond lengths or angle or external position or orientation coordinates is selected at random This one coordinate q is then altered by a small amount and the potential energy is evaluated at the new configuration The amount by which coordinates are varied is usually chosen to make the fraction of MC steps that are accepted by following the procedure detailed below approximately This has been shown to optimize the performance of the MC algorithm In implementing the MC process it is usually important to consider carefully how one defines the coordinates that will be used to generate the MC steps For example in the case of Ar atoms discussed earlier it might be acceptable to use the Cartesian coordinates of the atoms However for the water example it would be very inefficient to employ the Cartesian coordinates of the water molecules Displacement of for example one of the atoms along the xaxis while keeping all other coordinates fixed would alter the intramolecular OH bond energy and the HOH bending energy as well as the intermolecular hydrogen bonding energies to neighboring water molecules The intramolecular energy changes would likely be far in excess of unless a very small coordinate change were employed Because it is important to the efficiency of the MC process to make displacements that produce ca acceptance it is better for the water case to make use of coordinates such as the center of mass and orientation coordinates of the water molecules for which larger displacements produce energy changes within a few and smaller displacements of the OH stretching and HOH bending coordinates to keep the energy change within a few Another point to make about how the MC process is often used is that when the intermolecular energy is pair wise additive evaluation of the energy change accompanying the change in requires computational effort that is proportional to the number of molecules in the system because only those factors with or equal to the single molecule that is displaced need be computed This is why pair wise additive forms for are often employed Let us now return to how the MC process is implemented If the energy change is negative ie if the potential energy is lowered by the coordinate displacement the change in coordinate is allowed to occur and the resulting new configuration is counted among the MCaccepted configurations On the other hand if is positive the move from to is not simply rejected to do so would produce an algorithm directed toward finding a minimum on the energy landscape which is not the goal Instead the quantity is used to compute the probability for accepting this energyincreasing move In particular a random number between for example and is selected If the random number is greater than expressed in the same decimal format then the move is rejected If the random number is less than the move is accepted and the new location is included among the set of MCaccepted configurations Then new water molecule and its internal or external coordinate are chosen at random and the entire process is repeated In this manner one generates a sequence of MCaccepted moves representing a series of configurations for the system of water molecules Sometimes this series of configurations is called a Monte Carlo trajectory but it is important to realize that there is no dynamics or time information in this series This set of configurations has been shown to be properly representative of the geometries that the system will experience as it moves around at equilibrium at the specified temperature nb is the only way that information about the molecules kinetic energy enters the MC process but no time or dynamical attributes are contained in it As the series of accepted steps is generated one can keep track of various geometrical and energetic data for each accepted configuration For example one can monitor the distances R among all pairs of oxygen atoms in the water system being discussed and then average this data over all of the accepted steps to generate an oxygenoxygen radial distribution function as shown in Figure Alternatively one might accumulate the intermolecular interaction energies between pairs of water molecules and average this over all accepted configurations to extract the cohesive energy of the liquid water Figure Radial distribution functions between pairs of Oxygen atoms in HO at three different temperatures The MC procedure also allows us to compute the equilibrium average of any property that depends on the coordinates of the molecules Such an average would be written in terms of the normalized coordinate probability distribution function as The denominator in the definition of is of course proportional to the coordinatecontribution to the partition function In the MC process this average is computed by forming the following sum over the M MCaccepted configurations In most MC simulations millions of accepted steps contribute to the above averages At first glance it may seem that such a large number of steps represent an extreme computational burden However recall that straightforward discretization of the axes produced a result whose effort scaled as which is unfeasible even for small numbers of molecules So why do MC simulations work when the straightforward way fails That is how can one handle thousands or millions of coordinates when the above analysis would suggest that performing an integral over so many coordinates would require computations The main thing to understand is that the site discretization of the coordinates is a stupid way to perform the above integral because there are many in fact most coordinate values where the value of the quantity A whose average one wants multiplied by is negligible On the other hand the MC algorithm is designed to select as accepted steps those coordinates for which is nonnegligible So it avoids configurations that are stupid and focuses on those for which the probability factor is largest This is why the MC method works The standard Metropolis variant of the MC procedure was described above where its rules for accepting or rejecting trial coordinate displacements were given There are several other ways of defining rules for accepting or rejecting trial MC coordinate displacements some of which involve using information about the forces acting on the coordinates all of which can be shown to generate a series of MCaccepted configurations consistent with an equilibrium system The book Computer Simulations of Liquids M P Allen and D J Tildesley Oxford U Press New York provides good descriptions of these alternatives to the Metropolis MC method so I will not go further into these approaches here Umbrella Sampling It turns out that the MC procedure as outlined above is a highly efficient method for computing multidimensional integrals of the form where is a normalized positive probability distribution and is any property that depends on the multidimensional variable q There are however cases where this conventional MC approach needs to be modified by using socalled umbrella sampling To illustrate how this is done and why it is needed suppose that one wanted to use the MC process to compute an average with as the weighting factor of a function that is large whenever two or more molecules have high ie repulsive intermolecular potentials For example one could have Such a function could for example be used to monitor when pairs of molecules with centerofmass coordinates RJ and RI approach closely enough to undergo a reaction that requires them to surmount a high intermolecular barrier The problem with using conventional MC methods to compute in such cases is that i favors those coordinates for which the total potential energy is low So coordinates with high are very infrequently accepted ii However is designed to identify events in which pairs of molecules approach closely and thus have high values So there is a competition between and that renders the MC procedure ineffective in such cases because the average one wants to compute involves the product which is small for most values of q What is done to overcome this competition is to introduce a socalled umbrella weighting function that i attains it largest values where is large and ii is positive and takes on values between and so it can be used as shown below to define a proper probability weighting function One then replaces in the MC algorithm by the product and uses this as a weighting function To see how this replacement works we rewrite the average that needs to be computed as follows The interpretation of the last identity is that can be computed by i using the MC process to evaluate the average of but with a probability weighting factor of to accept or reject coordinate changes and ii also using the MC process to evaluate the average of q again with as the weighting factor and finally iii taking the average of divided by the average of to obtain the final result The secret to the success of umbrella sampling is that the product causes the MC process to emphasize in its acceptance and rejection procedure coordinates for which both and and hence are significant Of course the tradeoff is that the quantities and whose averages one computes using as the MC weighting function are themselves susceptible to being very small at coordinates where the weighting function is large Lets consider some examples of when and how one might want to use umbrella sampling techniques Suppose one has one system for which the evaluation of the partition function and thus all thermodynamic properties can be carried out with reasonable computational effort and another similar system ie one whose potential does not differ much from the first for which this task is very difficult Lets call the potential function of the first system and that of the second system The latter systems partition function can be written as follows where is the partition function of the first system and is the ensemble average of the quantity taken with respect to the ensemble appropriate to the first system This result suggests that one can form the ratio of the partition functions by computing the ensemble average of using the first systems weighting function in the MC process Likewise to compute for second system the average value of any property that depends only on the coordinates of the particles one can proceed as follows where is the ensemble average of the quantity taken with respect to the ensemble appropriate to the first system Using the result derived earlier for the ratio this expression for can be rewritten as In this form we are instructed to form the average of for the second system by a forming the ensemble average of using the weighting function for the first system b forming the ensemble average of using the weighting function for the first system and c taking the ratio of these two averages This is exactly what the umbrella sampling device tells us to do if we were to choose as the umbrella function In this example the umbrella is related to the difference in the potential energies of the two systems whose relationship we wish to exploit Under what circumstances would this kind of approach be useful Suppose one were interested in performing a MC average of a property for a system whose energy landscape has many local minima separated by large energy barriers and suppose it was important to sample configurations characterizing the many local minima in the sampling A straightforward MC calculation using as the weighting function would likely fail because a sequence of coordinate displacements from near one local minimum to another local minimum would have very little chance of being accepted in the MC process because the barriers are very high As a result the MC average would likely generate configurations representative of only the systems equilibrium existence near one local minimum rather than representative of its exploration of the full energy landscape However if one could identify those regions of coordinate space at which high barriers occur and construct a function that is large and positive only in those regions one could then use as the umbrella function and compute averages for the system having potential in terms of ensemble averages for a modified system whose potential is In Figure a I illustrate how the original and modified potential landscapes differ in regions between two local minima Figure a Qualitative depiction of the potential for a system having a large barrier and for the umbrellamodified system with potential The MCaccepted coordinates generated using the modified potential would sample the various local minima and thus the entire landscape in a much more efficient manner because they would not be trapped by the large energy barriers By using these MCaccepted coordinates one can then estimate the average value of a property appropriate to the potential having the large barriers by making use of the identity The above umbrella strategy could be useful in generating a good sampling of configurations characteristic of the many local minima which would be especially beneficial if the quantity emphasized those configurations This would be the case for example if measured the intramolecular and nearestneighbor oxygenhydrogen interatomic distances in a MC simulation of liquid water On the other hand if one wanted to use as a measure of the energy needed for a ion to undergo in a M aqueous solution of NaCl a change in coordination number from to as illustrated in Figure b one would need a sampling that is accurate both near the local minima corresponding to the and coordinate and the transitionstate structures Figure b Qualitative depiction of and coordinate ion in water and of the energy profile connecting these two structures Using an umbrella function similar to that discussed earlier to simply lower the barrier connecting the two ion structures may not be sufficient Although this would allow one to sample both local minima its sampling of structures near the transition state would be questionable if the quantity by which the barrier is lowered to allow MC steps moving over the barrier to be accepted with nonnegligible probability is large In such cases it is wise to employ a series of umbrellas to connect the local minima to the transition states Assuming that one has knowledge of the energies and local solvation geometries characterizing the two local minima and the transition state as well as a reasonable guess or approximation of the intrinsic reaction path refer back to Section of Chapter connecting these structures one proceeds as follows to generate a series of socalled windows within each of which the free energy of the solvated ion is evaluated Using the full potential of the system to constitute the unaltered weighting function one multiplies this by an umbrella function to form the umbrellaaltered weighting function In Uq sq is the value of the value of the intrinsic reaction coordinate IRC evaluated for the current geometry of the system q is the value of the IRC characterizing the first window and d is the width of this window The first window could for example correspond to geometries near the coordinate local minimum of the solvated ion structure The width of each window d should be chosen so that the energy variation within the window is no more than a kT in this way the MC process will have a good ie ca acceptance fraction and the configurations generated will allow for energy fluctuations uphill toward the TS of about this amount As the MC process is performed using the above weighting one constructs a histogram for how often the system reaches various values s along the IRC Of course the severe weighting caused by will not allow the system to realize any value of s outside of the window One then creates a second window that connects to the first window ie with and repeats the MC sampling using to generate a second histogram for how often the system reaches various values of s along the IRC within the second window This process is repeated at a series of connected windows whose centers range from the coordinate ion through the transition state and to the coordinate ion After performing this series of umbrellaaltered samplings one has in hand a series of histograms Within the window gives the relative probability of the system being at a point s along the IRC To generate the normalized absolute probability function Ps expressing the probability of being at a point s one can proceed as follows Because the first and second windows are connected at the point one can scale ie multiply it by a constant to match at this common point to produce a new function This new function describes exactly the same relative probability within the second window but unlike it connects smoothly to Because the second and third windows are connected at the point one can scale to match at this common point to produce a new function This process of scaling to match at is repeated until the final window connecting to Upon completing this series of connections one has in hand a continuous probability function which can be normalized In this way one can compute the probability of accessing the TS and the free energy profile at any point along the IRC It is by using a series of connected windows within each of which the MC process samples structures whose energies can fluctuate by that one generates a smooth connection from lowenergy to highenergy eg TS geometries Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Nonideality Henrys Law and Azeotropes Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay AzeotropesContributors and Attributions The proceeding discussion was based on the behaviors of ideal solutions of volatile compounds and for which both compounds follow Raoults Law Henrys Law can be used to describe these deviations For which the Henrys Law constant is determined for the specific compound Henrys Law is often used to describe the solubilities of gases in liquids The relationship to Raoults Law is summarized in Figure Figure The relationship between Raoults Law and Henrys Law for a binary mixture Henrys Law is depicted by the upper straight line and Raoults Law by the lower Example Solubility of Carbon Dioxide in Water The solubility of in water at oC is x M with a partial pressure of over the solution of bar Assuming the density of a saturated solution to be kgL calculate the Henrys Law constant for Solution In one L of solution there is g of water assuming the mass of CO dissolved is negligible The solubility of can be used to find the number of moles of dissolved in L of solution also and so the mol fraction of is And so or Azeotropes An azeotrope is defined as the common composition of vapor and liquid when they have the same composition Figure Phase diagrams for left a maximum boiling point azeotrope and right Ta maximum boiling point azeotrope Azeotropes can be either maximum boiling or minimum boiling as show in Figure Regardless distillation cannot purify past the azeotrope point since the vapor and quid phases have the same composition If a system forms a minimum boiling azeotrope and also has a range of compositions and temperatures at which two liquid phases exist the phase diagram might look like Figure Figure Phase diagram for a binary solution with the boiling point of a minimum boiling azeotrope that is higher that when components are miscible single phase Another possibility that is common is for two substances to form a twophase liquid form a minimum boiling azeotrope but for the azeotrope to boil at a temperature below which the two liquid phases become miscible In this case the phase diagram will look like Figure Example In the diagram make up of a system in each region is summarized below the diagram The point e indicates the azeotrope composition and boiling temperature Single phase liquid mostly compound A Single phase liquid mostly compound B Single phase liquid mostly A and vapor Single phase liquid mostly B and vapor Vapor miscible at all mole fractions since it is a gas Solution Within each twophase region III IV and the twophase liquid region the lever rule will apply to describe the composition of each phase present So for example the system with the composition and temperature represented by point b a singlephase liquid which is mostly compound A designated by the composition at point a and vapor with a composition designated by that at point c will be described by the lever rule using the lengths of tie lines lA and lB Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Nonideality in Gases Fugacity Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors and Attributions The relationship for chemical potential was derived assuming ideal gas behavior But for real gases that deviate widely from ideal behavior the expression has only limited applicability In order to use the simple expression on real gases a fudge factor is introduced called fugacity Using fugacity instead of pressure the chemical potential expression becomes where is the fugacity Fugacity is related to pressure but contains all of the deviations from ideality within it To see how it is related to pressure consider that a change in chemical potential for a single component system can be expressed as and so Differentiating the expression for chemical potential above with respect to pressure at constant volume results in leftdfracpartial mupartial p right_T left dfracpartialpartial p left muo RT ln left dfracffo right right right which simplifies to leftdfracpartial mupartial p right_T RT left dfracpartial ln fpartial p right_T V Multiplying both sides by gives where is the compression factor as discussed previously Now we can use the expression above to obtain the fugacity coefficient as defined by Taking the natural logarithm of both sides yields or Using some calculus and substitutions from above int leftdfracpartial ln gammapartial p right_T dp int leftdfracpartial ln fpartial p dfracpartial ln p partial p right_T dp Finally integrating from to yields If the gas behaves ideally In general this will be the limiting value as since all gases behave ideal as the pressure approaches The advantage to using the fugacity in this manner is that it allows one to use the expression to calculate the chemical potential insuring that Equation refeq holds even for gases that deviate from ideal behavior Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Nonideality in Solutions Activity Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Activity Coefficients for Ionic SolutesDebeyeHckel LawContributors and Attributions The bulk of the discussion in this chapter dealt with ideal solutions However real solutions will deviate from this kind of behavior So much as in the case of gases where fugacity was introduced to allow us to use the ideal models activity is used to allow for the deviation of real solutes from limiting ideal behavior The activity of a solute is related to its concentration by where is the activity coefficient is the molaliy of the solute and is unit molality The activity coefficient is unitless in this definition and so the activity itself is also unitless Furthermore the activity coefficient approaches unity as the molality of the solute approaches zero insuring that dilute solutions behave ideally The use of activity to describe the solute allows us to use the simple model for chemical potential by inserting the activity of a solute in place of its mole fraction The problem that then remains is the measurement of the activity coefficients themselves which may depend on temperature pressure and even concentration Activity Coefficients for Ionic Solutes For an ionic substance that dissociates upon dissolving the chemical potential of the cation can be denoted and that of the anion as For a solution the total molar Gibbs function of the solutes is given by where where denotes the chemical potential of an ideal solution and is the activity of the solute Substituting his into the above relationship yields Using a molal definition for the activity coefficient The expression for the total molar Gibbs function of the solutes becomes This expression can be rearranged to yield where all of the deviation from ideal behavior comes from the last term Unfortunately it impossible to experimentally deconvolute the term into the specific contributions of the two ions So instead we use a geometric average to define the mean activity coefficient For a substance that dissociates according to the general process the expression for the mean activity coefficient is given by DebeyeHckel Law In Debeye and Hckel Debye Hckel suggested a means of calculating the mean activity coefficients from experimental data Briefly they suggest that where is the dielectric constant of the solvent is the temperature in K and are the charges on the ions and is the ionic strength of the solution is given by For a solution in water at oC Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Normal Modes of Vibration Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah The Newton Equations of Motion for Vibration The Kinetic and Potential Energy Matrices The Harmonic Vibrational Energies and Normal Mode Eigenvectors The Use of Symmetry Symmetry Adapted Modes Point Group Symmetry of the Harmonic PotentialContributors and Attributions Having seen how one can use information about the gradients and Hessians on a BornOppenheimer surface to locate geometries corresponding to stable species and transition states let us now move on to see how this same data is used to treat vibrations on this surface For a polyatomic molecule whose electronic energys dependence on the Cartesian coordinates of its atoms the potential energy can be expressed approximately in terms of a Taylor series expansion about any of the local minima Of course different local minima ie different isomers will have different values for the equilibrium coordinates and for the derivatives of the energy with respect to these coordinates The Taylor series expansion of the electronic energy is written as V g_k V sum_k leftdfracpartial Vpartial q_kright q_k dfrac sum_jk q_j H_jk q_k Here is the energy at the current geometry is the gradient of the energy along the coordinate is the secondderivative or Hessian matrix and is the length of the step to be taken along this Cartesian direction If the geometry corresponds to a minimum or transition state the gradient terms will all vanish and the Hessian matrix will possess for linear species or for nonlinear molecules positive eigenvalues and or zero eigenvalues corresponding to translational and or rotational motions of the molecule for a minimum and one negative eigenvalues and or positive eigenvalues for a transition state The Newton Equations of Motion for Vibration The Kinetic and Potential Energy Matrices Truncating the Taylor series at the quadratic terms assuming these terms dominate because only small displacements from the equilibrium geometry are of interest one has the socalled harmonic potential The classical mechanical equations of motion for the coordinates can be written in terms of the above potential energy and the following kinetic energy function where is the time rate of change of the coordinate and is the mass of the atom on which the Cartesian coordinate resides The Newton equations thus obtained are where the force along the coordinate is given by minus the derivative of the potential along this coordinate within the harmonic approximation These classical equations can more compactly be expressed in terms of the time evolution of a set of socalled massweighted Cartesian coordinates defined as in terms of which the above Newton equations become and the massweighted Hessian matrix elements are The Harmonic Vibrational Energies and Normal Mode Eigenvectors Assuming that the undergo some form of sinusoidal time evolution and substituting this into the Newton equations produces a matrix eigenvalue equation in which the eigenvalues are the squares of the socalled normal mode vibrational frequencies and the eigenvectors give the amplitudes of motion along each of the massweighted Cartesian coordinates that belong to each mode Hence to perform a normalmode analysis of a molecule one forms the massweighted Hessian matrix and then finds the or nonzero eigenvalues as well as the corresponding eigenvectors It is useful to note that if this same kind of analysis were performed at a geometry corresponding to a transition state or of the values would be positive but one of them would be negative The eigenvector corresponding to the negative eigenvalue of the massweighted Hessian points along a very important direction that we will discuss later it is the direction of the socalled intrinsic reaction coordinate IRC When reporting the eigenvalues at such a transitionstate geometry one often says that there is one imaginary frequency because one of the values is negative this value of characterizes the curvature of the energy surface along the IRC at the transition state The positive vibrational eigenvalues of transitionstate geometries are used as discussed in Chapter to evaluate statistical mechanics partition functions for reaction rates and the negative value plays a role in determining the extent of tunneling through the barrier on the reaction surface Within this harmonic treatment of vibrational motion the total vibrational energy of the molecule is given as a sum of or independent contributions one for each normal mode The corresponding total vibrational wave function Psi prod_jNtext or psinu_j xj is a product of or harmonic oscillator functions one for each normal mode The energy gap between one vibrational level and another in which one of the quantum numbers is increased by unity ie for fundamental vibrational transitions is Delta E_nu_j rightarrow nu_j hbar omega_j The harmonic model thus predicts that the fundamental and hot band transitions should occur at the same energy and the overtone transitions should occur at exactly twice this energy One might wonder whether massweighted Cartesian coordinates would be better or more appropriate to use when locating minima and transition states on BornOppenheimer energy surfaces Although massweighted coordinates are indeed essential for evaluating harmonic vibrational frequencies and as we will see later for tracing out socalled intrinsic reaction paths their use produces the same minima and transition states as one finds using coordinates that are massweighted This is because the condition that all components of the gradient of the energy surface vanish at a minimum or at a transition state will automatically be obeyed when expressed in terms of massweighted coordinates since Notice that this means the geometries of all local minima and transition states on a given BornOppenheimer surface will be exactly the same regardless of what isotopes appear in the molecule For example for the reactions HCN rightarrow HNC or or or the geometries of the reactants products and transition states for each of the distinct reactions will not depend on the identity of the hydrogen isotopes However the harmonic vibrational frequencies will depend on the isotopes because the massweighted Hessian differs from the Hessian expressed in terms of nonmassweighted coordinates The Use of Symmetry Symmetry Adapted Modes It is often possible to simplify the calculation of the normal mode harmonic frequencies and eigenvectors by exploiting molecular point group symmetry For molecules that possess symmetry at a particular stable geometry the electronic potential displays symmetry with respect to displacements of symmetry equivalent Cartesian coordinates For example consider the water molecule at its equilibrium geometry as illustrated in Figure A very small movement of the molecules left atom in the positive direction produces the same change in the potential as a correspondingly small displacement of the right atom in the negative direction Similarly movement of the left H in the positive y direction produces an energy change identical to movement of the right H in the positive y direction Figure Water molecule showing its two bond lengths and angle The equivalence of the pairs of Cartesian coordinate displacements is a result of the fact that the displacement vectors are connected by the point group operations of the group In particular reflection of through the yz plane the two planes are depicted in Figure produces and reflection of through this same plane yields Figure Two planes of symmetry of the water molecule More generally it is possible to combine sets of Cartesian displacement coordinates into socalled symmetry adapted coordinates where the index labels the irreducible representation in the appropriate point group and j labels the particular combination of that symmetry ie there may be more than one kind of displacement that has a given symmetry G These symmetryadapted coordinates can be formed by applying the point group projection operators that are treated in detail in Chapter to the individual Cartesian displacement coordinates To illustrate again consider the molecule in the coordinate system described above The massweighted Cartesian displacement coordinates can be symmetry adapted by applying the following four projection operators to each of the original coordinates the symbol s denotes reflection through a plane and means rotation about the molecules axis Of course one will not obtain x independent symmetry adapted coordinates in this manner many identical combinations will arise and only will be independent The independent combinations of symmetry normalized to produce vectors of unit length are Q_a_ dfracsqrt X_L X_R Q_a_ dfracsqrt Y_L Y_R Q_a_ Y_O Those of symmetry are Q_b_ dfracsqrt X_L X_R Q_b_ dfracsqrt Y_L Y_R Q_b_ X_O and the combinations Q_b_ dfracsqrt Z_L Z_R Q_b_ Z_O are of symmetry whereas is of symmetry Point Group Symmetry of the Harmonic Potential These nine symmetryadapted coordinates are expressed as unitary transformations of the original massweighted Cartesian coordinates These transformation coefficients can be used to carry out a unitary transformation of the x massweighted Hessian matrix In so doing we need only form blocks H_Gamma_jl sum_kk C_Gamma_jk H_kk sqrtm_k m_k C_Gamma_lk within which the symmetries of the two modes are identical The offdiagonal elements H_Gamma_jGamma_l sum_kk C_Gamma_jk H_kk sqrtm_k m_k C_Gamma_lk vanish because the potential and the full vibrational Hamiltonian commutes with the point group symmetry operations As a result the x massweighted Hessian eigenvalue problem can be subdivided into two x matrix problems of and symmetry one x matrix of symmetry and one x matrix of symmetry For example the symmetry block His formed as follows leftbeginarrayccc dfracsqrt dfracsqrt dfracsqrt dfracsqrt endarrayright leftbeginarrayccc m_Hdfracpartial Vpartial x_Lm_H m_Hdfracpartial Vpartial x_L partial x_Rm_H m_Hdfracpartial Vpartial x_L partial y_Om_H m_Hdfracpartial Vpartial x_R partial x_Lm_H m_Hdfracpartial Vpartial x_Rm_H m_Hdfracpartial Vpartial x_R partial y_Om_H m_Hdfracpartial Vpartial y_O partial x_Lm_H m_Hdfracpartial Vpartial y_O partial x_Rm_H m_Hdfracpartial Vpartial y_Om_H endarrayright leftbeginarrayccc dfracsqrt dfracsqrt dfracsqrt dfracsqrt endarrayright The and blocks are formed in a similar manner The eigenvalues of each of these blocks provide the squares of the harmonic vibrational frequencies the eigenvectors provide the coefficients of the normal mode of symmetry in terms of the massweighted Cartesian coordinates The relationship can then be used to express these coefficients in terms of the original Cartesian coordinates Regardless of whether symmetry is used to block diagonalize the massweighted Hessian six for nonlinear molecules or five for linear species of the eigenvalues will equal zero The eigenvectors belonging to these zero eigenvalues describe the translations and or rotations of the molecule For example when expressed in terms of the original ie nonmassweighted Cartesian coordinates are three translation eigenvectors of and symmetry and is a rotation about the yaxis in the Figure of symmetry This rotation vector can be generated by applying the projection operator to or to The other two rotations are of and symmetry and involve spinning of the molecule about the and axes of the Figure respectively So of the Cartesian displacements are of symmetry of of and of Of these there are three translations and and three rotations and a This leaves two vibrations of and one of symmetry For the example treated here the three nonzero eigenvalues of the massweighted Hessian are therefore of and symmetry They describe the symmetric and asymmetric stretch vibrations and the bending mode respectively as illustrated in Figure Figure Symmetric and asymmetric stretch modes and bending mode of water The method of vibrational analysis presented here can work for any polyatomic molecule One knows the massweighted Hessian and then computes the nonzero eigenvalues which then provide the squares of the normal modes harmonic vibrational frequencies Point group symmetry can be used to block diagonalize this Hessian and to label the vibrational modes according to symmetry as we show in Figure for the molecule in tetrahedral symmetry Figure Symmetries of vibrations of methane Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Notation and Terminology Conventions for Spontaneous Processes Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers We now want to consider criteria for a spontaneous process in which a closed system passes from state A to state B State B can be an equilibrium state but state A is not We can denote the energy change for this process as and we can find it by measuring the heat and work exchanged with the surroundings as the process takes place or for a process in which the increments of heat and work are arbitrarily small Likewise we can denote the entropy change for the spontaneous process as or but we cannot find the entropy change by measuring or If we cannot find the entropy change we cannot find the Helmholtz or Gibbs free energy changes from their defining relationships and Moreover intensive variablespressure temperature and concentrationsmay not have welldefined values in a spontaneously changing system When we say that a reversible process occurs with some thermodynamic variable held constant we mean what we say The thermodynamic variable has the same value at every point along the path of reversible change In the remainder of this chapter we develop criteria for spontaneous change These criteria are statements about the values of and for a system that can undergo spontaneous change under particular conditions In stating some of these criteria we specify the conditions by saying that the pressure or the temperature is constant As we develop these criteria we will see that these stipulations have specific meanings When we say that a process occurs at constant volume isochorically we mean that the volume of the system remains the same throughout the process When we say that a spontaneous process occurs at constant pressure isobarically or isopiestically we mean that the pressure applied to the system by the surroundings is constant throughout the spontaneous process and that the system pressure is equal to the applied pressure at all times When we say that a spontaneous process occurs at constant temperature we may mean only that the system is continuously in thermal contact with its surroundings the temperature of the surroundings is constant in the initial and final states the system temperature is equal to the surroundings temperature Notation for Changes in Thermodynamic Quantities E vs E Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers From the outset of our study of energy we recognize that we are always dealing with energy changes Even when we write to indicate that energy is a function of and we recognize that represents the energy difference between the state of the system characterized by and and the state of the system when the independent variables correspond to a reference state in which by definition As we observe in we can sort thermodynamic variables into two classes Some like and can be measured only for a system Others like and can be measured only for a process To say that the volume of a system is one cubic meter has absolute significance To say that the energy of a system is one joule means nothing unless we know the reference state When we intend to specify that the reference state for energy is the particular state specified by and we write Otherwise when we write we could equally well write We intend either of these formulations to mean the same thing as and Whether we write or the quantity represented is the difference in energy between some initial and some final state When we focus on very small changes we can write or If our perspective is that we are describing a process we may prefer to write if our perspective is that we are describing a change in the system we may prefer to write In practice our choice depends primarily on what we have grown accustomed to in the context at hand In the discussion above we write We could equally well write The meaning is the same We can make similar statements about most thermodynamic functions Often there is no particular reason to prefer over or vice versa However there are circumstances in which the delta notation serves particular purposes If a system undergoes a change in which some thermodynamic variables remain constant the delta notation provides a convenient way to indicate that a particular variable is not constant For example if the volume of a system changes while the applied pressure remains constant we write Similarly we often want to describe processes in which some state functions are different in the final state than they are in the initial state while other state functions are the same in both states but not necessarily constant throughout the process In the next few chapters we develop properties of the state functions entropy enthalpy and Gibbs free energy We define the Gibbs free energy by the relationship To specify the relationship among the changes in these state functions when the final temperature is the same as the initial temperature we write Here too we often say that this relationship relates the changes in and when the temperature is constant This is another useful but potentially misleading figure of speech It is important to remember that the equation is valid for any path between the same two states even if the temperature varies wildly along that path so long as the initial and final states are at the same temperature Finally we find it convenient to use subscripted versions of the delta notation to specify particular kinds of processes For a process in which one mole of a pure substance vaporizes to its gas at a particular temperature we write and to denote the changes in enthalpy and Gibbs free energy respectively We can write to denote the change in the energy however is not a quantity that we find useful very often Similarly for the fusion and sublimation of one mole of a pure substance at a particular temperature we write and We also find it convenient to write and to denote the changes in these quantities when a chemical reaction occurs When we do so it is essential that we specify the corresponding stoichiometric equation Orbitals Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah The Hartree DescriptionThe LCAOExpansionAO Basis SetsSlatertype orbitals and Gaussiantype orbitalsThe Fundamental Core and Valence BasisPolarization FunctionsDiffuse Functions The Hartree Description The energies and wave functions within the most commonly used theories of atomic structure are assumed to arise as solutions of a Schrdinger equation whose Hamiltonian possess three kinds of energies Kinetic energy whose average value is computed by taking the expectation value of the kinetic energy operator with respect to any particular solution to the Schrdinger equation Coulombic attraction energy with the nucleus of charge Coulomb repulsion energies with all of the other electrons which are assumed to occupy other atomic orbitals AOs denoted with this energy computed as The Dirac notation is used to represent the sixdimensional Coulomb integral that describes the Coulomb repulsion between the charge density for the electron in and the charge density for the electron in Of course the sum over must be limited to exclude to avoid counting a selfinteraction of the electron in orbital with itself The total energy of the orbital is the sum of the above three contributions This treatment of the electrons and their orbitals is referred to as the Hartreelevel of theory As stated above when screened hydrogenic AOs are used to approximate the and orbitals the resultant values do not produce accurate predictions For example the negative of should approximate the ionization energy for removal of an electron from the AO Such ionization potentials IP s can be measured and the measured values do not agree well with the theoretical values when a crude screening approximation is made for the AO s The LCAOExpansion To improve upon the use of screened hydrogenic AOs it is most common to approximate each of the Hartree AOs as a linear combination of socalled basis AOs using what is termed the linearcombinationofatomicorbitals LCAO expansion In this equation the expansion coefficients are the variables that are to be determined by solving the Schrdinger equation After substituting the LCAO expansion for into this Schrdinger equation multiplying on the left by one of the basis AOs and then integrating over the coordinates of the electron in one obtains This is a matrix eigenvalue equation in which the and appear as eigenvalues and eigenvectors The matrices and are called the Hamiltonian and overlap matrices respectively An explicit expression for the former is obtained by introducing the earlier definition of he An important thing to notice about the form of the matrix Hartree equations is that to compute the Hamiltonian matrix one must know the LCAO coefficients of the orbitals which the electrons occupy On the other hand these LCAO coefficients are supposed to be found by solving the Hartree matrix eigenvalue equations This paradox leads to the need to solve these equations iteratively in a socalled selfconsistent field SCF technique In the SCF process one inputs an initial approximation to the coefficients This then allows one to form the Hamiltonian matrix defined above The Hartree matrix equations are then solved for new coefficients and for the orbital energies The new LCAO coefficients of those orbitals that are occupied are then used to form a new Hamiltonian matrix after which the Hartree equations are again solved for another generation of LCAO coefficients and orbital energies This process is continued until the orbital energies and LCAO coefficients obtained in successive iterations do not differ appreciably Upon such convergence one says that a selfconsistent field has been realized because the coefficients are used to form a Coulomb field potential that details the electronelectron interactions AO Basis Sets Slatertype orbitals and Gaussiantype orbitals As noted above it is possible to use the screened hydrogenic orbitals as the However much effort has been expended at developing alternative sets of functions to use as basis orbitals The result of this effort has been to produce two kinds of functions that currently are widely used The basis orbitals commonly used in the LCAO process fall into two primary classes Slatertype orbitals STOs are characterized by quantum numbers and and exponents which characterize the orbitals radial size The symbol denotes the normalization constant Cartesian Gaussiantype orbitals GTOs are characterized by quantum numbers and which detail the angular shape and direction of the orbital and exponents which govern the radial size For both types of AOs the coordinates and refer to the position of the electron relative to a set of axes attached to the nucleus on which the basis orbital is located Note that Slatertype orbitals STOs are similar to hydrogenic orbitals in the region close to the nucleus Specifically they have a nonzero slope near the nucleus In contrast GTOs have zero slope near because We say that STOs display a cusp at that is characteristic of the hydrogenic solutions whereas GTOs do not Although STOs have the proper cusp behavior near nuclei they are used primarily for atomic and linearmolecule calculations because the multicenter integrals which arise in polyatomicmolecule calculations we will discuss these integrals later in this Chapter cannot efficiently be evaluated when STOs are employed In contrast such integrals can routinely be computed when GTOs are used This fundamental advantage of GTOs has lead to the dominance of these functions in molecular quantum chemistry To overcome the primary weakness of GTO functions ie their radial derivatives vanish at the nucleus it is common to combine two three or more GTOs with combination coefficients which are fixed and not treated as LCAO parameters into new functions called contracted GTOs CGTOs Typically a series of radially tight medium and loose GTOs are multiplied by contraction coefficients and summed to produce a CGTO that approximates the proper cusp at the nuclear center although no such combination of GTOs can exactly produce such a cusp because each GTO has zero slope at Although most calculations on molecules are now performed using Gaussian orbitals it should be noted that other basis sets can be used as long as they span enough of the regions of space radial and angular where significant electron density resides In fact it is possible to use plane wave orbitals of the form where is a normalization constant and and are quantum numbers detailing the momenta or wavelength of the orbital along the and Cartesian directions The advantage to using such simple orbitals is that the integrals one must perform are much easier to handle with such functions The disadvantage is that one must use many such functions to accurately describe sharply peaked charge distributions of for example innershell core orbitals while still retaining enough flexibility to also describe the much smoother electron density in the valence regions Much effort has been devoted to developing and tabulating in widely available locations sets of STO or GTO basis orbitals for maingroup elements and transition metals This ongoing effort is aimed at providing standard basis set libraries which Yield predictable chemical accuracy in the resultant energies Are cost effective to use in practical calculations Are relatively transferable so that a given atoms basis is flexible enough to be used for that atom in various bonding environments eg hybridization and degree of ionization The Fundamental Core and Valence Basis In constructing an atomic orbital basis one can choose from among several classes of functions First the size and nature of the primary core and valence basis must be specified Within this category the following choices are common A minimal basis in which the number of CGTO orbitals is equal to the number of core and valence atomic orbitals in the atom A doublezeta DZ basis in which twice as many CGTOs are used as there are core and valence atomic orbitals The use of more basis functions is motivated by a desire to provide additional variational flexibility so the LCAO process can generate molecular orbitals of variable diffuseness as the local electronegativity of the atom varies A valence doublezeta VDZ basis has only one CGTO to represent the innershell orbitals but uses two sets of CGTOs to describe the valence orbitals A triplezeta TZ basis in which three times as many CGTOs are used as the number of core and valence atomic orbitals of course there are quadruplezeta and higherzeta bases also Moreover there are VTZ bases that treat the innershell orbitals with one CGTO and the valence orbitals with three CGTOs Optimization of the orbital exponents zs or as and the GTOtoCGTO contraction coefficients for the kind of bases described above has undergone considerable growth in recent years The theory group at the Pacific Northwest National Labs PNNL offer a world wide web site from which one can find and even download in a form prepared for input to any of several commonly used electronic structure codes a wide variety of Gaussian atomic basis sets This site can be accessed here Professor Kirk Peterson at Washington State University is involved in the PNNL basis set development project but he also hosts his own basis set site Polarization Functions One usually enhances any core and valence basis set with a set of socalled polarization functions They are functions of one higher angular momentum than appears in the atoms valence orbital space eg functions for C N and O and functions for H and they have exponents or which cause their radial sizes to be similar to the sizes of the valence orbitals ie the polarization orbitals of the H atom are similar in size to the orbital rather than to the valence orbital of hydrogen Thus they are not orbitals which describe the atoms valence orbital with one higher lvalue such higherl valence orbitals would be radially more diffuse A primary purpose of polarization functions is to give additional angular flexibility to the LCAO process in forming bonding orbitals between pairs of valence atomic orbitals This is illustrated in Figure where polarization dp orbitals on C and O are seen to contribute to formation of the bonding orbital of a carbonyl group by allowing polarization of the carbon atoms orbital toward the right and of the oxygen atoms orbital toward the left Figure Oxygen and Carbon Form a Bond That Uses the Polarization Functions on Each Atom Polarization functions are essential in strained ring compounds such as cyclopropane because they provide the angular flexibility needed to direct the electron density into regions between bonded atoms but they are also important in unstrained compounds when high accuracy is required Diffuse Functions When dealing with anions or Rydberg states one must further augment the AO basis set by adding socalled diffuse basis orbitals The valence and polarization functions described above do not provide enough radial flexibility to adequately describe either of these cases The PNNL web site data base cited above offers a good source for obtaining diffuse functions appropriate to a variety of atoms as does the site of Prof Kirk Peterson Once one has specified an atomic orbital basis for each atom in the molecule the LCAOMO procedure can be used to determine the coefficients that describe the occupied and virtual ie unoccupied orbitals It is important to keep in mind that the basis orbitals are not themselves the SCF orbitals of the isolated atoms even the proper atomic orbitals are combinations with atomic values for the coefficients of the basis functions The LCAOMOSCF process itself determines the magnitudes and signs of the In particular it is alternations in the signs of these coefficients allow radial nodes to form Other Factors that Affect Reaction Rates Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers A reaction that occurs in one solvent usually occurs also in a number of similar solvents For example a reaction that occurs in water will often occur with a low molecular weight alcoholor an alcoholwater mixture as the solvent Typically the same rate law is observed in a series of solvents but the rate constants are solventdependent Other chemical species that are present in the reaction medium but which are neither products nor reactants can also affect observed reaction rates Any such species meets the usual definition of a catalyst However common practice restricts use of the word catalyst to a chemical species that substantially increases the rate of the reaction A chemical species that decreases the rate of the reaction is usually called an inhibitor If we think that the rate effect of the nonreacting species results from a nonspecific or a greaterthanbondingdistance interaction with one or more reacting species we call the phenomenon a medium effect A solvent effect is a common kind of medium effect altering the solvent affects the reaction rate even though the solvent does not form a chemical bond to any of the reactants or products Dissolved salts can affect reaction rates in a similar way Such effects often occur when the degree of charge separation along the path of an elementary reaction is significantly different from that in the reactants Isotopic substitution in a reactant can affect the reaction rate Replacement of a hydrogen atom with a deuterium atom is the most common case The effect of an isotopic substitution on a reaction rate is called a kinetic isotope effect Kinetic isotope effects can provide valuable information about the reaction mechanism A kinetic isotope effect is expected if the energy needed make or break a chemical bond to the isotopically substituted atom is a significant component of the activation energy for the reaction Kinetic isotope effects are usually small in comparison to other factors that affect reaction rates A tenfold change in the reaction rate is a big kinetic isotope effect Effects much smaller than this are often useful indeed the absence of a kinetic isotope effect can help distinguish among alternative mechanisms In studies of reaction rates that are focused on finding the reaction mechanism many characteristics of the reaction that are not strictly raterelated can be important These include the stereochemistry of the product the Walden inversion that accompanies S reactions at tetrahedral carbon centers is a notable example Isotopic substitution that occurs incidental to a reaction can help establish that an intermediate is formed The effects of competing reactions are often significant The study of competing reactions is frequently helpful when the reaction involves a shortlived and otherwise undetectable intermediate The use of isotopic substitution and competing reactions is illustrated in Section in which we review the base hydrolysis of cobalt IIIcobalt pentaammine complexes Other Statements of the First Law Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers The first law has been stated in many ways Some are intended to be humorous or evocative rather than precise statements for example You cant get something useful work in some system for nothing no decrease in the energy of some other system Others are potentially ambiguous because we construct them to be as terse as possible To make them terse we omit ideas that we deem to be implicit A compact and often used statement is and is a state function In this statement the fact that energy is conserved is taken to be implicit in the operational definition We can give an equally valid statement by saying Energy is conserved in all processes In making this statement we assume that the definition of energy is understood and that the statefunction postulate is implicit in this definition To see that the postulate that energy is conserved and the postulate that energy is a state function are logically independent let us consider a system that undergoes a particular cyclic process which we call Cycle A In Cycle A the final state of the system is the same as its initial state the postulate that energy is a state function is then equivalent to the statement that The postulate that energy is conserved is equivalent to the statement that Now what can we say about Obviously if we combine the information from the two postulates it follows that The essential point however is that is not required by either postulate alone is not required by the postulate that energy is a state function because the surroundings do not necessarily traverse a cycle whenever the system does is not required by conservation of energy which merely requires and absent the requirement that be a state function could be anything In Chapter we explore a statement of the second law that denies the possibility of constructing a perpetual motion machine of the second kind Such a perpetual motion machine converts heat from a constanttemperature reservoir into work This statement is It is impossible to construct a machine that operates in a cycle exchanges heat with its surroundings at only one temperature and produces work in the surroundings A parallel statement is sometimes taken as a statement of the first law This statement denies the possibility of constructing a perpetual motion machine of the first kind This statement is It is impossible to construct a machine that operates in a cycle and converts heat into a greater amount of work The shared perspective and phrasing of these statements is esthetically pleasing Let us consider the relationship between this statement of the first law and the statement given in For brevity let us denote this impossibility statement as the machinebased statement of the first law and refer to it as proposition MFL We refer to the statement of the first law given in as proposition FL In the machinebased statement MFL we mean by a machine a system that accepts heat from its surroundings and produces a greater amount of work which appears in the surroundings If such a machine exists the machinebased statement of the first law is false and proposition MFL is true For one cycle of this firstlaw violating machine we have Since we have It follows that Our statement of the principle of conservation of energy then requires that for one cycle of this perpetual motion machine Our statement of the first law FL requires that since energy is a state function Since this is a contradiction the existence of a perpetual motion machine of the first kind proposition MFL implies that the first law energy is a state function proposition FL is false MFL FL From this result we can validly conclude If the first law is true the existence of a perpetual motion machine of the first kind is impossible MFL FL FLMFLFLMFL We cannot conclude that the impossibility of perpetual motion of the first kind implies that energy is a state function MFL FL does not imply MFLFL That is the impossibility of perpetual motion of the first kind as we have interpreted it is not shown by this argument to be equivalent to the first law as we have stated it It remains possible of course that this equivalence could be proved by some other argument Evidently when we take the impossibility of constructing a perpetual motion machine of the first kind as a statement of the first law we have a different interpretation in mind The difference is this When we specify a machine that operates in a cycle we intend that everything about the machine shall be the same at the end of the cycle as at the beginningincluding its energy That is we intend the statement to be understood as requiring that for one cycle of the perpetual motion machine Equivalently we intend the statement to be understood to include the stipulation that energy is a state function Now for one cycle of the perpetual motion machine we have and Given the basic idea that energy is additive so that we have that The impossibility statement asserts that this is false equivalently the impossibility statement asserts that energy cannot be created This conclusion is a weak form of the principle of conservation of energy it says less than we want the first law to say We postulate that energy can be neither created nor destroyed That is and are both false When we consider the impossibility statement to assert the principle of energy conservation we implicitly stipulate that the machine can also be run in reverse See problem We intend the first law to assert the existence of energy and to summarize its properties However we express the first law we recognize that the concept of energy encompasses several closely interrelated ideas Outcomes Events and Probability Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers We also need to introduce the idea that a function that successfully models the results of past experiments can be used to predict some of the characteristics of future results We reason as follows We have results from drawing many samples of a random variable from some distribution We suppose that a mathematical representation has been found that adequately summarizes the results of these experiences If the underlying distributionthe physical system in scientific applicationsremains the same we expect that a long series of future results would give rise to essentially the same mathematical representation If of many previous results have had a particular characteristic we expect that of a large number of future trials will have the same characteristic We also say that there is one chance in four that the next individual result will have this characteristic when we say this we mean that of a large number of future trials will have this characteristic and the next trial has as good a chance as any other to be among those that do The probability that an outcome will occur in the future is equal to the frequency with which that outcome has occurred in the past Given a distribution the possible outcomes must be mutually exclusive in any given trial the random variable can have only one of its possible values Consequently a discrete distribution is completely described when the probability of each of its outcomes is specified Many distributions are comprised of a finite set of N mutually exclusive possible outcomes If each of these outcomes is equally likely the probability that we will observe any particular outcome in the next trial is We often find it convenient to group the set of possible outcomes into subsets in such a way that each outcome is in one and only one of the subsets We say that such assignments of outcomes to subsets are exhaustive because every possible outcome is assigned to some subset we say that such assignments are mutually exclusive because no outcome belongs to more than one subset We call each such subset an event When we partition the possible outcomes into exhaustive and mutually exclusive events we can say the same things about the probabilities of events that we can say about the probabilities of outcomes In our discussions the term events will always refer to an exhaustive and mutually exclusive partitioning of the possible outcomes Distinguishing between outcomes and events just gives us some language conventions that enable us to create alternative groupings of the same set of real world observations Suppose that we define a particular event to be a subset of outcomes that we denote as U If in a large number of trials the fraction of outcomes that belong to this subset is F we say that the probability is F that the outcome of the next trial will belong to this event To express this in more mathematical notation we write When we do so we mean that the fraction of a large number of future trials that belong to this subset will be F and the next trial has as good a chance as any other to be among those that do In a sample comprising M observations the best forecast we can make of the number of occurrences of U is and we call this the expected number of occurrences of U in a sample of size M The idea of grouping real world observations into either outcomes or events is easy to remember if we keep in mind the example of tossing a die The die has six faces which are labeled with or dots The dots distinguish one face from another On any given toss one face of the die must land on top Therefore there are six possible outcomes Since each face has as good a chance as any other of landing on top the six possible outcomes are equally probable The probability of any given outcome is If we ask about the probability that the next toss will result in one of the evennumbered faces landing on top we are asking about the probability of an eventthe event that the next toss will have the characteristic that an evennumbered face lands on top Let us call this event That is event occurs if the outcome is a a or a These are three of the six equally likely outcomes Evidently the probability of this event is Having defined event as the probability of an evennumber outcome we still have several alternative ways to assign the oddnumber outcomes to events One assignment would be to say that all of the oddnumber outcomes belong to a second eventthe event that the outcome is odd The events even outcome and odd outcome are exhaustive and mutually exclusive We could create another set of events by assigning the outcomes and to event and the outcome to event Events and are also exhaustive and mutually exclusive We have a great deal of latitude in the way we assign the possible outcomes to events If it suits our purposes we can create many different exhaustive and mutually exclusive partitionings of the outcomes of a given distribution We require that each partitioning of outcomes into events be exhaustive and mutually exclusive because we want to apply the laws of probability to events Partial Molar Volume Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors and Attributions The partial molar volume of compound A in a mixture of A and B can be defined as Using this definition a change in volume for the mixture can be described using the total differential of or and integration yields This result is important as it demonstrates an important quality of partial molar quantities Specifically if represents the partial molar property for component i of a mixture The total property for the mixture is given by It should be noted that while the volume of a substance is never negative the partial molar volume can be An example of this appears in the dissolution of a strong electrolyte in water Because the water molecules in the solvation sphere of the ions are physically closer together than they are in bulk pure water there is a volume decrease when the electrolyte dissolves This is easily observable at high concentrations where a larger fraction of the water in the sample is tied up in solvation of the ions Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Perturbation Theory Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah An Example Problem Other Examples The Stark effect Electronelectron Coulomb repulsionContributors and Attributions In most practical applications of quantum mechanics to molecular problems one is faced with the harsh reality that the Schrdinger equation pertinent to the problem at hand cannot be solved exactly To illustrate how desperate this situation is I note that neither of the following two Schrdinger equations has ever been solved exactly meaning analytically The Schrdinger equation for the two electrons moving about the He nucleus The Schrdinger equation for the two electrons moving in an molecule even if the locations of the two nuclei labeled A and B are held clamped as in the BornOppenheimer approximation These two problems are examples of what is called the threebody problem meaning solving for the behavior of three bodies moving relative to one another Motions of the sun earth and moon even neglecting all the other planets and their moons constitute another threebody problem None of these problems even the classical Newtons equation for the sun earth and moon have ever been solved exactly So what does one do when faced with trying to study real molecules using quantum mechanics There are two very powerful tools that one can use to sneak up on the solutions to the desired equations by first solving an easier model problem and then using the solutions to this problem to approximate the solutions to the real Schrdinger problem of interest For example to solve for the energies and wave functions of a boron atom one could use hydrogenic orbitals but with and hydrogenic and orbitals with to account for the screening of the full nuclear charge by the two electrons as a starting point To solve for the vibrational energies of a diatomic molecule whose energy vs bond length is known one could use the Morse oscillator wave functions and energies as starting points But once one has decided on a reasonable model to use how does one connect this model to the real system of interest Perturbation theory and the variational method are the two tools that are most commonly used for this purpose and it is these two tools that are covered in this Chapter The perturbation theory approach provides a set of analytical expressions for generating a sequence of approximations to the true energy and true wave function This set of equations is generated for the most commonly employed perturbation method RayleighSchrdinger perturbation theory RSPT as follows First one decomposes the true Hamiltonian into a socalled zerothorder part this is the Hamiltonian of the model problem used to represent the real system and the difference which is called the perturbation and usually denoted It is common to associate with the perturbation a strength parameter which could for example be associated with the strength of the electric field when the perturbation results from the interaction of the molecule of interest with an electric field In such cases it is usual to write the decomposition of as A fundamental assumption of perturbation theory is that the wave functions and energies for the full Hamiltonian can be expanded in a Taylor series involving various powers of the perturbation parameter Hence one writes the energy and the wave function as zeroth first second etc order pieces which form the unknowns in this method E E E E E cdots with and being proportional to Next one substitutes these expansions of and into This produces one equation whose right and left hand sides both contain terms of various powers in the perturbation For example terms of the form and and are all of third power also called third order Next one equates the terms on the left and right sides that are of the same order This produces a set of equations each containing all the terms of a given order The zeroth first and secondorder such equations are given below It is straightforward to see that the nth order expression in this sequence of equations can be written as The zerothorder equation simply instructs us to solve the model Schrdinger equation to obtain the zerothorder wave function and its zerothorder energy Since is a Hermitian operator it has a complete set of such eigenfunctions which we label and E_k One of these states will be the one we are interested in studying eg we might be interested in the effect of an external electric field on the state of the hydrogen atom but as will become clear soon we actually have to find the full set of and eg we need to also find the etc states of the hydrogen atom when studying the electric fields effect on the state In the firstorder equation the unknowns are and recall that is assumed to be known because it is the difference between the Hamiltonian one wants to solve and the model Hamiltonian To solve the firstorder and higherorder equations one expands each of the corrections to the wave function of interest in terms of the complete set of wave functions of the zerothorder problem As noted earlier this means that one must solve not just for the zerothorder state one is interested in denoted above but for all of the other zerothorder states For example expanding in this manner gives Now the unknowns in the firstorder equation become and the expansion coefficients To solve one proceeds as follows First one multiplies this equation on the left by the complex conjugate of the zerothorder function for the state of interest and integrates over the variables on which the wave functions depend This gives The first and third terms cancel one another because and the fourth term reduces to because is assumed to be normalized This allows the above equation to be written as which is the RSPT expression for It says the firstorder correction to the energy of the unperturbed state can be evaluated by computing the average value of the perturbation with respect to the unperturbed wave function Returning to the firstorder equation and multiplying on the left by the complex conjugate of one of the other zerothorder functions gives Using H the first term reduces to and the fourth term vanishes because is orthogonal to because these two functions are different eigenfunctions of This reduces the equation to The unknown in this expression is which is the expansion coefficient for the expansion of in terms of the zerothorder functions In RSPT one assumes that the only contribution of to the full wave function psioccurs in zerothorder this is referred to as assuming intermediate normalization of y In other words because and for So the coefficients appearing in the above equation are all one needs to describe If the state of interest is nondegenerate in zerothorder ie none of the other is equal to E this equation can be solved for the needed expansion coefficients which allow the firstorder wave function to be written as where the index is restricted such that not equal the state you are interested in However if one or more of the zerothorder energies is equal to an additional step needs to be taken before the above expression for can be used If one were to try to solve without taking this extra step the values for those states with could not be determined because the first and third terms would cancel and the equation would read The way RSPT deals with this paradox is realize that within a set of degenerate states any orthogonal combinations of these states will also be degenerate So RSPT assumes that one has already chosen the degenerate sets of zerothorder states to make for This extra step is carried out in practice by forming the matrix representation of in the original set of degenerate zerothorder states and then finding the unitary transformation among these states that diagonalizes this matrix These transformed states are then what one uses as and in the RSPT expressions This means that the paradoxical result is indeed obeyed by this choice of states so one does not need to determine the coefficients for belonging to the degenerate zerothorder states ie these coefficients can be assumed to be zero The bottom line is that the expression remains valid but the summation index is now restricted to exclude any members of the zerothorder states that are degenerate with To obtain the expression for the secondorder correction to the energy of the state of interest one returns to Multiplying on the left by the complex conjugate of and integrating yields The intermediate normalization condition causes the fourth term to vanish and the first and third terms cancel one another Recalling the fact that is normalized the above equation reduces to Substituting the expression obtained earlier for allows to be written as where as before the sum over is limited to states that are not degenerate with in zerothorder These are the fundamental working equations of RayleighSchrdinger perturbation theory They instruct us to compute the average value of the perturbation taken over a probability distribution equal to to obtain the firstorder correction to the energy They also tell us how to compute the firstorder correction to the wave function and the secondorder energy in terms of integrals coupling to other zerothorder states and denominators involving energy differences An analogous approach is used to solve the second and higherorder equations For example the equation for the nth order energy and wave functions reads The nth order energy is obtained by multiplying this equation on the left by and integrating over the relevant coordinates and using the fact that is normalized and the intermediate normalization condition for all This allows one to recursively solve for higher and higher energy corrections once the various lowerorder wave functions are obtained To obtain the expansion coefficients for the expanded in terms of the zerothorder states one multiplies the above order equation on the left by one of the zerothorder states not equal to the state of interest and obtains The last term on the righthand side vanishes because and are orthogonal The terms containing the nth order expansion coefficients can be brought to the lefthand side to produce the following equation for these unknowns langlepsi_J psinrangle E langlepsi_J psinrangle langle psi_JV psinrangle E langlepsi_J psinrangle E langlepsi_Jpsinrangle E langle psi_Jpsinrangle En langle psi_Jpsirangle As long as the zerothorder energy is not degenerate with or that the zerothorder states have been chosen as discussed earlier to cause there to no contribution to from such degenerate states the above equation can be solved for the expansion coefficients which then define The RSPT equations can be solved recursively to obtain even highorder energy and wave function corrections and and are used to determine and as outlined above is determined from with and the expansion coefficients of are determined from the above equation with and higher are then determined from and the expansion coefficients of are determined from the above equation with This process can then be continued to higher and higher order Although modern quantum mechanics uses highorder perturbation theory in some cases much of what the student needs to know is contained in the first and second order results to which I will therefore restrict our further attention I recommend that students have in memory their own brain not a computer the equations for and so they can make use of them even in qualitative applications of perturbation theory as we will discuss later in this Chapter But first lets consider an example problem that illustrates how perturbation theory is used in a more quantitative manner An Example Problem As we discussed earlier an electron moving in a quasilinear conjugated bond framework can be modeled as a particle in a box An externally applied electric field of strength interacts with the electron in a fashion that can described by adding the perturbation to the zerothorder Hamiltonian Here is the position of the electron in the box is the electrons charge and is the length of the box The perturbation potential varies in a linear fashion across the box so it acts to pull the electron to one side of the box First we will compute the firstorder correction to the energy of the state and the firstorder wave function for the state In the wave function calculation we will only compute the contribution to made by this is just an approximation to keep things simple in this example Let me now do all the steps needed to solve this part of the problem Try to make sure you can do the algebra but also make sure you understand how we are using the firstorder perturbation equations The zerothorder wave functions and energies are given by and and the perturbation is The firstorder correction to the energy for the state having and denote is The first integral can be evaluated using the following identity with The second integral can be evaluated using the following identity with and Making all of these appropriate substitutions we obtain This result that the firstorder correction to the energy vanishes could have been foreseen In the expression for the product is an even function under reflection of through the midpoint in fact this is true for all of the particleinabox wave functions On the other hand the perturbation is an odd function under reflection through Thus the integral must vanish as its integrand is an odd function This simple example illustrates how one can use symmetry to tell ahead of time whether the integrals and contributing to the firstorder and higherorder energies and wave functions will vanish The contribution to the firstorder wave function made by the state is given by The two integrals in the numerator involve and Using the integral identities and intcosaxdx fracasinax we obtain the following and int_L xsinleftdfrac pi xLrightsinleftdfracpi xLrightdx fracleftint_L xcosleftdfracpi xLrightdx int_L xcosleftdfracpi xLrightdxright fracleft leftfracLpicosleftdfracpi xLright fracLxpisinleftdfracpi xLright rightBiggL leftfracLpicosleftdfracpi xLright fracLxpisinleftdfracpi xLrightright BiggLright fracLpi fracLpi fracLpi fracLpi fracLpi Making all of these appropriate substitutions we obtain for the firstorder wave function actually only the contribution So the wave function through first order ie the sum of the zeorth and firstorder pieces is In Figure we show the and zerothorder functions as well as the superposition function formed when the zerothorder and firstorder functions combine Figure blue and red particleinabox zerothorder functions left and the perturbed function through first order right arising from the electric field polarization Clearly the external electric field acts to polarize the wave function in a manner that moves its probability density toward the side of the box The degree of polarization will depend on the strength of the applied electric field For such a polarized superposition wave function there should be a net dipole moment induced in the system We can evaluate this dipole moment by computing the expectation value of the dipole moment operator with being the sum of our zeroth and firstorder wave functions In computing this integral we neglect the term proportional to because we are interested in only the term linear in because this is what gives the dipole moment Again allow me to do the algebra and see if you can follow where e int_L psileftxfracLrightpsi dx e int_L psileftxfracLrightpsi dx e int_L psileftxfracLrightpsi dx e int_L psileftxfracLrightpsi dx The first integral is zero we discussed this earlier when we used symmetry to explain why this vanishes The fourth integral is neglected since it is proportional to and we are interested in obtaining an expression for how the dipole varies linearly with The second and third integrals are identical and can be combined to give Substituting our earlier expressions for and we obtain These integrals are familiar from what we did to compute doing them we finally obtain Now Lets compute the polarizability of the electron in the state of the box and try to understand physically why a should depend as it does upon the length of the box To compute the polarizability we need to know that Using our induced moment result above we then find Notice that this finding suggests that the larger the box ie the length of the conjugated molecule the more polarizable the electron density This result also suggests that the polarizability of conjugated polyenes should vary nonlinearly with the length of the conjugated chain Other Examples Lets consider a few more examples of how perturbation theory is used in chemistry either quantitatively ie to actually compute changes in energies and wave functions or qualitatively ie to interpret or anticipate how changes might alter energies or other properties The Stark effect When a molecule is exposed to an electric field its electrons and nuclei experience a perturbation V textbfE cdot esum_n Z_n textbfR_n e sum_i textbfr_i where is the charge of the nucleus whose position is is the position of the electron and is the unit of charge The effect of this perturbation on the energies is termed the Stark effect The firstorder change to the energy of this molecule is evaluated by calculating where is the unperturbed wave function of the molecule ie the wave function in the absence of the electric field The quantity inside the integral is the electric dipole operator so this integral is the dipole moment of the molecule in the absence of the field For species that possess no dipole moment eg nondegenerate states of atoms and centrosymmetric molecules this firstorder energy vanishes It vanishes in the two specific cases mentioned because is either even or odd under the inversion symmetry but the product is even and the dipole operator is odd so the integrand is odd and thus the integral vanishes If one is dealing with a degenerate state of a centrosymmetric system things are different For example the and states of the hydrogen atom are degenerate so to apply perturbation theory one has to choose specific combinations that diagonalize the perturbation This means one needs to first form the x matrix leftbeginarraycc langle s V s rangle langle s V p_z rangle langle p_z V s rangle langle p_z V p_z rangle endarrayright where is taken to be the direction of the electric field The diagonal elements of this matrix vanish due to parity symmetry so the two eigenvalues are equal to These are the two firstorder because they are linear in and thus linear in energies So in such degenerate cases one can obtain linear Stark effects The two corrected zerothorder wave functions corresponding to these two shifted energies are and correspond to orbitals polarized into or away from the electric field The Stark effect example offers a good chance to explain a fundamental problem with applying perturbation theory One of the basic assumptions of perturbation theory is that the unperturbed and perturbed Hamiltonians are both bounded from below ie have a discrete lowest eigenvalues and allow each eigenvalue of the unperturbed Hamiltonian to be connected to a unique eigenvalue of the perturbed Hamiltonian Considering the example just discussed we can see that these assumptions are not met for the Stark perturbation Consider the potential that an electron experiences within an atom or molecule close to a nucleus of charge It is of the form in atomic units where the energy is given in Hartrees H eV and distances in Bohr units Bohr  where the first term is the Coulomb potential acting to attract the electron to the nucleus and the second is the electronfield potential assuming the field is directed along the direction In Figure a we show this potential for a given value of the angle Figure a Potential experienced by valence electron showing attraction to a nucleus located at the origin the deep well and the potential due to the applied electric field Along directions for which is negative to the right in Figure a this potential becomes large and positive as the distance of the electron from the nucleus increases for bound states such as the and states discussed earlier such regions are classically forbidden and the wave function exponentially decays in this direction However in directions along which is positive the potential is negative and strongly attractive for smallr ie near the nucleus then passes through a maximum eg near in Figure a at where ca eV in Figure a and then decreases monotonically as r increases In fact this potential approaches as approaches as we see in the left portion of Figure a The bottom line is that the total potential with the electric field present violates the assumptions on which perturbation theory is based However it turns out that perturbation theory can be used in such cases under certain conditions For example as applied to the Stark effect for the degenerate and levels of a hydrogenic atom ie a oneelectron system with nuclear charge if the energy of the and states lies far below the maximum in the potential perturbation theory can be used We know the energies of hydrogenic ions vary with and with the principal quantum number as So as long as the zerothorder energy of the state will like below the barrier on the potential surface Because the wave function can penetrate this barrier this state will no longer be a true bound state it will be a metastable resonance state recall we studied such states in Chapter where we learned about tunneling However if the zerothorder energy lies far below the barrier the extent of tunneling through the barrier will be small so the state will have a long lifetime In such cases we can use perturbation theory to describe the effects of the applied electric field on the energies and wave functions of such metastable states but we must realize that we are only allowed to do so in the limit of weak fields and for states that lie significantly below the barrier In this case perturbation theory describes the changes in the energy and wave function in regions of space where the zerothorder wave function is bound but does not describe at all the asymptotic part of the wave function where the electron is unbound Another example of Stark effects in degenerate cases arises when considering how polar diatomic molecules rotational energies are altered by an electric field The zerothorder wave functions appropriate to such cases are given by where the spherical harmonic is the rotational wave function is the vibrational function for level and is the electronic wave function The diagonal elements of the electricdipole operator vanish because the vibrationally averaged dipole moment which arises as is a vector quantity whose component along the electric field is again taking the field to lie along the direction Thinking of as so is the integrals because is an even function of ie of Because the angular dependence of the perturbation ie has no dependence matrix elements of the form also vanish This means that if one were to form the matrix representation of for the degenerate states belonging to a given all of its elements would be zero Thus the rotational energies of polar diatomic or rigid linear polyatomic molecules have no firstorder Stark splittings There will however be secondorder Stark splittings in which case we need to examine the terms that arise in the formula For a zerothorder state only certain other zerothorder states will have nonvanishing coupling matrix elements These nonzero integrals are governed by which can be shown to be of course if the term does not occur The limitation that must equal arises as above because the perturbation contains no terms dependent on the variable The limitation that comes from a combination of three conditions angular momentum coupling which you learned about in Chapter tells us that which happens to be proportional to can couple to to generate terms having or for their quantum number but only for their quantum number the and factors arising from the product must match for the integral not to vanish because finally the terms will vanish because of the inversion symmetry is odd under inversion but is even Using the fact that the perturbation is these two nonzero matrix elements can be used to express the secondorder energy for the level as EtextbfElanglemurangleleftdfracdfracJMJJBJ dfracdfracJMJJBJright where is Plancks constant and is the rotational constant for the molecule for a diatomic molecule of reduced mass and equilibrium bond length Before moving on to another example it is useful to point out some common threads that occur in many applications of perturbation theory and that will also be common to variational calculations that we discuss later in this Chapter Once one has identified the specific zerothorder state of interest one proceeds as follows The firstorder energy is evaluated In doing so one should first make use of any symmetry point group symmetry is treated later in this Chapter such as inversion angular momentum spin etc to determine whether this expectation value will vanish by symmetry in which case we dont bother to consider this matrix element any more We used this earlier when considering and to conclude that certain firstorder energies are zero If vanishes so the lowestorder effect is in second order or if we want to examine higherorder corrections we consider evaluating Before doing so explicitly we think about whether symmetry will limit the matrix elements entering into the expression for For example in the case just studied we saw that only other zerothorder states having or gave nonvanishing matrix elements In addition because contains energy denominators we may choose to limit our calculation to those other zerothorder states whose energies are close to our state of interest this assumes that such states will contribute a dominant amount to the sum You will encounter many times when reading literature articles in which perturbation theory is employed situations in which researchers have focused attention on zerothorder states that are close in energy to the state of interest and that have the correct symmetry to couple strongly ie have substantial to that state Electronelectron Coulomb repulsion In one of the most elementary pictures of atomic electronic structure one uses nuclear charge screening concepts to partially account for electronelectron interactions For example in ss Li one might posit a zerothorder wave function consisting of a product in which two electrons occupy a orbital and one electron occupies a orbital To find a reasonable form for the radial parts of these two orbitals one could express each of them as a linear combination of i one orbital having hydrogenic form with a nuclear charge of and ii a second orbital of form but with a nuclear charge of to account for the screening of the nucleus by the two innershell electrons where the index i labels the and orbitals to be determined Next one could determine the and expansion coefficients by requiring the fi to be approximate eigenfunctions of the Hamiltonian that would be appropriate for an electron attracted to the Li nucleus but not experiencing any repulsions with other electrons This would result in the following equation for the expansion coefficients leftbeginarraycc langle chi_sZr fracnablafracrchi_sZr rangle langle chi_sZr fracnablafracr chi_sZr rangle langle chi_sZr fracnablafracr chi_sZr rangle langle chi_sZr fracnablafracr chi_sZr rangle endarrayright leftbeginarrayccC Dendarrayright leftbeginarraycc langle chi_sZr chi_sZr rangle langle chi_sZr chi_sZr rangle langle chi_sZr chi_sZr rangle langle chi_sZr chi_sZr rangle endarrayright leftbeginarrayccC Dendarrayright This x matrix eigenvalue problem can be solved for the and coefficients and for the energies of the and orbitals The lowerenergy solution will have and will be this models description of the orbital The higherenergy solution will have and is the approximation to the orbital Using these and orbitals and the electron wave function they form as a zerothorder approximation how do we then proceed to apply perturbation theory The full threeelectron Hamiltonian can be decomposed into a zerothorder part and a perturbation The zerothorder energy of the wave function is where each of the are the energies obtained by solving the x matrix eigenvalue equation shown earlier The firstorder energy of this state can be written as Elangle phi_sr_alphaphi_sr_betaphi_sr_alphaVphi_sr_alphaphi_sr_betaphi_sr_alpha rangle J_ssJ_ss with the Coulomb interaction integrals being defined as To carry out the electron integral appearing in one proceeds as follows For the integral one integrates over the spin variables using and and then integrates over the coordinate of the third electron using to obtain which is The two integrals arise when carrying out similar integration for the terms arising from and So through first order the energy of the Li atom at this level of treatment is given by The factor contains the contributions from the kinetic energy and electronnuclear Coulomb potential The terms describe the Coulombic repulsions among the three electrons Each of the Coulomb integrals can be interpreted as being equal to the Coulombic interaction between electrons one at location the other at averaged over the positions of these two electrons with their spatial probability distributions being given by and respectively Although the example just considered is rather primitive it introduces a point of view that characterizes one of the most commonly employed models for treating atomic and molecular electronic structure the HartreeFock HF meanfield model which we will discuss more in Chapter In the HF model one uses as a zerothorder Hamiltonian consisting of a sum of oneelectron terms containing the kinetic energy the Coulomb attraction to the nucleus I use the Li atom as an example here and a potential This potential which is written in terms of Coulomb integrals similar to those we discussed earlier as well as socalled exchange integrals that we will discuss in Chapter is designed to approximate the interaction of an electron at location with the other electrons in the atom or molecule Because is oneelectron additive its eigenfunctions consist of products of eigenfunctions of the operator offers an approximation to the true Coulomb interactions expressed in terms of a smearedout electron distribution interacting with the electron at ri Perturbation theory is then used to treat the effect of the perturbation on the zerothorder states We say that the perturbation often called the fluctuation potential corrects for the difference between the instantaneous Coulomb interactions among the electrons and the meanfield average interactions Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Phase Diagrams for Binary Mixtures Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Partially Miscible LiquidsThe Lever RuleContributors and Attributions As suggested by the Gibbs Phase Rule the most important variables describing a mixture are pressure temperature and composition In the case of single component systems composition is not important so only pressure and temperature are typically depicted on a phase diagram However for mixtures with two components the composition is of vital important so there is generally a choice that must be made as to whether the other variable to be depicted is temperature or pressure Temperaturecomposition diagrams are very useful in the description of binary systems many of which will for twophase compositions at a variety of temperatures and compositions In this section we will consider several types of cases where the composition of binary mixtures are conveniently depicted using these kind of phase diagrams Partially Miscible Liquids A pair of liquids is considered partially miscible if there is a set of compositions over which the liquids will form a twophase liquid system This is a common situation and is the general case for a pair of liquids where one is polar and the other nonpolar such as water and vegetable oil Another case that is commonly used in the organic chemistry laboratory is the combination of diethyl ether and water In this case the differential solubility in the immiscible solvents allows the twophase liquid system to be used to separate solutes using a separatory funnel method Figure As is the case for most solutes their solubility is dependent on temperature For many binary mixtures of immiscible liquids miscibility increases with increasing temperature And then at some temperature known as the upper critical temperature the liquids become miscible in all compositions An example of a phase diagram that demonstrates this behavior is shown in Figure An example of a binary combination that shows this kind of behavior is that of methyl acetate and carbon disufide for which the critical temperature is approximately K at one atmosphere Ferloni Spinolo Similar behavior is seen for hexanenitrobenzene mixtures for which the critical temperature is K Figure Another condition that can occur is for the two immiscible liquids to become completely miscible below a certain temperature or to have a lower critical temperature An example of a pair of compounds that show this behavior is water and trimethylamine A typical phase diagram for such a mixture is shown in Figure Some combinations of substances show both an upper and lower critical temperature forming twophase liquid systems at temperatures between these two temperatures An example of a combination of substances that demonstrate the behavior is nicotine and water The Lever Rule The composition and amount of material in each phase of a two phase liquid can be determined using the lever rule This rule can be explained using the following diagram Figure Suppose that the temperature and composition of the mixture is given by point b in the above diagram The horizontal line segment that passes through point b is terminated at points a and c which indicate the compositions of the two liquid phases Point a indicates the mole faction of compound B in the layer that is predominantly A whereas the point c indicates the composition of the layer that is predominantly compound B The relative amounts of material in the two layers is then inversely proportional to the length of the tielines ab and bc which are given by and respectively In terms of mole fractions and The number of moles of material in the A layer and the number of moles in the B layer are inversely proportional to the lengths of the two lines and Or substituting the above definitions of the lengths and the ratio of these two lengths gives the ratio of moles in the two phases Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Point Group Symmetry Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Matrices as Group RepresentationsCharacters of RepresentationsAnother Basis and Another RepresentationReducible and Irreducible RepresentationsReducible RepresentationsA Change in BasisReduction of the Reducible RepresentationRotations as a BasisHow to Decompose Reducible Representations in GeneralCommonly Used BasesSummary More Examples The p Orbitals of Nitrogen A ShortCutProjector Operators Symmetry Adapted Linear Combinations of Atomic OrbitalsSummaryDirect Product RepresentationsDirect Products in NElectron Wave functionsDirect Products in Selection RulesOverviewContributors and Attributions It is assumed that the reader has previously learned how symmetry arises in molecular shapes and structures and what symmetry elements are eg planes axes of rotation centers of inversion etc We review and teach here only that material that is of direct application to symmetry analysis of molecular orbitals and vibrations and rotations of molecules We use a specific example the ammonia molecule to introduce and illustrate the important aspects of point group symmetry because this example contains most of the complexities that arise in any application of group theory to molecular problems Example The Symmetry Group of Ammonia The ammonia molecule belongs in its groundstate equilibrium geometry to the point group Its symmetry operations consist of two rotations rotations by and respectively about an axis passing through the nitrogen atom and lying perpendicular to the plane formed by the three hydrogen atoms three vertical reflection operations and the identity operation Corresponding to these six operations are symmetry elements the threefold rotation axis and the three symmetry planes and that contain the three bonds and the axis see Figure Figure Ammonia Molecule and its Symmetry Elements These six symmetry operations form a mathematical group A group is defined as a set of objects satisfying four properties A combination rule is defined through which two group elements are combined to give a result that we call the product The product of two elements in the group must also be a member of the group ie the group is closed under the combination rule One special member of the group when combined with any other member of the group must leave the group member unchanged ie the group contains an identity element Every group member must have a reciprocal in the group When any group member is combined with its reciprocal the product is the identity element The associative law must hold when combining three group members ie ABC must equal ABC The members of symmetry groups are symmetry operations the combination rule is successive operation The identity element is the operation of doing nothing at all The group properties can be demonstrated by forming a multiplication table Let us label the rows of the table by the first operation and the columns by the second operation Note that this order is important because most groups are not commutative The group multiplication table is as follows beginarraycpcmpcmpcmpcmpcmpcmpcmpcmc EC_C_sigma_vsigma_vsigma_vtextSecond Operationhline C_C_C_Esigma_vsigma_vsigma_v C_C_EC_sigma_vsigma_vsigma_v sigma_vsigma_vsigma_vsigma_vEC_C_ sigma_vsigma_vsigma_vsigma_vC_EC_ sigma_vsigma_vsigma_vsigma_vC_C_E textFirst textOperation endarray Note the reflection plane labels do not move That is although we start with in the plane in and in if moves due to the first symmetry operation remains fixed and a different H atom lies in the plane Matrices as Group Representations In using symmetry to help simplify molecular orbital mo or vibrationrotation energylevel identifications the following strategy is followed A set of objects belonging to the constituent atoms or molecular fragments in a more general case is introduced These objects are the orbitals of the individual atoms or of the fragments in the mo case they are unit vectors along the Cartesian and directions located on each of the atoms and representing displacements along each of these directions in the vibrationrotation case Symmetry tools are used to combine these objects into new objects each of which belongs to a specific symmetry of the point group Because the Hamiltonian electronic in the mo case and vibrationrotation in the latter case commutes with the symmetry operations of the point group the matrix representation of H within the symmetryadapted basis will be block diagonal That is objects of different symmetry will not interact only interactions among those of the same symmetry need be considered To illustrate such symmetry adaptation consider symmetry adapting the orbital of and the three orbitals of the three H atoms We begin by determining how these orbitals transform under the symmetry operations of the point group The act of each of the six symmetry operations on the four atomic orbitals can be denoted as follows S_NS_S_S_ oversetErightarrow S_NS_S_S_ hphantomS_NS_S_S_ oversetC_rightarrow S_NS_S_S_ hphantomS_NS_S_S_ oversetC_rightarrow S_NS_S_S_ hphantomS_NS_S_S_ oversetsigma_vrightarrow S_NS_S_S_ hphantomS_NS_S_S_ oversetsigma_vrightarrow S_NS_S_S_ hphantomS_NS_S_S_ oversetsigma_vrightarrow S_NS_S_S_ Here we are using the active view that a rotation rotates the molecule by The equivalent passive view is that the basis functions are rotated In the rotation ends up where began ends up where began and ends up where began These transformations can be thought of in terms of a matrix multiplying a vector with elements For example if is the representation matrix giving the transformation then the above action of on the four basis orbitals can be expressed as DC_ leftbeginarraycS_NS_S_S_endarrayright leftbeginarraycccc endarrayright leftbeginarraycS_NS_S_S_endarrayright leftbeginarraycS_NS_S_S_endarrayright We can likewise write matrix representations for each of the symmetry operations of the point group DC_ leftbeginarraycccc endarrayright hspacept DE leftbeginarraycccc endarrayright Dsigma_v leftbeginarraycccc endarrayright hspacept Dsigma_v leftbeginarraycccc endarrayright Dsigma_v leftbeginarraycccc endarrayright It is easy to verify that a rotation followed by a reflection is equivalent to a reflection alone In other words Note that this same relationship is carried by the matrices Dsigma_vDC_ leftbeginarraycccc endarrayright leftbeginarraycccc endarrayright leftbeginarraycccc endarrayright Dsigma_v Likewise we can verify that directly and we can notice that the matrices also show the same identity DC_Dsigma_v leftbeginarraycccc endarrayright leftbeginarraycccc endarrayright leftbeginarraycccc endarrayright Dsigma_v In fact one finds that the six matrices when multiplied together in all possible ways obey the same multiplication table as did the six symmetry operations We say the matrices form a representation of the group because the matrices have all the properties of the group Characters of Representations One important property of a matrix is the sum of its diagonal elements which is called the trace of the matrix and is denoted So is called the trace or character of the matrix In the above example The importance of the characters of the symmetry operations lies in the fact that they do not depend on the specific basis used to form the matrix That is they are invariant to a unitary or orthogonal transformation of the objects used to define the matrices As a result they contain information about the symmetry operation itself and about the space spanned by the set of objects The significance of this observation for our symmetry adaptation process will become clear later Note that the characters of both rotations are the same as are the characters of all three reflections Collections of operations having identical characters are called classes Each operation in a class of operations has the same character as other members of the class The character of a class depends on the space spanned by the basis of functions on which the symmetry operations act Another Basis and Another Representation Above we used as a basis If alternatively we use the onedimensional basis consisting of the orbital on the Natom we obtain different characters as we now demonstrate The act of the six symmetry operations on this can be represented as follows S_N oversetErightarrow S_N hspacept S_N oversetC_rightarrow S_N hspacept S_N oversetC_rightarrow S_N We can represent this group of operations in this basis by the onedimensional set of matrices D E hspacept DC_ hspacept DC_ D sigma_v hspacept Dsigma_v hspacept Dsigma_v Again we have These six x matrices form another representation of the group In this basis each character is equal to unity The representation formed by allowing the six symmetry operations to act on the Natom orbital is clearly not the same as that formed when the same six operations acted on the basis We now need to learn how to further analyze the information content of a specific representation of the group formed when the symmetry operations act on any specific set of objects Reducible and Irreducible Representations Reducible Representations Note that every matrix in the four dimensional group representation labeled has the socalled block diagonal form beginarraycccchline hline A B C D E F G H I hline endarray This means that these matrices are really a combination of two separate group representations mathematically it is called a direct sum representation We say that is reducible into a onedimensional representation and a threedimensional representation formed by the x submatrices that we will call DE leftbeginarrayccc endarrayright hspacept DC_ leftbeginarrayccc endarrayright hspacept DC_ leftbeginarrayccc endarrayright Dsigma_v leftbeginarrayccc endarrayright hspacept Dsigma_v leftbeginarrayccc endarrayright hspacept Dsigma_v leftbeginarrayccc endarrayright The characters of are Note that we would have obtained this representation directly if we had originally chosen to examine the basis alone also note that these characters are equal to those of minus those of A Change in Basis Now let us convert to a new basis that is a linear combination of the original basis Dont worry about how I constructed and yet As will be demonstrated later we form them by using symmetry projection operators defined below We determine how the basis functions behave under the group operations by allowing the operations to act on the and interpreting the results in terms of the In particular So the matrix representations in the new basis are DE leftbeginarrayccc endarrayright hspacept DC_ leftbeginarrayccc frac frac frac frac endarrayright DC_ leftbeginarrayccc frac frac frac frac endarrayright hspacept Dsigma_v leftbeginarrayccc endarrayright Dsigma_v leftbeginarrayccc frac frac frac frac endarrayright hspacept Dsigma_v leftbeginarrayccc frac frac frac frac endarrayright Reduction of the Reducible Representation These six matrices can be verified to multiply just as the symmetry operations do thus they form another threedimensional representation of the group We see that in the basis the matrices are block diagonal This means that the space spanned by the functions which is the same space as the span forms a reducible representation that can be decomposed into a one dimensional space and a two dimensional space via formation of the functions Note that the characters traces of the matrices are not changed by the change in bases The onedimensional part of the above reducible threedimensional representation is seen to be the same as the totally symmetric representation we arrived at before The twodimensional representation that is left can be shown to be irreducible it has the following matrix representations DE leftbeginarraycc endarrayright hspacept DC_ leftbeginarraycc frac frac frac frac endarrayright hspacept DC_ leftbeginarraycc frac frac frac frac endarrayright Dsigma_v leftbeginarraycc endarrayright hspacept Dsigma_v leftbeginarraycc frac frac frac frac endarrayright hspacept Dsigma_v leftbeginarraycc frac frac frac frac endarrayright The characters can be obtained by summing diagonal elements Rotations as a Basis Another onedimensional representation of the group can be obtained by taking rotation about the Zaxis the axis as the object on which the symmetry operations act In writing these relations we use the fact that reflection reverses the sense of a rotation The matrix representations corresponding to this onedimensional basis are DE hspacept DC_ hspacept DC_ Dsigma_v hspacept Dsigma_v hspacept D sigma_v These onedimensional matrices can be shown to multiply together just like the symmetry operations of the group They form an irreducible representation of the group because it is onedimensional it cannot be further reduced Note that this onedimensional representation is not identical to that found above for the Natom orbital or the function Overview We have found three distinct irreducible representations for the symmetry group two different onedimensional and one two dimensional representations Are there any more An important theorem of group theory shows that the number of irreducible representations of a group is equal to the number of classes Since there are three classes of operation ie E and we have found all the irreducible representations of the point group There are no more The irreducible representations have standard names the first that arising from the and orbitals is called the arising from is called and is called not to be confused with the identity operation E We will see shortly where to find and identify these names Thus our original representation was a combination of two representations and one representation We say that is a direct sum representation A consequence is that the characters of the combination representation can be obtained by adding the characters of its constituent irreducible representations beginarraycccc E C_ sigma_v A_ A_ E hline A_ oplus E endarray How to Decompose Reducible Representations in General Suppose you were given only the characters How can you find out how many times and appear when you reduce to its irreducible parts You want to find a linear combination of the characters of and that add up You can treat the characters of matrices as vectors and take the dot product of with leftbeginarraycccccc E C_ C_ sigma_v sigma_v sigma_v endarrayright leftbeginarraycc E C_ C_ sigma_v sigma_v sigma_v endarrayright The vector is not normalized hence to obtain the component of along a unit vector in the direction one must divide by the norm of this norm is The result is that the reducible representation contains components Analogous projections in the and directions give components of and respectively In general to determine the number of times irreducible representation appears in the reducible representation with characters one calculates where is the order of the group ie the number of operations in the group six in our example and are the characters of the irreducible representation Commonly Used Bases We could take any set of functions as a basis for a group representation Commonly used sets include Cartesian displacement coordinates located on the atoms of a polyatomic molecule their symmetry treatment is equivalent to that involved in treating a set of p orbitals on the same atoms quadratic functions such as d orbitals as well as rotations about the and axes The transformation properties of these very commonly used bases are listed in the character tables shown in Section Summary The basic idea of symmetry analysis is that any basis of orbitals displacements rotations etc transforms either as one of the irreducible representations or as a direct sum reducible representation Symmetry tools are used to first determine how the basis transforms under action of the symmetry operations They are then used to decompose the resultant representations into their irreducible components More Examples The p Orbitals of Nitrogen For a function to transform according to a specific irreducible representation means that the function when operated upon by a pointgroup symmetry operator yields a linear combination of the functions that transform according to that irreducible representation For example a orbital is the axis of on the nitrogen atom belongs to the representation because it yields unity times itself when or the identity operation act on it The factor of means that has symmetry since the characters the numbers listed opposite and below and in the character table shown in Section of all six symmetry operations are for the irreducible representation The and orbitals on the nitrogen atom transform as the representation since and the identity operation map and among one another Specifically C_ leftbeginarraycp_x p_y endarrayright leftbeginarraycc cos circ sin circ sin circ cos circ endarrayright leftbeginarraycp_x p_y endarrayright C_leftbeginarraycp_x p_y endarrayright leftbeginarraycc cos circ sin circ sin circ cos circ endarrayright leftbeginarraycp_x p_y endarrayright E leftbeginarraycp_x p_y endarrayright leftbeginarraycc endarrayright leftbeginarraycp_x p_y endarrayright sigma_v leftbeginarraycp_x p_y endarrayright leftbeginarraycc endarrayright leftbeginarraycp_x p_y endarrayright sigma_v leftbeginarraycp_x p_y endarrayright leftbeginarraycc frac fracsqrt fracsqrt frac endarrayright leftbeginarraycp_x p_y endarrayright sigma_vleftbeginarraycp_x p_y endarrayright leftbeginarraycc frac fracsqrt fracsqrt frac endarrayright leftbeginarraycp_x p_y endarrayright The x matrices which indicate how each symmetry operation maps and into some combinations of and are the representation matrices for that particular operation and for this particular irreducible representation IR For example leftbeginarraycc frac fracsqrt fracsqrt frac endarrayright DEsigma_v This set of matrices have the same characters as the matrices obtained earlier when the displacement vectors were analyzed but the individual matrix elements are different because we used a different basis set here and above it was and This illustrates the invariance of the trace to the specific representation the trace only depends on the space spanned not on the specific manner in which it is spanned A ShortCut A shortcut device exists for evaluating the trace of such representation matrices that is for computing the characters The diagonal elements of the representation matrices are the projections along each orbital of the effect of the symmetry operation acting on that orbital For example a diagonal element of the matrix is the component of along the direction More rigorously it is Thus the character of the matrix is the sum of and In general the character of any symmetry operation can be computed by allowing to operate on each orbital then projecting along ie forming and summing these terms If these rules are applied to the and orbitals of nitrogen within the point group one obtains This set of characters is the same as above and agrees with those of the representation for the point group Hence and belong to or transform as the representation This is why is to the right of the row of characters for the representation in the character table shown in Section In similar fashion the character table please refer to this table now states that and orbitals on nitrogen transform as E as do and but transforms as Earlier we considered in some detail how the three orbitals on the hydrogen atoms transform Repeating this analysis using the shortcut rule just described the traces characters of the x representation matrices are computed by allowing and to operate on and and then computing the component of the resulting function along the original function The resulting characters are and in agreement with what we calculated before Using the orthogonality of characters taken as vectors we can reduce the above set of characters to Hence we say that our orbital set of three orbitals forms a reducible representation consisting of the sum of and IRs This means that the three orbitals can be combined to yield one orbital of symmetry and a pair that transform according to the representation Projector Operators Symmetry Adapted Linear Combinations of Atomic Orbitals To generate the above and symmetryadapted orbitals we make use of socalled symmetry projection operators and These operators are given in terms of linear combinations of products of characters times elementary symmetry operations as follows where ranges over and and the identity operation The result of applying to say is P_A_ s_H_ s_H_ s_H_s_H_s_H_s_H_s_H_ s_H_s_H_s_H_ phi_A_ which is an unnormalized orbital having symmetry Clearly this same orbital would be generated by acting on or Hence only one orbital exists Likewise which is one of the symmetry adapted orbitals having symmetry The other orbital can be obtained by allowing to act on or It might seem as though three orbitals having symmetry were generated but only two of these are really independent functions For example is related to and as follows Thus only and are needed to span the twodimensional space of the representation If we include in our set of orbitals and require our orbitals to be orthogonal then we must find numbers and such that is orthogonal to A straightforward calculation gives or which agrees with what we used earlier to construct the functions in terms of the functions Summary Let us now summarize what we have learned thus far about point group symmetry Any given set of atomic orbitals atomcentered displacements or rotations can be used as a basis for the symmetry operations of the point group of the molecule The characters belonging to the operations of this point group within any such space can be found by summing the integrals over all the atomic orbitals or corresponding unit vector atomic displacements or rotations The resultant characters will in general be reducible to a combination of the characters of the irreducible representations To decompose the characters of the reducible representation to a sum of characters of the irreducible representation it is necessary to determine how many times the irreducible representation occurs in the reducible representation The expression for is in which is the order of the point group the total number of symmetry operations in the group eg for For example the reducible representation and formed by the three orbitals discussed above can be decomposed as follows These equations state that the three orbitals can be combined to give one orbital and since is degenerate one pair of orbitals as established above With knowledge of the the symmetryadapted orbitals can be formed by allowing the projectors to operate on each of the primitive atomic orbitals How this is carried out was illustrated for the orbitals in our earlier discussion These tools allow a symmetry decomposition of any set of atomic orbitals into appropriate symmetryadapted orbitals Before considering other concepts and grouptheoretical machinery it should once again be stressed that these same tools can be used in symmetry analysis of the translational vibrational and rotational motions of a molecule The twelve motions of three translations three rotations six vibrations can be described in terms of combinations of displacements of each of the four atoms in each of three directions Hence unit vectors placed on each atom directed in the and directions form a basis for action by the operations of the point group In the case of the characters of the resultant x representation matrices form a reducible representation in the point group For example under the and atoms are interchanged so unit vectors on either one will not contribute to the trace Unit zvectors on and remain unchanged as well as the corresponding yvectors However the xvectors on and are reversed in sign The total character for the and atoms are interchanged so unit vectors on either one will not contribute to the trace Unit zvectors on and remain unchanged as well as the corresponding yvectors However the xvectors on and are reversed in sign The total character for is thus This representation can be decomposed as follows From the information on the right side of the character table translations of all four atoms in the and directions transform as and respectively whereas rotations about the and axes transform as and E Hence of the twelve motions three translations have and symmetry and three rotations have and symmetry This leaves six vibrations of which two have symmetry none have symmetry and two pairs have symmetry We could obtain symmetryadapted vibrational and rotational bases by allowing symmetry projection operators of the irreducible representation symmetries to operate on various elementary Cartesian atomic displacement vectors centered on the four atoms Direct Product Representations Direct Products in NElectron Wave functions We now turn to the symmetry analysis of orbital products Such knowledge is important because one is routinely faced with constructing symmetryadapted electron configurations that consist of products of individual spin orbitals one for each electron A pointgroup symmetry operator S when acting on such a product of orbitals gives the product of acting on each of the individual orbitals For example reflection of an orbital product through the plane in applies the reflection operation to all electrons Just as the individual orbitals formed a basis for action of the pointgroup operators the configurations orbital products form a basis for the action of these same pointgroup operators Hence the various electronic configurations can be treated as functions on which operates and the machinery illustrated earlier for decomposing orbital symmetry can then be used to carry out a symmetry analysis of configurations Another shortcut makes this task easier Since the symmetry adapted individual orbitals transform according to irreducible representations the representation matrices for the term products shown above consist of products of the matrices belonging to each This matrix product is not a simple product but what is called a direct product To compute the characters of the direct product matrices one multiplies the characters of the individual matrices of the irreducible representations of the orbitals that appear in the electron configuration The directproduct representation formed by the orbital products can therefore be symmetryanalyzed reduced using the same tools as we used earlier For example if one is interested in knowing the symmetry of an orbital product of the form note lower case letters are used to denote the symmetry of electronic orbitals whereas capital letters are reserved to label the overall configurations symmetry in symmetry the following procedure is used For each of the six symmetry operations in the point group the product of the characters associated with each of the six spin orbitals orbital multiplied by  or  spin is formed In the specific case considered here and Notice that the contributions of any doubly occupied nondegenerate orbitals eg and to these direct product characters are unity because for all operators for any onedimensional irreducible representation As a result only the singly occupied or degenerate orbitals need to be considered when forming the characters of the reducible directproduct representation For this example this means that the directproduct characters can be determined from the characters of the two active ie nonclosedshell orbitals the orbitals That is From the directproduct characters belonging to a particular electronic configuration eg one must still decompose this list of characters into a sum of irreducible characters For the example at hand the directproduct characters decompose into one one and one representation This means that the configuration contains and symmetry elements Projection operators analogous to those introduced earlier for orbitals can be used to form symmetryadapted orbital products from the individual basis orbital products of the form where and denote the occupation or of the two degenerate orbitals and In Appendix III of Electronic Spectra and Electronic Structure of Polyatomic Molecules G Herzberg Van Nostrand Reinhold Co New York NY the resolution of direct products among various representations within many point groups are tabulated When dealing with indistinguishable particles such as electrons it is also necessary to further project the resulting orbital products to make them antisymmetric for Fermions or symmetric for Bosons with respect to interchange of any pair of particles This step reduces the set of electron states that can arise For example in the above configuration case only and states arise the and possibilities disappear when the antisymmetry projector is applied In contrast for an configuration all states arise even after the wave function has been made antisymmetric The steps involved in combining the point group symmetry with permutational antisymmetry are illustrated in Chapter of this text as well as in Chapter of my QMIC text Direct Products in Selection Rules Two states and that are eigenfunctions of a Hamiltonian in the absence of some external perturbation eg electromagnetic field or static electric field or potential due to surrounding ligands can be coupled by the perturbation only if the symmetries of and of the two wave functions obey a socalled selection rule In particular only if the coupling integral is nonvanishing will the two states be coupled by The role of symmetry in determining whether such integrals are nonzero can be demonstrated by noting that the integrand considered as a whole must contain a component that is invariant under all of the group operations ie belongs to the totally symmetric representation of the group if the integral is to not vanish In terms of the projectors introduced above we must have not vanish Here the subscript denotes the totally symmetric representation of whatever point group applies The symmetry of the product is according to what was covered earlier given by the direct product of the symmetries of of and of So the conclusion is that the integral will vanish unless this triple direct product contains when it is reduced to its irreducible components a component of the totally symmetric representation Another way to state the above result and a way this is more often used in practice is that the integral will vanish unless the symmetry of the direct product matches the symmetry of Only when these symmetries match will the triple direct product contain a nonzero component of the totally symmetric representation This is very much the same as what we saw earlier in this Chapter when we discussed how angular momentum coupling could limit which states contribute to the secondorder perturbation theory energy The angular momenta of and of when coupled must have a component that matches the angular momentum of To see how this result is used consider the integral that arises in formulating the interaction of electromagnetic radiation with a molecule within the electricdipole approximation Here is the vector giving together with the unit charge the quantum mechanical dipole moment operator where and are the charge and position of the nth nucleus and is the position of the jth electron Now consider evaluating this integral for the singlet transition in formaldehyde Here the closedshell ground state is of symmetry and the singlet excited state which involves promoting an electron from the nonbonding lone pair orbital on the Oxygen atom into the antibonding orbital on the CO moiety is of symmetry The direct product of the two wave function symmetries thus contains only symmetry The three components and of the dipole operator have respectively and symmetry Thus the triple direct products give rise to the following possibilities There is no component of symmetry in the triple direct product so the integral vanishes The alternative way of reaching this same conclusion is to notice that the direct product of the symmetries of the orbital and the lone pair orbital is which does not match the symmetry of any component of the dipole operator Either route allows us to conclude that the excitation in formaldehyde is electric dipole forbidden Overview We have shown how to make a symmetry decomposition of a basis of atomic orbitals or Cartesian displacements or orbital products into irreducible representation components This tool is very helpful when studying spectroscopy and when constructing the orbital correlation diagrams that form the basis of the WoodwardHoffmann rules that play useful roles in predicting whether chemical reactions will have energy barriers in excess of thermodynamic barriers We also learned how to form the directproduct symmetries that arise when considering configurations consisting of products of symmetryadapted spin orbitals Finally we learned how the direct product analysis allows one to determine whether or not integrals of products of wave functions with operators between them vanish This tool is of utmost importance in determining selection rules in spectroscopy and for determining the effects of external perturbations on the states of the species under investigation Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Predicting Rate Laws from Proposed Mechanisms Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics Case ICase IICase III Because a proposed mechanism can only be valid if it is consistent with the rate law found experimentally the rate law plays a central role in the investigation of chemical reaction mechanisms The discussion above introduces the problems and methods associated with collecting rate data and with finding an empirical rate law that fits experimental concentrationversustime data We turn now to finding the rate laws that are consistent with a particular proposed mechanism For simplicity we consider reactions in closed constantvolume systems In principle numerical integration can be used to predict the concentration at any time of each of the species in any proposed reaction mechanism This prediction can be compared to experimental observations to see whether they are consistent with the proposed mechanism To do the numerical integration it is necessary to know the initial concentrations of all of the chemical species and to know or assume values of all of the rate constants The initial concentrations are known from the procedure used to initiate the reaction However the rate constants must be determined by some iterative procedure in which initial estimates of the rate constants are used to predict concentrationversustime data that can be compared to the experimental results to produce refined estimates In practice we tailor our choice of reaction conditions so that we can use various approximations to test whether a proposed mechanism can explain the data We now consider the most generally useful of these approximations In this discussion we assume that the overall reaction goes to completion that is at equilibrium the concentration of the reactant whose concentration is limiting has become essentially zero If the overall reaction involves more than one elementary step then an intermediate compound is involved A valid mechanism must include this intermediate and more than one differential equation may be needed to characterize the time rate of change of all of the species involved in the reaction We focus on conditions and approximations under which the rate of appearance of the final products in a multistep reaction mechanism can be described by a single differential equation the rate law We examine the application of these approximations to a particular reaction mechanism When we understand the application of these approximations to this mechanism the ways in which they can be used in other situations are clear Consider the following sequence of elementary steps whose kinetics are described by the following simultaneous differential equations The general analytical solution for this system of coupled differential equations can be obtained but it is rather complex because increases early in the reaction passes through a maximum and then decreases at long times In principle experimental data could be fit to these equations The numerical approach requires that we select values for and and then numerically integrate to get and as functions of time In principle we could refine our estimates of and by comparing the calculated values of one or more concentrations to the experimental ones In practice the approximate treatments we consider next are more expedient When we begin a kinetic study we normally have a working hypothesis about the reaction mechanism and we design our experiments to simplify the differential equations that apply to it For the present example we will assume that we always arrange the experiment so that and In consequence at all times Also we restrict our considerations to experiments in which This exemplifies the use of flooding The practical effect is that the concentration of remains effectively constant at its initial value throughout the entire reaction which simplifies the differential equations significantly In the present instance setting means that the ratelaw term can be replaced to a good approximation by where Once we have decided upon the reaction conditions we are going to use whether the resulting concentrationversustime data can be described by a single differential equation depends on the relative magnitudes of the rate constants in the several steps of the overall reaction Particular combinations of relationships that lead to simplifications are often referred to by particular names we talk about a combination that has a ratedetermining step or one that involves a prior equilibrium or one in which a steadystate approximation is applicable To see what we mean by these terms let us consider some particular relationships that can exist among the rate constants in the mechanism above Case I Suppose that and We often describe this situation by saying rather imprecisely that the reaction to convert to is very fast and that the reaction to convert back to and is very slowcompared to the reaction that forms from and When is produced in these circumstances it is converted to so rapidly that we never observe a significant concentration of in the reaction mixture The formation of a molecule of is tantamount to the formation of a molecule of and the reaction produces at essentially the same rate that it consumes or We say that the first step is the ratedetermining step in the reaction We have The assumption that means that we can neglect the smaller term in the equation for giving the approximation Letting and recognizing that our assumptions make the massbalance condition becomes Choosing means that The rate equation becomes firstorder Since is not strictly constant it is a pseudofirstorder rate constant The disappearance of is said to follow a pseudofirstorder rate equation The concept of a ratedetermining step step is an approximation In general the consequence we have in mind when we invoke this approximation is that no intermediate species can accumulate to a significant concentration if it is produced by the ratedetermining step or by a step that occurs after the ratedetermining step We do not intend to exclude the accumulation of a species that is at equilibrium with another product Thus in the mechanism we suppose that the conversion of to is ratedetermining and that the interconversion of and is so rapid that their concentrations always satisfy the equilibrium relationship For the purpose at hand we do not consider to be an intermediate is a product that happens to be at equilibrium with the coproduct Case II Suppose that In this case is fast compared to the rate at which is converted to and we say that is the ratedetermining step We can now distinguish three subcases depending upon the way behaves during the course of the reaction Case IIa Suppose that and Then is rapid and essentially quantitative That is within a short time of initiating the reaction all of the stoichiometrically limiting reactant is converted to Letting and recognizing that our assumptions make the massbalance condition becomes After a short time the rate at which is formed becomes or The disappearance of and the formation of follow a firstorder rate law Case IIb If the forward and reverse reactions in the first elementary process are rapid then this process may be effectively at equilibrium during the entire time that is being formed This is the case that and Then throughout the course of the reaction we have Letting and making the further assumption that throughout the reaction the massbalance condition becomes Substituting into the equilibriumconstant expression we find Substituting into we have where The disappearance of A and the formation of D follow a pseudofirstorder rate equation The pseudofirstorder rate constant is a composite quantity that is directly proportional to Case IIc If we suppose that the first step is effectively at equilibrium during the entire time that is being produced as in case IIb but that is not negligibly small compared to we again have With the massbalance condition becomes Eliminating between the massbalance and equilibriumconstant equations gives so that becomes The formation of follows a pseudofirstorder rate equation The disappearance of is also pseudofirstorder but the pseudofirstorder rate constant is different As in Case IIb the pseudofirstorder rate constant is a composite quantity but now its dependence on is more complex The result for Case IIc reduces to that for Case IIb if Case III In the cases above we have assumed that one or more reactions are intrinsically much slower than others are The differential equations for this mechanism can also become much simpler if all three reactions proceed at similar rates but do so in such a way that the concentration of the intermediate is always very small If the concentration of is always very small then we expect the graph of versus time to have a slope that is approximately zero In this case we have so that With becomes As in the previous cases the disappearance of and the formation of follow a pseudofirstorder rate equation The pseudofirstorder rate constant is again a composite quantity which depends on and the values of all of the rate constants Case III illustrates the steadystate approximation in which we assume that the concentration of an intermediate species is much smaller than the concentrations of other species that affect the reaction rate Under these circumstances we can be confident that the timederivative of the intermediates concentration is negligible compared to the reaction rate so that it is a good approximation to set it equal to zero The idea is simply that if the concentration is always small its timederivative must also be small If the graph of the intermediates concentration versus time is always much lower than that of other participating species then its slope will be much less Equating the time derivative of the steadystate intermediates concentration to zero produces an algebraic expression that involves the intermediates concentration Solving this expression for the concentration of the steadystate intermediate makes it possible to greatly simplify the set of simultaneous differential equations that is predicted by the mechanism When there are multiple intermediates to which the approximation is applicable remarkable simplifications can result This often happens when the mechanism involves freeradical intermediates The name steadystate approximation is traditional When we use it we do so on the understanding that the state which is approximately steady is the concentration of the intermediate not the state of the system Since a net reaction is occurring the state of the system is distinctly not constant Prelude to Chemical Equilibria Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors and Attributions The small is great the great is small all is in equilibrium in necessity Victor Hugo in Les Miserables As was discussed in Chapter the natural tendency of chemical systems is to seek a state of minimum Gibbs function Once the minimum is achieved movement in any chemical direction will not be spontaneous It is at this point that the system achieves a state of equilibrium From the diagram above it should be clear that the direction of spontaneous change is determined by minimizing If the slope of the curve is negative the reaction will favor a shift toward products And if it is positive the reaction will favor a shift toward reactants This is a nontrivial point as it underscores the importance of the composition of the reaction mixture in the determination of the direction of the reaction Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Prelude to Phase Equilibrium Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors and Attributions From the very elementary stages of our journey to describe the physical nature of matter we learn to classify mater into three or more phases solid liquid and gas This is a fairly easy classification system that can be based on such simple ideas as shape and volume Phase Shape Volume Solid Fixed Fixed Liquid Variable Fixed Gas Variable Variable As we have progressed we have seen that solids and liquids are not completely incompressible as they may have nonzero values of And we learn that there are a number of finer points to describing the nature of the phases about which we all learn in grade school In this chapter we will employ some of the tools of thermodynamics to explore the nature of phase boundaries and see what we can conclude about them Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Prelude to Putting the First Law to Work Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors and Attributions As has been seen in previous chapters may important thermochemical quantities can be expressed in terms of partial derivatives Two important examples are the molar heat capacities and which can be expressed as and These are properties that can be measured experimentally and tabulated for many substances These quantities can be used to calculate changes in quantities since they represent the slope of a surface or in the direction of the specified path constant or This allows us to use the following kinds of relationships and Delta H int leftdfracpartial Hpartial Tright_p dT Because thermodynamics is kind enough to deal in a number of state variables the functions that define how those variable change must behave according to some very well determined mathematics This is the true power of thermodynamics Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Prelude to Thermodynamics Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay No headers Albert Einstein a noted physicist said of thermodynamics Einstein A law is more impressive the greater the simplicity of its premises the more different are the kinds of things it relates and the more extended its range of applicability It is the only physical theory of universal content which I am convinced that within the framework of applicability of its basic concepts will never be overthrown Thermodynamics is the study of how energy flows into and out of systems and how it flows through the universe People have been studying thermodynamics for a very long time and have developed the field a great deal including the incorporation of highlevel mathematics into the process Many of the relationships may look cumbersome or complicated but they are always describing the same basic thing the flow of energy through the universe Energy of course can be used to do many useful things such as allow us to drive our cars use electronic devices heat our homes and cook our food Chemistry is important as well since many of the processes in which we generate energy depend on chemical reactions such as the combustion of hydrocarbons to generate heat or electron transfer reactions to generate electron flow The previous chapter investigated gases which are convenient systems to use to frame many discussions of thermodynamics since they can be modeled using specific equations of state such as the ideal gas law or the van der Waals law These relationships depend on an important class of variables known as state variables State variables are those variables which depend only upon the current conditions affecting a system Pressure temperature and molar volume are examples of state variables A number of variables required to describe the flow of energy in a system do depend on the pathway a system follows to come into its current state To illustrate the difference consider climbing a mountain You may choose to walk straight up the side of the mountain or you may choose to circle the mountain several times in order to get to the top These two pathways will differ in terms of how far you actually walk a pathdependent variable to attain the same change in altitude an example of a state variable Pressure and Molar Volume Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors and Attributions Italian physicist Evangelista Torricelli Evangelista Torricelli was the inventor of an ingenious device that could be used to measure air pressure Basically he took a glass tube closed at one end and filled it with mercury He then inverted it submerging the open end below the surface level in a pool of mercury The mercury in the glass tube was then allowed to drain leaving a vacuum known as a Torrocellian vacuum in the open space at the closed end of the tube Figure Evangelista Torricelli Evangelista Torricelli portrayed on the frontpage of Lezioni dEvangelista Torricelli Public Domain Remarkably the tube did not drain completely Torricelli was able to use the residual column height to measure the pressure of the air pushing down on the surface of the pool of mercury The larger the pressure pushing down on the exposed surface the larger the column height is observed to be The ambient air pressure can be computed by equating the force generated by the mass of the mercury in the column to the force generated by ambient air pressure after normalizing for surface area The resulting relationship is where is the density of the mercury gcm is the acceleration due to gravity and is the height of the column Torricelli found that at sea level the height of the column was cm A force of N acting on an area of m is a Pascal Pa A standard atmosphere is Pa kPa or cm Hg mm Hg Another commonly used unit of pressure is the bar Figure Set up for the Torricelli barometer Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Pressure Dependence of Gibbs Energy Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay No headers The pressure and temperature dependence of is also easy to describe The best starting place is the definition of Taking the total differential of yields The differential can be simplified by substituting the combined first and second law statement for consider a reversible process and work only Canceling the and terms leaves This suggests that the natural variables of are and So the total differential can also be expressed dG left dfracpartial Gpartial p right_T dp left dfracpartial Gpartial T right_p dT labelTotal And by inspection of Equations refTotal and refTotal it is clear that left dfracpartial Gpartial p right_T V and left dfracpartial Gpartial T right_p S It is also clear that the Maxwell relation on is given by left dfracpartial Vpartial T right_p left dfracpartial Spartial p right_T which is an extraordinarily useful relationship since one of the terms is expressible entirely in terms of measurable quantities left dfracpartial Vpartial T right_p Valpha The pressure dependence of is given by the pressure derivative at constant temperature left dfracpartial Gpartial p right_T V labelMax which is simply the molar volume For a fairly incompressible substance such as a liquid or a solid the molar volume will be essentially constant over a modest pressure range Example Gold under Pressure The density of gold is gcm Calculate for a g sample of gold when the pressure on it is increased from atm to atm Solution The change in the Gibbs function due to an isothermal change in pressure can be expressed as Delta G int_p_p_ left dfracpartial Gpartial p right_T dp And since substituting Equation refMax results in Assuming that the molar volume is independent or pressure over the stated pressure range becomes So the molar change in the Gibbs function can be calculated by substituting the relevant values Contributors Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Pressure Dependence of Kp Le Chteliers Principle Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors and Attributions Since the equilibrium constant is a function of which is defined for a specific composition all reactants in their standard states and at unit pressure or fugacity changes in pressure have no effect on equilibrium constants for a fixed temperature However changes in pressure can have profound effects on the compositions of equilibrium mixtures To demonstrate the relationship one must recall Daltons law of partial pressures According to this relationship the partial pressure of a component of a gasphase mixture can be expressed It is the combination of mole fractions that describes the composition of the equilibrium mixture Substituting the above expression into the expression for yields This expression can be factored into two pieces one containing the mole fractions and thus describing the composition and one containing the total pressure The second factor is a constant for a given total pressure If the first term is given the symbol the expression becomes In this expression has the same form as an equilibrium constant but is not itself a constant The value of will vary with varying composition and will need to vary with varying total pressure in most cases in order to maintain a constant value of Example Consider the following reaction at equilibrium In which direction will the equilibrium shift if the volume of the reaction vessel is decreased Solution A decrease in the volume will lead to an increase in total pressure Since the equilibrium constant can be expressed as An increase in pressure will lead to an increase in to maintain a constant value of So the reaction will shift to form more of the products and Note This should make some sense since a shift to the side of the reaction with fewer moles of gas will lower the total pressure of the reaction mixture and thus relieving the stress introduced by increasing the pressure This is exactly what is expected according to Le Chateliers principle It should be noted that there are several ways one can affect the total pressure of a gasphase equilibrium These include the introduction or removal of reactants or products perhaps through condensation or some other physical process a change in volume of the reaction vessel or the introduction of an inert gas that does not participate in the reaction itself Changes in the temperature will be discussed in a later section The principle of Le Chateliers can be used as a guide to predict how the equilibrium composition will respond to a change in pressure Le Chateliers principle When a stress is introduced to a system at equilibrium the system will adjust so as to reduce the stress Le Chatliers principle is fairly clear on how to think about the addition or removal of reactants or products For example the addition of a reactant will cause the system to shift to reduce the partial pressure of the reactant It can do this by forming more products An important exception to the rule that increasing the total pressure will cause a shift in the reaction favoring the side with fewer moles of gas occurs when the total pressure is increased by introducing an inert gas to the mixture The reason is that the introduction of an inert gas will affect the total pressures and the partial pressures of each individual species Example A L vessel is charged with atm of A and the following reaction is allowed to come to equilibrium at K with What are the equilibrium partial pressures and mole fractions of A and B If the volume of the container is doubled what are the equilibrium partial pressures and mole fractions of A and B If atm of Ar an inert gas is introduced into the system described in b what are the equilibrium partial pressures and mole fractions of A and B once equilibrium is reestablished Solution Part a First we can use an ICE table to solve part a A B Initial atm Change x x Equilibrium atm x x So for convenience consider to have units of atm Solving for yields values of Clearly while a solution to the mathematical problem is not physically meaningful since the equilibrium pressure of B cannot be negative So the equilibrium partial pressures are given by So the mole fractions are given by Part b The volume is doubled Again an ICE table is useful The initial pressures will be half of the equilibrium pressures found in part a A B Initial atm atm Change x x Equilibrium atm x atm x So the new equilibrium pressures can be found from And the values of that solve the problem are We reject the negative root since it would cause both of the partial pressures to become negative So the new equilibrium partial pressures are And the mole fractions are We can see that the mole fraction of decreased and the mole fraction increased This is the result expected by Le Chatliers principle since the lower total pressure favors the side of the reaction with more moles of gas Part c We introduce atm of an inert gas The new partial pressures are And because the partial pressures of A and B are unaffected the equilibrium does not shift What is affected is the composition and so the mole fractions will change And since Within roundoff error the value obtained is the equilibrium constant So the conclusion is that the introduction of an inert gas even though it increases the total pressure does not induce a change in the partial pressures of the reactants and products so it does not cause the equilibrium to shift Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay ICE is an acronym for Initial Change Equilibrium An ICE table is a tool that is used to solve equilibrium problems in terms of an unknown number of moles or something proportional to moles such as pressure or concentration will shift for a system to establish equilibrium See Tro or a similar General Chemistry text for more background and information Pressure Variations for Macroscopic Samples Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers At K the standard deviation of speeds is about of the average speed Clearly the relative variation among molecular speeds in a sample of ordinary gas is very large Why do we not observe macroscopic effects from this variation In particular if we measure the pressure at a small area of the container wall why do we not observe pressure variations that reflect the wide variety of speeds with which molecules strike the wall Qualitatively the answer is obvious A single molecule whose scalar velocity is contributes to the pressure on the walls of its container See problem When we measure pressure we measure an average squared velocity Even if we measure the pressure over a very small area and a very short time the number of molecules striking the wall during the time of the measurement is very large Consequently the average speed of the molecules hitting the wall during any one such measurement is very close to the average speed in any other such measurement We are now able to treat this question quantitatively For gas at K and bar roughly molecules collide with a square millimeter of wall every microsecond See problem The standard deviation of the velocity of an molecule is Using the central limit theorem the standard deviation of the average of molecular speeds is The distribution of the average of molecular speeds is very narrow indeed Similarly when molecular velocities follow the MaxwellBoltzmann distribution function we can show that the expected value of the pressure for a singlemolecule collision is See problem The variance of the distribution of these individual pressure measurements is so that the magnitude of the standard deviation is comparable to that of the average For the distribution of averages of pressure contributions we find and Probability Density Functions for Velocity Components in Spherical Coordinates Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers We introduce the idea of a threedimensional probabilitydensity function by showing how to find it from data referred to a Cartesian coordinates system The probability density associated with a particular molecular velocity is just a numbera number that depends only on the velocity Given a velocity the probability density associated with that velocity must be independent of our choice of coordinate system We can express the threedimensional probability density using any coordinate system We turn now to expressing velocities and probability density functions using spherical coordinates Just as we did for the Cartesian velocity components we deduce the cumulative probability functions and for the sphericalcoordinate components Our deduction of from the experimental data uses values that are associated with all possible values of and Corresponding statements apply to our deductions of and We also obtain their derivatives the probabilitydensity functions and From the properties of probabilitydensity functions we have Let be the arbitrarily small increment of volume in velocity space in which the and components of velocity lie between and and and and Then the probability that the velocity of a randomly selected molecule lies within is Note that the product is not a threedimensional probability density function This is most immediately appreciated by recognizing that is not an incremental volume in velocity space That is We let be the probabilitydensity function for the velocity vector in spherical coordinates When and specify the velocity is the probability per unit volume at that velocity We want to use to express the probability that an arbitrarily selected molecule has a velocity vector whose magnitude lies between and while its component lies between and and its component lies between and This is just times the velocityspace volume included by these ranges of and When we change from Cartesian coordinates to spherical coordinates the transformation is See Figure As sketched in Figure an incremental increase in each of the coordinates of the point specified by the vector advances the vector to the point When and are arbitrarily small these two points specify the diagonally opposite corners of a rectangular parallelepiped whose edges have the lengths and The volume of this parallelepiped is Hence the differential volume elementdifferential volume element in Cartesian coordinates becomes in spherical coordinates Mathematically this conversion is obtained using the absolute value of the Jacobian of the transformation That is where the Jacobian is a determinate of partial derivatives Since the differential unit of volume in spherical coordinates is the probability that the velocity components lie within the indicated ranges is We can develop the next step in Maxwells argument by taking his assumption to mean that the threedimensional probability density function is expressible as a product of three onedimensional functions That is we take Maxwells assumption to assert the existence of independent functions and such that The probability that the and components of velocity lie between and and and and becomes Since and are independent it follows that Moreover the assumption that velocity is independent of direction means that must actually be independent of that is must be a constant We let this constant be so By the same argument we set Each of these probabilitydensity functions must be normalized This means that from which we see that and It is important to recognize that while and are probability density functions and are not However is a probability density function We can see this by noting that if were a probability density its integral over all possible values of would be one Instead we find Similarly when we find we can show explicitly that Our notation now allows us to express the probability that an arbitrarily selected molecule has a velocity vector whose magnitude lies between and while its component lies between and and its component lies between and using three equivalent representations of the probability density function The threedimensional probabilitydensity function in spherical coordinates is This shows explicitly that is independent of and if the speed is independent of direction the probability density function that describes velocity must be independent of the coordinates and that specify its direction Problems Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Which of the following differential expressions are exact a b c d e f Show that is exact Find by integrating the term Find by integrating the term A marble of mass is free to move on a surface whose height above the plane is a What is the gravitational potential energy of the marble expressed as a function of and b The force experienced by the marble due to gravity is the vector function What is on this surface c What is the differential of Is exact or inexact d The vector description of a general path is the position vector and so If we push the marble up the surface from point to point along the path express as a vector function of e If we push the marble along the path in part d with a force just large enough to overcome the force of gravity what is the increment of work associated with an increment of motion f How much work must we do if we are to move the marble from to point along the path in part d using the force in part e What is the relationship between this amount of work and the change in the energy of the marble during this process g Suppose that we push the marble up the surface from point to point along the path What is the vector description of this path h How much work must we do if we are to move the marble from point to point along the path in part g using the force in part b Compare this result to your result in part f Explain Consider the plane What is for this surface Evaluate by integrating along each of the following paths a b c d A mole sample of a monatomic ideal gas is expanded reversibly and isothermally at K from L to L How much work is done on the gas What are and for the gas in this process A mole sample of a monatomic ideal gas is expanded irreversibly from L to L at a constant applied pressure equal to the final pressure of the gas The initial and final temperatures are K How much work is done on the gas What are and for the gas in this process Compare and for this process to the corresponding quantities for the process in problem Compare the initial and final states of the gas to the corresponding states in problem A mole sample of a monatomic ideal gas is expanded reversibly and adiabatically from L to L The initial temperature is K What is the final temperature What are the initial and final pressures How much work is done on the gas What are and for the gas in this process The equation of state for a hardsphere gas is where is the number of moles and is the molar volume of the hard spheres How much work is done on this gas when n moles of it expand reversibly and isothermally from to Strictly speaking can the spontaneous expansion of a real gas be isothermal Can it be free Can it be adiabatic Can the reversible expansion of a gas be isothermal Can it be free Can it be adiabatic Consider a machine that operates in a cycle and converts heat into a greater amount of work What would happen to the energy of the universe if this machine could be operated in reverse Show that the product of pressure and volume has the units of energy Give a counterexample to prove that each of the following propositions is false a If is a state function is conserved b If is an extensive quantity that satisfies is a state function Notes Since the temperature of the water increases and the process is to be reversible we must keep the temperature of the thermal reservoir just greater than that of the water throughout the process We can accomplish this by using a quantity of ideal gas as the heat reservoir By reversibly compressing the ideal gas we can reversibly deliver the required heat while maintaining the required temperature We consider this operation further in Section Random Variables Expected Values and Population Sets Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers When we sample a particular distribution the value that we obtain depends on chance and on the nature of the distribution described by the function The probability that any given trial will produce in the interval is equal to We often find situations in which a second function of call it is also of interest If we sample the distribution and obtain a value of the random variable then the value of associated with that trial is The question arises Given and the distribution function what should we expect the value of to be That is if we get a value of from the distribution and then find what value should we expect to find for While this seems like a reasonable question it is obvious that we can give a meaningful answer only when we can define more precisely just what we mean by expect To understand our definition of the expected value sometimes called the expectation value of let us consider a game of chance Suppose that we have a needle that rotates freely on a central axis When spun the needle describes a circular path and its point eventually comes to rest at some point on this path The location at which the needle stops is completely random Imagine that we divide the circular path into six equal segments which we number from one to six When we spin the needle it is equally likely to stop over any of these segments Now let us suppose that we conduct a lottery by selling six tickets also numbered from one to six We decide the winner of the lottery by spinning the needle The holder of the ticket whose number matches the number on which the needle stops receives a payoff of After the spin one ticket is worth and the other five are valueless We ask Before the spin what is any one of the lottery tickets worth In this context it is reasonable to define the expected value of a ticket as the amount that we should be willing to pay to buy a ticket If we buy them all we receive when the winning ticket is selected If we pay per ticket to buy them all we get our money back If we buy all the tickets the expected value of each ticket is What if we buy only one ticket Is it reasonable to continue to say that its expected value is We argue that it is One argument is that the expected value of a ticket should not depend on who owns the ticket so it should not depend on whether we buy one two or all of them A more general argument supposes that repeated lotteries are held under the same rules If we spend to buy one ticket in each of a very large number of such lotteries we expect that we will eventually break even Since the needle comes to rest at each number with equal probability we reason that Since we assume that the fraction of times our ticket would be selected in a long series of identical lotteries is the same thing as the probability that our ticket will be selected in any given drawing we can also express the expected value as Clearly the ticket is superfluous The game depends on obtaining a value of a random variable from a distribution The distribution is a spin of the needle The random variable is the location at which the needle comes to rest We can conduct essentially the same game by allowing any number of participants to bet that the needle will come to rest on any of the six equally probable segments of the circle If an individual repeatedly bets on the same segment in many repetitions of this game the total of his winnings eventually matches the total amount that he has wagered More precisely the total of his winnings divided by the total amount he has wagered becomes arbitrarily close to one Suppose now that we change the rules Under the new rules we designate segment of the circle as the payoff segment Participants pay a fixed sum to be eligible for the payoff for a particular game Each game is decided by a spin of the needle If the needle lands in segment everyone who paid to participate in that game receives Evidently the new rules have no effect on the value of participation Over the long haul a participant in a large number of games wins in onesixth of these games We take this to be equivalent to saying that he has a probability of onesixth of winning in a given game in which he participates His expected payoff is Let us change the game again We subdivide segment into equalsize segments and The probability that the needle lands in or is In this new game the payoff is when the needle lands in either segment or segment We can use any of the arguments that we have made previously to see that the expected payoff game is now However the analysis that is most readily generalized recognizes that the payoff from this game is just the sum of the payout from the previous game plus the payout from a game in which the sole payout is whenever the needle lands in segment For the new game we have We can devise any number of new games by dividing the needles circular path into nonoverlapping segments Each segment is a possible outcome We number the possible outcomes  label these outcomes and denote their probabilities as We say that the probability of outcome is the expected frequency of outcome We denote the respective payoffs as Straightforward generalization of our last analysis shows that the expected value for participation in any game of this type is Moreover the spinner is representative of any distribution so it is reasonable to generalize further We can say that the expected value of the outcome of a single trial is always the probabilityweighted sum over all possible outcomes of the value of each outcome A common notation uses angular brackets to denote the expected value for a function of the random variable the expected value of is For a discrete distribution with exhaustive mutuallyexclusive outcomes probabilities and outcome values payoffs we define the expected value expected value of to be Now let us examine the expected value of from a slightly different perspective Let the number of times that each of the various outcomes is observed in a particular sample of observations be We have The set specifies the way that the possible outcomes are populated in this particular series of observations We call a population set If we make a second series of N observations we obtain a second population set We infer that the best forecast we can make for the number of occurrences of outcome in any future series of N observations is We call the expected number of observations of outcome in a sample of size In a particular series of trials the number of occurrences of outcome and hence of is For the set of outcomes the average value of is Collecting a second sample of observations produces a second estimate of If is small successive estimates of may differ significantly from one another If we make a series of observations multiple times we obtain multiple population sets In general the population set from one series of observations is different from the population set for a second series of observations If collecting such samples of a sufficiently large number of times must produce some population sets more than once and among those that are observed more than once one must occur more often than any other We call it the most probable population set Let the elements of the most probable population set be We infer that the most probable population set is the best forecast we can make about the outcomes of any future sample of from this distribution Moreover we infer that the best estimate we can make of is that it equals the expected number of observations of outcome that is Now and must be natural numbers while need only be real In particular we can have must be or or some higher integer This is a situation of practical importance because circumstances may limit the sample size to a number that is much less than the number of possible outcomes We encounter this situation in our discussion of statistical thermodynamics in Chapter We find that the number of molecules in a system can be much smaller than the number of outcomesobservable energy levelsavailable to any given molecule If many more than outcomes have about the same probability repeated collection of samples of observations can produce a series of population sets each population set different from all of the others in each of which every element is either zero or one When this occurs it may be that no single population set is significantly more probable than any of many others Nevertheless every outcome occurs with a welldefined probability We infer that the set is always an adequate proxy for calculating the expected value for the most probable population set To illustrate this kind of distribution suppose that there are possible outcomes of which the first and last thousand have probabilities that are so low that they can be taken as zero while the middle outcomes have approximately equal probabilities Then for and while for We are illustrating the situation in which the number of outcomes we can observe is much less than the number of outcomes that have appreciable probability which is So let us take the number of trials to be If the value of for each of the middle outcomes is the same say for then our calculation of the expected value of will be regardless of which population set results from the four trials That is because all of the populations sets that have a significant chance to be observed have and for exactly four values of in the range all of the population sets that have a significant chance to be observed give rise to the same expected value Let us compute the arithmetic average using the most probable population set for a sample of N trials In this case the number of observations of the outcome is For a discrete distribution is the value of that we calculate from the most probable population set or its proxy We can extend the definition of the expected value to cases in which the cumulative probability distribution function and the outcomevalue function are continuous in the domain of the random variable To do so we divide this domain into a finite number of intervals We let be the lower limit of in the interval Then the probability that a given trial yields a value of the random variable in the interval is and we can approximate the expected value of for the continuous distribution by the finite sum In the limit as becomes arbitrarily large and all of the intervals become arbitrarily small the expected value of for a continuous distribution becomes This integral is the value of where is the probability density function for the distribution If c is a constant we have If is a second function of the random variable we have Rate Laws by the Study of Initial Rates Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers In concept the most straightforward way to measure reaction rate directly is to measure the change in the concentration of one reagent in a short time interval immediately following initiation of the reaction The initial concentrations are known from the way the reaction mixture is prepared If necessary the initial mixture can be prepared so that known concentrations of products or reaction intermediates are present The initial reaction rate is approximated as the measured concentration change divided by the elapsed time The accuracy of initialrate measurements is often poor This can result from concentration variations associated with initiation of the reaction the actual mixing process is not instantaneous and significant reaction can occur before the mixture becomes truly homogeneous Measuring small changes in concentration with sufficient accuracy can also be difficult Enzymes are naturally occurring catalysts for biochemical reactions In the study of enzymecatalyzed reactions it is usually possible to select the enzyme concentration and other reaction conditions so that the initial rate can be measured with adequate accuracy For such studies initialrate measurements are used extensively For other types of reactions the method of initial rates is usually less effective than alternative methods To illustrate the application of the method suppose we have a reaction and that we are able to measure small changes in with good accuracy We seek a rate law of the form For any given experiment we approximate by and approximate the average concentrations of the reagents over the interval by their initial values and By carrying out an number of such experiments with suitably chosen initial concentrations we can determine the functional form of the rate law and evaluate the rate constants that appear in it Table Hypothetical reaction rate data Table presents data for a hypothetical reaction that serve to illustrate the basic concept We suppose that initial rates have been determined for four different combinations of initial concentrations Comparison of the first and second experiments indicates that doubling doubles the reaction rate indicating that the rate depends on to the first power Comparison of the first and third experiments indicates that doubling leaves the reaction rate unchanged implying that the rate is independent of Comparison of the first and fourth experiments indicates that doubling increases the reaction rate by a factor of four implying that the rate is proportional to the second power of We infer that the rate law is Given the form of the rate law an estimate of the value of the rate constant can be obtained from the data for each experiment For this illustration we calculate from each of the experiments Rate Laws for Elementary Processes Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics Bimolecular Elementary ProcessesTermolecular Elementary ProcessesUnimolecular Elementary Processes Bimolecular Elementary Processes If we think about an elementary bimolecular reaction rate law between molecules and we recognize that the reaction can occur only when the molecules come into contact They must collide before they can react So the probability that they react must be proportional to the probability that they collide and the number of molecules of product formed per unit time must be proportional to the number of collisions that occur in unit time In our development of the collision theory for bimolecular reactions in the gas phase to we find that the number of such collisions is proportional to the concentration of each reactant It is clear that this conclusion must apply to any bimolecular reaction If we have a vessel containing some concentration of molecules and some concentration of molecules the collection experiences some number of collisions per unit time If we double the concentration of molecules each molecule is twice as likely as before to encounter a molecule Indeed for any increase in the concentration of molecules the number of collisions of an molecule with molecules increases in the same proportion The number of collisions must be proportional to the concentration of molecules Likewise increasing the concentration of A molecules must increase the number of collisions proportionately the number of collisions must also be proportional to the concentration of molecules We conclude that the rate for any bimolecular reaction between molecular substances and is described by the equations This is a secondorder rate law and the proportionality constant is called a secondorder rate constant In Section we derive an equation for the frequency with which a type molecule collides with type molecules in the gas phase when the concentration of type molecules is and the kinetic energy along the line of centers exceeds a threshold value per molecule or per mole The rate at which such collisions occur is which is just times the rate at which collisions of any energy occur between molecules of type and molecules of type If reaction occurs at every collision between a molecule and a molecule in which the kinetic energy along the line of centers exceeds the collision rate equals the reaction rate We have If the temperaturedependence of the rate constant is given by the Arrhenius equation the rate of the bimolecular reaction between species and species is where is independent of temperature and The collisiontheory model for the bimolecular reaction is almost the same the difference being a factor of in the preexponential factor The effect of the term is usually small in comparison to the effect of temperature in the exponential term Thus the temperature dependence predicted by collision theory which is a highly simplified theoretical model and that predicted by the Arrhenius equation which is an empirical generalization usually used to describe data taken over a limited temperature range are in substantial agreement Experimentally determined values of the preexponential factor for gasphase bimolecular reactions can approach the value calculated from collision theory However particularly for reactions between polyatomic molecules the experimental value is often much smaller than the calculated collision frequency We rationalize this observation by recognizing that our collidingspheres model provides no role for the effect of molecular structures When the colliding molecules are not spherical the collision angle is an incomplete description of their relative orientation If the relative orientation of two colliding molecules is unfavorable to reaction it is entirely plausible that they can fail to react no matter how energetic their collision To recognize this effect we suppose that the reaction rate is proportional to a steric factor where represents the probability that a colliding pair of molecules have the relative orientation that is necessary for reaction to occur Of course must be less than one Taking this amplification of the collision model into account the relationship between the reaction rate and the collision frequency becomes When we consider reactions in solution we recognize that there are usually many more solvent molecules than reactant molecules As a result collisions of a reactant molecule with solvent molecules are much more frequent than collisions of a molecule of one reactant with a molecule of another reactant The high frequency of collisions with solvent molecules means that the net distance moved by a reactant molecule in unit time is much less in solution than in a gas This decreases the probability that two reactant molecules will meet On the other hand once two reactant molecules near one another the solvent molecules tend to keep them together and they are likely to collide with one another many times before they finally drift apart This is known as the solventcage effect We can expect these effects to roughly offset one another Termolecular Elementary Processes A termolecular elementary process is a reaction in which three reactant molecules collide For this to happen an molecule and a molecule must be very close to one another at exactly the time that a molecule encounters the pair of them If the reactants are not very concentrated the probability that a given molecule is very close to a molecule during any short time interval is small The probability that this molecule will be hit by a molecule during the same time interval is also very small The probability that all three species will collide at the same time is the product of two small probabilities under any given set of conditions the number of collisions involving three molecules is smaller than the number of collisions between two molecules The probability of a termolecular collision and hence the rate of a termolecular elementary process is proportional to the concentrations of all three reacting species However the low probability of a termolecular collision means that we can expect the termolecular rate constant to be very small If termolecular mechanisms are rare highermolecularity mechanisms must be exceedingly rare if indeed any occur at all For most chemical reactions the mechanism is a series of unimolecular and bimolecular elementary reactions Unimolecular Elementary Processes A unimolecular elementary process is one in which a molecule spontaneously undergoes a chemical change If we suppose that there is a constant probability that any given molecule undergoes reaction in unit time then the total number reacting in unit time is proportional to the number of molecules present Let the average number of moles reacting in unit time be the number of molecules in the system be and the proportionality constant be We choose a unit of time that is small enough to insure that If the probability of reaction is constant we have Since is the number of moles that react in unit time the number of moles that react in time is so that Dividing by the volume of the system we have In the limit that the term on the left becomes the reaction rate and since we have Thus a constant reaction probability implies that a unimolecular reaction has a firstorder rate law If the volume is constant we have The idea that a unimolecular reaction corresponds to a constant reaction probability can be rationalized by introducing a simple model of the reaction process This model assumes that reactant molecules have a distribution of energies that only molecules whose energies exceed some minimum can react and that this excess energy must be in some specific internal motion before the reaction can occur Molecules exchange energy by colliding with one another When a molecule acquires excess energy as the result of a collision redistribution of this energy among the motions available to the molecule is not instantaneous A characteristic length of time is required for excess energy to reach the specific internal motion that leads to reaction Any given molecule can retain excess energy only for the short time between two collisions The molecule gains excess energy in one collision and loses it in a subsequent one Reaction can occur only if the excess energy reaches the specific internal motion before the molecule undergoes a deactivating collision We return to these ideas in and In summary only two kinds of elementary processes are needed to develop a mechanism for nearly any chemical change These elementary processes and their rate laws are Unimolecular A Bimolecular A B Finally we should note that we develop these rate laws for elementary processes under the assumption that the rate at which molecules collide is proportional to the concentrations of the colliding species In doing so we implicitly assume that intermolecular forces of attraction or repulsion have no effect on this rate When our goal is to predict rate laws from reaction mechanisms this assumption is almost always an adequate approximation However when we study chemical equilibria we often find that we must allow for the effects of intermolecular forces in order to obtain an adequate description In chemical thermodynamics we provide for the effects of such forces by introducing the idea of a chemical activity The underlying idea is that the chemical activity of a compound is the effective concentration of the compoundwe can view it as the concentration corrected for the effects of intermolecular forces Rate Laws from Experiments in a Continuous Stirred Tank Reactor Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers A continuous stirred tank reactor CSTRor capacityflow reactoris a superior method of collecting kinetic data when the rate law is complex Unfortunately a CSTR tends to be expensive to construct and complex to operate Figure gives a schematic representation of the essential features of a CSTR Fresh reagents are fed to a reactor vessel of volume at a constant rate A portion of the reactor contents is continuously removed at the same volumetric flow rate Because the addition and removal of material occur at the same rate the reactor is always filled with a fixed volume of reaction mixture The reaction vessel and its contents are maintained at a constant temperature The vessel contains a stirrer which operates continuously and at a high enough speed to keep the contents of the vessel homogeneous free of concentration and temperature gradients at all times Figure A continuous stirredtank reactor The essential idea involved in the operation of a CSTR is that after the passage of sufficient time the concentrations of the various species present in the reactor become constant We say that the reactor contains steadystate concentrations of the reactants and products When the reactor reaches this steady state processes that increase reagent concentrations are occurring at the same rate as processes that decrease them Let the reaction be of the form The concentrations of the reagents in the feed solution are known Let the concentration of in the fresh feed solution be Let the rate at which fresh reagentcontaining solution is fed to the reactor be Homogeneous reaction mixture is withdrawn from the vessel at the same flow rate The amount of in the reactor is increased by the flow of fresh reactant solution into the reactor It is decreased both by reaction and by the flow of solution out of the reactor The steadystate reaction rate is the number of moles of reactant consumed by the reaction per unit time per unit volume of reaction vessel after all of the reagent concentrations have become constant Since is a reactant this rate is where is the contribution that the reaction makes to the rate at which the number of moles of in the reactor changes Since all of the reaction occurs within the vessel and the vessel is entirely filled with the solution is also the number of moles of consumed by reaction per unit time per unit volume of solution At steady state the number of moles of in the reactor is determined by the number of moles of entering the reactor per unit time the number of moles of being consumed by reaction per unit time and the number of moles of leaving the reactor in the effluent stream per unit time In unit time the number of moles entering with the feed is given by the number leaving with the effluent is given by In unit time the contribution that the reaction makes to the change in the number of moles of present is When the steady state is reached the number of moles entering plus the change due to reaction must equal the number of moles leaving or in unit time Solving for we have We define reaction rate so that If is produced by the reaction the massbalance equation is As with the method of initial rates the rate law is determined by measuring reaction rates in a series of experiments in which the steadystate concentrations of the various reactants and products vary For each experiment it is necessary to determine both the reaction rate and the steadystate concentration of each reagent that might be involved in the rate law Using the equation above the rate is calculated from the difference between a reagent concentration in the feed solution and its steadystate concentration in the reactor The concentration of each reagent in the effluent is the same as its concentration in the reactor so the necessary concentration information can be obtained by chemical analysis of the effluent solution The chemical analysis must be done in such a way that no significant reaction occurs between the time the material leaves the reaction vessel and the time the analysis is completed Reaction Enthalpies Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Standard Enthalpy of FormationIonization ReactionsAverage Bond EnthalpiesContributors and Attributions Reaction enthalpies are important but difficult to tabulate However because enthalpy is a state function it is possible to use Hess Law to simplify the tabulation of reaction enthalpies Hess Law is based on the addition of reactions By knowing the reaction enthalpy for constituent reactions the enthalpy of a reaction that can be expressed as the sum of the constituent reactions can be calculated The key lies in the canceling of reactants and products that Ccur in the data reactions but not in the target reaction Example Find for the reaction Given with with Solution The target reaction can be generated from the data reactions plus equals COg O_g rightarrow CO_g so Standard Enthalpy of Formation One of the difficulties with many thermodynamic state variables such as enthalpy is that while it is possible to measure changes it is impossible to measure an absolute value of the variable itself In these cases it is necessary to define a zero to the scale defining the variable For enthalpy the definition of a zero is that the standard enthalpy of formation of a pure element in its standard state is zero All other enthalpy changes are defined relative to this standard Thus it is essential to very carefully define a standard state Definition the Standard State The standard state of a substance is the most stable form of that substance at atmosphere pressure and the specified temperature Using this definition a convenient reaction for which enthalpies can be measured and tabulated is the standard formation reaction This is a reaction which forms one mole of the substance of interest in its standard state from elements in their standard states The enthalpy of a standard formation reaction is the standard enthalpy of formation Some examples are with with It is important to note that the standard state of a substance is temperature dependent For example the standard state of water at C is solid whereas the standard state at room temperature is liquid Once these values are tabulated calculating reaction enthalpies becomes a snap Consider the heat combustion of methane at C as an example The reaction can expressed as a sum of a combination of the following standard formation reactions with with with Delta H_fo kJmol The target reaction can be generated from the following combination of reactions with with H_g O_g rightarrow H_Ol with Delta H_fo colorred times left kJmol right kJmol CH_g O_g rightarrow CO_g H_Ol with Alternately the reaction enthalpy could be calculated from the following relationship where is the stoichiometric coefficient of a species in the balanced chemical reaction For the combustion of methane this calculation is beginalign Delta _rxn mol leftDelta H_foCO_right mol leftDelta H_foH_Oright mol leftDelta H_foCH_right mol kJmol mol left kJmol right mol left kJmol right kJmol endalign A note about units is in order Note that reaction enthalpies have units of kJ whereas enthalpies of formation have units of kJmol The reason for the difference is that enthalpies of formation or for that matter enthalpies of combustion sublimation vaporization fusion etc refer to specific substances andor specific processes involving those substances As such the total enthalpy change is scaled by the amount of substance used General reactions on the other hand have to be interpreted in a very specific way When examining a reaction like the combustion of methane with The correct interpretation is that the reaction of one mole of CHg with two moles of Og to form one mole of COg and two moles of HOl releases kJ at C Ionization Reactions Ionized species appear throughout chemistry The energy changes involved in the formation of ions can be measured and tabulated for several substances In the case of the formation of positive ions the enthalpy change to remove a single electron at K is defined as the ionization potential with The removal of subsequent electrons requires energies called the nd Ionization potential rd ionization potential and so on with with An atom can have as many ionization potentials as it has electrons although since very highly charged ions are rare only the first few are important for most atoms Similarly the electron affinity can be defined for the formation of negative ions In this case the first electron affinity is defined by with The minus sign is included in the definition in order to make electron affinities mostly positive Some atoms such as noble gases will have negative electron affinities since the formation of a negative ion is very unfavorable for these species Just as in the case of ionization potentials an atom can have several electron affinities with with Average Bond Enthalpies In the absence of standard formation enthalpies reaction enthalpies can be estimated using average bond enthalpies This method is not perfect but it can be used to get ballpark estimates when more detailed data is not available A bond dissociation energy is defined by with In this process one adds energy to the reaction to break bonds and extracts energy for the bonds that are formed As an example consider the combustion of ethanol In this reaction five CH bonds one CC bond and one CO bond and one OO bond must be broken Also four CO bonds and one OH bond are formed Bond Average Bond Energy kJmol CH CC CO OO CO OH The reaction enthalpy is then given by beginalign Delta H_c kJmol kJmol kJmol nonumber kJmol kJmol kJmol nonumber kJmol endalign Because the bond energies are defined for gasphase reactants and products this method does not account for the enthalpy change of condensation to form liquids or solids and so the result may be off systematically due to these differences Also since the bond enthalpies are averaged over a large number of molecules containing the particular type of bond the results may deviate due to the variance in the actual bond enthalpy in the specific molecule under consideration Typically reaction enthalpies derived by this method are only reliable to within Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Reaction Rates and Rate Laws Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Chemical reactions occur under a wide variety of circumstances Many chemicals are manufactured by passing a homogeneous mixture of gaseous reactants through a bed of solid catalyst pellets Corrosion of metals is a reaction between the solid metal and oxygen from the air often catalyzed by other common chemical species like water or chloride ion An enormous number of biological reactions occur within the cells of living organisms In the laboratory we typically initiate a reaction by mixing the reactants often with a solvent in a temperaturecontrolled vessel Chemical reactions can be carried out in batch reactors and in a wide variety of flow reactors A batch reactor is simply a container in which we initiate the reaction by mixing the reactants with one another and any additional ingredients and in which the reaction occurs and the products remainuntil we get around to removing them A reaction carried out under these conditions is called a batch reaction If any of the reactants are gases a batch reactor must be sealed to prevent their escape Otherwise we may leave the reactor open to the atmosphere as the reaction occurs Flow reactor have been designed to achieve a variety of objectives Nevertheless they have a number of characteristics in common A flow reactor is a container into which reactants and other ingredients are injected The products are recovered by withdrawing portions of the reaction mixture from one or more locations within the reactor The rates at which materials are injected or withdrawn are usually constant In the simplest case the reactants are mixed at one end of a long tube The reacting mixture flows through the tube If the tube is long enough the mixture emerging from the other end contains the equilibrium concentrations of reactants and products In such a tubular reactor it is usually a good approximation to assume that the material injected during one short time interval does not mix with the material injected during the next time interval as they pass through the tube We view the contents of the reactor as a series of fluid plugs that traverse the reactor independently of one another and call this behavior plug flow In Section we discuss another simple flow stirred tank called a continuous stirredtank reactor CSTR or a capacityflow reactor A CSTR consists of a single constantvolume vessel into which reactants are continuously injected and from which reaction mixture is continuously withdrawn The contents of this container are constantly stirred In our discussion we assume that the reactor is completely filled with a homogeneous liquid solution We express the rate of reaction within the CSTR in moles per liter of reactor volume per second When we talk about the rate of a particular reaction we intend to specify the amount of chemical change that occurs in unit time because of that reaction It is usually advantageous to specify the amount of chemical change in units of moles We can specify the amount of chemical change by specifying the number of moles of a reactant that are consumed or the number of moles of a product that are produced per second by that reaction If we do so the amount of chemical change depends on the stoichiometric coefficient of the reactant or product that we choose Moreover the rate is proportional to the size of the system Since the properties of reaction rates that are of interest to us are usually independent of the size of the system we find it convenient to express reaction rates as moles per second per unit system size so that the most convenient units are usually concentration per second For reactors containing heterogeneous catalysts we typically express the reaction rate in moles per unit volume of catalyst bed per second For corrosion of a metal surface we often express the rate in moles per unit area per second For biological reactions we might express the reaction rate in moles per gram of biological tissue per second For reactions in liquid solutions we typically express the rate in moles per liter of reaction mixture per second or Evidently we need to express the rate of a reaction in a way that accounts for the stoichiometry of the reaction and is independent of the size of the system Moreover we must distinguish the effect of the reaction on the number of moles of a reagent present from the effects of other processes because competing reactions and mechanical processes can affect the amount of a substance that is present To develop the basic idea underlying our definition of reaction rate let us consider a chemical substance that undergoes a single reaction in a closed system whose volume is For a gasphase reaction this volume can vary with time so that The volume of any open system can vary with time Since the system is closed the reaction is the is the only process that can change the amount of that is present Let be the increase in the number of moles of in a short interval that includes time Let the average rate at which the number of moles of increases in this interval be The corresponding instantaneous rate is To express this information per unit volume we can define the instantaneous rate of reaction of at time as Experimental studies of reaction rate are typically done in constantvolume closed systems under conditions in which only one reaction occurs Most of the discussion in this chapter is directed toward reactions in which these conditions are satisfied and the system comprises a single homogeneous phase In the typical case we mix reactants with a liquid solvent in a reactor and immerse the reactor in a constanttemperature bath Under these conditions the rate at which a particular substance reacts is equal to the rate at which its concentration changes Writing to designate the molarity of we have If we express a reaction rate as a rate of concentration change it is essential that both conditions be satisfied If both and vary with time we have The instantaneous rate at which substance undergoes a particular reaction is equal to only if the reaction is the sole process that changes the contribution to made by vanishes only if the volume is constant If a single reaction is the only process that occurs in a particular system the rate at which the number of moles of any reactant or product changes is a measure of the rate of the reaction However these rates depend on the stoichiometric coefficients and the size of the system For a reaction of specified stoichiometry we can use the extent of reaction to define a unique reaction rate The amounts of reactants and products present at any time are fixed by the initial conditions and the stoichiometry of the reaction Let us write to denote the number of moles of reagent present at an arbitrary time and to denote the number of moles of present at the time that the reaction is initiated We define the extent of reaction as the change in the number of moles of a product divided by the products stoichiometric coefficient or as the change in the number of moles of a reactant divided by the negative of the reactants stoichiometric coefficient For the stoichiometry we have If is the limiting reagentlimiting reagent varies from zero when the reaction is initiated with to when At any time we have and we can define a unique reaction rate as The relationship between the instantaneous rate at which reactant undergoes this reaction and the reaction rate is If the volume is constant we have and the reaction rate is The name extent of reaction is sometimes given to the fraction of the stoichiometrically possible reaction that has occurred To distinguish this meaning we call it the fractional conversion When is the stoichiometrically limiting reactant the fractional conversion is The extent of reaction and the fractional conversion are related as We have and The rate of a reaction usually depends on the concentrations of some or all of the substances involved The dependence of reaction rate on concentrations is the rate law It must be determined by experiment For reaction the observed rate law is often of the form where are small positive or negative integers or less often simple fractions We use a conventional terminology to characterize rate laws like this one We talk about the order in a chemical species and the order of the reaction To characterize the rate law above we say that the reaction is order in compound order in compound order in compound and order in compound We also say that the reaction is order overall Here is an experimentally determined parameter that we call the rate constant or rate coefficient It frequently happens that we are interested in an overall chemical change whose stoichiometric mechanism involves two or more elementary reactions In this case an exact rate model includes a differential equation for each elementary reaction Nevertheless it is often possible to approximate the rate of the overall chemical change by a single differential equation which may be a relatively complex function of the concentrations of the species present in the reaction mixture For the reaction above the experimental observation might be In such cases we continue to call the differential equation the rate law The concept of an overall order is no longer defined The constants and may or may not be rate constants for elementary reactions that are part of the overall process Nevertheless it is common to call any empirical constant that appears in a rate law a rate constant In a complex rate law the constants can often be presented in more than one way In the example above we can divide numerator and denominator by say to obtain a representation in which the constant coefficients have different values one of which is unity Most of the rest of this chapter is devoted to understanding the relationship between an observed overall reaction rate and the rates of the elementary processes that contribute to it Our principal objective is to understand chemical equilibrium rates at in terms of competing forward and reverse reactions At equilibrium chemical reactions may be occurring rapidly however no concentration changes can be observed because each reagent is produced by one set of reactions at the same rate as it is consumed by another set For the most part we focus on reactions that occur in closed constantvolume systems Real Gases Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay The van der Waals EquationThe Virial EquationThe LeonardJones PotentialThe Boyle TemperatureCritical BehaviorThe Principle of Corresponding StatesContributors and Attributions While the ideal gas law is sufficient for the prediction of large numbers of properties and behaviors for gases there are a number of times that deviations from ideality are extremely important The van der Waals Equation Several equations of state have been suggested to account for the deviations from ideality One simple but useful expression is that proposed by Johannes Diderik van der Waals Johannes Diderik van der Waals Biographical Figure Johannes van der Waals van der Waals equation introduced corrections to the pressure and volume terms of the ideal gas law in order to account for intermolecular interactions and molecular size respectively or In this expression and are variables of a given substance which can be measured and tabulated In general molecules with large intermolecular forces will have large values of and large molecules will have large values of b Some van der Waals constants are given in Table Table van der Waals constants for select Species Gas frequency of collisions a atm L mol b Lmol He N CO CH The van der Walls model is useful because it makes it so simple to interpret the parameters in terms of molecular size and intermolecular forces But it does have limitations as well as is the case of every scientific model Some other useful twoparameter and threeparameter or more equations of state include the RedlichKwong Dieterici and Clausius models Table These have the advantage that they allow for temperature dependence on some of the parameters which as will be seen later is necessary to model certain behaviors of real gases Table Other equations of State Model Equation of State Ideal van der Waals van der Waals J D RedlichKwong Redlich Kwong Dieterici Dieterici Clausius Virial Equations The Virial Equation A very handy expression that allows for deviations from ideal behavior is the Virial Equation of state This is a simple power series expansion in which the higherorder terms contain all of the deviations from the ideal gas law In the limit that BT the Second Virial Coefficient and CT are zero the equation becomes the ideal gas law Also the molar volume of gases are small the contributions from the third fourth etc terms decrease in magnitude allowing one to truncate the series at a convenient point The second virial coefficient can be predicted from a theoretical intermolecular potential function by The quality of an intermolecular potential can be determined partially by the potentials ability to predict the value of the second virial coefficient The LeonardJones Potential An intermolecular potential function is used to describe the interactions between molecules These interactions will have to include attractive forces which will draw molecules together and repulsive forces which will push them apart If the molecules are hard spheres lacking any attractive interactions the potential function is fairly simple In this function is determined by the size of the molecules If two molecules come within a distance of one another they collide bouncing off in a perfectly elastic collision Real molecules however with have a range of intermolecular separations through which they will experience attractive forces the socalled soft wall of the potential surface And then at very small separations the repulsive forces will dominate pushing the molecules apart the socalled hard wall of the potential surface A commonly used intermolecular potential is the LeonardJones potential This function has the form where governs the width of the potential well and governs the depth The distance between molecules is given by The repulsive interactions between molecules are contained in the first terms and the attractive interactions are found in the second term Figure The estimation of LennardJones potential parameters for mixed pairs of atoms CC BYSA Cnrowley Taylor Series Expansion A commonly used method of creating a power series based on another equation is the Taylor Series Expansion This is an expansion of a function about a useful reference point where each of the terms is generated by differentiating the original function For a function the Taylor series can be generated from the expression This can be applied to any equation of state to derive an expression for the virial coefficients in terms of the parameters of the equation of state Application to the van der Waals equation The van der Waals equation can be written in terms of molar volume Equation refvdw When multiplying the right hand side by where yields This expression can be Talyor expanded to the first three terms about which corresponds to an infinite molar volume The coefficient terms that are needed for the expansion are dfracdpdu big_u left dfracRTbu dfracbRTubu au right_u RT dfracdpdu big_u dfrac left dfracbRTbu dfracbRTbu dfracbRTubu au right_u RT a And the virial equation can then be expressed in terms of the van der Waals parameters as Substituting and simplifying gives the desired result And the second virial coefficient is given by The Boyle Temperature A useful way in which deviations from ideality can be expressed is by defining the compression factor given by where is the molar volume For an ideal gas under all combinations of and However real gases will show some deviation although all gases approach ideal behavior at low p high Vm and high T The compression factor for nitrogen at several temperatures is shown below over a range of pressures Figure Compressibility of select gases as a function of applied pressure As can be seen the gas behaves closer to ideally over a longer range of pressure at the higher temperatures In general there is one temperature the Boyle temperature at which a gas will approach ideal behavior as the pressure goes to zero asymptotically and thus behave ideally over a broad range of lower pressures The Boyle temperature is found by solving or Using the virial equation of state Equation refviral the Boyle temperature can be expressed in terms of the virial coefficients Starting with the compression factor and then differentiating with respect to yields So it can be concluded that at the Boyle temperature the second virial coefficient is equal to zero This should make some sense given that the first virial coefficient provides most of the deviation from the ideal gas law and so it must vanish as the gas behaves more ideally Critical Behavior The isotherms lines of constant temperature of CO reveal a very large deviation from ideal behavior At high temperatures CO behaves according to Boyles Law However at lower temperatures the gas begins to condense to form a liquid at high pressures At one specific temperature the critical temperature the isotherm begins to display this critical behavior The temperature pressure and molar volume and at this point define the critical point In order to solve for expressions for the critical constants one requires three equations The equation of state provides one relationship The second can be generated by recognizing that the slope of the isotherm at the critical point is zero And finally the third expression is derived by recognizing that the isotherm passes through an inflection point at the critical point Using the van der Waals equation as an example these three equations can be generated as follows Figure Condensation of a van der Waal gas Solving these expressions for and yields The critical variables can be used in this fashion to determine the values of the molecular parameters used in an equation of state such as the van der Waals equation for a given substance The Principle of Corresponding States The principle of corresponding states was proposed by van der Waals in van der Waals J D He noted that the compression factor at the critical point is very nearly the same for any substance This is consistent with what is predicted by the van der Waals equation which predicts irrespective of substance Further it can be noted that based on reduced variables defined by several physical properties are found to be comparable for real substances For example Guggenheim for argon krypton nitrogen oxygen carbon dioxide and methane the reduced compressibility is Also the reduced compression factor can be plotted as a function of reduced pressure for several substances at several reduced isotherms with surprising consistency irrespective of the substance Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Real Gases Versus Ideal Gases Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Now we need to expand on the qualifications with which we begin this chapter We imagine that the results of a large number of experiments are available for our analysis Our characterization of these results has been that all gases obey the same equationsBoyles law Charles law and the ideal gas equationand do so exactly This is an oversimplification In fact they are always approximations They are approximately true for all gases under all reasonable conditions but they are not exactly true for any real gas under any condition It is useful to introduce the idea of hypothetical gases that obey the classical gas equations exactly In the previous section we call the combination of Boyles law and Charles law the ideal gas equation We call the hypothetical substances that obey this equation ideal gases Sometimes we refer to the classical gas laws collectively as the ideal gas laws At very high gas densities the classical gas laws can be very poor approximations As we have noted they are better approximations the lower the density of the gas In fact experiments show that the pressurevolumetemperature behavior of any real gasreal gas becomes arbitrarily close to that predicted by the ideal gas equation in the limit as the pressure goes to zero This is an important observation that we use extensively At any given pressure and temperature the ideal gas laws are better approximations for a compound that has a lower boiling point than they are for a compound with a higher boiling point Another way of saying this is that they are better approximations for molecules that are weakly attracted to one another than they are for molecules that are strongly attracted to one another Forces between molecules cause them to both attract and repel one another The net effect depends on the distance between them If we assume that there are no intermolecular forcesintermolecular forces acting between gas molecules we can develop exact theories for the behavior of macroscopic amounts of the gas In particular we can show that such substances obey the ideal gas equation We shall see that a complete absence of repulsive forces implies that the molecules behave as point masses Evidently the difference between the behavior of a real gas and the behavior it would exhibit if it were an ideal gas is just a measure of the effects of intermolecular forces The ideal gas equation is not the only equation that gives a useful representation for the interrelation of gas pressurevolumetemperature data There are many such equations of state They are all approximations but each can be a particularly useful approximation in particular circumstances We discuss van der Waals equation equation and the virial equations later in this chapter Nevertheless we use the ideal gas equation extensively We will see that much of chemical thermodynamics is based on the behavior of ideal gases Since there are no ideal gases this may seem odd at best If there are no ideal gases why do we waste time talking about them After all we dont want to slog through tedious longwinded pointless digressions We want to understand how real stuff behaves Unfortunately this is more difficult The charm of ideal gases is that we can understand their behavior the ideal gas equation expresses this understanding in a mathematical model Real gases are another story We can reasonably say that we can best understand the behavior of a real gas by understanding how and why it is different from the behavior of a hypothetical ideal gas that has the same molecular structure Reversible and Irreversible Pathways Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Constant Volume PathwaysConstant Pressure PathwaysAdiabatic PathwaysContributors and Attributions The most common example of work in the systems discussed in this book is the work of expansion It is also convenient to use the work of expansion to exemplify the difference between work that is done reversibly and that which is done irreversibly The example of expansion against a constant external pressure is an example of an irreversible pathway It does not mean that the gas cannot be recompressed It does however mean that there is a definite direction of spontaneous change at all points along the expansion Imagine instead a case where the expansion has no spontaneous direction of change as there is no net force push the gas to seek a larger or smaller volume The only way this is possible is if the pressure of the expanding gas is the same as the external pressure resisting the expansion at all points along the expansion With no net force pushing the change in one direction or the other the change is said to be reversible or to occur reversibly The work of a reversible expansion of an ideal gas is fairly easy to calculate If the gas expands reversibly the external pressure can be replaced by a single value which represents both the pressure of the gas and the external pressure or But now that the external pressure is not constant cannot be extracted from the integral Fortunately however there is a simple relationship that tells us how changes with changing the equation of state If the gas is assumed to be an ideal gas And if the temperature is held constant so that the expansion follows an isothermal pathway the nRT term can be extracted from the integral Equation refisothermal is derived for ideal gases only a van der Waal gas would result in a different version Example Gas Expansion What is the work done by mol an ideal gas expanding reversibly from a volume of L to a volume of L at a constant temperature of K Solution Using Equation refisothermal to calculate this Note A reversible expansion will always require more work than an irreversible expansion such as an expansion against a constant external pressure when the final states of the two expansions are the same The work of expansion can be depicted graphically as the area under the pV curve depicting the expansion Comparing examples and for which the initial and final volumes were the same and the constant external pressure of the irreversible expansion was the same as the final pressure of the reversible expansion such a graph looks as follows The work is depicted as the shaded portion of the graph It is clear to see that the reversible expansion the work for which is shaded in both light and dark gray exceeds that of the irreversible expansion shaded in dark gray only due to the changing pressure of the reversible expansion In general it will always be the case that the work generated by a reversible pathway connecting initial and final states will be the maximum work possible for the expansion It should be noted although it will be proven in a later chapter that for an isothermal reversible process involving only pV work is for an ideal gas This is true because the internal energy U is a measure of a systems capacity to convert energy into work In order to do this the system must somehow store that energy The only mode in which an ideal gas can store this energy is in the translational kinetic energy of the molecules otherwise molecular collisions would not need to be elastic which as you recall was a postulate of the kinetic molecular theory And since the average kinetic energy is a function only of the temperature it and therefore can only change if there is a change in temperature Hence for any isothermal process for an ideal gas And perhaps just as usefully for an isothermal process involving an ideal gas as any energy that is expended by doing work must be replaced with heat lest the system temperature drop Constant Volume Pathways One common pathway which processes can follow is that of constant volume This will happen if the volume of a sample is constrained by a great enough force that it simply cannot change It is not uncommon to encounter such conditions with gases since they are highly compressible anyhow and also in geological formations where the tremendous weight of a large mountain may force any processes occurring under it to happen at constant volume If reversible changes in which the only work that can be done is that of expansion socalled pV work are considered the following important result is obtained However since the volume is constant As such can be expressed only in terms of the heat that flows into or out of the system at constant volume Recall that can be found by This suggests an important definition for the constant volume heat capacity which is When Equation refeq is integrated the Example Isochoric Pathway Consider mol of an ideal gas with that undergoes a temperature change from K to K at a constant volume of L Calculate and for this change Solution Since this is a constant volume process Equation refisochoric is applicable for an isochoric process Assuming is independent of temperature Since this a constant volume pathway Constant Pressure Pathways Most laboratorybased chemistry occurs at constant pressure Specifically it is exposed to the constant air pressure of the laboratory glove box or other container in which reactions are taking place For constant pressure changes it is convenient to define a new thermodynamic quantity called enthalpy or For reversible changes at constant pressure for which only pV work is done And just as in the case of constant volume changes this implies an important definition for the constant pressure heat capacity Example Isobaric Gas Expansion Consider mol of an ideal gas with that changes temperature change from K to K at a constant pressure of atm Calculate and for this change Solution assuming is independent of temperature So via Equation refheat specifically the integrated version of it using differences instead of differentials Now that and are determined then work can be calculated It makes sense that is negative since this process is an gas expansion Example Isothermal Gas Expansion Calculate and for mol of an ideal gas expanding reversibly and isothermally at K from a volume of L and a pressure of atm to a volume of L and a pressure of atm Solution Since this is an isothermal expansion Equationrefisothermal is applicable Since this is an isothermal expansion where due to Boyles Law Adiabatic Pathways An adiabatic pathway is defined as one in which no heat is transferred Under these circumstances if an ideal gas expands it is doing work against the surroundings provided the external pressure is not zero and as such the internal energy must drop And since is negative there must also be a decrease in the temperature How big will the decrease in temperature be and on what will it depend The key to answering these questions comes in the solution to how we calculate the work done If the adiabatic expansion is reversible and done on an ideal gas and Equating these two terms yields Using the ideal gas law for an expression for And rearranging to gather the temperature terms on the right and volume terms on the left yields This expression can be integrated on the left between and and on the right between and Assuming that is independent of temperature over the range of integration it can be pulled from the integrand in the term on the right The result is or or or Once is known it is easy to calculate and Example mol of an ideal gas CV R initially occupies L at K The gas expands adiabatically and reversibly to a final volume of L Calculate and for the expansion Solution Since the pathway is adiabatic Using Equation refEqAlternative So For calculating work we integrate Equation refAdiabate to get The following table shows recipes for calculating and for an ideal gas undergoing a reversible change along the specified pathway Table Thermodynamics Properties for a Reversible Expansion or Compression Pathway Isothermal Isochoric Isobaric adiabatic Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Reversible Motion of A Mass in A Constant Gravitational Field Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Let us explore our ideas about reversibility further by considering the familiar case of a bowling ball ball that can move vertically in the effectively constant gravitational field near the surface of the earth We begin by observing that we develop our description by abstracting from reality We consider idealized models because we want to develop theories that capture the most important features of real systems We ignore less important features In the present example we know that the behavior of the bowling ball will be slightly influenced by its frictional interaction with the surrounding atmosphere We attribute these interactions to a property of air that we call viscosity We assume that this effect can be ignored This causes no difficulty so long as our experiments are too insensitive to observe the effects of this atmospheric drag If necessary of course we could do our experiments inside a vacuum chamber so that the system we study experimentally better meets the assumptions we make in our analysis Alternatively we could expand our theory to include the effects of atmospheric drag To raise an initially stationary bowling ball to a greater height requires that we apply a vertical upward force that exceeds the downward gravitational force on the ball Let height increase in the upward direction and let and be the height and vertical velocity of the ball at time Let the mass of the ball be and let the ball be at rest at time zero Representing the initial velocity and height as and we have and Letting the gravitational acceleration be the gravitational force on the ball is To raise the ball we must apply a vertical force that makes the net force on the ball greater than zero That is we require so that If is constant is constant we find for the height and velocity of the ball at any later time and Let us consider the state of the system when the ball reaches a particular height Let the corresponding time velocity kinetic energy and potential energy at be and respectively Since and we have tau lefth_Srightfracmv_S fracmleftfracf_netmrightt_S f_neth_S The energy we must supply to move the ball from height zero to is equal to the work done by the surroundings on the ball The increase in the energy of the ball is At this input energy is present as the kinetic and potential energy of the ball We have where the kinetic and potential energies are and respectively The ball rises only if the net upward force is positive Then the ball arrives at with a nonzero velocity and kinetic energy If we make smaller and smaller it takes the ball longer and longer to reach when it arrives its velocity and kinetic energy are smaller and smaller However no matter how long it takes the ball to reach when it arrives its potential energy is Now let us consider the energy change in a process in which the ball begins at rest at height zero and ends at rest at At the end we have To effect this change in a real system we must apply a net upward force to the ball to get it moving later we must apply a net downward force to slow the ball in such a way that its velocity becomes zero at exactly the time that it reaches There are infinitely many ways we could apply forces to meet these conditions The net change in the balls energy is the same for all of them We find it useful to use a hypothetical process to calculate this energy change In this hypothetical process the upward force is always just sufficient to oppose the gravitational force on the ball That is so that and from the development above and Of course This is a hypothetical process because the ball would not actually move under these conditions We see that the hypothetical process is the limiting case in a series of real processes in which we make smaller and smaller In all of these processes the potential energy change is If the ball is stationary and the ball remains at rest whatever its height If we make the ball rises If we make the ball falls If and the ball is moving only slowly in either direction a very small change in can be enough to reverse the direction of motion These are the characteristics of a reversible process an arbitrarily small change in the applied force changes the direction of motion The advantage of working with the hypothetical reversible process is that the integral of the applied force over the distance through which it acts is the change in the potential energy of the system While we cannot actually carry out a reversible process we can compute the work that must be done if we know the limiting force that is required in order to effect the change This is true because the velocity and kinetic energy of the ball are zero throughout the process When the process is reversible the change in the potential energy of the ball is equal to the work done on the ball we have Gravitational potential energy is an important factor in some problems of interest in chemistry Other forms of potential energy are important much more often Typically our principal interest is in the potential energy change associated with a change in the chemical composition of a system We are seldom interested in the kinetic energy associated with the motion of a macroscopic system as a whole We can include effects that arise from gravitational forces or from the motion of the whole system in our thermodynamic models but we seldom find a need to do so For systems in which the motion of the whole system is important the laws of mechanics are usually sufficient we find out what we want to know about such systems by solving their equations of motion When we discuss the first law of thermodynamics we write or for the energy change that accompanies some physical change in a system Since chemical applications rarely require that we consider the location of the system or the speed with which it may be moving usually encompasses only work that changes the energy of the system itself Then designates the energy of the macroscopic system itself As noted earlier we often recognize this by calling the energy of the system its internal energy Some writers use the symbol to represent the internal energy intending thereby to make it explicit that the energy under discussion is independent of the systems location and motion Reversible vs Irreversible PressureVolume Work Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers In Section we consider heat transfer in reversible processes Similar considerations apply to the exchange of work between a system and its surroundings When we use a piston to compress a gas in a cylinder we must apply sufficient inward force on the piston to overcome the outward force applied by the gas In any real system it is necessary also to overcome the force of friction in order to slide the piston into the cylinder We ignore friction imagining that we can make its effects arbitrarily small The gas can be compressed only if the applied pressure exceeds the gas pressure If the applied pressure equals the gas pressure the piston remains stationary If the applied pressure is greater than the gas pressure by any eversosmall amount the gas will be compressed Conversely if the applied pressure is infinitesimally less than the gas pressure the gas will expand The work done under such conditions is reversible work an arbitrarily small change in the relative pressures can reverse the direction in which the piston moves We summarize these conditions by saying that reversible pressurevolume work can occur only if the system and its surroundings are at mechanical equilibrium Now let us think about calculating the reversible work for isothermally compressing a gas by sliding a piston into a cylinder In any real experiment we must have and any real experiment is necessarily irreversible In a reversible experiment we have and the reversible work is For one mole of an ideal gas we have Since the temperature is constant the reversible isothermal work becomes where and are the initial and final volumes of the gas respectively This has a straightforward graphical interpretation For an ideal gas at constant temperature is inversely proportional to As sketched in Figure the reversible work corresponds to the area between this curve and the abscissa and between the initial and the final gas volumes Figure Reversible versus irreversible expansion of an ideal gas In contrast an irreversible expansion corresponds to movement of the piston when or equivalently Therefore the work done on the gas is less in the reversible case than it is in the irreversible case Both work terms are less than zero The absolute value of the reversible work is greater than the absolute value of the irreversible work From our definitions of reversible and irreversible pressurevolume work we have and so long as the initial and final states are the same in the irreversible process as they are in the reversible constanttemperature process The shaded area in Figure represents the work done on the gas when the applied pressure is instantaneously decreased to the final pressure attained by the gas in the reversible process For the reversible process the pressurevolume curve accurately depicts the state of the gas as the volume increase takes place The temperature of the gas is constant along this curve While we can trace a similar line of pressurevolume points for the irreversible expansion this line does not define a set of intermediate states that the system occupies during the irreversible expansion The state of the gas is well defined only in the equilibrium state that precedes the irreversible pressure drop and in the equilibrium state that the system ultimately attains It is convenient to describe these two processes as a reversible process and a spontaneous process that take the system from the same initial state to the same final state However this language obscures a significant point In the initial state for the reversible process we have In the initial state for the spontaneous process we have and What we mean of course is that the values of all of the state functions for the hypothetical initial state of the spontaneous process are the same as those for the equilibrium initial state of the reversible process So long as we can say that the process takes the system from the same initial state to the same final state a similar argument can be made for reversible and irreversible work of any kind Whatever the force the isothermal reversible work done on the system is always less than the irreversible work for taking the system between the same two states This is an important result In Chapter we find that it is a logical consequence of the second law of thermodynamics Finally let us consider a reversible process in which a system completes a pressurevolume cycle The system traverses a closed path in the pressurevolume plane Such a path is depicted in Figure We let the smallest and largest volumes reached during the cycle be and respectively The closed path is composed of a highpressure segment and a lowpressure segment that meet at and On each of these segments the pressure is a function of volume We let pressures on the high and lowpressure segments be and respectively In the interval we have At the limiting volumes we have and The system temperature varies continuously around the closed path The work done on the system as it traverses the highpressure segment from to is represented in Figure by area Figure Reversible pressurevolume work in a cycle We have The work done on the system as it traverses the lowpressure segment from to is represented by area We have When the lowpressure segment is traversed in the opposite direction we have When the system traverses the cycle in the counterclockwise direction the net work done on the system is Thus the net work done on the system is represented on the graph by the area which is just the negative area in the pressurevolume plane that is bounded by the closed path Reversible vs Irreversible Processes Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers When we think about a physical system that is undergoing a reversible change we imagine that the system passes through a series of states In each of these states every thermodynamic variable has a welldefined value in every phase of the system We suppose that successive states of the changing system are arbitrarily close to one another in the sense that the successive values of every thermodynamic are arbitrarily close to one another These suppositions are equivalent to assuming that the state of the system and the value of every thermodynamic variable are continuous functions of time Then every thermodynamic variable is either constant or a continuous function of other thermodynamic variables When we talk about a reversible process we have in mind a physical system that behaves in this way and in which an arbitrarily small change in one of the thermodynamic variables can reverse the direction in which other thermodynamic variables change A process that is not reversible is said to be irreversible We distinguish between two kinds of irreversible processes A process that cannot occur under a given set of conditions is said to be an impossible process A process that can occur but does not do so reversibly is called a possible process or a spontaneous process Another essential characteristic of a reversible process is that changes in the system are driven by conditions that are imposed on the system by the surroundings In our discussion of the phase equilibria of water we note that the surroundings can transfer heat to the system only when the temperature of the surroundings is greater than that of the system However if the process is to be reversible this temperature difference must be arbitrarily small so that heat can be made to flow from the system to the surroundings by an arbitrarily small decrease in the temperature of the surroundings Similar considerations apply when the process involves the exchange of work between system and surroundings We focus on changes in which the work exchanged between system and surroundings is pressurevolume work A process can occur reversibly only if the pressure of the system and the pressure applied to the system by the surroundings differ by an arbitrarily small amount To abbreviate these statements we customarily introduce a figure of speech and say that for a reversible process or and that or Since a reversible process involves a complementary exchange of energy increments between system and surroundings it is evident that an isolated system cannot undergo a reversible change Any change that occurs in an isolated system must be spontaneous By the contrapositive an isolated system that cannot undergo change must be at equilibrium While and are necessary conditions for a reversible process they are not sufficient A spontaneous process can occur under conditions in which the system temperature is arbitrarily close to the temperature of the surroundings and the system pressure is arbitrarily close to the applied pressure Consider a mixture of hydrogen and oxygen in a cylinder closed by a frictionless piston We suppose that the surroundings are maintained at a constant temperature and that the surroundings apply a constant pressure to the piston We suppose that the system contains a small quantity of a poorly effective catalyst By controlling the activity of the catalyst we can arrange for the formation of water to occur at an arbitrarily slow ratea rate so slow that the temperature and pressure gradients that occur in the neighborhood of the catalyst are arbitrarily small Nevertheless the reaction is a spontaneous process not a reversible one If the process were reversible an arbitrarily small increase in the applied pressure would be sufficient to reverse the direction of reaction causing water to decompose to hydrogen and oxygen Rotations of Molecules Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Rotational Motion For Rigid Diatomic and Linear Polyatomic Molecules Rotational Motions of Rigid NonLinear Moleculesa The Rotational Kinetic Energyb The Eigenfunctions and Eigenvalues for Special Casesi Spherical Topsii Symmetric Topsiii Asymmetric TopsContributors and Attributions Rotational Motion For Rigid Diatomic and Linear Polyatomic Molecules This Schrdinger equation relates to the rotation of diatomic and linear polyatomic molecules It also arises when treating the angular motions of electrons in any spherically symmetric potential A diatomic molecule with fixed bond length rotating in the absence of any external potential is described by the following Schrdinger equation frachbarmu left fracRsinthetafracpartialpartial theta leftsintheta fracpartialpartial theta right fracRsintheta fracpartialpartial phi right psi E psi or where is the square of the total angular momentum operator expressed in polar coordinates above The angles and describe the orientation of the diatomic molecules axis relative to a laboratoryfixed coordinate system and is the reduced mass of the diatomic molecule The differential operators can be seen to be exactly the same as those that arose in the hydrogenlikeatom case discussed earlier in this Chapter Therefore the same spherical harmonics that served as the angular parts of the wave function in the hydrogenatom case now serve as the entire wave function for the socalled rigid rotor These are exactly the same functions as we plotted earlier when we graphed the and orbitals The energy eigenvalues corresponding to each such eigenfunction are given as E_J frachbar JJmu R B JJ and are independent of Thus each energy level is labeled by and is fold degenerate because ranges from to Again this is just like we saw when we looked at the hydrogen orbitals the p orbitals are fold degenerate and the d orbitals are fold degenerate The socalled rotational constant defined as depends on the molecules bond length and reduced mass Spacings between successive rotational levels which are of spectroscopic relevance because as shown in Chapter angular momentum selection rules often restrict the changes in that can occur upon photon absorption to and are given by These energy spacings are of relevance to microwave spectroscopy which probes the rotational energy levels of molecules In fact microwave spectroscopy offers the most direct way to determine molecular rotational constants and hence molecular bond lengths The rigid rotor provides the most commonly employed approximation to the rotational energies and wave functions of linear molecules As presented above the model restricts the bond length to be fixed Vibrational motion of the molecule gives rise to changes in which are then reflected in changes in the rotational energy levels ie there are different values for different vibrational levels The coupling between rotational and vibrational motion gives rise to rotational constants that depend on vibrational state as well as dynamical couplings called centrifugal distortions which cause the total rovibrational energy of the molecule to depend on rotational and vibrational quantum numbers in a nonseparable manner Within this rigid rotor model the absorption spectrum of a rigid diatomic molecule should display a series of peaks each of which corresponds to a specific transition The energies at which these peaks occur should grow linearly with as shown above An example of such a progression of rotational lines is shown in the Figure Figure Typical rotational absorption profile showing intensity vs value of the absorbing level The energies at which the rotational transitions occur appear to fit the formula rather well The intensities of transitions from level to level vary strongly with primarily because the population of molecules in the absorbing level varies with These populations are given when the system is at equilibrium at temperature in terms of the degeneracy of the Jth level and the energy of this level by the Boltzmann formula where is the rotational partition function For low values of the degeneracy is low and the factor is near unity As increases the degeneracy grows linearly but the factor decreases more rapidly As a result there is a value of given by taking the derivative of with respect to and setting it equal to zero at which the intensity of the rotational transition is expected to reach its maximum This behavior is clearly displayed in the above figure The eigenfunctions belonging to these energy levels are the spherical harmonics which are normalized according to int_piint_piY_LMthetaphiY_LMthetaphisintheta dtheta dphi delta_LL delta_mmprime As noted above these functions are identical to those that appear in the solution of the angular part of Hydrogenic atoms The above energy levels and eigenfunctions also apply to the rotation of rigid linear polyatomic molecules the only difference is that the moment of inertia I entering into the rotational energy expression which is for a diatomic is given by where ma is the mass of the atom and is its distance from the center of mass of the molecule to this atom Rotational Motions of Rigid NonLinear Molecules a The Rotational Kinetic Energy The classical rotational kinetic energy for a rigid polyatomic molecule is where the are the three principal moments of inertia of the molecule the eigenvalues of the moment of inertia tensor This tensor has elements in a Cartesian coordinate system whose origin is located at the center of mass of the molecule that can be computed as I_KK sum_j m_j R_j R_Kj hspacecm textfor K K I_KK sum_j m_j R_Kj R_Kj hspacecm textfor K ne K As discussed in more detail in R N Zare Angular Momentum John Wiley New York the components of the corresponding quantum mechanical angular momentum operators along the three principal axes are The angles and are the Euler angles needed to specify the orientation of the rigid molecule relative to a laboratoryfixed coordinate system The corresponding square of the total angular momentum operator can be obtained as textbfJ textbfJ_a textbfJ_b textbfJ_c hbar fracpartialpartial theta hbarcottheta fracpartialpartial theta hbar fracsintheta leftfracpartialpartial phi fracpartialpartial chi costhetafracpartialpartial phipartial chi right and the component along the lab fixed axis is as we saw much earlier in this text b The Eigenfunctions and Eigenvalues for Special Cases i Spherical Tops When the three principal moment of inertia values are identical the molecule is termed a spherical top In this case the total rotational energy can be expressed in terms of the total angular momentum operator As a result the eigenfunctions of are those of and as well as both of which commute with and with one another is the component of along the labfixed axis and commutes with because and act on different angles The energies associated with such eigenfunctions are EJKM frachbar JJI for all ie quantum numbers ranging from to in unit steps and for all ie quantum numbers ranging from to Each energy level is therefore degenerate because there are possible values and possible values for each The eigenfunctions of and are given in terms of the set of socalled rotation matrices which obey textbfJ_a JMKrangle hbar K JMKrangle These functions are proportional to the spherical harmonics multiplied by which reflects its cdependence ii Symmetric Tops Molecules for which two of the three principal moments of inertia are equal are called symmetric tops Those for which the unique moment of inertia is smaller than the other two are termed prolate symmetric tops if the unique moment of inertia is larger than the others the molecule is an oblate symmetric top An American football is prolate and a Frisbee is oblate Again the rotational kinetic energy which is the full rotational Hamiltonian can be written in terms of the total rotational angular momentum operator and the component of angular momentum along the axis with the unique principal moment of inertia Here the moment of inertia I denotes that moment that is common to two directions that is I is the nonunique moment of inertia As a result the eigenfunctions of are those of and or and of and the corresponding energy levels are EJKM frachbar JJI hbar K leftfracI_a fracIright for prolate tops EJKM frachbar JJI hbar K leftfracI_c fracIright for oblate tops again for and ie or and quantum numbers respectively ranging from to in unit steps Since the energy now depends on these levels are only degenerate due to the different values that arise for each value Notice that for prolate tops because is smaller than the energies increase with increasing for given In contrast for oblate tops since is larger than the energies decrease with for given The eigenfunctions are the same rotation matrix functions as arise for the sphericaltop case so they do not require any further discussion at this time iii Asymmetric Tops The rotational eigenfunctions and energy levels of a molecule for which all three principal moments of inertia are distinct a socalled asymmetric top cannot analytically be expressed in terms of the angular momentum eigenstates and the and quantum numbers In fact no one has ever solved the corresponding Schrdinger equation for this case However given the three principal moments of inertia and a matrix representation of each of the three contributions to the rotational Hamiltonian can be formed within a basis set of the rotationmatrix functions discussed earlier This matrix will not be diagonal because the functions are not eigenfunctions of the asymmetric top However the matrix can be formed in this basis and subsequently brought to diagonal form by finding its eigenvectors and its eigenvalues The vector coefficients express the asymmetric top eigenstates as Because the total angular momentum still commutes with each such eigenstate will contain only one value and hence can also be labeled by a quantum number psi_nJ thetaphichi sum_M K C_n JMK J M Krangle To form the only nonzero matrix elements of within the basis one can use the following properties of the rotationmatrix functions see for example R N Zare Angular Momentum John Wiley New York hbar sqrtJJ KK sqrtJJ K K Each of the elements of and must of course be multiplied respectively by and and summed together to form the matrix representation of The diagonalization of this matrix then provides the asymmetric top energies and wave functions Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Simultaneous Processes Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers The number of moles of a substance in a system can change with time because several processes occur simultaneously Not only can a given substance participate in more than one reaction but also the amount of it that is present can be affected by processes that are not chemical reactions A variety of transport process can operate to increase or decrease the amount of the substance that is present in the reaction mixture A pure solid reactant could dissolve in a reacting solution or a product could precipitate from it as the reaction proceeds A reacting species could diffuse into a reactor across a semipermeable membrane Controlled amounts of a reacting species could be added either continuously or at specified intervals Each of the simultaneous processes contributes to the change in the number of moles of present At every instant each of these contributions can be characterized by a rate Over a short time interval let be the contribution that the process makes to the change in the amount of in volume If even though the process may not be a reaction we use to represent its rate its contribution to the rate at which the amount of changes is If there are numerous such processes whose rates are the observed overall rate is If the volume is constant and To illustrate these ideas let us consider the base hydrolyses of methyl and ethyl iodide No intermediates are observed in these reactions If we carry out the base hydrolysishydrolysisethyl iodide of methyl iodide in a closed constantvolume system we can express the reaction rate in several equivalent ways If a mixture of methyl and ethyl iodide is reacted with aqueous base both hydrolysis reactions consume hydroxide ion and produce iodide ion The rates of these individual processes can be expressed as and but the rates at which the concentrations of hydroxide ion and iodide ion change depend on the rates of both reactions We have In principle either of the reaction rates can be measured by finding the change over a short time interval in the number of moles of a particular substance present Simultaneous processes occur when a reaction does not go to completion The hydrolysis of ethyl acetate can reach equilibrium before the limiting reactant is completely consumed The reaction rate defined as falls to zero However ethyl acetate molecules continue to undergo hydrolysis the extent of reaction becomes constant because ethyl acetate molecules are produced from acetic acid and ethanol at the same rate as they are consumed by hydrolysis Evidently the rate of the forward reaction does not fall to zero even though the net reaction rate does Let represent the number of moles of ethyl acetate undergoing hydrolysis per unit time per unit volume Let represent the number of moles of ethyl acetate being produced per unit time per unit volume The net rate of consumption of ethyl acetate is At equilibrium and In such cases it can be ambiguous to refer to the reaction or the rate of reaction The rates of the forward and of the net reaction are distinctly different things So long as no intermediate species accumulate to significant concentrations in the reaction mixture we can find the forward and reverse rates for a reaction like this at any particular equilibrium composition in a straightforward way When we initiate reaction with no acetic acid or ethanol present the rate of the reverse reaction must be zero We can find the rate law for the forward reaction by studying the rate of the hydrolysis reaction when the product concentrations are low Under these conditions and From the rate law that we find and the equilibrium concentrations we can calculate the rate of the forward reaction at equilibrium Likewise when the ethyl acetate concentration is low the rate of the hydrolysis reaction is negligible in comparison to that of the esterification reaction We have and and we can find the rate law for the esterification reaction by studying the rate of the esterification reaction when the concentration of ethyl acetate is negligible From this rate law we can calculate the rate of the reverse reaction at the equilibrium concentrations Single Component Phase Diagrams Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay No headers The stability of phases can be predicted by the chemical potential in that the most stable form of the substance will have the minimum chemical potential at the given temperature and pressure This can be summarized in a phase diagram like the one shown below In this diagram the phase boundaries can be determined by measuring the rate of cooling at constant temperature A typical cooling curve is shown below The temperature will decrease over time as a sample is allowed to cool When the substance undergoes a phase change say from liquid to solid the temperature will stop changing while heat is extracted due to the phase change The temperature at which the halt occurs provides one point on the boundary at the temperature of the halt and the pressure at which the cooling curve was measured The same data can be obtained by heating the system using a technique such as scanning calorimetry In this experiment heat is supplied to a sample at a constant rate and the temperature of the sample is measured with breaks occurring at the phase change temperatures SolidLiquid Systems Eutectic Points Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Incongruent MeltingContributors and Attributions A phase diagram for two immiscible solids and the liquid phase which is miscible in all proportions is shown in Figure The point labeled e is the eutectic point meaning the composition for which the mixture of the two solids has the lowest melting point The four main regions can be described as below Twophase solid Solid mostly A and liquid A and B Solid mostly B and liquid A and B Single phase liquid A and B Figure Phase diagram of a twocomponent system that exhibits an eutectic point The unlabeled regions on the sides of the diagram indicate regions where one solid is so miscible in the other that only a single phase solid forms This is different than the twophase solid region where there are two distinct phases meaning there are regions crystals perhaps that are distinctly A or B even though they are intermixed within on another Region I contains two phases a solid phase that is mostly compound A and a liquid phase which contains both A and B A sample in region II such as the temperaturecomposition combination depicted by point b will consist of two phases is a liquid mixture of A and B with a composition given by that at point a and the other is a single phase solid that is mostly pure compound B but with traces of A entrained within it As always the lever rule applies in determining the relative amounts of material in the two phases In the case where the widths of the small regions on either side of the phase diagram are negligibly small a simplified diagram with a form similar to that shown in Figure can be used In this case it is assumed that the solids never form a single phase The tinlead system exhibits such behavor Figure A simplified phase diagram of a twocomponent system that exhibits an eutectic point Another important case is that for which the two compounds A and B can react to form a third chemical compound C If the compound C is stable in the liquid phase does not decompose upon melting the phase diagram will look like Figure Figure A simplified phase diagram of a twocomponent system that exhibits an eutectic point In this diagram the vertical boundary at is indicative of the compound formed by and From the mole fraction of it is evident that the formula of compound is The reaction that forms compound C is Thus at overall compositions where there is excess compound A B is the limiting reagent and for there is an excess of compound is now the limiting reagent With this in mind the makeup of the sample in each region can be summarized as Two phase solid A and C Two phase solid C and B Solid A and liquid A and C Solid C and liquid A and C Solid C and liquid C and B Solid B and liquid C and B liquid Single phase liquid A and C or C and B depending on which is present in excess Zinc and Magnesium are an example of two compounds that demonstrate this kind of behavior with the third compound having the formula Ghosh MezbahulIslam Medraj Incongruent Melting Oftentimes the stable compound formed by two solids is only stable in the solid phase In other words it will decompose upon melting As a result the phase diagram will take a lightly different form as is shown in Figure Figure A phase diagram of a twocomponent system that exhibits incongruent melting In this diagram the formula of the stable compound is consistent with But you will notice that the boundary separating the two twophase solid regions does not extend all of the way to the single phase liquid portion of the diagram This is because the compound will decompose upon melting The process of decomposition upon melting is also called incongruent melting The makeup of each region can be summarized as Two phase solid A and C Two phase solid C and B Solid A and liquid A and B Solid C and liquid A and B Solid B and liquid A and B There are many examples of pairs of compounds that show this kind of behavior One combination is sodium and potassium which form a compound that is unstable in the liquid phase and so it melts incongruently Rossen Bleiswijk Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Solubility Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors and Attributions The maximum solubility of a solute can be determined using the same methods we have used to describe colligative properties The chemical potential of the solute in a liquid solution can be expressed If this chemical potential is lower than that of a pure solid solute the solute will dissolve into the liquid solvent in order to achieve a lower chemical potential So the point of saturation is reached when the chemical potential of the solute in the solution is equal to that of the pure solid solute Since the mole fraction at saturation is of interest we can solve for The difference in the chemical potentials is the molar Gibbs function for the phase change of fusion So this can be rewritten It would be convenient if the solubility could be expressed in terms of the enthalpy of fusion for the solute rather than the Gibbs function change Fortunately the GibbsHelmholtz equation gives us a means of making this change Noting that Differentiation of the above expression for with respect to at constant yields Separating the variables puts this into an integrable form that can be used to see how solubility will vary with temperature So if the enthalpy of fusion is constant over the temperature range of to the temperature of interest And will give the mole fraction of the solute in a saturated solution at the temperature The value depends on both the enthalpy of fusion and the normal melting point of the solute Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Solubility of Ionic Compounds Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors and Attributions The solubility of ionic compounds in water can also be described using the concepts of equilibrium If you consider the dissociation of a generic salt MX The equilibrium expression is is the solubility product and is the equilibrium constant that describes the solubility of an electrolyte And again the pure solid MX is not included in the expression since it has unit activity throughout the establishment of equilibrium Example What is the maximum solubility of CuS at C Solution Yup time for an ICE table Initial Change x x Equilibrium x x So the equilibrium expression is Example Common Ion What is the maximum solubility of at C in M NaS with Solution In this problem we need to consider the existence of Saq from the complete dissociation of the strong electrolyte NaS An ICE table will help as usual Initial M Change x x Equilibrium x M x Given the miniscule magnitude of the solubility product x will be negligibly small compared to MS the equilibrium expression is The huge reduction in solubility is due to the common ion effect The existence of sulfide in the solution due to sodium sulfide greatly reduces the solutions capacity to support additional sulfide due to the dissociation of Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Solutions Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Contributions Solutions a First determine the eigenvalues det l l l l l l l l l l or l Next determine the eigenvectors First the eigenvector associated with eigenvalue C C C C C Note The second row offers no new information eg C C C C C from normalization C C C C C C C and therefore C For the eigenvector associated with eigenvalue C C C C C C C again the second row offers no new information C C from normalization C C C C C C C and therefore C Therefore the eigenvector matrix becomes b First determine the eigenvalues det det det From a the solutions then become and Next determine the eigenvectors First the eigenvector associated with eigenvalue the third root C C row one C C C C row two C C C C again the third row offers no new information C C C from normalization C C C C and therefore C Next find the pair of eigenvectors associated with the degenerate eigenvalue of First root one eigenvector one C C no new information from row one C C C row two C C again the third row offers no new information C C C from normalization C C C C C C Second root two eigenvector two C C no new information from row one C C C row two C C again the third row offers no new information C C C from normalization C C C C C C C Note again two equations in three unknowns CC CC CC from orthogonalization Now there are five equations with six unknowns Arbitrarily choose C whenever there are degenerate eigenvalues there are not unique eigenvectors because the degenerate eigenvectors span a or more dimensional space not two unique directions One always is then forced to choose one of the coefficients and then determine all the rest different choices lead to different final eigenvectors but to identical spaces spanned by these eigenvectors C C C C CC CC CC from orthogonalization C C C C and C Therefore the eigenvector matrix becomes a KE KE KE KE b p mv ipx jpy kpz p where i j and k are unit vectors along the x y and z axes c Ly zpx xpz Ly z x First derive the general formulas for in terms of rq and f and and in terms of xy and z The general relationships are as follows x r Sinq Cosf r x y z y r Sinq Sinf sinq z r Cosq cosq tanf First and from the chain rule yz yz yz xz xz xz xy xy xy Evaluation of the many coefficients gives the following yz Sinq Cosf yz yz xz Sinq Sinf xz xz xy Cosq xy and xy Upon substitution of these coefficients Sinq Cosf Sinq Sinf and Cosq Next and from the chain rule qf qf qf rf rf rf and rq rq rq Again evaluation of the the many coefficients results in qf qf qf rf rf rf rq y rq x and rq Upon substitution of these coefficients y x Note these many coefficients are the elements which make up the Jacobian matrix used whenever one wishes to transform a function from one coordinate representation to another One very familiar result should be in transforming the volume element dxdydz to rSinqdrdqdf For example a Lx Lx Lx b Lz i Lz B dBdx dBdx i x x x x x ii x x x iii ex ex ex ex ex ex iv x x x v x x x x Bv is an eigenfunction of Ai x x Bv x x x x x x x x x x x x eigenvalue is Biii is an eigenfunction of Aii Biii ex ex eigenvalue is Bii is an eigenfunction of Aiii x Bii x x x x eigenvalue is Bi is an eigenfunction of Avi x Bi x x x x x x x x x x x eigenvalue is Biv is an eigenfunction of Av x x Biv x x x x x x x x x x x eigenvalue is i In ammonia the only core orbital is the N s and this becomes an a orbital in Cv symmetry The N s orbitals and H s orbitals become a and an e set of orbitals The remaining N p orbitals also become a and a set of e orbitals The total valence orbitals in Cv symmetry are a and e orbitals ii In water the only core orbital is the O s and this becomes an a orbital in Cv symmetry Placing the molecule in the yz plane allows us to further analyze the remaining valence orbitals as O pz a O py as b and O px as b The H s H s combination is an a whereas the H s H s combination is a b iii Placing the oxygens of HO in the yz plane z bisecting the oxygens and the cis hydrogens distorted slightly in x and x directions allows us to analyze the orbitals as follows The core O s O s combination is an a orbital whereas the O s O s combination is a b orbital The valence orbitals are O s O s a O s O s b O px O px b O px O px a O py O py a O py O py b O pz O pz b O pz O pz a H s H s a and finally the H s H s b iv For the next two problems we will use the convention of choosing the z axis as principal axis for the Dh Dh and Cv point groups and the xy plane as the horizontal reflection plane in Cs symmetry Dh Dh Cv Cs N s sg ag a a N s sg ag a a N px pxu bu b a N py pyu bu b a N pz su bu a a a Ynx Sin Pnxdx dx The probability that the particle lies in the interval x is given by Pn This integral can be integrated to give Pn Pn Pn fq Sin b If n is even Sin and Pn If n is odd and n Sin and Pn If n is odd and n Sin and Pn The higher Pn is when n Then Pn Pn c Yt e aYne bYme HY aYnEne bYmEme aEn bEm abe bae Since and are zero aEn bEm note the time independence d The fraction of systems observed in Yn is a The possible energies measured are En and Em The probabilities of measuring each of these energies is a and b e Once the system is observed in Yn it stays in Yn f PEn cn cn xLxdx dx These integrals can be evaluated to give cn LLbfLnp LbfxLnp cn Cosnp Cos cn L Cosnp Cosnp cn cn cn cn If n is even then cn If n is odd then cn The probability of making a measurement of the energy and obtaining one of the eigenvalues given by En is PEn if n is even PEn if n is odd g ohLfx CieeCj Since Ejdij CjCjEje For other properties CieeCj but does not necessarily ajdij because the Yj are not eigenfunctions of A unless AH CiCje Therefore in general other properties are time dependent a The lowest energy level for a particle in a dimensional box is when n n and n The total energy with L L L will be Etotal Note that n is not possible The next lowest energy level is when one of the three quantum numbers equals and the other two equal n n n n n n n n n Each of these three states have the same energy Etotal Note that these three states are only degenerate if L L L b       L L L L  L L For L L L V LLL L EtotalL e e For L  L L V LLL LL L VL EtotalL e e In comparing the total energy at constant volume of the undistorted box L L L versus the distorted box L  L L it can be seen that as long as L  L c In order to minimize the total energy expression take the derivative of the energy with respect to L and set it equal to zero But since V LLL LL then L VL This substitution gives L V L V LL L L L L d Calculate energy upon distortion cube V L L L L V distorted V LL LL L L  L L DE EtotalL L L EtotalL  L L Since V  V  x cm and x erg cm DE x erg cm DE x erg cm DE x erg DE x erg DE eV a H Cartesian coordinates Finding andfrom the chain rule gives y y x x Evaluation of the coefficients gives the following y Cosf y x Sinf and x Upon substitution of these coefficients Cosf at fixed r Sinf at fixed r at fixed r at fixed r at fixed r So H cylindrical coordinates fixed r The Schrdinger equation for a particle on a ring then becomes HY EY EF F The general solution to this equation is the now familiar expression Ff Ceimf Ceimf where m Application of the cyclic boundary condition Ff Ffp results in the quantization of the energy expression E where m It can be seen that the m values correspond to angular momentum of the same magnitude but opposite directions Normalization of the wavefunction over the region to p corresponding to or m will result in a value of for the normalization constant Ff eimf       b x erg cm x erg DE x erg x erg but DE hn hcl So l hcDE l x cm x  Sources of error in this calculation include i The attractive force of the carbon nuclei is not included in the Hamiltonian ii The repulsive force of the other pelectrons is not included in the Hamiltonian iii Benzene is not a ring iv Electrons move in three dimensions not one Yf Cosf This wavefunction needs to be expanded in terms of the eigenfunctions of the angular momentum operator This is most easily accomplished by an exponential expansion of the Cos function Yf The wavefunction is now written in terms of the eigenfunctions of the angular momentum operator but they need to include their normalization constant Yf Once the wavefunction is written in this form in terms of the normalized eigenfunctions of the angular momentum operator having mas eigenvalues the probabilities for observing angular momentums of and can be easily identified as the squares of the coefficients of the corresponding eigenfunctions P P P a mv eV v v x cmsec The length of the N molecule is  x cm v t x sec b The normalized ground state harmonic oscillator can be written as Y eax where a and x r re Calculating constants aN x cm  For N Yr er aN x cm  For N Yr er c Pv Let Pv I where I integral I erdr Let C  C  A  A  r  r  I CCdr Focusing on the exponential ArrArr Ar rr r Ar rr r A Ar Ar Arr Ar Ar Let A A A B Ar Ar C CC and D Ar Ar I Cdr Cdr where Arr D Ar Br D Ar rr r D Ar Br D such that Ar B Ar D D and r D Ar D A D D I Cdr CeDdy CeD Now back substituting all of these constants I CCexp I exp exp I Pv I so there is a probability a En DE En En x erg DE l x cm cm b Y eax eax  Dx x x x cm  c Dx The smaller k and m become the larger the uncertainty in the internuclear distance becomes Helium has a small m and small attractive force between atoms This results in a very large Dx This implies that it is extremely difficult for He atoms to vibrate with small displacement as a solid even as absolute zero is approached a W W e Making this substitution results in the following three integrals W a a W a b Optimize b by evaluating b So b or b and b Substituting this value of b into the expression for W gives W a a pam pam am am am which is in error by only a H kx f a for a x a f for x  a a a a a a adx a aosupaa aakosupa a a a a a a b Substituting a binto the above expression for E we obtain E km c E and mka So a or a Therefore fbest and Ebest km d a H y y Ylmqf ll Ylmqf E ll b V eez eerCosq E eer Using the given identity this becomes E eer eer The spherical harmonics are orthonormal thus and E E eer Using the given identity this becomes eer eer This indicates that the only term contributing to the sum in the expression for Eis when l and m otherwise vanishes from orthonormality In quantum chemistry when using orthonormal functions it is typical to write the term as a delta function for example dlm which only has values of or dij when i j and when i  j This delta function when inserted into the sum then eliminates the sum by picking out the nonzero component For example dlm so E E and E Inserting these energy expressions above yields E c E E E E a d a a r xcm r  aH  aCs  The above diagram indicates how the SALCAOs are formed from the ss and p N atomic orbitals It can be seen that there are sg su pux puy pgx and pgy SALCAOs The Hamiltonian matrices Fock matrices are given Each of these can be diagonalized to give the following MO energies sg and hartrees su and pux puy pgx pgy It can be seen that the sg orbitals are bonding the su orbitals are antibonding the pux and puy orbitals are bonding and the pgx and pgy orbitals are antibonding Using these approximate energies we can draw the following MO diagram This MO diagram is not an orbital correlation diagram but can be used to help generate one The energy levels on each side C and H can be superimposed to generate the reactant side of the orbital correlation diagram and the center CH levels can be used to form the product side Ignoring the core levels this generates the following orbital correlation diagram a The two F p orbitals top and bottom generate the following reducible representation Dh E C C sh S sv Gp This reducible representation reduces to A and A irreducible representations Projectors may be used to find the symmetryadapted AOs for these irreducible representations fa fa b The three trigonal F p orbitals generate the following reducible representation Dh E C C sh S sv Gp This reducible representation reduces to A and E irreducible representations Projectors may be used to find the symmetryadapted AOs for these irreducible representations but they are exactly analogous to the previous few problems fa fe f f f fe c The P sp orbitals generate the following reducible representation Dh E C C sh S sv Gsp This reducible representation reduces to A and E irreducible representations Again projectors may be used to find the symmetryadapted AOs for these irreducible representations fa fe fe The leftover P pz orbital generate the following irreducible representation Dh E C C sh S sv Gpz This irreducible representation is A fa f Drawing an energy level diagram using these SALCAOs would result in the following a For nondegenerate point groups one can simply multiply the representations since only one representation will be obtained a  b b Constructing a box in this case is unnecessary since it would only contain a single row Two unpaired electrons will result in a singlet S MS and three triplets S MS S MS S MS The states will be BMS BMS BMS and BMS b Remember that when coupling nonequivalent linear molecule angular momenta one simple adds the individual Lz values and vector couples the electron spin So in this case pupu we have ML values of and and The term symbol D is used to denote the spatially doubly degenerate level ML and there are two distinct spatially nondegenerate levels denoted by the term symbol S ML Again two unpaired electrons will result in a singlet S MS and three triplets S MSS MSS MS The states generated are then D ML one state MS D ML one state MS D ML three states MS and D ML three states MS and S ML one state MS S ML one state MS S ML three states MS and and S ML three states MS and c Constructing the box for two equivalent p electrons one obtains ML MS papa papb papb papb From this box one obtains six states D ML one state MS D ML one state MS S ML one state MS S ML three states MS and d It is not necessary to construct a box when coupling nonequivalent angular momenta since vector coupling results in a range from the sum of the two individual angular momenta to the absolute value of their difference In this case dd L and S The term symbols are G G F F D D P P S and S The L and S angular momenta can be vector coupled to produce further splitting into levels J L S L S Denoting J as a term symbol subscript one can identify all the levels and subsequent J states G states G states G states G states F states F states F states F states D states D states D states D states P states P states P state P states S states and S state e Construction of a box for the two equivalent d electrons generates note the box has been turned side ways for convenience MS ML dadb dada dadb dbda dada dadb dbda dadb dada dada dadb dbda dadb dbda dada dada dadb dbda dadb dbda dadb The term symbols are G F D P and S The L and S angular momenta can be vector coupled to produce further splitting into levels G states F states F states F states D states P states P states P state and S state a Once the spatial symmetry has been determined by multiplication of the irreducible representations the spin coupling gives the result b There are three states here aaba and abbb c aaab a All the Slater determinants have in common the sasbsasb core and hence this component will not be written out explicitly for each case PMLMS papa apza PMLMS papa aa ipxapya PMLMS papa apza As you can see the symmetries of each of these states cannot be labeled with a single irreducible representation of the Cv point group For example pxapza is xz B and pyapza is yz B and hence the PMLMS state is a combination of B and B symmetries But the three PMLMS functions are degenerate for the C atom and any combination of these three functions would also be degenerate Therefore we can choose new combinations that can be labeled with pure Cv point group labels PxzMS pxapza B PyxMS pyapxa A PyzMS pyapza B Now we can do likewise for the five degenerate D states DMLMS papb ab DMLMS papb ab DMLMS DMLMS DMLMS ab Analogous to the three P states we can also choose combinations of the five degenerate D states which can be labeled with pure Cv point group labels DxxyyMS pxapxb pyapyb A DyxMS pxapyb pyapxb A DzxMS pzapxb pzbpxa B DzyMS pzapyb pzbpya B DzzxxyyMS DMLMS A The only state left is the S SMLMS ab Each of the components of this state are A and hence this state has A symmetry b Forming symmetryadapted AOs from the C and H atomic orbitals would generate the following The bonding nonbonding and antibonding orbitals of CH can be illustrated in the following manner c d e It is necessary to determine how the wavefunctions found in part a correlate with states of the CH molecule PxzMS B sgspxpz  snpps PyxMS A sgspxpy  snpps PyzMS B sgspypz  snss DxxyyMS A  snpp sns DyxMS A  snspp DzxMS B  snspp DzyMS B  snss DzzxxyyMS A  sns snpp sns Note the C H state to which the lowest A sns CH state decomposes would be sgspy This state sgspy cannot be obtained by a simple combination of the D states In order to obtain pure sgspy it is necessary to combine S with D For example sgspy This indicates that a configuration correlation diagram must be drawn with a barrier near the D asymptote to represent the fact that A CH correlates with a mixture of D and S carbon plus hydrogen The C H state to which the lowest B snspp CH state decomposes would be sgspypx f If you follow the B component of the CP H since it leads to the groundstate products to B CH you must go over an approximately Kcalmole barrier Of course this path produces B CH product Distortions away from Cv symmetry for example to Cs symmetry would make the a and b orbitals identical in symmetry a The b orbitals would maintain their different symmetry going to a symmetry Thus B and A both A in Cs symmetry and odd under reflection through the molecular plane can mix The system could thus follow the A component of the CP H surface to the place marked with a circle on the CCD where it crosses the B surface upon which it then moves and continues to products As a result the barrier would be lowered You can estimate when the barrier occurs late or early using thermodynamic information for the reaction ie slopes and asymptotic energies For example an early barrier would be obtained for a reaction with the characteristics and a late barrier would be obtained for a reaction with the characteristics This relation between reaction endothermicity or exothermicity and the character of the transition state is known as the Hammond postulate Note that the CP H CH reaction of interest here has an early barrier g The reaction CD H CH A should have no symmetry barrier this can be recognized by following the A CD H reactants down to the A CH products This problem in many respects is analogous to problem The B surface certainly requires a two configuration CI wavefunction the ssnpx ppyspx and the snpxs pspxpz The A surface could use the ssn pspy only but once again there is no combination of D determinants which gives purely this configuration pspy Thus mixing of both D and S determinants are necessary to yield the required pspy configuration Hence even the A surface would require a multiconfigurational wavefunction for adequate description Configuration correlation diagram for the reaction CH C CH a CCl is tetrahedral and therefore is a spherical top CHCl has Cv symmetry and therefore is a symmetric top CHCl has Cv symmetry and therefore is an asymmetric top b CCl has such high symmetry that it will not exhibit pure rotational spectra because it has no permanent dipole moment CHCl and CHCl will both exhibit pure rotation spectra NH is a symmetric top oblate Use the given energy expression E A B K B JJ A cm B cm selection rules DJ and the fact that lies along the figure axis such that DK to give DE B J B B and B J and So lines are at cm cm and cm To convert between cm and energy multiply by hc xJ secxcm sec x J cm Let all quantities in cm be designated with a bar eg cm a hc Re m x x kg x kg hc hc cm x J Re Re x m  De x cm wexe cm D D cm eV ae cm B Be ae cm B Be ae cm b The molecule has a dipole moment and so it should have a pure rotational spectrum In addition the dipole moment should change with R and so it should have a vibrationrotation spectrum The first three lines correspond to J J J E wev wexev BvJJ DeJJ DE we wexe BJJ BJJ DeJ JJ JJ J JJ JJ xJ JJ JJ xJ cm cm cm The CHCl molecule has a sh plane of symmetry plane of molecule a C axis to the molecular plane and inversion symmetry this results in Ch symmetry Using Ch symmetry the modes can be labeled as follows n n n n and n are ag n and n are au n is bg and n n n and n are bu Molecule I Molecule II RCH  RCH  HCH HCH yH R Sin q yH zH R Cos q zH Center of MassCOM clearly X Y Z Z a Ixx MY Z Ixy MXY Ixx Ixx Iyy Iyy Izz Izz Ixz Iyz Ixy b Since the moment of inertia tensor is already diagonal the principal moments of inertia have already been determined to be Ia Ib Ic Iyy Izz Ixx Iyy Izz Ixx Using the formula A X A cm similarly B cm and C cm So Molecule I Molecule II y  A y  A z  B z  B x  C x  C c Averaging B C B B C B B C A B A B Using the prolate top formula E A B K B JJ Molecule I Molecule II E K JJ E K JJ Levels J and K J For a given level defined by J and K there are MJ degeneracies given by J x d Molecule I Molecule II e Assume molecule I is CH and molecule II is CH Then DE EJjCH EJiCH where ECH K JJ and ECH K JJ For Rbranches Jj Ji DK DER EJjCH EJiCH Ji Ji JiJi Ji Ji Ji Ji Ji Ji Ji For Pbranches Jj Ji DK DEP EJjCH EJiCH Ji Ji JiJi JiJi Ji Ji Ji JiJi This indicates that the R branch lines occur at energies which grow closer and closer together as J increases since the Ji term will cancel The P branch lines occur at energies which lie more and more negative ie to the left of the origin So you can predict that if molecule I is CH and molecule II is CH then the Rbranch has a band head and the Pbranch does not This is observed therefore our assumption was correct molecule I is CH and molecule II is CH f The band head occurs when Ji Ji Ji Ji so J or At J DER J J DER cm above the origin a Dh E C C C C C i S S sh sd sv Ag xyz Ag Rz Bg Bg Eg RxRy xzyz Eg xyxy Au Au z Bu Bu Eu xy Eu GCH b The number of irreducible representations may be found by using the following formula nirrep where g the order of the point group for Dh nAg nAg nBg nBg nEg nEg nAu nAu nBu nBu nEu nEu We see that GCH AgEgBuEu c x and y  Eu z  Au so the ground state Ag level can be excited to the degenerate Eu level by coupling through the x or y transition dipoles Therefore Eu is infrared active and polarized d x y z  Ag xz yz  Eg x y xy  Eg so the ground state Ag level can be excited to the degenerate Eg level by coupling through the x y or xy transitions or be excited to the degenerate Ag level by coupling through the xz or yz transitions Therefore Ag and Eg are Raman active e The Bu mode is not IR or Raman active a Evaluate the zcomponent of mfi mfi pze r Cosqs where ys e and ypz r Cosq e mfi r Cosq e e r Cosqe r Cosq e e r Cosqe Cosq p p Cosqsupp p b Examine the symmetry of the integrands for pz e x s and pz e y s Consider reflection in the xy plane Function Symmetry pz x s y Under this operation the integrand of pz e x s is it is antisymmetric and hence pz e x s Similarly under this operation the integrand of pz e y s is it is also antisymmetric and hence pz e y s c tR Ei Epz Z Ef Es Z Ei Ef Z Making the substitutions for Ei Ef and mfi in the expression for tR we obtain tR Inserting e we obtain tR x x sec x So for example Atom tR H ns He ps Li ps Be ps Ne fs a H H lHt Ht Vqt Hjk Ekjk wk Ek i Hy let yrt iand insert into the Schrdinger equation ieiwjtjj ijj eiwjtjj eiwjt im eiwmt eiwjt So m eiwjmt Going back a few equations and multiplying from the left by jk instead of jm we obtain eiwjt ik eiwkt eiwjt So k eiwjkt Now let cm cm cml cml ck ck ckl ckl and substituting into above we obtain m ml ml lHmj eiwjmt first order m  cm second order m nst order mn Similarly first order k  ckm second order k nst order kn So m cm Hmm eiwmmt Hmm cmt and similarly k cm Hkm eiwmkt Hkm eiwmkt ckt Vkm m m Hmj eiwjmt Hmm cm eiwjmt t Similarly k Hkj eiwjkt Hkm eiwmkt ckt eiwjkt eiwmkt heiwmk heiwmk So the overall amplitudes cm and ck to second order are cmt t ckt eiwmkt b The perturbation equations still hold mn kn So cm and ck m Hmm cm Vmm k Hkm eiwmkt ck Vkm m eiwmjht Vmj eht eiwjmt Vmm eht cm eht eht k eiwmjht Hkj eiwjkt Hkm eiwmkt ck Therefore to second order cmt eht ckt c In part a the ct grow linearly with time for Vmm while in part b they remain finite for h The result in part a is due to the sudden turning on of the field d ckt ckt Now look at the limit as h ckt  when Em Ek limha dEmEk So the final result is the nd order golden rule expression ckt dEmEklimh a Tnm evaluating sVs using only the radial portions of the s and s wavefunctions since the spherical harmonics will integrate to unity where V er the change in Coulomb potential when tritium becomes He sVs e e rdr sVs sVs sVs Now En Es Es Es Es So Tnm for Z b jmr js e Y The orthogonality of the spherical harmonics results in only sstates having nonzero values for Anm We can then drop the Y integrating this term will only result in unity in determining the value of Ass ynr ys e Remember for js Z and for ys Z Anm e e rdr Anm e rdr Anm We obtain Anm Anm Anm Anm The transition probability is the square of this amplitude Tnm for Z The difference in these two results parts a and b will become negligible at large values of Z when the perturbation becomes less significant than in the case of Z is along Z lab fixed and is along z the CI molecule fixed bond The angle between Z and z is b emCosb emD So I DD Sinbdbdgda emSinbdbdgda Now use DD to obtain I emSinbdbdgda Now use Sinbdbdgda dJjdMmdKn to obtain I emdJjdMmdKn emJMJMJKJK We use JKJK and JMJM to give I em empiJMJK empiMK The J symbols vanish unless K K and M M So I empiMKdMMdKK b and vanish unless J J J J DJ The K quantum number can not change because the dipole moment lies along the molecules C axis and the lights electric field thus can exert no torque that twists the molecule about this axis As a result the light can not induce transitions that excite the molecules spinning motion about this axis a B atom ssp P ground state L S gives a degeneracy LS of O atom ssp P ground state L S gives a degeneracy LS of The total number of states formed is then b We need only consider the p orbitals to find the low lying molecular states Which in reality look like this This is the correct ordering to give a S ground state The only lowlying electron configurations are ps or ps These lead to P and S states respectively c The bond orders in both states are d The S is but gu symmetry cannot be specified since this is a heteronuclear molecule e Only one excited state the P is spinallowed to radiate to the S Consider symmetries of transition moment operators that arise in the electric dipole contributions to the transition rate z S xy P the P S is electric dipole allowed via a perpendicular band f Since ionization will remove a bonding electron the BO bond is weaker than the BO bond g The ground state BO is S corresponding to a p electron configuration An electron configuration of p s leads to a P and a P state The P will be lower in energy A p s configuration will lead to higher lying states of S D and S h There should be bands corresponding to formation of BO in the S P and P states Since each of these involves removing a bonding electron the FranckConden integrals will be appreciable for several vibrational levels and thus a vibrational progression should be observed a The bending p vibration is degenerate b HCN  bending fundamental c HCN  stretching fundamental d CH stretch n in figure is s CN stretch is s and HCN n in figure bend is p e Under z s light the CN stretch and the CH stretch can be excited since y s y s and z s provides coupling f Under xy p light the HCN bend can be excited since y s y p and xy p provides coupling g The bending vibration is active under xy perpendicular polarized light DJ are the selection rules for transitions The CH stretching vibration is active under z polarized light DJ are the selection rules for transitions F fi ei fj h fi fi Let the closed shell Fock potential be written as Vij and the e component as hij fi  fj and the delta as dij so that hij Vij dijei using fi fj and fk and transforming from the MO to AO basis we obtain Vij CmiCgkCnjCkk Vmn where Vmn Pgk and Pgk hij hmn where hmn cm  cn and dij So hij Vij dijej becomes hmn Vmn ej ej hmn Vmn for all ij CmiCnj for all ij Therefore Cnj This is FC SCE in the AO basis The Slater Condon rule for zero spin orbital difference with N electrons in N spin orbitals is E If all orbitals are doubly occupied and we carry out the spin integration we obtain E where i and j now refer to orbitals not spinorbitals If the occupied orbitals obey Ffk ekfk then the expression for E in problem can be rewritten as E We recognize the closed shell Fock operator expression and rewrite this as E I will use the QMIC software to do this problem Lets just start from the beginning Get the starting guess MO coefficients on disk Using the program MOCOEFS it asks us for the first and second MO vectors We input for the first mo this means that the first MO is times the He s orbital plus times the H s orbital this bonding MO is more likely to be heavily weighted on the atom having the higher nuclear charge and for the second Our beginning LCAOMO array looks like and is placed on disk in a file we choose to call mocoefsdat We also put the AO integrals on disk using the program RW_INTS It asks for the unique one and two electron integrals and places a canonical list of these on disk in a file we choose to call ao_integralsdat At this point it is useful for us to step back and look at the set of equations which we wish to solve FC SCE The QMIC software does not provide us with a socalled generalized eigenvalue solver one that contains an overlap matrix or metric so in order to use the diagonalization program that is provided we must transform this equation FC SCE to one that looks like FC CE We do that in the following manner Since S is symmetric and positive definite we can find an Ssuch that SS SS S etc rewrite FC SCE by inserting unity between FC and multiplying the whole equation on the left by S This gives SFSSC SSCE SCE Letting F SFS C SC and inserting these expressions above give FC CE Note that to get the next iterations MO coefficients we must calculate C from C C SC so multiplying through on the left by Sgives SC SSC C This will be the method we will use to solve our fock equations Find Sby using the program FUNCT_MAT this program generates a function of a matrix This program will ask for the elements of the S array and write to disk a file name of your choice a good name might be shalf containing the Sarray Now we are ready to begin the iterative Fock procedure a Calculate the Fock matrix F using program FOCK which reads in the MO coefficients from mocoefsdat and the integrals from ao_integralsdat and writes the resulting Fock matrix to a user specified file a good filename to use might be something like fock b Calculate F SFSusing the program UTMATU which reads in F and Sfrom files on the disk and writes F to a user specified file a good filename to use might be something like fockp Diagonalize F using the program DIAG This program reads in the matrix to be diagonalized from a user specified filename and writes the resulting eigenvectors to disk using a user specified filename a good filename to use might be something like coefp You may wish to choose the option to write the eigenvalues Fock orbital energies to disk in order to use them at a later time in program FENERGY Calculate C by using C SC This is accomplished by using the program MATXMAT which reads in two matrices to be multiplied from user specified files and writes the product to disk using a user specified filename a good filename to use might be something like mocoefsdat c The QMIC program FENERGY calculates the total energy khk klkl kllk and ek khk This is the conclusion of one iteration of the Fock procedure you may continue by going back to part a and proceeding onward d and e Results for the successful convergence of this system using the supplied QMIC software are as follows this data is provided to give the student assurance that they are on the right track alternatively one could switch to the QMIC program SCF and allow that program to iteratively converge the Fock equations The oneelectron AO integrals The twoelectron AO integrals The initial MOAO coefficients AO overlap matrix S S ITERATION The charge bond order matrix The Fock matrix F S F S The eigenvalues of this matrix Fock orbital energies are Their corresponding eigenvectors C S C are The new MOAO coefficients C S C The oneelectron MO integrals The twoelectron MO integrals The closed shell Fock energy from formula khk klkl kllk from formula ek khk the difference is ITERATION The charge bond order matrix The Fock matrix S F S The eigenvalues of this matrix Fock orbital energies are Their corresponding eigenvectors C S C are The new MOAO coefficients C S C The oneelectron MO integrals The twoelectron MO integrals The closed shell Fock energy from formula khk klkl kllk from formula ek khk the difference is ITERATION The charge bond order matrix The Fock matrix S F S The eigenvalues of this matrix Fock orbital energies are Their corresponding eigenvectors C S C are The new MOAO coefficients C S C The oneelectron MO integrals The twoelectron MO integrals The closed shell Fock energy from formula khk klkl kllk from formula ek khk the difference is ITERATION The charge bond order matrix The Fock matrix S F S The eigenvalues of this matrix Fock orbital energies are Their corresponding eigenvectors C S C are The new MOAO coefficients C S C The oneelectron MO integrals The twoelectron MO integrals The closed shell Fock energy from formula khk klkl kllk from formula ek khk the difference is ITERATION The charge bond order matrix The Fock matrix S F S The eigenvalues of this matrix Fock orbital energies are Their corresponding eigenvectors C S C are The new MOAO coefficients C S C The oneelectron MO integrals The twoelectron MO integrals The closed shell Fock energy from formula khk klkl kllk from formula ek khk the difference is ITERATION The charge bond order matrix The Fock matrix S F S The eigenvalues of this matrix Fock orbital energies are Their corresponding eigenvectors C S C are The new MOAO coefficients C S C The oneelectron MO integrals The twoelectron MO integrals The closed shell Fock energy from formula khk klkl kllk from formula ek khk the difference is ITERATION The charge bond order matrix The Fock matrix S F S The eigenvalues of this matrix Fock orbital energies are Their corresponding eigenvectors C S C are The new MOAO coefficients C S C The oneelectron MO integrals The twoelectron MO integrals The closed shell Fock energy from formula khk klkl kllk from formula ek khk the difference is ITERATION The charge bond order matrix The Fock matrix S F S The eigenvalues of this matrix Fock orbital energies are Their corresponding eigenvectors C S C are The new MOAO coefficients C S C The oneelectron MO integrals The twoelectron MO integrals The closed shell Fock energy from formula khk klkl kllk from formula ek khk the difference is f In looking at the energy convergence we see the following Iter Formula Formula If you look at the energy differences SCF at iteration n SCF converged and plot this data versus iteration number and do a th order polynomial fit we see the following In looking at the polynomial fit we see that the convergence is primarily linear since the coefficient of the linear term is much larger than those of the cubic and higher terms g The converged SCF total energy calculated using the result of problem is an upper bound to the ground state energy but during the iterative procedure it is not Only at convergence does the expectation value of the Hamiltonian for the Hartree Fock determinant become equal to that given by the equation in problem h Yes the s configuration does dissociate properly because at at R the lowest energy state is He H which also has a s orbital occupancy ie s on He and s on H At convergence the MO coefficients are f f and the integrals in this MO basis are h h h g g g g g g a H b The eigenvalues are E and E The corresponding eigenvectors are C C c a b d The third configuration ss Adding this configuration to the previous x CI results in the following x full CI H Evaluating the new matrix elements H H H H H e The eigenvalues are E E and E The corresponding eigenvectors are C C C f We need the nonvanishing matrix elements of the dipole operator in the MO basis These can be obtained by calculating them by hand They are more easily obtained by using the TRANS program Put the e AO integrals on disk by running the program RW_INTS In this case you are inserting z z and z insert for all the e integrals call the output file ao_dipoleints for example The converged MOAO coefficients should be in a file mocoefsdat is fine The transformed integrals can be written to a file name of your choice for example mo_dipoleints These matrix elements are z z z The excitation energies are E E and E E Using the SlaterConden rules to obtain the matrix elements between configurations we obtain Hz Now YzY CTHzC this can be accomplished with the program UTMATU T and YzY CTHzC T g Using the converged coefficients the orbital energies obtained from solving the Fock equations are e and e The resulting expression for the PT firstorder wavefunction becomes s s s s s s h As you can see from part c the matrix element sHss this is also a result of the Brillouin theorem and hence this configuration does not enter into the firstorder wavefunction i s s To normalize we divide by s s In the x CI we obtained s s j The expression for the nd order RSPT is E au Comparing the x CI energy obtained to the SCF result we have au STO total energy STOG total energy G total energy The STOG orbitals were generated as a best fit of primitive Gaussians giving CGTO to the STO So STOG can at best reproduce the STO result The G orbitals are more flexible since there are CGTOs per atom This gives orbitals more parameters to optimize and a lower total energy R HeH Energy H Energy Plotting total energy vs geometry for HeH Plotting total energy vs geometry for H For HeH at R au the eigenvalues of the converged Fock matrix and the corresponding converged MOAO coefficients are E E E E E E E E E E E E E E E E E E E E Notice that this indicates that orbital is a combination of the s functions on He only dissociating properly to He H For H at R au the eigenvalues of the converged Fock matrix and the corresponding converged MOAO coefficients are E E E E E E E E E E E E E E E E E E E E Notice that this indicates that orbital is a combination of the s functions on both H atoms dissociating improperly equal probabilities of H dissociating to two neutral atoms or to a proton plus hydride ion The H CI result R Sg Su Su Sg For H at R au the eigenvalues of the Hamiltonian matrix and the corresponding determinant amplitudes are determinant sgasgb sgbsua sgasub suasub This shows as expected the mixing of the first Sg sg and the nd Sg su determinants in the first and fourth states and the Su and Su states as the second and third states Also notice that the first Sg state has coefficients note specifically the combination and the second Sg state has the opposite coefficients with the same signs note specifically the combination The combination always gives a higher energy than the combination F atoms have ssp P ground electronic states that are split by spinorbit coupling into P and P states that differ by only eV in energy a The degeneracy of a state having a given J is J and the J state is lower in energy because the p orbital shell is more than half filled I learned this in inorganic chemistry class so qel expkT exp eVkT eV is equivalent to k K so kT T hence qel expkT expT b Q qNN so ln Q N lnq lnN E kT lnQT NkT lnqT Nk expT expT c Using the fact that kTeV at TK make a qualitative graph of N vs T for T ranging from K to K At T K EN is small and equal to k exp exp At T K EN has grown to k exp exp which is approximately k a The difference between a linear and bent transition state would arise in the vibrational and rotational partition functions For the linear TS one has N vibrations recall that one loses one vibration as a reaction coordinate but for the bent TS one has N vibrations For the linear TS one has rotational axes and for the bent TS one has So the ratio of rate constants will reduce to ratios of vibration and rotation partition functions In particular one will have klinearkbent qvibN qrotqvibNqrot qvibqrot b Using qt qr qv I would expect klinearkbent to be of the order of Constructing the Slater determinant corresponding to the state sasa with the rows labeling the orbitals and the columns labeling the electron gives sasa Starting with the MS S state which in a box for this ML MS case would contain only one product function sasa and applying S gives S SSMS SSMS SSMS sasa Ssasa Ssasa sbsa sasb So SSMS SSMS The three triplet states are then SSMS sasa SSMS and SSMS sbsb The singlet state which must be constructed orthogonal to the three singlet states and in particular to the SSMS state can be seen to be SSMS Applying S and Sz to each of these states gives Sz sasa sasa Szsasa Szsasa sasa sasa sasa S sasa SS Sz Sz sasa SSsasa Szsasa Szsasa sasa sasa sasa Sz sbsa sasb sbsa sasb S SS Sz Sz SS Sz sbsb sbsb Szsbsb Szsbsb sbsb sbsb sbsb S sbsb SS Sz Sz sbsb SSsbsb Szsbsb Szsbsb sbsb sbsb sbsb Sz sbsa sasb sbsa sasb S SS Sz Sz SS As shown in problem c for two equivalent p electrons one obtains six states D ML one state MS D ML one state MS S ML one state MS and S ML three states MS and By inspecting the box in problem c it should be fairly straightforward to write down the wavefunctions for each of these D ML papb D ML papb S ML S ML MS papa S ML MS S ML MS pbpb We can conveniently couple another s electron to the states generated from the ss configuration SL S with sL S giving L S S states and S states SL S with sL S giving L S S states Constructing a box for this case would yield ML MS sasasa sasasb sasbsa sbsasa One can immediately identify the wavefunctions for two of the quartets they are single entries SSMS sasasa SSMS sbsbsb Applying S to SSMS yields SSSMS SSMS SSMS Ssasasa So SSMS Applying S to SSMS yields SSSMS SSMS SSMS Ssbsbsb So SSMS It only remains to construct the doublet states which are orthogonal to these quartet states Recall that the orthogonal combinations for systems having three equal components for example when symmetry adapting the sp hybrids in Cv or Dh symmetry give results of and Notice that the quartets are the combinations and therefore the doublets can be recognized as SSMS SSMS SSMS SSMS As illustrated in problem a p configuration two equivalent p electrons gives rise to the term symbols P D and S Coupling an additional electron d to this p configuration will give the desired sspd term symbols PLS with DLS generates L and S with term symbols F FD DP and P DLS with DLS generates L and Swith term symbols G F D P and S SLS with DLS generates L and Swith term symbol D The notation used for the Slater Condon rules will be as follows a zero spin orbital difference b one spin orbital difference fp  fp fpp c two spin orbital differences fp  fp and fq  fq gpqpq gpqqp d three or more spin orbital differences i PMLMS papa H Using the Slater Condon rule a above I will denote these SCaSCd f f g g ii PMLMS Evaluating each matrix element gives faa fbb gabab gabba SCa f f g gabba gabab SCc g gbaab gbaba SCc g fbb faa gbaba gbaab SCa f f g Substitution of these expressions give f f g f f g g iii SMLMS Evaluating each matrix element gives faa fbb gabab gabba SCa f f g gabab gabba SCc g gabab gabba SCc g faa fbb gabab gabba SCa f f g gabab gabba SCc g faa fbb gabab gabba SCa f f g Substitution of these expressions give g g g g f f g iv DMLMS Evaluating we note that all the Slater Condon matrix elements generated are the same as those evaluated in part iii the signs for the wavefunction components and the multiplicative factor of two for one of the components however are different f g g g g f f g i DMLMS papb faa fbb gabab gabba SCa f f g f g ii SMLMS Evaluating each matrix element gives faa fbb gabab gabba SCa f f g gabba gabab SCc g gbaab gbaba SCc g fbb faa gbaba gbaab SCa f f g Substitution of these expressions give f f g g iii SMLMS f f g gabba gabab SCc g gbaab gbaba SCc g fbb faa gbaba gbaab SCa f f g Substitution of these expressions give f f g g The order of the answers is J I G K B D E A C H F p NVNb N akTV but pkT lnQVTN so we can integrate to obtain ln Q lnQ  pkT dV  NVNb N akTV dV N lnVNb NakT V So Q VNbexpakT NVN a MD because you need to keep track of how far the molecule moves as a function of time and MC does not deal with time b MC is capable of doing this although MD is also However MC requires fewer computational steps so I would prefer to use it c MC can do this as could MD Again because MC needs fewer computational steps Id use it Suppose you are carrying out a MonteCarlo simulation involving Ar atoms Further suppose that the potentials are pairwise additive and that your computer requires approximately floating point operations FPOs eg multiply add divide etc to compute the interaction potential between any pair of atoms d For each MC move we must compute only the change in potential energy To do this we need to compute only the change in the pair energies that involve the atom that was moved This will require x FPOs the being the number of atoms other than the one that moved So for a million MC steps I would need x x FPOs At x FPOs per second this will require seconds or a little over eight minutes e Because the statistical fluctuations in MC calculations are proportional to N where N is the number of steps taken I will have to take times as many steps to cut the statistical errors in half So this will require x seconds or seconds f If we have one million rather than one thousand atoms the second calculation of part d would require times as much time This ratio arises because the time to compute the change in potential energy accompanying a MC move is proportional to the number of other atoms So the calculation would take x seconds or about seconds or about hours g We would be taking s s per step MD steps Each step requires that we compute all forcesVRIJ between all pairs of atoms There are x such pairs So to compute all the forces would require xx FPOs x FPOs So we will need x FPOsstep x steps FPOs per second x seconds or about hours h The graduate student is times slower than the Mflop computer so it will take herhim times as long so x seconds or about years First Na has a S ground state term symbol whose degeneracy is S Na has a S ground state whose degeneracy is The symmetry number for Na is s The D value given is kcal mol The Kp equilibrium constant would be given in terms of partial pressures as and then using pVNkT Kp pNapNa kT qNaVqNaV in terms of the partition functions a qNa pmkTh V qel qNA pmkTh V pIkTh exphnkT exphnkT expDekT We can combine the De and the hnkT to obtain the D which is what we were given b For Na I will use cgs units in all cases qV p x x x x x For Na qN x x exp expDkT x x x x So Kp x x x x dynes cm atm The differences in krate will arise from differences in the number of translational rotational and vibrational partition functions arising in the adsorbed and gasphase species Recall that krate kTh expEkT qTSVqNOV qClV In the gas phase NO has translations two rotations and one vibration Cl has translations two rotations and one vibration the NOCl TS which is bent has translations three rotations and five vibrations recall that one vibration is missing and is the reaction coordinate In the adsorbed state NO has translations one rotation and three vibrations Cl has translations one rotation and three vibrations the NOCl TS which is bent has translations one rotation and eight vibrations again one vibration is missing and is the reaction coordinate So in computing the partition function ratio qTSVqNOV qClV for the adsorbed and gasphase cases one does not obtain the same number of translational rotational and vibrational factors In particular the ratio of these factors for the adsorbed and gasphase cases gives the ratio of rate constants as follows kadkgas qtransVqvib which should be of the order of using the ratio of partition functions as given Notice that this result suggests that reaction rates can be altered by constraining the reacting species to move freely in lower dimensions even if one does not alter the energetics eg activation energy or thermochemistry Contributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Some Important Applications of Statistical Mechanics Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah GasMolecule Thermodynamics Einstein and Debye Models of Solids Lattice Theories of Surfaces and Liquids Virial Corrections to IdealGas BehaviorContributors and Attributions In this Section I introduce several applications of statistical mechanics that are important for students to be aware of because they arise frequently when chemists make use of the tools of statistical mechanics These examples include The basic equations connecting the translational rotational vibrational and electronic properties of isolated ie gasphase molecules to their thermodynamics The most basic descriptions of the vibrations of ions atoms or molecules within crystals The most elementary models for describing cooperative behavior and phase transitions in gassurface and liquidliquid systems The contributions of intermolecular forces to the thermodynamics of gases GasMolecule Thermodynamics The equations relating the thermodynamic variables to the molecular partition functions can be employed to obtain the following expressions for the energy heat capacity Helmholz free energy entropy and chemical potential in the case of a gas ie in the absence of intermolecular interactions of polyatomic molecules dfracANkT ln leftleftdfracpi mkThbarright dfracV_eNright lnleftdfracsqrtpisigma sqrtdfracpi I_AkThbar sqrtdfracpi I_BkThbar sqrtdfracpi I_CkThbarright dfracSNk ln leftleftdfracpi mkThbarright dfracV_eNright lnleftdfracsqrtpisigma sqrtdfracpi I_AkThbar sqrtdfracpi I_BkThbar sqrtdfracpi I_CkThbarright dfracmukT ln leftleftdfracpi mkThbarright dfrackTpright lnleftdfracsqrtpisigma sqrtdfracpi I_AkThbar sqrtdfracpi I_BkThbar sqrtdfracpi I_CkThbarright sum_JN leftdfrachnu_JkT lnBigexpBigdfrachnu_JkTBigBigright dfracD_ekT lnomega_e Earlier in this Chapter in Section we showed how these equations are derived so I refer the reader back to that treatment for further details Notice that except for the chemical potential all of these quantities are extensive properties that depend linearly on the number of molecules in the system Except for the chemical potential and the pressure all of the variables appearing in these expressions have been defined earlier when we showed the explicit expressions for the translational vibrational rotational and electronic partition functions These are the working equations that allow one to compute thermodynamic properties of stable molecules ions and even reactive species such as radicals in terms of molecular properties such as geometries vibrational frequencies electronic state energies and degeneracies and the temperature pressure and volume Einstein and Debye Models of Solids These two models deal with the vibrations of crystals that involve motions among the neighboring atoms ions or molecules that comprise the crystal These interfragment vibrations are called phonons In the Einstein model of a crystal one assumes that Each atom ion or molecule from which the crystal is constituted is trapped in a potential well formed by its interactions with neighboring species This potential is denoted with the volumetonumber ratio written to keep in mind that it likely depends on the packing density ie the distances among neighbors within the crystal Keep in mind that f represents the interaction of any specific atom ion or molecule with the other such species So not is the total interaction energy among all of the species the factor of is necessary to avoid double counting Each such species is assumed to undergo local harmonic vibrational motions about its equilibrium position within the local well that traps it If the crystal is isotropic the force constants that characterize the harmonic potential along the and directions are equal if not these parameters may be unequal It is these force constants along with the masses of the atoms ions or molecules that determine the harmonic frequencies of the crystal The interspecies phonon vibrational partition function of the crystal is then assumed to be a product of partition functions one for each atom ion or molecule in the crystal with each partition function taken to be of the harmonic vibrational form There is no factor of in the denominator because unlike a gas of species each of these species atoms ions or molecules are constrained to stay put ie not free to roam independently in the trap induced by their neighbors In this sense the species are distinguishable rather than indistinguishable as they are in the gas case The factor arises when one asks what the total energy of the crystal is aside from its vibrational energy relative to separated species in other words what is the total cohesive energy of the crystal This energy is times the energy of any single species but as noted above divided by to avoid double counting the interspecies interaction energies This partition function can be subjected to the thermodynamic equations discussed earlier to compute various thermodynamic properties One of the most useful to discuss for crystals is the heat capacity which is given by see the vibrational contribution to expressed in Section At very high temperatures this function can be shown to approach which agrees with the experimental observation know as the law of Dulong and Petit However at very low temperatures this expression approaches which goes to zero as approaches zero but not in a way that is consistent with experimental observation That is careful experimental data shows that all crystal heat capacities approach zero proportional to at low temperature the Einstein models approaches zero but not in the form found in experiments So although the Einstein model offers a very useful model of how a crystals stability relates to and how its depends on vibrational frequencies of the phonon modes it does not work well at low temperatures Nevertheless it remains a widely used model in which to understand the phonons contributions to thermodynamic properties as long as one does not attempt to extrapolate its predictions to low In the Debye model of phonons in crystals one abandons the view in which each atom ion or molecule vibrates independently about it own equilibrium position and replaces this with a view in which the constituent species vibrate collectively in wavelike motions Each such wave has a wave length and a frequency that are related to the speed of propagation of such waves in the crystal by The speed is a characteristic of the crystals interspecies forces it is large for stiff crystals and small for soft crystals In a manner much like we used to determine the density of quantum states within a threedimensional box one can determine how many waves can fit within a cubic crystalline box having frequencies between and The approach to this problem is to express the allowed wave lengths and frequencies as where is the length of the box on each of its sides and is an integer This prescription forces all wave lengths to match the boundary condition for vanishing at the box boundaries Then carrying out a count of how many waves have frequencies between and for a box whose sides are all equal gives the following expression The primary observation to be made is that the density of waves is proportional to It is conventional to define the parameter a in terms of the maximum frequency that one obtains by requiring that the integral of over all allowed add up to the total number of interspecies vibrations that can occur This then gives the constant a in terms of and and allows to be written as The Debye model uses this wave picture and computes the total energy of the crystal much as done in the Einstein model but with the sum over vibrational modes replaced by a continuous integral over the frequencies weighted by the density of such states see the vibrational contribution to expressed in Section where the integral over ranges from to nm It turns out that the heat capacity obtained by taking the temperature derivative of this expression for can be written as follows where the socalled Debye function is defined by and the integral is taken from to The important thing to be noted about the Debye model is that the heat capacity as defined above extrapolates to at high temperatures thus agreeing with the law of Dulong and Petit and varies at low temperature as So the Debye heat capacity does indeed vary as at low as careful experiments indicate For this reason it is appropriate to use the Debye model whenever one is interested in properly treating the energy heat capacity and other thermodynamic properties of crystals at temperatures for which is small At higher temperatures it is appropriate to use either the Debye or Einstein models The major difference between the two lies in how they treat the spectrum of vibrational frequencies that occur in a crystal The Einstein model says that only one or at most three if three different values are used frequency occurs nu_J dfracpi sqrtdfrack_Jm each species in the crystal is assumed to vibrate at this frequency In contrast the Debye model says that the species vibrate collectively and with frequencies ranging from n up to the socalled Debye frequency which is proportional to the speed at which phonons propagate in the crystal In turn this speed depends on the stiffness ie the interspecies potentials within the crystal Lattice Theories of Surfaces and Liquids This kind of theory can be applied to a wide variety of chemical and physical problems so it is a very useful model to be aware of The starting point of the model is to consider a lattice containing sites each of which has nearest neighbor sites nb clearly will depend on the structure of the lattice and to imagine that each of these sites can exist in either of two states that we label A and B Before deriving the basic equations of this model let me explain how the concepts of sites and A and B states are used to apply the model to various problems The sites can represent binding sites on the surface of a solid and the two states A and B can represent situations in which the site is either occupied A or unoccupied B by a molecule that is chemisorbed or physisorbed to the site This point of view is taken when one applies lattice models to adsorption of gases or liquids to solid surfaces The sites can represent individual spin molecules or ions within a lattice and the states A and B can denote the a and b spin states of these species This point of view allows the lattice models to be applied to magnetic materials The sites can represent positions that either of two kinds of molecules A and B might occupy in a liquid or solid in which case A and B are used to label whether each site contains an A or a B molecule This is how we apply the lattice theories to liquid mixtures The sites can represent cis and trans conformations in linkages within a polymer and A and B can be used to label each such linkage as being either cis or trans This is how we use these models to study polymer conformations In Figure I show a twodimensional lattice having sites of which are occupied by dark A species and are occupied by lighter B species Figure Twodimensional lattice having sites with A and B species The partition function for such a lattice is written in terms of a degeneracy and an energy as usual The degeneracy is computed by considering the number of ways a total of species can be arranged on the lattice The interaction energy among the A and B species for any arrangement of the A and B on the lattice is assumed to be expressed in terms of pair wise interaction energies In particular if only nearest neighbor interaction energies are considered one can write the total interaction energy of any arrangement as where is the number of nearest neighbor pairs of type IJ and is the interaction energy of an IJ pair The example shown in Figure has and The three parameters that characterize any such arrangement can be reexpressed in terms of the numbers and of A and B species and the number of nearest neighbors per site as follows N_BB N_AB cN_B Note that the sum of these two equations states the obvious fact that twice the sum of AA BB and AB pairs must equal the number of A and B species multiplied by the number of neighbors per species Using the above relationships among and we can rewrite the interaction energy as The reason it is helpful to write in this manner is that it allows us to express things in terms of two variables over which one has direct experimental control and and one variable that characterizes the degree of disorder among the A and B species That is if is small the A and B species are arranged on the lattice in a phaseseparated manner whereas if is large the A and B are well mixed The total partition function of the A and B species arranged on the lattice is written as follows Here and are the partition functions electronic vibrational etc of the A and B species as they sit bound to a lattice site and is the number of ways that species of type A and of type B can be arranged on the lattice such that there are AB type nearest neighbors Of course is the interaction energy discussed earlier The sum occurs because a partition function is a sum over all possible states of the system There are no factors because as in the Einstein and Debye crystal models the A and B species are not free to roam but are tied to lattice sites and thus are distinguishable This expression for can be rewritten in a manner that is more useful by employing the earlier relationships for and where The quantity plays a central role in all lattice theories because it provides a measure of how different the AB interaction energy is from the average of the AA and BB interaction energies As we will soon see if is large and negative ie if the AA and BB interactions are highly attractive phase separation can occur if is positive phase separation will not occur The problem with the above expression for the partition function is that no one has yet determined an analytical expression for the degeneracy factor Therefore in the most elementary lattice theory known as the BraggWilliams approximation one approximates the sum over by taking the following average value of in the expression for This average is formed by taking the number of A sites and multiplying by the number of neighbor sites c and by the fraction of these neighbor sites that would be occupied by a B species if mixing were random This approximation produces Finally we realize that the sum is equal to the number of ways of arranging A species and B species on the lattice regardless of how many AB neighbor pairs there are This number is of course So the BraggWilliams lattice model partition function reduces to The most common connection one makes to experimental measurements using this partition function arises by computing the chemical potentials of the A and B species on the lattice and equating these to the chemical potentials of the A and B as they exist in the gas phase In this way one uses the equilibrium conditions equal chemical potentials in two phases to relate the vapor pressures of A and B which arise through the gasphase chemical potentials to the interaction energy Let me now show you how this is done First we use to compute the A and B chemical potentials on the lattice This gives and an analogous expression for with replacing The expression for the gasphase chemical potentials and given earlier in this Chapter has the form mu kT ln leftleftdfracpi mkThbarright dfrackTpright kT lnleftdfracsqrtpisigma sqrtdfracpi I_AkThbar sqrtdfracpi I_BkThbar sqrtdfracpi I_CkThbarright kT sum_JN leftdfrachnu_JkT lnBigexpBigdfrachnu_JkTBigBigright D_e kT lnomega_e within which the vapor pressure appears The pressure dependence of this gasphase expression can be factored out to write each as mu_Ag mu_A kT lnp_A where is the vapor pressure of A in atmosphere units and denotes all of the other factors in Likewise the latticephase chemical potentials can be written as a term that contains the and dependence and a term that does not where is the mole fraction of A Of course an analogous expression holds for We now perform two steps We equate the gasphase and latticephase chemical potentials of species A in a case where the mole fraction of A is unity This gives where is the vapor pressure of A that exists over the lattice in which only A species are present We equate the gas and latticephase chemical potentials of A for an arbitrary chemical potential and obtain which contains the vapor pressure of A over the lattice covered by A and B with being the mole fraction of A Subtracting these two equations and rearranging we obtain an expression for how the vapor pressure of A depends on Recall that the quantity is related to the interaction energies among various species as Let us examine that physical meaning of the above result for the vapor pressure First if one were to totally ignore the interaction energies ie by taking one would obtain the well known Raoults Law expression for the vapor pressure of a mixture In Figure I plot the A and B vapor pressures vs The two straight lines are of course just the Raoults Law findings I also plot the vapor pressure for three values of the interaction energy parameter When is positive meaning that the AB interactions are more energetically favorable than the average of the AA and BB interactions the vapor pressure of A is found to deviate negatively from the Raoults Law prediction This means that the observed vapor pressure is lower than is that expected based solely on Raoults Law On the other hand when is negative the vapor pressure deviates positively from Raoults Law Figure Plots of vapor pressures in an A B mixture as predicted in the lattice model with the BraggWilliams approximation An especially important and interesting case arises when the parameter is negative and has a value that makes be more negative than It turns out that in such cases the function suggested in this BraggWilliams model displays a behavior that suggests a phase transition may occur Hints of this behavior are clear in Figure where one of the plots displays both a maximum and a minimum but the plots for and for do not Let me now explain this further by examining the derivative of with respect to Setting this derivative to zero in search of a maximum or minimum and solving for the values of that make this possible one obtains Because is a mole fraction it must be less than unity and greater than zero The above result giving the mole fraction at which will not produce a realistic value of unless If there is only one value of ie that produces a zero slope for there will be two such values given by which is what we see in Figure where the plot displays both a maximum and a minimum What does it mean for to be less than and why is this important For to be negative it means that the average of the AA and BB interactions are more energetically favorable than is the AB interactions It is for this reason that a phase separation is may be favored in such cases ie the A species prefer to be near other A species more than to be near B species and similarly for the B species However thermal motion can overcome a slight preference for such separation That is if is not large enough can overcome this slight preference This is why must be less than not just less than zero So the bottom line is that if the AA and BB interactions are more attractive on average than are the AB interactions one can experience a phase separation in which the A and B species do not remain mixed on the lattice but instead gather into two distinct kinds of domains One domain will be rich in the A species having an value equal to that shown in the right dot in Figure The other domains will be rich in B and have an value of that shown by the left dot As I noted in the introduction to this Section lattice models can be applied to a variety of problems We just analyzed how it is applied within the BraggWilliams approximation to mixtures of two species In this way we obtain expressions for how the vapor pressures of the two species in the liquid or solid mixture display behavior that reflects their interaction energies Let me now briefly show you how the lattice model is applied in some other areas In studying adsorption of gases to sites on a solid surface one imagines a surface containing M sites per unit area A with molecules that have been adsorbed from the gas phase bound to these sites In this case the interaction energy introduced earlier involves only interactions among neighboring adsorbed molecules there are no lateral interactions among empty surface sites or between empty surface sites and adsorbed molecules So we can make the following replacements in our earlier equations N_A rightarrow N_ad where is the number of nearest neighbor pairs of adsorbed species and is the pairwise interaction energy between such a pair The primary result obtained by equating the chemical potentials of the gasphase and adsorbed molecules is Here is the partition function of the gasphase molecules per unit volume is the partition function of the adsorbed molecules which contains the adsorption energy as and is called the coverage ie the fraction of surface sites to which molecules have adsorbed Clearly plays the role that the mole fraction played earlier This socalled adsorption isotherm equation allows one to connect the pressure of the gas above the solid surface to the coverage As in our earlier example something unusual occurs when the quantity is negative and beyond a critical value In particular differentiating the expression for with respect to and finding for what values vanishes one finds Since is a positive fraction this equation can only produce useful values if In this case this means that if the attractions between neighboring adsorbed molecules is strong enough it can overcome thermal factors to cause phaseseparation to occur The kind of phase separation on observes is the formation of islands of adsorbed molecules separated by regions where the surface has little or no adsorbed molecules There is another area where this kind of lattice model is widely used When studying magnetic materials one often uses the lattice model to describe the interactions among pairs of neighboring spins eg unpaired electrons on neighboring molecules or nuclear spins on neighboring molecules In this application one assumes that up or down spin states are distributed among the lattice sites which represent where the molecules are located and are the total number such spins so is a measure of what is called the net magnetization of the sample The result of applying the BraggWilliams approximation in this case is that one again observes a critical condition under which strong spin pairings occur In particular because the interactions between a and a spins denoted and between and spins denoted are equal and opposite the variable characteristic of all lattice models reduces to X E_alphabeta E_alphaalpha E_betabeta J The critical condition under which one expects like spins to pair up and thus to form islands of arich centers and other islands of brich centers is or Virial Corrections to IdealGas Behavior Recall from our earlier treatment of classical partition function that one can decompose the total partition function into a product of two factors Q dfrachNMNint exp Big dfracHy pkTBig dy dp int exp BigdfracUrkTBig dr one of which is the result if no intermolecular potentials are operative The second factor Q_rm inter dfracVN int exp BigdfracUrkTBig dr thus contains all of the effects of intermolecular interactions Recall also that all of the equations relating partition functions to thermodynamic properties involve taking and derivatives of So all such equations can be cast into sums of two parts that arising from and that arising from In this Section we will be discussing the contributions of to such equations The first thing that is done to develop the socalled cluster expansion of is to assume that the total intermolecular potential energy can be expressed as a sum of pair wise additive terms where labels the distance between molecule and molecule This allows the exponential appearing in to be written as a product of terms one for each pair of molecules Each of the exponentials is then expressed as follows the last equality being what defines These functions are introduced because whenever the molecules and are distant from one another and thus not interacting vanishes so approaches unity and thus vanishes In contrast whenever molecules and are close enough to experience strong repulsive interactions is large and positive so approaches These properties make a useful measure of how molecules are interacting if they are not if they are repelling strongly and if they are strongly attracting is large and positive Inserting the functions into the product expansion of the exponential one obtains expBigdfracUkTBig prod_IJ f_IJ sum_IJ f_IJ sum_IJ sum_KL f_IJ f_KL cdots which is called the cluster expansion in terms of the pair functions When this expansion is substituted into the expression for we find where the integral is over all of the molecules center of mass coordinates The integrals involving only one function are all equal ie for any pair the molecules are identical in their interaction potentials and reduce to The integrals over produce which combines with to produce the seen Finally because depends only on the relative positions of molecules and the six dimensional integral over can be replaced by integrals over the relative location of the two molecules r and the position of their center of mass The integral over gives one more factor of and the above cluster integral reduces to with the coming from the angular integral over the relative coordinate Because the total number of molecules is very large it is common to write the factor as The cluster integrals containing two factors can also be reduced However it is important to keep track of different kinds of such factors depending on whether the indices are all different or not For example terms of the form with and all unique reduce again using the equivalence of the molecules and the fact that depends only on the relative positions of and J to dfracN pi V int f_ r_ dr_ int f_ r_ dr_ where again I used the fact that is very large to replace by On the other hand cluster integrals with for example but and different reduce as follows Because depends only on the relative positions of molecules and and depends on the relative positions of and the ninedimensional integral over can be changed to a sixdimensional integral over and an integral over the location of molecule the latter integral produces a factor of when carried out Thus the above cluster integral reduces to There is a fundamental difference between cluster integrals of the type and those involving The former are called unlinked clusters because they involve the interaction of molecules and and a separate interaction of molecules and The latter are called linked because they involve molecule interacting simultaneously with molecules and although and need not be close enough to cause to be nonzero The primary differences between unlinked and linked cluster contributions are The total number of unlinked terms is proportional to while the number of linked terms is proportional to This causes the former to be more important than the latter because they are more numerous The linked terms only become important at densities where there is a significant probability that three molecules occupy nearby regions of space The unlinked terms on the other hand do not require that molecules and be anywhere near molecules and This also causes the unlinked terms to dominate especially at low and moderate densities I should note that a similar observation was made in Chapter when we discussed the configuration interaction and coupledcluster expansion of electronic wave functions That is we noted that doubly excited configurations analogous to are the most important contributions beyond the single determinant and that quadruple excitations in the form of unlinked products of double excitations were next most important not triple excitations The unlinked nature in this case was related to the amplitudes of the quadruple excitations being products of the amplitudes of two double excitations So both in electronic structures and in liquid structure one finds that pair correlations followed by unlinked pair correlations are the most important to consider Clearly the cluster expansion approach to can be carried to higher and higherlevel clusters eg involving or etc Generally one finds that the unlinked terms eg in this example are most important because they are proportional to higher powers of and because they do not require more than binary collisions It is most common however to employ a severely truncated expansion and to retain only the linked terms Doing so for produces at the lower levels Q_rm inter dfrac BigdfracNVBig pi V int f r dr dfrac BigdfracNVBig pi V int f r dr One of the most common properties to compute using a partition function that includes molecular interactions in the cluster manner is the pressure which is calculated as Using and inserting the above expression for produces the following result for the pressure where the socalled virial coefficients and are defined as the factors proportional to and respectively The second virial coefficients expression in terms of the cluster integrals is B_ pi int f r dr pi int BigexpBigdfracUrkTBig Big r dr The third virial coefficient involves higher order cluster integrals The importance of such cluster analysis is that they allow various thermodynamic properties eg the pressure above to be expressed as one contribution that would occur if the system consisted of noninteracting molecules and a second contribution that arises from the intermolecular forces It thus allows experimental measurements of the deviation from ideal ie noninteracting behavior to provide a direct way to determine intermolecular potentials For example by measuring pressures at various values and various temperatures one can determine and thus gain valuable information about the intermolecular potential Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Some Important Properties of Events Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics The Probability of Alternative EventsThe Probability of Compound Events If we know the probabilities of the possible outcomes of a trial we can calculate the probabilities for combinations of outcomes These calculations are based on two rules which we call the laws of probability If we partition the outcomes into exhaustive and mutually exclusive events the laws of probability also apply to events Since as we define them events is a more general term than outcomes we call them the law of the probability of alternative events and the law of the probability of compound events These laws are valid so long as three conditions are satisfied We have already discussed the first two of these conditions which are that the outcomes possible in any individual trial must be exhaustive and mutually exclusive The third condition is that if we make more than one trial the outcomes must be independent that is the outcome of one trial must not be influenced by the outcomes of the others We can view the laws of probability as rules for inferring information about combinations of events The law of the probability of alternative events applies to events that belong to the same distribution The law of the probability of compound events applies to events that can come from one or more distributions An important special case occurs when the compound events are successive samplings of a given distribution that we identify as the parent distribution If the random variable is a number and we average the numbers that we obtain from successive samplings of the parent distribution these averagesof themselves constitute a distribution If we know certain properties of the parent distribution we can calculate corresponding properties of the distribution of averagesof values obtained by sampling the parent distribution These calculations are specified by the central limit theorem which we discuss in Section In general when we combine events from two distributions we can view the result as an event that belongs to a third distribution At first encounter the idea of combining events and distributions may seem esoteric A few examples serve to show that what we have in mind is very simple Since an event is a set of outcomes an event occurs whenever any of the outcomes in the set occurs Partitioning the outcomes of tossing a die into even outcomes and odd outcomes illustrates this idea The event even outcome occurs whenever the outcome of a trial is or The probability of an event can be calculated from the probabilities of the underlying outcomes We call the rule for this calculation the law of the probabilities of alternative events We create the opportunity for confusion here because we are illustrating the idea of alternative events by using an example in which we call the alternatives alternative outcomes rather than alternative events We need to remember that event is a more general term than outcome One possible partitioning is that which assigns every outcome to its own event We discuss the probabilities of alternative events further below To illustrate the idea of compound events let us consider a first distribution that comprises tossing a coin and a second distribution that comprises drawing a card from a poker deck The first distribution has two possible outcomes the second distribution has possible outcomes If we combine these distributions we create a third distribution that comprises tossing a coin and drawing a card from a poker deck The third distribution has possible outcomes If we know the probabilities of the outcomes of the first distribution and the probabilities of the outcomes of the second distribution and these probabilities are independent of one another we can calculate the probability of any outcome that belongs to the third distribution We call the rule for this calculation the law of the probability of compound events We discuss it further below A similar situation occurs when we consider the outcomes of tossing two coins We assume that we can tell the two coins apart Call them coin and coin We designate heads and tails for coins and as and respectively There are four possible outcomes in the distribution we call tossing two coins and If we could not tell the coins apart would be the same thing as there would be only three possible outcomes We can view the distribution tossing two coins as being a combination of the two distributions that we can call tossing coin and tossing coin We can also view the distribution tossing two coins as a combination of two distributions that we call tossing a coin a first time and tossing a coin a second time We view the distribution tossing two coins as being equivalent to the distribution tossing one coin twice This is an example of repeated trials which is a frequently encountered type of distribution In general we call such a distribution a distribution of events from a trial repeated N times and we view this distribution as being completely equivalent to N simultaneous trials of the same kind Chapter considers the distribution of outcomes when a trial is repeated many times Understanding the properties of such distributions is the single most essential element in understanding the theory of statistical thermodynamics The central limit theorem relates properties of the repeatedtrials distribution to properties of the parent distribution The Probability of Alternative Events If we know the probability of each of two mutually exclusive events that belong to an exhaustive set the probability that one or the other of them will occur in a single trial is equal to the sum of the individual probabilities Let us call the independent events A and B and represent their probabilities as and respectively The probability that one of these events occurs is the same thing as the probability that either A occurs or B occurs We can represent this probability as The probability of this combination of events is the sum That is Above we define Y as the event that a single toss of a die comes up either or Because each of these outcomes is one of six mutuallyexclusive equallylikely outcomes the probability of either of them is From the law of the probability of alternative events we have We define as the event that a single toss of a die comes up even From the law of the probability of alternative events we have We define as the event that a single toss comes up If there are independent events denoted the law of the probability of alternative events asserts that the probability that one of these events will occur in a single trial is If these independent events encompass all of the possible outcomes the sum of their individual probabilities must be unity Figure A simple case that illustrates the laws of probability The Probability of Compound Events Let us now suppose that we make two trials in circumstances where event is possible in the first trial and event is possible in the second trial We represent the probabilities of these events by and and stipulate that they are independent of one another that is the probability that occurs in the second trial is independent of the outcome of the first trial Then the probability that occurs in the first trial and occurs in the second trial is equal to the product of the individual probabilities To illustrate this using outcomes from dietossing let us suppose that event is tossing a and event is tossing a Then and The probability of tossing a in a first trial and tossing a in a second trial is then If we want the probability of getting one and one in two tosses we must add to this the probability of tossing a first and a second If there are independent events denoted the law of the probability of compound events asserts that the probability that will occur in a first trial and will occur in a second trial etc is beginalign PleftE_ and E_ anddots E_idots and E_omega right PleftE_righttimes PleftE_righttimes dots times PleftE_irighttimes dots times PleftE_omega rightpt prodomega _iPE_i endalign Standard Enthalpies of Reaction Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers The benefit of these conventions is that at any particular temperature the standard enthalpy change for a reaction which we designate as is given by If we have the enthalpies of formation we can compute the enthalpy change for the reaction We can demonstrate this by writing out the chemical equations corresponding to the formation of A B C and D from their elements When we multiply these chemical equations by the appropriately signed stoichiometric coefficient and add them we obtain the chemical equation for the indicated reaction of A and B to give C and D See below Because enthalpy is a state function the enthalpy change that we calculate this way will be valid for any process that converts the specified reactants into the specified products The oxidation of methane to methanol is a reaction that illustrates the value of this approach The normal products in the oxidation of methane are of course carbon dioxide and water If the reaction is done with an excess of methane a portion of the carboncontaining product will be carbon monoxide rather than carbon dioxide In any circumstance methanol is at best a trace product Nevertheless it would be very desirable to devise a catalyst that quantitativelyor nearly quantitativelyconverted methane to methanol according to the equation This is frequently called a selective oxidation to distinguish it from the nonselective oxidation that produces carbon dioxide and water If the catalyst were not inordinately expensive or shortlived and the operating pressure were sufficiently low this would be an economical method for the manufacture of methanol Methanol is currently manufactured from methane However the process involves two steps and requires a substantial capital investment If the cost of manufacturing methanol could be decreased sufficiently it would become economically feasible to convert natural gas which cannot be transported economically unless it is feasible to build a pipeline for the purpose into liquid methanol which is readily transported by ship At present the economic feasibility of marine transport of liquefied natural gas LNG is marginal but it appears to be improving This technology would make it possible to utilize the fuel value of known natural gas resources that are presently useless because they are located too far from population centers When we contemplate trying to develop a catalyst and a manufacturing plant to carry out this reaction we soon discover reasons for wanting to know the enthalpy change One is that the oxidative manufacture of methanol will be exothermic so burning the methanol produced will yield less heat than would be produced by burning the methane from which it was produced We want to know how much heat energy is lost in this way Another reason is that a manufacturing plant will have to control the temperature of the oxidation reaction in order to maintain optimal performance If the temperature is too low the reaction rate will be too slow If the temperature is too high the catalyst may be deactivated in a short time and the production of carbon oxides will probably be excessive A chemical engineer designing a plant will need to know how much heat is produced so that he can provide adequate cooling equipment Because we do not know how to carry out this reaction we cannot measure its enthalpy change directly However if we have the enthalpies of formation for methane and methanol we can compute this enthalpy change Summing the reactions gives and summing the enthalpy changes gives Figure A thermochemical cycle to find The diagram in Figure shows how these conventions and the fact that enthalpy is a state function work together to produce for the reaction the result that the standard reaction enthalpy is given by This cycle highlights another aspect of the conventions that we have developed Note that is the difference between the enthalpies of formation of the separated products and the enthalpies of formation of the separated reactants We often talk about as if it were the enthalpy change that would occur if we mixed moles of with moles of and the reaction proceeded quantitatively to yield a mixture containing moles of and moles of This is usually a good approximation However to relate rigorously the standard enthalpy of reaction to the enthalpy change that would occur in a real system in which this reaction took place it is necessary to recognize that there can be enthalpy changes associated with the pressurevolume changes and with the processes of mixing the reactants and separating the products Let us suppose that the reactants and products are gases in their hypothetical idealgas states at bar and that we carry out the reaction by mixing the reactants in a sealed pressure vessel We suppose that the reaction is then initiated and that the products are formed rapidly reaching some new pressure and an elevated temperature To be specific we could imagine the reaction be the combustion of methane We would mix known amounts of methane and oxygen in a pressure vessel and initiate the reaction using an electrical spark We allow the temperature to return to the original temperature of the reactants there is an accompanying pressure change Experimentally we measure the heat evolved as the mixed reactants are converted to the mixed products at the original temperature To complete the process corresponding to the standard enthalpy change however we must also separate the products and bring them to a pressure of bar That is the standard enthalpy of reaction and the enthalpy change we would measure are related by the following sequence of changes where the middle equation corresponds to the process whose enthalpy change we actually measure Summing the reaction equations gives and summing the enthalpy changes for the series of steps gives the standard enthalpy change for the reaction It turns out that the enthalpy changes for the compression mixing separation and expansion processes are usually small compared to This is the principal justification for our frequent failure to consider them explicitly For ideal gases these enthalpy changes are identically zero In Chapter we see that the entropy changes for the mixing and separation processes are important When we call the standard enthalpy change for the reaction we are indulging in a degree of poetic license Since is a computed difference between the enthalpies of the pure products and those of the pure reactants the corresponding reaction is a purely formal change which is a distinctly different thing from the realworld process that actually occurs Standard State Heat Capacities Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers We have observed that depends on volume and temperature while depends on pressure and temperature Compilations of heat capacity data usually give values for rather than When the temperaturedependence of is known such compilations usually express it as an empirical polynomial function of temperature In Chapter we find an explicit function for the dependence of on pressure If we have an equation of state for a substance we can find this pressure dependence immediately It is usually negligible For ideal gases it is zero and is independent of pressure Compilations often give data for the standard state heat capacity at a specified temperature For condensed phases this is the heat capacity for the substance at one bar For gases this is the heat capacity of the substance in its ideal gas standard state K K C_s Standard States and Enthalpies of Formation Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers A useful convention makes it possible to tabulate enthalpy data for individual compounds in such a way that the enthalpy change for any chemical reaction can be calculated from the tabulated information for the reactions reactants and products The convention comprises the following rules I At any particular temperature we define the standard state of any liquid or solid substance to be the most stable form of that substance at a pressure of one bar For example for water at C the standard state is ice at a pressure of one bar at C it is liquid water at a pressure of one bar II At any particular temperature we define the standard state of a gas to be the ideal gas standard state at that temperature By the ideal gas standard state we mean a finite low pressure at which the real gas behaves as an ideal gas We know that it is possible to find such a pressure because any gas behaves as an ideal gas at a sufficiently low pressure Since the enthalpy of an ideal gas is independent of pressure we can also think of a substance in its ideal gas standard state as a hypothetical substance whose pressure is one bar but whose molar enthalpy is that of the real gas at an arbitrarily low pressure III For any substance at any particular temperature we define the standard enthalpy of formation as the enthalpy change for a reaction in which the product is one mole of the substance and the reactants are the compounds constituent elements in their standard states For water at C this reaction is For water at C it is For water at C it is IV The standard enthalpy of formation is given the symbol where the superscript degree sign indicates that the reactants and products are all in their standard states The subscript indicates that the enthalpy change is for the formation of the indicated compound from its elements Frequently the compound and other conditions are specified in parentheses following the symbol The solid liquid and gas states are usually indicated by the letters s or liq and g respectively The letter c is sometimes used to indicate that the substance is in a crystalline state In this context specification of the gas state normally means the ideal gas standard state Thermochemicaldata tables that include standard enthalpies of formation can be found in a number of publications or on the internet For some substances values are available at a number of temperatures For substances for which less data is available these tables usually give the value of the standard enthalpy of formation at K In this context K is frequently abbreviated to K V For any element at any particular temperature we define the standard enthalpy of formation to be zero When we define standard enthalpies of formation we choose the elements in their standard states as a common reference state for the enthalpies of all substances at a given temperature While we could choose any arbitrary value for the enthalpy of an element in its standard state choosing it to be zero is particularly convenient State Functions in Systems Undergoing Spontaneous Change Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers In this chapter we introduce ideas that underlie classical thermodynamics Because the development of classical thermodynamics relies on the properties of reversible processes we have devoted considerable attention to specifying what we mean by a reversible process and to the relationship between reversible processes and the equilibrium states available to a system In Section we develop this theory The development assumes that we can measure the heat and work exchanged between a system and its surroundings It assumes that we can measure the state functions volume pressure temperature and the amounts moles of chemical substances in a system We define other state functions whose values can be computed from these measurable quantities From observations that we make on systems that are undergoing reversible change we develop numerous relationships among these state functions No real system can change in exactly the manner we have in mind when we talk about a reversible process Strictly speaking any process that actually occurs must be spontaneous The idea of reversible change is clearly an abstraction from reality Nevertheless we can determineto a good approximationthe way in which one variable depends on another in a reversible process We accomplish this by making measurements on a real system whose behavior approximates the ideal of reversibility as closely as possible We express theapproximateresult of any such measurement as a number Normally we view the approximate character of the number to be a consequence of experimental error When we say that we make measurements on a system that is undergoing a reversible change we mean that we are making the measurements on a process that satisfies our definition of reversibility closely enough for the purpose at hand There are two reasons for the fact that reversible processes play an essential role in the development of the equations of thermodynamics The first is that we can measure the entropy change for a process only if the process is reversible The second and subtler reason is that an intensive variable may not have a unique value in a system that is undergoing a spontaneous change If the temperature the pressure or the concentration of a component varies from point to point within the system then that state function does not have a unique value and we cannot use it to model the change This occurs for example when gasoline explodes in a cylinder of a piston engine The system consists of the contents of the cylinder At any given instant the pressure temperature and component concentrations vary from place to place within the cylinder In general no single value of any of these intensive variables is an adequate approximation for use in the thermodynamic equations that characterize the system as a whole To explore this idea further let us think about measuring changes in extensive state functions during a spontaneous process Since we are free to define the system as we please we can choose a definition that makes the volume readily measurable In the pistonengine example there is no ambiguity about the volume of the system at any instant While pointtopoint variability means that the concentrations of the chemical components are not defined for the system as a whole we are confident that there is some specific number of moles of each component present in the system at every instant We can reach this conclusion by imagining that we can instantaneously freeze the composition by stopping all reactions We can then find the number of moles of each component at our leisure If the system is not too inhomogeneous we can devise an alternative procedure for makingin conceptsuch composition measurements We imagine dividing the system into a large number of macroscopic subsystems Each of these subsystems has a welldefined volume We suppose also that each of them has welldefined thermodynamic functions at any given instant that is we assume that the pressure temperature and concentrations are approximately homogeneous within each of these subsystems If this condition is satisfied we can sum up the number of moles of a component in each of the subvolumes to obtain the number of moles of that component in the whole system We can make a similar argument for any extensive thermodynamic function so it applies to the energy entropy enthalpy and the Helmholtz and Gibbs free energies As long as the pointtopoint variability within the system is small enough so that a division of the system into macroscopic subsystems produces subsystems that are approximately homogeneous we can find the value for any extensive thermodynamic function in each individual subsystem and for the system as a whole The measurement we propose has the character of a gedanken experiment We can describe a procedure for making the measurement whether we can actually perform the procedure or not This argument does not work for intensive thermodynamic functions It is true that we could produce a weightedaverage value for the temperature by multiplying the temperature of each subsystem by the subsystem volume adding up the products and dividing the sum by the volume of the whole system however the result would not be an intensive property of the whole system For one thing we could produce a different average temperature for every extensive variable by using it rather than the volume as the weighting factor in the averagetemperature computation Moreover no such weightedaverage temperature can reflect the fact that different temperatures in different subsystems result in grossly different reaction rates No single temperature represents the state of the whole system and we can make the same statement about any other intensive thermodynamic function For a nonhomogeneous system that can be subdivided into approximately homogeneous macroscopic subsystems we can measure in principle the values of the systems extensive state functions however its intensive state functions are essentially undefined On the other hand we may be able to assume that an effectively homogeneous subsystem of macroscopic proportions does have welldefined extensive and intensive state functions even if it is not in an equilibrium state While a spontaneously changing system need not be homogenous we commonly encounter systems that are homogeneous to within some arbitrarily small deviation Consider a closed and wellstirred system in which some chemical reaction is occurring slowly We immerse this system in a constanttemperature bath and arrange for the applied pressure to be constant From experience we know that the temperature and pressure within such a system will be essentially constant equal to the bath temperature and the applied pressure respectively and homogeneous throughout the system In such a system the temperature and the pressure of the system are at equilibrium with those imposed by the surroundings The chemical process is not at equilibrium but the component concentrations are homogeneous An important question now arises Are all of the equations of equilibrium thermodynamics applicable to a system in which some processes occur spontaneously That they are not is evident from the fact that we can calculate an entropy change from its defining equation only if the behavior of the system is reversible Nevertheless we will find that the relationships among state functions that we derive for reversible processes can be augmented to describe spontaneous processes that occur in homogeneous systems The necessary augmentation consists of the addition of terms that express the effects of changing composition In Section we develop the fundamental equation which applies to any reversible process in a closed system In Section we infer that the fundamental equation becomes for a spontaneous process in which and are the chemical potentialchemical potential and the change in the number of moles of component respectively The distinction between reversiblereversible process and spontaneous processspontaneous processes plays a central role in our theory We find a group of relationships that express this distinction and we call these relationships criteria for change In Section we find that if and only if the process is reversible while if and only if the process is spontaneous We find a close connection between the criteria for change and the compositiondependent terms that are needed to model the thermodynamic functions during spontaneous processes We find that if and only if the process is reversible while if and only if the process is spontaneous In thinking about spontaneous processes we should also keep in mind that the validity of our general relationships among state functions does not depend on our ability to measure the state functions of any particular state of a system For example we can find relationships among the molar volume and other thermodynamic properties of liquid water Liquid water does not exist at C and bar so we cannot undertake to measure its thermodynamic properties However by using our relationships among state functions and properties that we measure for liquid water where it does exist we can estimate the thermodynamic properties of liquid water at C and bar The results are two steps removed from reality they are the estimated properties of a hypothetical substancehypothetical substance Nevertheless they have predictive value for example we can use them to predict that liquid water at C and bar will spontaneously vaporize to form gaseous water at bar The equations of thermodynamics are creatures of theory We should not expect every circumstance that is described by the theory to exist in reality What we require is that the theory accurately describe every circumstance that actually occurs To develop the equations of classical thermodynamics we consider reversible processes We then find general criteria for change that apply to any sort of change in any system Later we devise criteria based on the changes that occur in the composition of the system In this book we consider such compositionbased criteria only for homogeneous systems An extensive theory has been developed to model spontaneous processes in systems that are not necessarily homogeneous This theory is often called irreversible thermodynamics or nonequilibrium thermodynamics Development of this theory has led to a wide variety of useful insights about various molecular processes However much of what we are calling classical thermodynamics also describes irreversible processes Even as we develop our theory of reversible thermodynamics we use arguments that apply the equations we infer from reversible processes to describe closely related systems that are not at equilibrium Statistical Thermodynamics Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Statistical thermodynamics is a theory that uses molecular properties to predict the behavior of macroscopic quantities of compounds While the origins of statistical thermodynamics predate the development of quantum mechanics the modern development of statistical thermodynamics assumes that the quantized energy levels associated with a particular system are known From these energylevel data a temperaturedependent quantity called the partition function can be calculated From the partition function all of the thermodynamic properties of the system can be calculated We begin our development of statistical thermodynamics by using the energy levels of an individual molecule to find its molecular partition function and the thermodynamic properties of a system that contains noninteracting molecules of that substance Later we see that the partition function of a system containing molecules that do interact with one another can be found by very similar arguments Statistical thermodynamics has also been applied to the general problem of predicting reaction rates This application is called transition state theory or the theory of absolute reaction rates In principle we should be able to predict the rate of any reaction To do so we need only to solve the quantum mechanical equations that give the energy levels associated with the reactants and the energy levels associated with a transitory chemical structure called the transition state for the reaction From the energy levels we calculate partition functions from partition functions we calculate thermodynamic functions and from these thermodynamic functions we obtain the reaction rate There is a big difference between in principle and in practice While increases in computer speed make it increasingly feasible to do quantum mechanical calculations to useful degrees of accuracy the results of such calculations remain too inaccurate to give generally reliable reaction rate predictions The theory of absolute reaction rates is an important application of statistical thermodynamics However it is not included in this book Quantum mechanical calculations are not the only way to obtain the energylevel information that is needed to evaluate partition functions Particularly for small molecules these energy levels can be deduced from spectroscopic data In these cases the theory of statistical thermodynamics enables us to calculate thermodynamic properties from spectroscopic measurements Excellent agreement is obtained between the values of thermodynamic functions obtained from classical thermodynamic thermochemical measurements and those obtained from statisticalthermodynamic calculations based on energy levels derived from spectroscopic measurements In Chapter we consider a particular example to illustrate this point Statistics for Molecular Speeds Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Expected values for several quantities can be calculated from the MaxwellBoltzmann probability density function The required definite integrals are tabulated in Appendix D The most probable speed is the speed at which the MaxwellBoltzmann equation takes on its maximum value At this speed we have from which The average speed or is the expected value of the scalar velocity We find The meansquare speed or is the expected value of the velocity squared and the root meansquare speed is Example Figure The MaxwellBoltzmann distribution function for at K Figure shows the velocity distribution K for nitrogen molecules at K Solution Finally let us find the variance of the velocity that is the expected value of For at K we calculate Statistics the Mean and the Variance of a Distribution Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers There are two important statistics associated with any probability distribution the mean of a distribution and the variance of a distribution The mean is defined as the expected value of the random variable itself The Greek letter is usually used to represent the mean If is the cumulative probability distribution the mean is the expected value for From our definition of expected value the mean is The variance is defined as the expected value of The variance measures how dispersed the data are If the variance is large the data areon averagefarther from the mean than they are if the variance is small The standard deviation is the square root of the variance The Greek letter is usually used to denote the standard deviation Then denotes the variance and If we have a small number of points from a distribution we can estimate and by approximating these integrals as sums over the domain of the random variable To do this we need to estimate the probability associated with each interval for which we have a sample point By the argument we make in Section the best estimate of this probability is simply where is the number of sample points We have therefore That is the best estimate we can make of the mean from data points is where is the ordinary arithmetic average Similarly the best estimate we can make of the variance is Now a complication arises in that we usually do not know the value of The best we can do is to estimate its value as It turns out that using this approximation in the equation we deduce for the variance gives an estimate of the variance that is too small A more detailed argument see Section shows that if we use to approximate the mean the best estimate of usually denoted is Figure Variance is analogous to a moment of inertia Dividing by rather than compensates exactly for the error introduced by using rather than The mean is analogous to a center of mass The variance is analogous to a moment of inertia For this reason the variance is also called the second moment about the mean To show these analogies let us imagine that we draw the probability density function on a uniformly thick steel plate and then cut along the curve and the axis Figure Let be the mass of the cutout piece of plate is the mass below the probability density curve Let and be the increments of area and mass in the thin slice of the cutout that lies above a small increment of Let be the density of the plate expressed as mass per unit area Since the plate is uniform is constant We have and so that The mean of the distribution corresponds to a vertical line on this cutout at If the cutout is supported on a knifeedge along the line gravity induces no torque the cutout is balanced Since the torque is zero we have Since is a constant property of the cutout it follows that The cutouts moment of inertia about the line is The moment of inertia about the line is simply the mass per unit area times the variance of the distribution If we let we have We define the mean of as the expected value of It is the value of we should expect to get the next time we sample the distribution Alternatively we can say that the mean is the best prediction we can make about the value of a future sample from the distribution If we know the best prediction we can make is If we have only the estimated mean then is the best prediction we can make Choosing makes the difference as small as possible These ideas relate to another interpretation of the mean We saw that the variance is the second moment about the mean The first moment about the mean is Since the last two integrals are and respectively the first moment about the mean is zero We could have defined the mean as the value for which the first moment of about is zero The first moment about the mean is zero The second moment about the mean is the variance We can define third fourth and higher moments about the mean Some of these higher moments have useful applications Strategies for Geometry Optimization and Finding Transition States Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Finding Local Minima Finding Transition States Energy Surface IntersectionsEndnotesContributors and Attributions The extension of the harmonic and Morse vibrational models to polyatomic molecules requires that the multidimensional energy surface be analyzed in a manner that allows one to approximate the molecules motions in terms of many nearly independent vibrations In this Section we will explore the tools that one uses to carry out such an analysis of the surface but first it is important to describe how one locates the minimumenergy and transitionstate geometries on such surfaces Finding Local Minima Many strategies that attempt to locate minima on molecular potential energy landscapes begin by approximating the potential energy for geometries collectively denoted in terms of Cartesian coordinates in a Taylor series expansion about some starting point geometry ie the current molecular geometry in an iterative process or a geometry that you guessed as a reasonable one for the minimum or transition state that you are seeking Here is the energy at the current geometry is the gradient of the energy along the coordinate is the secondderivative or Hessian matrix and is the length of the step to be taken along this Cartesian direction An example of an energy surface in only two dimensions is given in the Figure where various special aspects are illustrated For example minima corresponding to stable molecular structures transition states first order saddle points connecting such minima and higher order saddle points are displayed Figure Twodimensional potential surface showing minima transition states and paths connecting them If the only knowledge that is available is and the gradient components eg computation of the second derivatives is usually much more computationally taxing than is evaluation of the gradient so one is often forced to work without knowing the Hessian matrix elements the linear approximation suggests that one should choose step elements that are opposite in sign from that of the corresponding gradient elements if one wishes to move downhill toward a minimum The magnitude of the step elements is usually kept small in order to remain within the trust radius within which the linear approximation to is valid to some predetermined desired precision ie one wants to assure that is not too large When second derivative data is available there are different approaches to predicting what step to take in search of a minimum and it is within such Hessianbased strategies that the concept of stepping along independent modes arises We first write the quadratic Taylor expansion in matrixvector notation with the elements collected into the column vector whose transpose is denoted Introducing the unitary matrix that diagonalizes the symmetric matrix the above equation becomes Because is diagonal we have where are the eigenvalues of the Hessian matrix For nonlinear molecules of these eigenvalues will be nonzero for linear molecules will be nonzero The or zero eigenvalues of have eigenvectors that describe translation and rotation of the entire molecule they are zero because the energy surface does not change if the molecule is rotated or translated It can be difficult to properly identify the or translation and rotation eigenvalues of the Hessian because numerical precision issues often cause them to occur as very small positive or negative eigenvalues If the molecule being studied actually does possess internal ie vibrational eigenvalues that are very small eg the torsional motion of the methyl group in ethane has a very small energy barrier as a result of which the energy is very weakly dependent on this coordinate one has to be careful to properly identify the translationrotation and internal eigenvalues By examining the eigenvectors corresponding to all of the low Hessian eigenvalues one can identify and thus separate the former from the latter In the remainder of this discussion I will assume that the rotations and translations have been properly identified and the strategies I discuss will refer to utilizing the remaining or eigenvalues and eigenvectors to carry out a series of geometry steps designed to locate energy minima and transition states The eigenvectors of form the columns of the array that brings to diagonal form Therefore if we define and to be the component of the step and of the gradient along the eigenvector of the quadratic expansion of can be written in terms of steps along the or directions that correspond to nonzero Hessian eigenvalues The advantage to transforming the gradient step and Hessian to the eigenmode basis is that each such mode labeled m appears in an independent uncoupled form in the expansion of This allows us to take steps along each of the directions in an independent manner with each step designed to lower the potential energy when we are searching for minima strategies for finding a transition state will be discussed below For each eigenmode direction one can ask for what size step would the quantity be a minimum Differentiating this quadratic form with respect to and setting the result equal to zero gives that is one should take a step opposite the gradient but with a magnitude given by the gradient divided by the eigenvalue of the Hessian matrix If the current molecular geometry is one that has all positive values this indicates that one may be close to a minimum on the energy surface because all are positive at minima In such a case the step is opposed to the gradient along all or directions much like the gradientbased strategy discussed earlier suggested The energy change that is expected to occur if the step is taken can be computed by substituting into the quadratic equation for This clearly suggests that the step will lead downhill in energy along each eigenmode as long as all of the values are positive For example if one were to begin with a good estimate for the equilibrium geometries of ethylene and propene one could place these two molecules at a distance longer than the expected interfragment equilibrium distance in the van der Waals complex formed when they interact Because both fragments are near their own equilibrium geometries and at a distance at which longrange attractive forces will act to draw them together a strategy such as outlined above could be employed to locate the van der Waals minimum on their energy surface This minimum is depicted qualitatively in Figure a Figure a Van der Waals complex upper right formed between ethylene and propene whose geometry might be located using the prescription outlined above Product of the cycloaddition reaction methylcyclobutane lower right Beginning at one would find that of the eigenvalues of the Hessian matrix are nonzero where is the total number of atoms in the ethylenepropene complex Of these nonzero eigenvalues three will have eigenvectors describing radial and angular displacements of the two fragments relative to one another the remaining will describe internal vibrations of the complex The eigenvalues belonging to the interfragment radial and angular displacements may be positive or negative because you made no special attempt to orient the molecules at optimal angles and you may not have guessed very well at optimal the equilibrium interfragment distance so it would probably be wisest to begin the energyminimization process by using gradient information to step downhill in energy until one reaches a geometry at which all of the Hessian matrix eigenvalues are positive From that point on steps determined by both the gradient and Hessian ie can be used unless one encounters a geometry at which one of the eigenvalues is very small in which case the step along this eigenmode could be unrealistically large In this case it would be better to not take for the step along this particular direction but to take a small step in the direction opposite to the gradient to improve chances of moving downhill Such smalleigenvalue issues could arise for example if the torsion angle of propenes methyl group happened during the sequence of geometry steps to move into a region where eclipsed rather than staggered geometries are accessed Near eclipsed geometries the Hessian eigenvalue describing twisting of the methyl group is negative near staggered geometries it is positive Whenever one or more of the are negative at the current geometry one is in a region of the energy surface that is not sufficiently close to a minimum to blindly follow the prescription along all modes If only one is negative one anticipates being near a transition state at which all gradient components vanish and all but one are positive with one negative In such a case the above analysis suggests taking a step along all of the modes having positive but taking a step of opposite direction eg unless is very small in which case a small step opposite is best along the direction having negative if one is attempting to move toward a minimum This is what I recommended in the preceding paragraph when an eclipsed geometry which is a transition state for rotation of the methyl group is encountered if one is seeking an energy minimum Finding Transition States On the other hand if one is in a region where one Hessian eigenvalues is negative and the rest are positive and if one is seeking to find a transition state then taking steps along all of the modes Having positive eigenvalues and taking along the mode having negative eigenvalue is appropriate The steps will act to keep the energy near its minimum along all but one direction and the step will move the system uphill in energy along the direction having negative curvature exactly as one desires when walking uphill in a streambed toward a mountain pass However even the procedure just outlined for finding a transition state can produce misleading results unless some extent of chemical intuition is used Let me give an example to illustrate this point Lets assume that one wants to find begin near the geometry of the van der Waals complex involving ethylene and propene and to then locate the transition state on the reaction path leading to the cycloaddition products methylcyclobutane as also shown in Figure a Consider employing either of two strategies to begin the walk leading from the van der Waals complex to the desired transition state TS One could find the lowest nontranslation or nonrotation Hessian eigenvalue and take a small step uphill along this direction to begin a streambed walk that might lead to the TS Using the smallest Hessian eigenvalue to identify a direction to explore makes sense because it is along this direction that the energy surface rises least abruptly at least near the geometry of the reactants One could move the ethylene radially a bit say  closer to the propene to generate an initial geometry to begin the TS search This makes sense because one knows the reaction must lead to interfragment carboncarbon distances that are much shorter in the methylcyclobutane products than in the van der Waals complex The first strategy suggested above will likely fail because the series of steps generated by walking uphill along the lowest Hessian eigenmode will produce a path leading from eclipsed to staggered orientation of propenes methyl group Indeed this path leads to a TS but it is not the cycloaddition TS that we want The takehome lesson here is that uphill streambed walks beginning at a minimum on the reactants potential energy surface may or may not lead to the desired TS Such walks are not foolish to attempt but one should examine the nature of the eigenmode being followed to judge whether displacements along this mode make chemical sense Clearly only rotating the methyl group is not a good way to move from ethylene and propene to methylcyclobutane The second strategy suggested above might succeed but it would probably still need to be refined For example if the displacement of the ethylene toward the propene were too small one would not have distorted the system enough to move it into a region where the energy surface has negative curvature along the reaction path as it must have as one approaches the TS So if the Hessian eigenmodes whose eigenvectors possess substantial interfragment radial displacements are all positive one has probably not moved the two fragments close enough together Probably the best way to then proceed would be to move the two fragments even closer or to move them along a linear synchronous path connecting the reactants and products until one finds a geometry at which a negative Hessian eigenvalues eigenmode has substantial components along what appears to be reasonable for the desired reaction path ie substantial displacements leading to shorter interfragment carboncarbon distances Once one has found such a geometry one can use the strategies detailed earlier eg to then walk uphill along one mode while minimizing along the other modes to move toward the TS If successful such a process will lead to the TS at which all components of the gradient vanish and all but one eigenvalue of the Hessian is positive The takehome lesson of the example is it is wise to try to first find a geometry close enough to the TS to cause the Hessian to have a negative eigenvalue whose eigenvector has substantial character along directions that make chemical sense for the reaction path In either a series of steps toward a minimum or toward a TS once a step has been suggested within the eigenmode basis one needs to express that step in terms of the original Cartesian coordinates so that these Cartesian values can be altered within the software program to effect the predicted step Given values for the or step components nb the step components along the or modes having zero Hessian eigenvalues can be taken to be zero because the would simply translate or rotate the molecule one must compute the To do so we use the relationship and write its inverse using the unitary nature of the matrix to compute the desired Cartesian step components In using the Hessianbased approaches outlined above one has to take special care when one or more of the Hessian eigenvalues is small This often happens when one has a molecule containing soft modes ie degrees of freedom along which the energy varies little or as one moves from a region of negative curvature into a region of positive curvature or vice versa in such cases the curvature must move through or near zero For these situations the expression can produce a very large step along the mode having small curvature Care must be taken to not allow such incorrect artificially large steps to be taken Energy Surface Intersections I should note that there are other important regions of potential energy surfaces that one must be able to locate and characterize Above we focused on local minima and transition states Later in this Chapter and again in Chapter we will discuss how to follow socalled reaction paths that connect these two kinds of stationary points using the type of gradient and Hessian information that we introduced earlier in this Chapter It is sometimes important to find geometries at which two BornOppenheimer energy surfaces and intersect because such regions often serve as efficient funnels for trajectories or wave packets evolving on one surface to undergo socalled nonadiabatic transitions to the other surface Lets spend a few minutes thinking about under what circumstances such surfaces can indeed intersect because students often hear that surfaces do not intersect but instead undergo avoided crossings To understand the issue let us assume that we have two wave functions and both of which depend on coordinates These two functions are not assumed to be exact eigenfunctions of the Hamiltonian but likely are chosen to approximate such eigenfunctions To find the improved functions and that more accurately represent the eigenstates one usually forms linear combinations of and from which a x matrix eigenvalue problem arises leftbeginarraycc H_E H_ H_ H_E endarrayright This quadratic equation has two solutions These two solutions can be equal ie the two state energies can cross only if the square root factor vanishes Because this factor is a sum of two squares each thus being positive quantities this can only happen if two identities hold simultaneously ie at the same geometry and The main point then is that in the dimensional space the two states will generally not have equal energy However in a space of two lower dimensions because there are two conditions that must simultaneously be obeyed and their energies may be equal They do not have to be equal but it is possible that they are It is based upon such an analysis that one usually says that potential energy surfaces in dimensions may undergo intersections in spaces of dimension If the two states are of different symmetry eg one is a singlet and the other a triplet the offdiagonal element vanishes automatically so only one other condition is needed to realize crossing So we say that two states of different symmetry can cross in a space of dimension For a triatomic molecule with internal degrees of freedom this means that surfaces of the same symmetry can cross in a space of dimension ie along a line while those of different symmetry can cross in a space of dimension ie in a plane An example of such a surface intersection is shown in Figure c Figure c Depiction of the and BornOppenheimer surfaces arising when Al combines with to form First considering the reaction of Al s p P with to form AlHA_ as if it were to occur in symmetry the atoms occupied p orbital can be directed in either of three ways If it is directed toward the midpoint of the HH bond it produces an electronic state of symmetry If it is directed out of the plane of the it gives a state of symmetry and if it is directed parallel to the HH bond it generates a state of symmetry The state is as shown in the upper left of Figure c repulsive as the Al atoms s and p orbitals begin to overlap with the hydrogen molecules orbital at large values The state in which the occupied p orbital is directed sideways parallel to the HH bond leads to a shallow van der Waals well at longR but also moves to higher energy at shorter values The ground state of the molecule has its five valence orbitals occupied as follows two electrons occupy a bonding AlH orbital of symmetry two electrons occupy a bonding AlH orbital of symmetry and the remaining electron occupies a nonbonding orbital of character localized on the Al atom and having a symmetry This orbital occupancy of the molecules ground state does not correlate directly with any of the three degenerate configurations of the ground state of which are and as explained earlier It is this lack of direct configuration correlation that generates the reaction barrier show in Figure c Let us now return to the issue of finding the lowerdimensional or space in which two surfaces cross assuming one has available information about the gradients and Hessians of both of these energy surfaces and There are two components of characterizing the intersection space within which One has to first locate one geometry lying within this space and then one has to sample nearby geometries eg that might have lower total energy lying within this subspace where To locate a geometry at which the difference function passes through zero one can employ conventional functional minimization methods such as those detailed earlier when discussing how to find energy minima to locate where but now the function one is seeking to locate a minimum on is the potential energy surface difference Once one such geometry has been located one subsequently tries to follow the seam ie for a triatomic molecule this is the onedimensional line of crossing for larger molecules it is a dimensional space within which the function remains zero Professor David Yarkony has developed efficient routines for characterizing such subspaces D R Yarkony Acc Chem Res The basic idea is to parameterize steps away from in a manner that constrains such steps to have no component along either the gradient of or along the gradient of Because requires having both and taking steps obeying these two constraints allows one to remain within the subspace where and are simultaneously obeyed Of course it is a formidable task to map out the entire or dimensional space within which the two surfaces intersect and this is essentially never done Instead it is common to try to find for example the point within this subspace at which the two surfaces have their lowest energy An example of such a point is labeled RMECP in Figure c and would be of special interest when studying reactions taking place on the lowerenergy surface that have to access the surfacecrossing seam to evolve onto the upper surface The energy at RMECP reflects the lowest energy needed to access this surface crossing Such intersection seam location procedures are becoming more commonly employed but are still under very active development so I will refer the reader to Prof Yarkonys paper cited above for further guidance For now it should suffice to say that locating such surface intersections is an important ingredient when one is interested in studying for example photochemical reactions in which the reactants and products may move from one electronic surface to another or thermal reactions that require the system to evolve onto an excited state through a surface crossing Endnotes This is a series of geometries defined through a linear interpolation using a parameter between the Cartesian coordinates belonging to the equilibrium geometry of the reactants and the corresponding coordinates of the products Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Summary Thermodynamic Functions as Criteria for Change Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers For a spontaneous process we conclude that the entropy change of the system must satisfy the inequality For any process that occurs reversibly we conclude that For every incremental part of a reversible process that occurs in a closed system we have the following relationships At constant entropy the energy relationship becomes At constant temperature the Helmholtz free energy relationship becomes For reversible processes in which all work is pressurevolume work From these general equations we find the following relationships for reversible processes when various pairs of variables are held constant If the only work is pressurevolume work then and these relationships become For every incremental part of an irreversible process that occurs in a closed system at constant entropy and and and For an irreversible process at constant temperature and and and When an irreversible process occurs with various pairs of variables held constant we find For irreversible processes in which the only work is pressurevolume work these inequalities become Temperature Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors and Attributions Another important variable that describes the state of a system it the systems temperature Like pressure temperature scales experienced an important process of development over time Three of the most important temperature scales in US culture are the Fahrenheit Celsius and Kelvin scales Figure left G Daniel Fahrenheit CC BY and right Anders Celsius G Daniel Fahrenheit wanted to develop a temperature scale that would be convenient to use in his laboratory He wanted it to be of convenient magnitude and wanted to avoid having to use any negative values for temperature So he define the zero of his temperature scale to be the lowest temperature he could create in his laboratory which was in a saturated brinewaterice slurry He then defined F as his own body temperature As a result using his temperature scale water has a normal melting point the temperature at atm pressure at which water ice melts of F Similarly water boils again at atm pressure at a temperature of F The difference between these values is F Anders Celsius also thought a degree temperature scale made sense and was given the name the centigrade scale He defined C on his scale as the normal boiling point of water and C as the normal freezing point By todays standards this inverted temperature scale makes little sense The modern Celsius temperature scale defines C as the normal freezing point of water and C as the normal boiling point The difference is C Comparing this to the Fahrenheit scale one can easily construct a simple equation to convert between the two scales Solving these equations for and yields And so conversion between the two scales is fairly simple Many physical properties of matter suggest that there is an absolute minimum temperature that can be attained by any sample This minimum temperature can be shown by several types or experiments to be C An absolute temperature scale is one that assigns the minimum temperature a value of One particularly useful scale is named after William Lord Kelvin Kelvin Lord William Thomson Figure William Lord Kelvin The Kelvin scale fixes the normal melting temperature of water at K and the boiling point at K As such temperatures can be converted using the following expression Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Temperature and the Ideal Gas Thermometer Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers In Section we suppose that we have a thermometer that we can use to measure the temperature of a gas We suppose that this thermometer uses a liquid and we define an increase in temperature by the increase in the volume of this liquid Our statement of Charles law asserts that the volume of a gas is a linear function of the volume of the liquid in our thermometer and that the same linear function is observed for any gas As we note in Section there is a problem with this statement Careful experiments with such thermometers produce results that deviate from Charles law With sufficiently accurate volume measurements this occurs to some extent for any choice of the liquid in the thermometer If we make sufficiently accurate measurements the volume of a gas is not exactly proportional to the volume of any liquid or solid that we might choose as the working substance in our thermometer That is if we base our temperature scale on a liquid or solid substance we observe deviations from Charles law There is a further difficulty with using a liquid as the standard fluid on which to base our temperature measurements temperatures outside the liquid range of the chosen substance have to be measured in some other way Evidently we can choose to use a gas as the working fluid in our thermometer That is our gasvolume measuring device is itself a thermometer This fact proves to be very useful because of a further experimental observation To a very good approximation we find If we keep the pressures in the thermometer and in some other gaseous system constant at low enough values both gases behave as ideal gases and we find that the volumes of the two gases are proportional to each other over any range of temperature Moreover this proportionality is observed for any choice of either gas This means that we can define temperature in terms of the expansion of any constantpressure gas that behaves ideally In principle we can measure the same temperature using any gas so long as the constant operating pressure is low enough When we do so our device is called the ideal gas thermometer In so far as any gas behaves as an ideal gas at a sufficiently low pressure any real gas can be used in an ideal gas thermometer and to measure any temperature accurately Of course practical problems emerge when we attempt to make such measurements at very high and very low temperatures The very nearly direct proportionality of two lowpressure real gas volumes contrasts with what we observe for liquids and solids In general the volume of a given liquid or solid substance is not exactly proportional to the volume of a second liquid or solid substance over a wide range of temperatures In practice the idealgas thermometer is not as convenient to use as other thermometerslike the mercuryinglass thermometer However the idealgas thermometer is used to calibrate other thermometers Of course we have to calibrate the idealgas thermometer itself before we can use it We do this by assigning a temperature of K to the triple point of water It turns out that the melting point of ice isnt sufficiently reproducible for the most precise work Recall that the triple point is the temperature and pressure at which all three phases of water are at equilibrium with one another with no air or other substances present The triplepoint pressure is Pa or atm See Section From both theoretical considerations and experimental observations we are confident that no system can attain a temperature below absolute zero Thus the size of the kelvin one degree on the Kelvin scale is fixed by the difference in temperature between a system at the triple point of water and one at absolute zero If our ideal gas thermometer has volume at thermal equilibrium with some other constanttemperature system the proportionality of and means that With the triple point fixed at K experiments find the freezing point of airsaturated water to be K when the system pressure is atmosphere So the melting point of ice is K and the triplepoint is C We will find two reasons for the fact that the melting point is lower than the triple point In Section we find that the melting point of ice decreases as the pressure increases In Section we find that solutes usually decrease the temperature at which the liquid and solid states of a substance are in phase equilibrium If we could use an ideal gas in our idealgas thermometer we could be confident that we had a rigorous operational definition of temperature However we note in Section that any real gas will exhibit departures from ideal gas behavior if we make sufficiently accurate measurements For extremely accurate work we need a way to correct the temperature value that we associate with a given realgas volume The issue here is the value of the partial derivative For one mole of an ideal gas is a constant For a real gas it is a function of temperature Let us assume that we know this function Let the molar volume of the real gas at the triple point of water be and its volume at thermal equilibrium with a system whose true temperature is be We have When we know the integrand on the left as a function of temperature we can do the integration and find the temperature corresponding to any measured volume When the working fluid in our thermometer is a real gas we make measurements to find as a function of temperature Here we encounter a circularity To find from pressurevolumetemperature data we must have a way to measure temperature however this is the very thing that we are trying to find In principle we can surmount this difficulty by iteratively correcting the temperature that we associate with a given realgas volume As a first approximation we use the temperatures that we measure with an uncorrected realgas thermometer These temperatures are a first approximation to the idealgas temperature scale Using this scale we make nonpressurevolumetemperature measurements that establish as a function of temperature for the real gas This function is where is the constantpressure heat capacity and is the JouleThomson coefficient Both are functions of temperature We introduce in Section We discuss the JouleThomson coefficient further in Section below and in detail in Section Typically and the value of is well approximated by With established using this scale integration yields a secondapproximation to the idealgas temperatures We could repeat this process until successive temperature scales converge at the number of significant figures that our experimental accuracy can support In practice there are several kinds of idealgas thermometers and numerous corrections are required for very accurate measurements There are also numerous other ways to measure temperature each of which has its own complications Our development has considered some of the ideas that have given rise to the concept that temperature is fundamental property of nature that can be measured using a thermodynamictemperature scale on which values begin at zero and increase to arbitrarily high values This thermodynamic temperature scale is a creature of theory whose realworld counterpart would be the scale established by an idealgas thermometer whose gas actually obeyed at all conditions We have seen that such an idealgas thermometer is itself a creature of theory The current realworld standard temperature scale is the International Temperature Scale of ITS This defines temperature over a wide range in terms of the pressurevolume relationships of helium isotopes and the triple points of several selected elements The triple points fix the temperature at each of several conditions up to K the freezing point of copper Needless to say the temperatures assigned at the fixed points are the results of painstaking experiments designed to give the closest possible match to the thermodynamic scale A variety of measuring devicesthermometerscan be used to interpolate temperature values between different pairs of fixed points Temperature Dependence of A and G Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors and Attributions In differential form the free energy functions can be expressed as and So by inspection it is easy to see that left dfracpartial Apartial T right_V S and left dfracpartial Gpartial T right_p S And so it should be fairly straightforward to determine how each changes with changing temperature and But the temperature dependence of the entropy needed to be known in order to evaluate the integral A convenient workaround can be obtained starting from the definitions of the free energy functions and Dividing by yields and Now differentiating each expression with respect to at constant or respectively yields and Or differentiating with respect to provides a simpler form that is mathematically equivalent and Focusing on the second expression since all of the arguments apply to the first as well we see a system that can be integrated Multiplying both sides by yields Or for finite changes and and integration assuming the enthalpy change is constant over the temperature interval yields dfracDelta G_T_T_ dfracDelta G_T_T_ Delta H left dfracT_ dfracT_ right labelGH Equation refHG is the GibbsHelmholtz equation and can be used to determine how changes with changing temperature The equivalent equation for the Helmholtz function is dfracDelta A_T_T_ dfracDelta A_T_T_ Delta U leftdfracT_ dfracT_ right labelGH Example Given the following data at K calculate at K for the following reaction Compound kJmol kJmol CHg COg HOg Solution and and can be calculated fairly easily It will be assumed that is constant over the temperature range of K K So using Equation refGH with the data just calculated gives Note became a little bit less negative at the higher temperature which is to be expected for a reaction which is exothermic An increase in temperature should tend to make the reaction less favorable to the formation of products which is exactly what is seen in this case Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Temperature Dependence of Enthalpy Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors and Attributions It is often required to know thermodynamic functions such as enthalpy at temperatures other than those available from tabulated data Fortunately the conversion to other temperatures is not difficult At constant pressure And so for a temperature change from to Delta H int_T_T_ C_p dT labelEQ Equation refEQ is often referred to as Kirchhoffs Law If is independent of temperature then If the temperature dependence of the heat capacity is known it can be incorporated into the integral in Equation refEQ A common empirical model used to fit heat capacities over broad temperature ranges is After combining Equations refEQ and refEQ the enthalpy change for the temperature change can be found obtained by a simple integration Solving the definite integral yields beginalign Delta H left aT dfracb T dfraccT right_T_T_ aT_T_ dfracbT_T_ c left dfracT_ dfracT_ right labelineq endalign This expression can then be used with experimentally determined values of and some of which are shown in the following table Table Empirical Parameters for the temperature dependence of Substance a J mol K b J mol K c J mol K Cgr x x COg x x HOl Ng x x Pbs x x Example Heating Lead What is the molar enthalpy change for a temperature increase from K to K for Pbs Solution The enthalpy change is given by Equation refEQ with a temperature dependence given by Equation refEQ using the parameters in Table This results in the integral form Equation refineq when substituted with the relevant parameters of Pbs from Table beginalign Delta H dfracJmolK K K dfrac times fracJmolK left K K right times dfracJKmol left dfracK dfracK right Delta H dfracJmol dfracJmol dfracJmol dfracJmol end align For chemical reactions the reaction enthalpy at differing temperatures can be calculated from Example Enthalpy of Formation The enthalpy of formation of NHg is kJmol at oC Calculate the enthalpy of formation at oC Solution with Compound Cp J mol K Ng Hg NHg beginalign Delta H K Delta H K Delta C_pDelta T dfracJmol left left dfracJmolKright left dfracJmolKright left dfracJmolKright right K K dfrackJmol endalign Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Temperature Dependence of Equilibrium Constants the van t Hoff Equation Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors and Attributions The value of Kp is independent of pressure although the composition of a system at equilibrium may be very much dependent on pressure Temperature dependence is another matter Because the value of is dependent on temperature the value of is as well The form of the temperature dependence can be taken from the definition of the Gibbs function At constant temperature and pressure Substituting For the two values of and using the appropriate temperatures yields And simplifying the expression so that only terms involving K are on the left and all other terms are on the right results in the van t Hoff equation which describes the temperature dependence of the equilibrium constant Because of the assumptions made in the derivation of the GibbsHelmholtz equation this relationship only holds if is independent of temperature over the range being considered This expression also suggests that a plot of as a function of should produce a straight line with a slope equal to Such a plot is known as a van t Hoff plot and can be used to determine the reaction enthalpy Example A certain reaction has a value of at C and Calculate the value of at C Solution This is a job for the van t Hoff equation T K T K K K So Equation refvH becomes Note the value of increased with increasing temperature which is what is expected for an endothermic reaction An increase in temperature should result in an increase of product formation in the equilibrium mixture But unlike a change in pressure a change in temperature actually leads to a change in the value of the equilibrium constant Example Given the following average bond enthalpies for PCl and ClCl bonds predict whether or not an increase in temperature will lead to a larger or smaller degree of dissociation for the reaction XY DXY kJmol PCl ClCl Solution The estimated reaction enthalpy is given by the total energy expended breaking bonds minus the energy recovered by the formation of bonds Since this reaction involves breaking two PCl bonds costing kJmol and the formation of one ClCl bond recovering kJmol it is clear that the reaction is endothermic by approximately kJmol As such an increase in temperature should increase the value of the equilibrium constant causing the degree of dissociation to be increased at the higher temperature Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay The Barometric Formula Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers We can measure the pressure of the atmosphere at any location by using a barometer A mercury barometer is a sealed tube that contains a vertical column of liquid mercury The space in the tube above the liquid mercury is occupied by mercury vapor Since the vapor pressure of liquid mercury at ordinary temperatures is very low the pressure at the top of the mercury column is very low and can usually be ignored The pressure at the bottom of the column of mercury is equal to the pressure of a column of air extending from the elevation of the barometer all the way to the top of the earths atmosphere As we take the barometer to higher altitudes we find that the height of the mercury column decreases because less and less of the atmosphere is above the barometer Figure Atmospheric pressure versus altitude If we assume that the atmosphere is composed of an ideal gas and that its temperature is constant we can derive an equation for atmospheric pressure as a function of altitude Imagine a cylindrical column of air extending from the earths surface to the top of the atmosphere Figure The force exerted by this column at its base is the weight of the air in the column the pressure is this weight divided by the crosssectional area of the column Let the crosssectional area of the column be Consider a short section of this column Let the bottom of this section be a distance from the earths surface while its top is a distance from the earths surface The volume of this cylindrical section is then Let the mass of the gas in this section be The pressure at is less than the pressure at by the weight of this gas divided by the crosssectional area The weight of the gas is The pressure difference is We have Since we are assuming that the sample of gas in the cylindrical section behaves ideally we have Substituting for and taking the limit as we find where we introduce as the number of moles of gas in the sample as the molar mass of this gas and as the mass of an individual atmosphere molecule The last equality on the right makes use of the identities and Separating variables and integrating between limits and we find so that and Either of the latter relationships is frequently called the barometric formula If we let be the number of molecules per unit volume we can write and so that the barometric formula can be expressed in terms of these number densities as The BornOppenheimer Approximation Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Your First Application of Quantum Mechanics Motion of a Particle in One Dimension The Classical Probability Density Quantum Treatment Energies and Wave functions Probability Densities Classical and Quantum Probability Densities Time Propagation of Wave functionsContributors and Attributions One of the most important approximations relating to applying quantum mechanics to molecules and molecular ions is known as the BornOppenheimer BO approximation The basic idea behind this approximation involves realizing that in the full electronsplusnuclei Hamiltonian operator introduced above the time scales with which the electrons and nuclei move are usually quite different In particular the heavy nuclei ie even a H nucleus weighs nearly times what an electron weighs move ie vibrate and rotate more slowly than do the lighter electrons For example typical bond vibrational motions occur over time scales of ca s molecular rotations require times as long but electrons undergo periodic motions within their orbits on the s timescale if they reside within core or valence orbitals Thus we expect the electrons to be able to promptly adjust their motions to the much more slowly moving nuclei This observation motivates us to consider solving the Schrdinger equation for the movement of the electrons in the presence of fixed nuclei as a way to represent the fully adjusted state of the electrons at any fixed positions of the nuclei Of course we then have to have a way to describe the differences between how the electrons and nuclei behave in the absence of this approximation and how they move within the approximation These differences give rise to socalled nonBornOppenheimer corrections radiationless transitions surface hops and nonadiabatic transitions which we will deal with later It should be noted that this separation of time scales between fast electronic and slow vibration and rotation motions does not apply as well to for example Rydberg states of atoms and molecules As discussed earlier in such states the electron in the Rydberg orbital has much lower speed and much larger radial extent than for typical core or valence orbitals For this reason corrections to the BO model are usually more important to make when dealing with Rydberg states The electronic Hamiltonian that pertains to the motions of the electrons in the presence of clamped nuclei produces as its eigenvalues through the equation energies that depend on where the nuclei are located ie the coordinates As its eigenfunctions one obtains what are called electronic wave functions which also depend on where the nuclei are located The energies are what we usually call potential energy surfaces An example of such a surface is shown in Figure Figure Two dimensional potential energy surface showing local minima transition states and paths connecting them This surface depends on two geometrical coordinates and is a plot of one particular eigenvalue vs these two coordinates Although this plot has more information on it than we shall discuss now a few features are worth noting There appear to be three minima ie points where the derivative of with respect to both coordinates vanish and where the surface has positive curvature These points correspond as we will see toward the end of this introductory material to geometries of stable molecular structures The surface also displays two firstorder saddle points labeled transition structures A and B that connect the three minima These points have zero first derivative of with respect to both coordinates but have one direction of negative curvature As we will show later these points describe transition states that play crucial roles in the kinetics of transitions among the three stable geometries Keep in mind that Figure shows just one of the surfaces each molecule has a groundstate surface ie the one that is lowest in energy as well as an infinite number of excitedstate surfaces Lets now return to our discussion of the BO model and ask what one does once one has such an energy surface in hand The motion of the nuclei are subsequently within the BO model assumed to obey a Schrdinger equation in which defines a rotationvibration Hamiltonian for the particular energy state of interest The rotational and vibrational energies and wave functions belonging to each electronic state ie for each value of the index in are then found by solving a Hamiltonian This BO model forms the basis of much of how chemists view molecular structure and molecular spectroscopy For example as applied to formaldehyde we speak of the singlet ground electronic state with all electrons spin paired and occupying the lowest energy orbitals and its vibrational and rotational states as well as the and electronic states and their vibrational and rotational levels Although much more will be said about these concepts later in this text the student should be aware of the concepts of electronic energy surfaces ie the and the vibrationrotation states that belong to each such surface I should point out that the Cartesian coordinates used to describe the positions of the molecules nuclei can be replaced by Cartesian coordinates specifying the center of mass of the nuclei and other socalled internal coordinates that can be used to describe the molecules orientation these coordinates appear in the rotational kinetic energy and its bond lengths and angles these coordinates appear in the vibrational kinetic and potential energies When centerofmass and internal coordinates are used in place of the Cartesian coordinates the BornOppenheimer energy surfaces are seen to depend only on the internal coordinates Moreover if the molecules energy does not depend on its orientation eg if it is moving freely in the gas phase the will also not depend on the orientational coordinates but only on the vibrational coordinates Having been introduced to the concepts of operators wave functions the Hamiltonian and its Schrdinger equation it is important to now consider several examples of the applications of these concepts The examples treated below were chosen to provide the reader with valuable experience in solving the Schrdinger equation they were also chosen because they form the most elementary chemical models of electronic motions in conjugated molecules and in atoms rotations of linear molecules and vibrations of chemical bonds Your First Application of Quantum Mechanics Motion of a Particle in One Dimension This is a very important problem whose solutions chemists use to model a wide variety of phenomena Lets begin by examining the motion of a single particle of mass in one direction which we will call while under the influence of a potential denoted The classical expression for the total energy of such a system is where is the momentum of the particle along the xaxis To focus on specific examples consider how this particle would move if were of the forms shown in Figure where the total energy is denoted by the position of the horizontal line Figure Three characteristic potentials showing left and right classical turning points at energies denoted by the horizontal lines The Classical Probability Density I would like you to imagine what the probability density would be for this particle moving with total energy and with varying as the above three plots illustrate To conceptualize the probability density imagine the particle to have a blinking lamp attached to it and think of this lamp blinking say times for each time it takes for the particle to complete a full transit from its left turning point to its right turning point and back to the former The turning points and are the positions at which the particle if it were moving under Newtons laws would reverse direction as the momentum changes sign and turn around These positions can be found by asking where the momentum goes to zero These are the positions where all of the energy appears as potential energy and correspond in the above figures to the points where the dark horizontal lines touch the plots as shown in the central plot The probability density at any value of represents the fraction of time the particle spends at this value of ie within and Think of forming this density by allowing the blinking lamp attached to the particle to shed light on a photographic plate that is exposed to this light for many oscillations of the particle between and Alternatively one can express the probability that the particle spends between and by dividing the spatial distance by the velocity pm of the particle at the point Because is constant throughout the particles motion will be small at values where the particle is moving quickly ie where is low and will be high where the particle moves slowly where is high So the photographic plate will show a bright region where is high because the particle moves slowly in such regions and less brightness where is low Note however that as approaches the classical turning points the velocity approaches zero so the above expression for will approach infinity It does not mean the probability of finding the particle at the turning point is infinite it means that the probability density is infinite there This divergence of is a characteristic of the classical probability density that will be seen to be very different from the quantum probability density The bottom line is that the probability densities anticipated by analyzing the classical Newtonian dynamics of this one particle would appear as the histogram plots shown in Figure illustrate Figure Classical probability plots for the three potentials shown Where the particle has high kinetic energy and thus lower it spends less time and is small Where the particle moves slowly it spends more time and is larger For the plot on the right is constant within the box so the speed is constant hence is constant for all values within this onedimensional box I ask that you keep these plots in mind because they are very different from what one finds when one solves the Schrdinger equation for this same problem Also please keep in mind that these plots represent what one expects if the particle were moving according to classical Newtonian dynamics which we know it is not Quantum Treatment To solve for the quantum mechanical wave functions and energies of this same kind of problem we first write the Hamiltonian operator as discussed above by replacing by We then try to find solutions to that obey certain conditions These conditions are related to the fact that is supposed to be the probability density for finding the particle between and To keep things as simple as possible lets focus on the box potential shown in the right side of Figure This potential expressed as a function of is for and for for between and The fact that is infinite for and for and that the total energy must be finite says that must vanish in these two regions for and for This condition means that the particle cannot access regions of space where the potential is infinite The second condition that we make use of is that must be continuous this means that the probability of the particle being at cannot be discontinuously related to the probability of it being at a nearby point It is also true that the spatial derivative must be continuous except at points where the potential has an infinite discontinuity like it does in the example shown on the right in Figure The continuity of relates to continuity of momentum recall is a momentum operator When a particle moves under for example one of the two potential shown on the left or middle of Figure the potential smoothly changes as kinetic and potential energy interchange during the periodic motion In contrast when moving under the potential on the right of Figure the potential undergoes a sudden change of direction when the particle hits either wall So even classically the particles momentum undergoes a discontinuity at such hardwall turning points These conditions of continuity of and its spatial first derivative and that must vanish in regions of space where the potential is extremely high were postulated by the pioneers of quantum mechanics so that the predictions of the quantum theory would be in line with experimental observations Energies and Wave functions The secondorder differential equation has two solutions because it is a second order equation in the region between and where and where is defined as Hence the most general solution is some combination of these two We could alternatively use and as the two independent solutions we do so later in Section to illustrate because and can be rewritten in terms of and that is they span exactly the same space The fact that must vanish at nb vanishes for because is infinite there and is continuous so it must vanish at the point means that the weighting amplitude of the term must vanish because at That is The amplitude of the term is not affected by the condition that vanish at since itself vanishes at So now we know that is really of the form The condition that also vanish at because it vanishes for where again is infinite has two possible implications Either or must be such that The option would lead to an answer that vanishes at all values of and thus a probability that vanishes everywhere This is unacceptable because it would imply that the particle is never observed anywhere The other possibility is that Lets explore this answer because it offers the first example of energy quantization that you have probably encountered As you know the sin function vanishes at integral multiples of Hence must be some multiple of lets call the integer and write using the definition of in the form Solving this equation for the energy we obtain This result says that the only energy values that are capable of giving a wave function that will obey the above conditions are these specific values In other words not all energy values are allowed in the sense that they can produce functions that are continuous and vanish in regions where is infinite If one uses an energy that is not one of the allowed values and substitutes this into the resultant function will not vanish at I hope the solution to this problem reminds you of the violin string that we discussed earlier Recall that the violin string being tied down at and at gave rise to quantization of the wavelength just as the conditions that be continuous at and gave energy quantization Substituting into gives The value of A can be found by remembering that is supposed to represent the probability density for finding the particle at Such probability densities are supposed to be normalized meaning that their integral over all values should amount to unity So we can find A by requiring that where the integral ranges from to Looking up the integral of and solving the above equation for the socalled normalization constant gives and so The values that can take on are the choice is unacceptable because it would produce a wave function that vanishes at all The full x and t dependent wave functions are then given as Notice that the spatial probability density is not dependent on time and is equal to because the complex exponential disappears when is formed This means that the probability of finding the particle at various values of is timeindependent Another thing I want you to notice is that unlike the classical dynamics case not all energy values are allowed In the Newtonian dynamics situation could be specified and the particles momentum at any value was then determined to within a sign In contrast in quantum mechanics one must determine by solving the Schrdinger equation what the allowed values of are These values are quantized meaning that they occur only for discrete values determined by a quantum number by the mass of the particle m and by characteristics of the potential in this case Probability Densities Lets now look at some of the wave functions and compare the probability densities that they represent to the classical probability densities discussed earlier The and wave functions are shown in the top of Figure The corresponding quantum probability densities are shown below the wave functions in two formats as plots and shaded plots that could relate to the flashing light way of monitoring the particles location that we discussed earlier Figure The two lowest wave functions and probability densities A more complete set of wave functions for ranging from to are shown in Figure Figure Seven lowest wave functions and energies Notice that as the quantum number increases the energy also increases quadratically with in this case and the number of nodes in also increases Also notice that the probability densities are very different from what we encountered earlier for the classical case For example look at the and densities and compare them to the classical density illustrated in Figure Figure Classical probability density for potential shown The classical density is easy to understand because we are familiar with classical dynamics In this case we say that is constant within the box because the fact that is constant causes the kinetic energy and hence the speed of the particle to remain constant and this is true for any energy In contrast the quantum wave functions plot is peaked in the middle of the box and falls to zero at the walls The density has two peaks one to the left of the box midpoint and one to the right a node at the box midpoint and falls to zero at the walls One thing that students often ask me is how does the particle get from being in the left peak to being in the right peak if it has zero chance of ever being at the midpoint where the node is The difficulty with this question is that it is posed in a terminology that asks for a classical dynamics answer That is by asking how does the particle get one is demanding an answer that involves describing its motion ie it moves from here at time to there at time Unfortunately quantum mechanics does not deal with issues such as a particles trajectory ie where it is at various times but only with its probability of being somewhere ie The next section will treat such paradoxical issues even further Classical and Quantum Probability Densities As just noted it is tempting for most beginning students of quantum mechanics to attempt to interpret the quantum behavior of a particle in classical terms However this adventure is full of danger and bound to fail because small light particles simply do not move according to Newtons laws To illustrate lets try to understand what kind of classical motion would be consistent with the or quantum plots shown in Figure However as I hope you anticipate this attempt at gaining classical understanding of a quantum result will not work in that it will lead to nonsensical results My point in leading you to attempt such a classical understanding is to teach you that classical and quantum results are simply different and that you must resist the urge to impose a classical understanding on quantum results at least until you understand under what circumstances classical and quantum results should or should not be comparable For the case in Figure we note that is highest at the box midpoint and vanishes at and In a classical mechanics world this would mean that the particle moves slowly near and more quickly near and Because the particles total energy must remain constant as it moves in regions where it moves slowly the potential it experiences must be high and where it moves quickly must be small This analysis nb based on classical concepts would lead us to conclude that the arises from the particle moving in a potential that is high near and low as approaches or L A similar analysis of the plot for would lead us to conclude that the particle for which this is the correct must experience a potential that is high midway between and high midway between and and low near and near and These conclusions are crazy because we know that the potential for which we solved the Schrdinger equation to generate both of the wave functions and both probability densities is constant between and That is we know the same applies to the particle moving in the and states whereas the classical motion analysis offered above suggests that is different for these two cases What is wrong with our attempt to understand the quantum plots The mistake we made was in attempting to apply the equations and concepts of classical dynamics to a plot that did not arise from classical motion simply put one cannot ask how the particle is moving ie what is its speed at various positions when the particle is undergoing quantum dynamics Most students when first experiencing quantum wave functions and quantum probabilities try to think of the particle moving in a classical way that is consistent with the quantum This attempt to retain a degree of classical understanding of the particles movement is almost always met with frustration as I illustrated with the above example and will illustrate later in other cases Continuing with this first example of how one solves the Schrdinger equation and how one thinks of the quantized values and wave functions let me offer a little more optimistic note than offered in the preceding discussion If we examine the plot shown in Figure for and think of the corresponding we note that the plot would look something like that shown in Figure Figure Quantum probability density for showing seven peaks and six nodes It would have seven maxima separated by six nodes If we were to plot for a very large value such as we would find a plot having maxima separated by nodes with the maxima separated approximately by distances of L Such a plot when viewed in a coarsegrained sense ie focusing with somewhat blurred vision on the positions and heights of the maxima looks very much like the classical plot in which is constant for all Another way to look at the difference between the lown and highn quantum probability distributions is reflected in the socalled local de Broglie wavelength It can be shown that the classical and quantum probabilities will be similar in regions of space where This inequality will be true when is much larger than which is consistent with the view that high quantum states behave classically but it will not hold when is only slightly above ie for lowenergy quantum states and for any quantum state near classical turning points or when is smaller than ie in classically forbidden regions In summary it is a general result of quantum mechanics that the quantum distributions for large quantum numbers take on the form of the classical for the same potential that was used to solve the Schrdinger equation except near turning points and in classically forbidden regions It is also true that at any specified energy classical and quantum results agree better when one is dealing with heavy particles than for light particles For example a given energy corresponds to a higher quantum number in the particleinabox formula for a heavier particle than for a lighter particle Hence heavier particles moving with a given energy have more classical probability distributions To gain perspective about this matter in the table shown below I give the energy levels in kcal mol for a particle whose mass is or times an electrons mass constrained to move within a onedimensional region of length in Bohr units denoted  Energies kcal mol for various and combinations m me L a L a L a L a m me xn xn xn xn m me xn xn xn xn m me xn xn xn xn m me xn xn xn xn Clearly for electrons even when free to roam over nanometers eg or one does not need to access a very high quantum state to reach kcal mol of energy eg would be adequate for Recall it is high quantum states where one expects the classical and quantum spatial probability distribution to be similar So when treating electrons one is probably nearly always going to have to make use of quantum mechanics and one will not be able to rely on classical mechanics For light nuclei with masses near times the electrons mass if the particle is constrained to a small distance range eg again even low quantum states will have energies in excess of kcal mol Only when free to move over of to does kcal mol correspond to relatively large quantum numbers for which one expects nearclassical behavior The data shown in the above table can also be used to estimate when quantum behavior such as BoseEinstein condensation can be expected When constrained to particles in the amu mass range have translational energies in the cal mol range Realizing that cal mol K this means that translational temperatures near K would be needed to cause these particles to occupy their ground state In contrast particles with masses in the range of amu even when constrained to distances of ca  require to exceed ca before having kcal mol of translational energy When constrained to  kcal mol requires to exceed So heavy particles will even at low energies behave classically except if they are constrained to very short distances We will encounter this socalled quantumclassical correspondence principal again when we examine other model problems It is an important property of solutions to the Schrdinger equation because it is what allows us to bridge the gap between using the Schrdinger equation to treat small light particles and the Newton equations for macroscopic big heavy systems Time Propagation of Wave functions For a particle in a box system that exists in an eigenstate having an energy the timedependent wave function is that can be generated by applying the socalled time evolution operator to the wave function at where an explicit form for is The function has a spatial probability density that does not depend on time because since However it is possible to prepare systems even in real laboratory settings in states that are not single eigenstates we call such states superposition states For example consider a particle moving along the x axis within the box potential but in a state whose wave function at some initial time is This is a superposition of the and eigenstates The probability density associated with this function is The and components the superposition and the probability density at are shown in the first three panels of Figure Figure The and wave functions upper left their superposition upper right and the bottom left and timeevolved bottom right probability densities of the superposition It should be noted that the probability density associated with this superposition state is not symmetric about the midpoint even though the and component wave functions and densities are Such a density describes the particle localized more strongly in the largex region of the box than in the smallx region at Now lets consider the superposition wave function and its density at later times Applying the time evolution operator to generates this timeevolved function at time t The spatial probability density associated with this is At this function clearly reduces to that written earlier for Notice that as time evolves this density changes because of the factor it contains In particular note that as moves through a period of time the cos factor changes sign That is for the factor is for the cos factor is for it returns to The result of this timevariation in the cos factor is that changes in form from that shown in the bottom left panel of Figure to that shown in the bottom right panel at and then back to the form in the bottom left panel at One can interpret this time variation as describing the particles probability density not its classical position initially localized toward the right side of the box moving to the left and then back to the right Of course this time evolution will continue over more and more cycles as time evolves further This example illustrates once again the difficulty with attempting to localize particles that are being described by quantum wave functions For example a particle that is characterized by the eigenstate is more likely to be detected near than near or because the square of this function is large near A particle in the state is most likely to be found near and but not near or The issue of how the particle in the latter state moves from being near to is not something quantum mechanics deals with Quantum mechanics does not allow us to follow the particles trajectory which is what we need to know when we ask how it moves from one place to another Nevertheless superposition wave functions can offer to some extent the opportunity to follow the motion of the particle For example the superposition state written above as has a probability amplitude that changes with time as shown in Figure Moreover this amplitudes major peak does move from side to side within the box as time evolves So in this case we can say with what frequency the major peak moves back and forth In a sense this allows us to follow the particles movements but only to the extent that we are satisfied with ascribing its location to the position of the major peak in its probability distribution That is we can not really follow its precise location but we can follow the location of where it is very likely to be found However notice that the time it takes the particle to move from right to left is dependent upon the energy difference between the two states contributing to the superposition state not to the energy of either of these states which is very different from what would expect if the particle were moving classically These are important observation that I hope the student will keep fresh in mind They are also important ingredients in modern quantum dynamics in which localized wave packets which are similar to superposed eigenstates discussed above are used to detail the position and speed of a particles main probability density peak The above example illustrates how one timeevolves a wave function that is expressed as a linear combination ie superposition of eigenstates of the problem at hand There is a large amount of current effort in the theoretical chemistry community aimed at developing efficient approximations to the evolution operator that do not require to be explicitly written as a sum of eigenstates This is important because for most systems of direct relevance to molecules one can not solve for the eigenstates it is simply too difficult to do so You can find a significantly more detailed treatment of the researchlevel treatment of this subject in my Theory Page web site and my QMIC textbook However lets spend a little time on a brief introduction to what is involved The problem is to express where is some initial wave function but not an eigenstate in a manner that does not require one to first find the eigenstates of and to expand in terms of these eigenstates after which the desired function is written as The basic idea is to break the operator into its kinetic and potential energy components and to realize that the differential operators appear in only The importance of this observation lies in the fact that and do not commute which means that is not equal to nb recall that for two quantities to commute means that their order of appearance does not matter Why do they not commute Because contains second derivatives with respect to the coordinates q_j that depends on so for example is not equal to The fact that and do not commute is important because the most obvious attempt to approximate is to write this single exponential in terms of and However the identity is not fully valid as one can see by expanding all three of the above exponential factors as and noting that the two sides of the above equation only agree if one can assume that which as we noted is not true In most modern approaches to time propagation one divides the time interval into many ie of them small time slices One then expresses the evolution operator as a product of shorttime propagators the student should by now be familiar with the fact that and are operators so from now on I will no longer necessarily use bold lettering for these quantities If one can then develop an efficient means of propagating for a short time one can then do so over and over again times to achieve the desired fulltime propagation It can be shown that the exponential operator involving can better be approximated in terms of the and exponential operators as follows So if one can be satisfied with propagating for very short time intervals so that the term can be neglected one can indeed use as an approximation for the propagator It can also be shown that the socalled split shorttime expression provides an even more accurate representation of the shorttime propagator because expansions of the left and righthand sides agree to higher orders in To progress further one then expresses acting on in terms of the eigenfunctions of the kinetic energy operator Note that these eigenfunctions do not depend on the nature of the potential V so this step is valid for any and all potentials The eigenfunctions of are the momentum eigenfunctions that we discussed earlier and they obey the following orthogonality and completeness relations Writing as and using the above expression for gives Then inserting the explicit expressions for and in terms of gives Now allowing to act on produces The integral over above can be carried out analytically and gives So the final expression for the shorttime propagated wave function is which is the working equation one uses to compute knowing Notice that all one needs to know to apply this formula is the potential at each point in space One does not need to know any of the eigenfunctions of the Hamiltonian to apply this method This is especially attractive when dealing with very large molecules or molecules in condensed media where it is essentially impossible to determine any of the eigenstates and where the energy spacings between eigenstates is extremely small However one does have to use this formula over and over again to propagate the initial wave function through many small time steps to achieve full propagation for the desired time interval Because this type of time propagation technique is a very active area of research in the theory community it is likely to continue to be refined and improved Further discussion of it is beyond the scope of this book so I will not go further into this direction The web site of Professor Nancy Makri provides access to further information about the quantum time propagation research area Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis The Carnot Cycle for an Ideal Gas and the Entropy Concept Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Historically the steam engine was the first machine for converting heat into work that could be exploited on a large scale The steam engine played a major role in the industrial revolution and thus in the development of todays technologyintensive economy It was important also in the development of the basic concepts of thermodynamics A steam engine produces work when hot steam under pressure is introduced into a cylinder driving a piston outward A shaft connects the piston to a flywheel When the connecting shaft reaches its greatest extension the spent steam is vented to the atmosphere Thereafter the flywheel drives the piston inward The economic viability of the steam engine derives in part from the fact that the spent steam can be vented to the atmosphere at the end of each cycle However this is not a necessary feature of heat engines We can devise engines that alternately heat and cool a captive working fluid to convert heat energy into mechanical work Stirling engines are practical devices of this type A Carnot engine is a conceptual engine that exploits the response of a closed system to temperature changes A Carnot engine extracts heat from one reservoir at a fixed high temperature and discharges a lesser amount of heat into a second reservoir at a fixed lower temperature An amount of energy equal to the difference between these increments of heat energy appears in the surroundings as work For one cycle of the Carnot engine let the heat transferred to the system from the hot and cold reservoirs be and respectively We have and Let the net work done on the system be and the net work that appears in the surroundings be We have and For one cycle of the engine and since it follows that The energy input to the Carnot engine is and the useful work that appears in the surroundings is The heat accepted by the lowtemperature reservoir is a waste product in the sense that it represents energy that cannot be converted to mechanical work using this cycle All feasible heat engines share this feature of the Carnot engine In contrast a perpetual motion machine of the second kind converts its entire heat intake to work no portion of its heat intake goes unused The efficiency with which the Carnot engine converts the input energy to useful output energy is therefore We can generalize our consideration of heat engines to include any series of changes in which a closed system exchanges heat with its surroundings at more than one temperature delivers a positive quantity of work to the surroundings and returns to its original state We use the Carnot cycle and the machinebased statement of the second law to analyze systems that deliver pressurevolume work to the surroundings We consider both reversible and irreversible systems We begin by considering reversible Carnot cycles If any system reversibly traverses any closed path on a pressurevolume diagram the area enclosed by the path represents the pressurevolume work exchanged between the system and its surroundings If the area is not zero the system temperature changes during the cycle If the cycle is reversible all of the heat transfers that occur must occur reversibly We can apply our reasoning about reversible cycles to any closed system containing any collection of chemical substances so long as any phase changes or chemical reactions that occur do so reversibly This means that all phase and chemical changes that occur in the system must adjust rapidly to the new equilibrium positions that are imposed on them as a system traverses a Carnot cycle reversibly Figure An ideal gas Carnot cycle Note that the pressure axis is compressed In P is plotted vs V In Figure we describe the operation of a reversible Carnot engine in which the working fluid is an ideal gas We designate the systems initial pressure volume and temperature by and From this initial state we cause the ideal gas to undergo a reversible isothermal expansion in which it absorbs a quantity of heat from a hightemperature heat reservoir at We designate the pressure volume and temperature at the end of this isothermal expansion as and In a second step we reversibly and adiabatically expand the ideal gas until its temperature falls to that of the second lowtemperature heat reservoir We designate the pressure volume and temperature at the end of this adiabatic expansion as and We begin the return portion of the cycle by reversibly and isothermally compressing the ideal gas at the temperature of the cold reservoir We continue this reversible isothermal compression until the ideal gas reaches the pressure and volume from which an adiabatic compression will just return it to the initial state We designate the pressure volume and temperature at the end of this isothermal compression by and During this step the ideal gas gives up a quantity of heat to the lowtemperature reservoir Finally we reversibly and adiabatically compress the ideal gas to its original pressure volume and temperature For the hightemperature isothermal step we have and for the lowtemperature isothermal step we have For the adiabatic expansion and compression we have The corresponding energy and work terms are for the adiabatic expansion and for the adiabatic compression The heatcapacity integrals are the same except for the direction of integration they sum to zero and we have The net work done on the system is the sum of the work for these four steps The heat input occurs at the hightemperature reservoir so that The heat discharge occurs at the lowtemperature reservoir so that For one cycle of the reversible idealgas Carnot engine Because the two adiabatic steps involve the same limiting temperatures the energy of an ideal gas depends only on temperature and for both steps we see from Section that and The integrals over are the same except for the direction of integration They sum to zero so that and Using this result the second equation for the reversible Carnot engine efficiency becomes Equating our expressions for the efficiency of the reversible Carnot engine we find from which we have Since there is no heat transfer in the adiabatic steps and we can write this sum as If we divide the path around the cycle into a large number of very short segments the limit of this sum as the become very small is where the superscript serves as a reminder that the cycle must be traversed reversibly Now we can define a new function by the differential expression In this expression is the incremental change in that occurs when the system reversibly absorbs a small of increment of heat at a particular temperature For an ideal gas traversing a Carnot cycle we have shown that is of course the entropy function described in our entropybased statement of the second law We now want to see what the machinebased statement of the second law enables us to deduce about the properties of Since the change in is zero when an ideal gas goes around a complete Carnot cycle we can conjecture that is a state function Of course the fact that around one particular cycle does not prove that is a state function If is a state function it must be true that around any cycle whatsoever We now prove this for any reversible cycle The proof has two steps In the first we show that for a machine that uses any reversible system operating between two constanttemperature heat reservoirs to convert heat to work In the second step we show that for any system that reversibly traverses any closed path The Carnot Cycle for Any Reversible System Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers To show that for any reversible system taken around a Carnot cycle we first observe that the Carnot cycle can be traversed in the opposite direction In this case work is delivered to the engine and a quantity of heat is transferred from the lowtemperature reservoir to the hightemperature reservoir Operated in reverse the Carnot engine is a refrigerator Suppose that we have two identical idealgas Carnot machines one of which we operate as an engine while we operate the other as a refrigerator If we configure them so that the work output of the engine drives the refrigerator the effects of operating them together cancel completely The refrigerator exactly consumes the work output of the engine The heat transfers to and from the heat reservoirs offset exactly Now let us consider an idealgas Carnot engine and any other reversible engine that extracts heat from a hightemperature reservoir and rejects a portion of it to a lowtemperature reservoir Let us call these engines A and B We suppose that one is operated to produce work in its surroundings the other is operated to consume this work and transfer net heat energy from the lowtemperature to the hightemperature reservoir Let the net work done in one cycle on machines A and B be and respectively We can choose to make these engines any size that we please Let us size them so that one complete cycle of either engine exchanges the same quantity of heat with the hightemperature reservoir That is if the hightemperature reservoir delivers heat to engine A then it delivers heat to engine B Figure diagrams these engines With one operating as an engine and the other operating as a refrigerator we have When both engine and refrigerator have completed a cycle the high temperature reservoir has returned to its original state Figure Matched heat engine and refrigerator and a system that combines them We can create a combined device that consists of A running as an engine B running as a refrigerator and the hightemperature reservoir Figure also diagrams this combination When it executes one complete cycle the initial condition of the combined device is restored Therefore since E is a state function we have where we use the constraint Let us consider the possibility that that is the combined device does net work on the surroundings Then implies that In this cyclic process the combined device takes up a positive quantity of heat from a constanttemperature reservoir and delivers a positive quantity of work to the surroundings There is no other change in either the system or the surroundings This violates the machinebased statement of the second law Evidently it is not possible for the combined device to operate in the manner we have hypothesized We conclude that any such machine must always operate such that that is the net work done on the combined machine during any complete cycle must be either zero or some positive quantity In concluding that we specify that the combined machine has A running as a heat engine and B running as a refrigerator Now suppose that we reverse their roles and let and represent the net work for the reversed combination Applying the same argument as previously we conclude that But since the direction of operation is reversed for both machines we must also have and Hence we have or We conclude therefore that for any two matched reversible engines operating around a Carnot cycle This conclusion can be restated as a condition on the efficiencies of the two machines The individual efficiencies are and The efficiency equation is unaffected by the direction of operation because changing the direction changes the sign of every energy term in the cycle Changing the direction of operation is equivalent to multiplying both the numerator and denominator by minus one Then from it follows that Since we sized A and B so that we have so that for any reversible Carnot engines A and B operating between the same two heat reservoirs For the ideal gas engine we found For any reversible Carnot engine we have so that and This means that the efficiency relationship applies to any reversible Carnot engine It follows that the integral of around a Carnot cycle is zero for any reversible system The validity of these conclusions is independent of type of work that the engine produces if engine A is an idealgas engine engine B can be comprised of any system and can produce any kind of work In obtaining this result from the machinebased statement of the second law we make the additional assumption that pressurevolume work can be converted entirely to any other form of work and vice versa That is we assume that the work produced by engine A can reversibly drive engine B as a refrigerator whether engines A and B produce the same or different kinds of work The Chain Rule and the Dividethrough Rule Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers If we have while and are functions of another variable the chain rule states that If and are functions of variables and that is and the chain rule for partial derivatives is A useful mnemonic recognizes that these equations can be generated from the total differential by dividing through by We must specify that the new partial derivatives are taken with held constant This is sometimes called the dividethrough rule The dividethrough rule is a reliable expedient for generating new relationships among partial derivatives As a further example dividing by and specifying that any other variable is to be held constant produces a valid equation Letting w be the variable held constant we obtain where we recognize that The result is just the chain rule for when and that is when If we require that remain constant while and vary we can use the dividethough rule to obtain another useful relationship from the total differential If is constant This can only be true if there is a relationship between and To find this relationship we use the dividethrough rule to find when Dividing by and stipulating that is constant we find Since and we have In Chapter we find that the dividethrough rule is a convenient way to generate thermodynamic relationships The Clapeyron Equation Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors and Attributions Based on the thermodynamic criterion for equilibrium it is possible to draw some conclusions about the state variables and and how they are related along phase boundaries First the chemical potentials of the two phases and in equilibrium with one another must be equal Also any infinitesimal changes to the chemical potential of one phase must be offset by an infinitesimal change to the chemical potential of the other phase that is equal in magnitude Taking the difference between these Equations refeq and refeq shows that And since can be expressed in terms of molar volume and molar entropy It is clear that there will be constraints placed on changes of temperature and pressure while maintaining equilibrium between the phases Gathering pressure terms on one side and temperature terms on the other The differences and are the changes in molar volume and molar entropy for the phase changes respectively So the expression can be rewritten or Equation refclap is the Clapeyron equation This expression makes it easy to see how the phase diagram for water is qualitatively different than that for most substances Specifically the negative slope of the solidliquid boundary on a pressuretemperature phase diagram for water is very unusual and arises due to the fact that for water the molar volume of the liquid phase is smaller than that of the solid phase Given that for a phase change the Clapeyron equation is sometimes written Example Freezing WAter Calculate the magnitude of the change in freezing point for water and the density of ice is while that for liquid water is for an increase in pressure of at Solution The molar volume of ice is given by The molar volume of liquid water at oC is given by So for the phase change of which corresponds to an endothermic change is To find the change in temperature use the Clapeyron Equation Equation refclap and separating the variables Integration with the assumption that does not change much over the temperature range yields or so So the melting point will decrease by K Note that the phase with the smaller molar volume is favored at the higher pressure as expected from Le Chateliers principle Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay The ClausiusClapeyron Equation Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Temperature Dependence to Contributors and Attributions The Clapeyron equation can be developed further for phase equilibria involving the gas phase as one of the phases This is the case for either sublimation or vaporization In the case of vaporization the change in molar volume can be expressed Since substances undergo a very large increase in molar volume upon vaporization the molar volume of the condensed phase liquid in this case is negligibly small compared to the molar volume of the gas ie So And if the vapor can be treated as an ideal gas Substitution into the Claperyron equation yields Separating the variables puts the equation into an integrable form Noting that makes the integration very easy If the enthalpy of vaporization is independent of temperature over the range of conditions This is the ClausiusClapeyron equation It can also be used to describe the boundary between solid and vapor phases by substituting the enthalpy of sublimation Example The vapor pressure of a liquid triples when the temperature is increased from C to C What is the enthalpy of vaporization for the liquid Solution The problem can be solved using the ClausiusClapeyron equation Equation refCC The following values can be used Substitution into the ClausiusClapeyron equation yields The ClausiusClapeyron equation also suggests that a plot of vs should yield a straight line the slope of which is provided that is independent of temperature over the range of temperatures involved This approach is very useful when there are several pairs of measurements of vapor pressure and temperature Such a plot is shown below for water Figure For water which has a very large temperature dependence the linear relationship of vs holds fairly well over a broad range of temperatures So even though there is some curvature to the data a straight line fit still results in a reasonable description of the data depending of course on the precision needed in the experiment For this fit of the data is found to be kJmol Temperature Dependence to For systems that warrant it temperature dependence of can be included into the derivation of the model to fit vapor pressure as a function of temperature For example if the enthalpy of vaporization is assumed to take the following empirical form and substituting it into the differential form of the ClausiusClapeyron equation Equation refdiffCC generates or And so the integrated form becomes The results of fitting these data to the temperature dependent model are shown in the table below J mol a J mol K b J mol K c This results in calculated values of of kJmol at K and kJmol at K The results are a little bit skewed since there is no data above oC included in the fit A larger temperature dependence would be found if the highertemperature data were included in the fit Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay The Concept of Equilibrium Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers We are familiar with the idea that a system undergoing change eventually reaches equilibrium We say that a system is at equilibrium when no further change is possible When we talk about change we always have in mind some particular property We measure the change in the system by the amount of change in this property When the property stops changing we infer that the system has stopped changing and we say that the system has come to equilibrium Of course we may interest ourselves in a system in which many properties undergo change In such cases we recognize that the system as a whole cannot be at equilibrium until all of these properties stop changing On the other hand we also recognize that the absence of observable change is not enough to establish that a system is at equilibrium with respect to all of the possible changes that it could undergo We know that hydrogen burns readily in oxygen to form water but a mixture of hydrogen and oxygen undergoes no change under ordinary conditions This unchanging mixture is plainly not at equilibrium with respect to the combustion reaction Only when a catalyst or an ignition source is introduced does reaction begin It is also possible indeed probable that a system can be at equilibrium with respect to one process and not be at equilibrium with respect to other processes which while possible simply do not occur under the conditions at hand For example if an aqueous solution of the oxygencarrying protein hemoglobin is added to the hydrogenair system the protein will add or lose coordinated oxygen molecules until the equilibrium composition is reached If our investigation is focused on the proteinoxygenation reaction we do not hesitate to say that the system is at equilibrium The nonoccurrence of the oxygenhydrogen reaction is not relevant to the phenomenon we are studying It is even possible to reach a nonequilibrium state in which the concentrations of the reactants and products are constant Such a system is said to have reached a steady state In order for this to occur the reaction must occur in an open system that is one in which materials are being added or removed there must be continuous addition of reactants and continuous removal of products In Chapter we discuss a simple system in which this can be achieved A closed system is one that can neither gain nor lose material An isolated system is a closed system that can neither gain nor lose energy in consequence its volume is fixed In an isolated system change ceases when equilibrium is reached and conversely We will consider several commonly encountered kinds of change including mechanical motions heat transfers phase changes partitioning of a solute between two phases and chemical reactions Here we review briefly what occurs in each of these kinds of change In Chapter we review the characteristics that each of these kinds of change exhibits at equilibrium A system in mechanical equilibrium is stationary because the net force acting on any macroscopic portion of the system is zero Another way of describing such a situation is to say that the system does not move because of the presence of constraints that prevent movement Two macroscopic objects are in thermal equilibrium if they are at the same temperature We take this to be equivalent to saying that if the two objects are in contact with one another no heat flows between them Moreover if object A is in thermal equilibrium with each of two other objects B and C then we invariably find that objects B and C are in thermal equilibrium with one another This observation is sometimes called the zeroth law of thermodynamics It justifies the concept of temperature and the use of a standard systema thermometerto measure temperature For an isolated system to be in phase equilibrium it must contain macroscopic quantities of two or more phases and the amount of each phase present must be unchanging For example at K and bar and in the presence of one atmosphere of air liquid water and ice are in equilibrium the amounts of water and ice remain unchanged so long as the system remains isolated Similarly a saturated aqueous solution of copper sulfate is in equilibrium with solid copper sulfate if the system is isolated the amounts of solid and dissolved copper sulfate remain constant If a system is in phase equilibrium we can remove a portion of any phase without causing any change in the other phases At equilibrium the concentrations of species present in the various phases are independent of the absolute amount of each phase present It is only necessary that some amount of each phase be present To describe this property we say that the condition for equilibrium for is the same irrespective of the amounts of the phases present in the particular system For example if one of the species is present in both a gas phase and a condensed phase we can specify the equilibrium state by specifying the pressure and temperature of the system However we can change the relative amounts of the phases present in this equilibrium state by changing the volume of the system If its volume can change the system is not isolated Partitioning of a solute between two immiscible condensed phases is important in many chemical systems If we add water and chloroform to the same vessel two immiscible liquid phases are formed Elemental iodine is very sparingly soluble in water and substantially more soluble in chloroform If we add a small amount of iodine to the waterchloroform system some of the iodine dissolves in the water and the remainder dissolves in the chloroform layer We say that the iodine is distributed between the two phases When the iodine concentrations become constant we say that the system has reached distribution equilibrium In a chemical reaction one or more chemical substances reactants undergo a change to produce one or more new chemical substances products We are accustomed to representing chemical substances by symbols and representing their reactions by chemical equations Thus for the hydrolysis of ethyl acetate we write A chemical equation like this expresses a stoichiometric relationship between reactants and products Often we invoke it as a symbol for various distinctly different physical situations For example We may view the equation as a symbolic representation of a single solution that contains the four compounds ethyl acetate water acetic acid and ethanoland possibly other substances We may view the equation as a symbolic representation of a relationship between two systems whose proportions are arbitrary The first system comprises ethyl acetate and water The second system comprises acetic acid and ethanol The equation represents the idea that the first system can be converted into the second We may view the symbols on each side of the equation as representing mixtures of the indicated chemical substances in the specified stoichiometric proportions We may view the equation as representing the specified stoichiometric proportions of pure unmixed chemical substances When we are discussing changes in standard thermodynamic properties that accompany a chemical reaction this is the interpretation that we have in mind When we discuss a chemical equation the intended interpretation is normally evident from the context Indeed we often skip back and forth among these interpretations in the course of a single discussion Nevertheless it is important to avoid confusing them By doing experiments we can discover that there is an equation that uniquely defines the position of a chemical reaction at equilibrium an equation that we usually think of as the definition of the equilibrium constant If our measurements are not too accurate or we confine our study to a limited range of concentrations or the system is particularly well behaved we can express the equilibrium constant as a function of concentrations For the hydrolysis of ethyl acetate we find In general for the reaction we find That is at equilibrium the indicated function of reactant concentrations always computes to approximately the same numerical value When our concentration measurements are more accurate we find that we must introduce new quantities that we call chemical activities We can think of an activity as a corrected concentration The correction compensates for the effects of intermolecular attraction and repulsion Denoting the activity of substance as we find that gives a fully satisfactory characterization of the equilibrium states that are possible for systems in which this reaction occurs the equilibrium constant computed as a function of reactant activities always has exactly the same numerical value We can develop the equilibrium constant expression from three distinctly different theoretical treatments We develop it first from some basic ideas about the rates of chemical reactions Then we obtain same result from both the macroscopicbehavior considerations of classical thermodynamics and the molecularproperty considerations of statistical thermodynamics Our most basic concept of equilibrium is based on the observation that change in an isolated system eventually ceases once change ceases it never resumes In this book we call the idea of a static state of an isolated system the primitive equilibrium We also observe that change eventually ceases in a closed system that is not isolated but whose temperature pressure and volume are kept constant Conversely if a system is at equilibrium its temperature pressure and volume are necessarily constant all interactions between such a system and its surroundings can be severed without changing any of the properties of the system We can view any particular equilibrium state as a primitive equilibrium state A system whose temperature pressure or volume is established by interactions between the system and its surroundings is inherently more variable than an isolated system For a given isolated system only one equilibrium state exists for a system that interacts with its surroundings many different equilibrium states may be possible In chemical thermodynamics our goal is to develop mathematical models that specify the equilibrium states available to a system we seek models in which the independent variables include pressure temperature volume and other conditions that can be imposed on the system by its surroundings In this conception an equilibrium system is characterized by a set of points in a variable space We can think of this set of points as a surface or a manifold in the variable space every point in the set is a different primitiveequilibrium state of the system By imposing particular changes on some variables a particular equilibrium system can be made to pass continuously through a series of primitiveequilibrium states For reasons that become apparent as we proceed we use the name Gibbsian equilibrium to denote this more general conception When we talk about equilibrium in thermodynamics we usually mean Gibbsian equilibrium In Chapter we see that the idea of Gibbsian equilibrium is closely related to the idea of a reversible process We also introduce Gibbs phase rule which amounts to a more precise definition from the perspective of classical thermodynamics of what we mean by Gibbsian equilibrium in chemical systems The Difference between Cp and Cv Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors and Attributions Constant volume and constant pressure heat capacities are very important in the calculation of many changes The ratio appears in many expressions as well such as the relationship between pressure and volume along an adiabatic expansion It would be useful to derive an expression for the difference as well As it turns out this difference is expressible in terms of measureable physical properties of a substance such as and In order to derive an expression lets start from the definitions and The difference is thus In order to evaluate this difference consider the definition of enthalpy Differentiating this yields Dividing this expression by and constraining to constant gives The last term is kind enough to vanish since at constant pressure After converting the remaining terms to partial derivatives This expression is starting to show some of the players For example and So Equation reftotal becomes In order to evaluate the partial derivative above first consider Then the total differential can be expressed Dividing by and constraining to constant will generate the partial derivative we wish to evaluate The last term will become unity so after converting to partial derivatives we see that This incidentally is an example of partial derivative transformation type III Now we are getting somewhere and So the Equation refeq can be rewritten If we can find an expression for we are almost home free Fortunately that is an easy expression to derive Begin with the combined expression of the first and second laws Now divide both sides by and constrain to constant The last term is unity so after conversion to partial derivatives we see A Maxwell relation specifically the Maxwell relation on can be used Substituting this into Equation refeq yields and since then Now substituting this into the expression into Equation refeq to get This can now be substituted into the Equation refeq yields The terms will cancel And subtracting from both sides gives the desired result And this is a completely general result since the only assumptions made were those that allowed us to use the combined first and second laws in the form That means that this expression can be applied to any substance whether gas liquid animal vegetable or mineral But what is the result for an ideal gas Since we know that for an ideal gas and Substitution back into Equation reffinal yields beginalign C_p C_V dfracTV leftdfracTrightleftdfracpright So for an ideal gas That is good to know no Example Derive the expression for the difference between and by beginning with the definition of differentiating dividing by to generate the partial derivative definition of In this approach you will need to find expressions for and and also utilize the MaxwellRelation on Solution Begin with the definition of enthalpy Differentiate the expression Now divide by and constrain to constant as described in the instructions to generate the partial derivative definition of Now what is needed is an expression for This can be derived from the total differential for by dividing by and constraining to constant This again is an example of partial derivative transformation type III To continue we need an expression for This can be quickly generated by considering the total differential of its natural variables Dividing by and constraining to constant yields Using the Maxwell Relation on we can substitute So Equation refeqE becomes Now substitute this back into the expression for Equation refeqE This can now substituted for the righthand side of the initial expression for back into Equation refeqE Several terms cancel one another Equation refeqE can then be rearranged to yield or which might look familiar Equation reffinal Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay The Distribution Function as a Summary of Experimental Results Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers In Section we derive Boyles law from Newtons laws using the assumption that all gas molecules move at the same speed at a given temperature This is a poor assumption Individual gas molecules actually have a wide range of velocities In Chapter we derive the MaxwellBoltzmann distribution law for the distribution of molecular velocities This law gives the fraction of gas molecules having velocities in any range of velocities Before developing the MaxwellBoltzmann distribution law we need to develop some ideas about distribution functions Most of these ideas are mathematical We discuss them in a nonrigorous way focusing on understanding what they mean rather than on proving them The overriding idea is that we have a realworld source of data We call this source of data the distribution We can collect data from this source to whatever extent we please The datum that we collect is called the distributions random variable We call each possible value of the random variable an outcome The process of gathering a set of particular values of the random variable from a distribution is often called sampling or drawing a sample The set of values that is collected is called the sample The set of values that comprise the sample is often called the data In scientific applications the random variable is usually a number that results from making a measurement on a physical system Calling this process drawing a sample can be inappropriate Often we call the process of getting a value for the random variable doing an experiment doing a test or making a trial As we collect increasing amounts of data the accumulation quickly becomes unwieldy unless we can reduce it to a mathematical model We call the mathematical model we develop a distribution function because it is a function that expresses what we are able to learn about the data sourcethe distribution A distribution function is an equation that summarizes the results of many measurements it is a mathematical model for a realworld source of data Specifically it models the frequency of an event with which we obtain a particular outcome We usually believe that we can make our mathematical model behave as much like the realworld data source as we want if we use enough experimental data in developing it Often we talk about statistics By a statistic we mean any mathematical entity that we can calculate from data Broadly speaking a distribution function is a statistic because it is obtained by fitting a mathematical function to data that we collect Two other statistics are often used to characterize experimental data the mean and the variance The mean and variance are defined for any distribution We want to see how to estimate the mean and variance from a set of experimental data collected from a particular distribution We distinguish between discrete and continuous distributions A discrete distribution is a realworld source of data that can produce only particular data values A coin toss is a good example It can produce only two outcomesheads or tails A continuous distribution is a realworld source of data that can produce data values in a continuous range The speed of an automobile is a good example An automobile can have any speed within a rather wide range of speeds For this distribution the random variable is automobile speed Of course we can generate a discrete distribution by aggregating the results of sampling a continuous distribution if we lump all automobile speeds between mph and mph together we lose the detailed information about the speed of each automobile and retain only the total number of automobiles with speeds in this interval The Dumas Bulb Method for Measuring Decomposition Equilibrium Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors and Attributions A classic example of an experiment that is employed in many physical chemistry laboratory courses uses a Dumas Bulb method to measure the dissociation of NOg as a function of temperature Mack France In this experiment a glass bulb is used to create a constant volume container in which a volatile substance can evaporate or achieve equilibrium with other gases present The latter is of interest in the case of the reaction The reaction is endothermic so at higher temperatures a larger degree of dissociation is observed The procedure is to first calibrate the internal volume of the Dumas bulb This is done using a heavy gas such as SF and comparing the mass of the bulb when evacuated to the mass of the bulb full of the calibrant gas at a particular pressure and temperature Figure The Dumas bulb is then charged with a pure sample of the gas to be investigated such as NO and placed in a thermalized bath It is then allowed to come to equilibrium Once Equilibrium is established the stopcock is opened to allow gas to escape until the internal pressure is set to the pressure of the room The stopcock is then closed and the bulb weighed to determine the total mass of gas remaining inside The experiment is repeated at higher and higher temperatures so that at each subsequent measurement the larger degree of dissociation creates more molecules of gas and an increase in pressure in the bulb along with the higher temperature which then leads to the expulsion of gas when the pressure is equilibrated The degree of dissociation is then determined based on the calculated gas density at each temperature where is the measured density and is the theoretical density if no dissociation occurs calculated from the ideal gas law for the given temperature pressure and molar mass of the dissociating gas and is the number of fragments into which the dissociating gas dissociates ieg for Equation reqeq The equilibrium constant is then calculated as Finally a vant Hoff plot is generated to determine the reaction enthalpy Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay The Effect of Temperature on Reaction Rates Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers In practice rate constants vary in response to changes in several factors Indeed they are usually the same in two experiments only if we keep everything but the reagent concentrations the same Another way of saying this is that the rate law captures the dependence of reaction rate on concentrations while the dependence of reaction rate on any other variable appears as a dependence of rate constants on that variable Temperature usually has a big effect The experimentally observed dependence of rate constants on temperature can be expressed in a compact fashion Over small temperature ranges it can usually be expressed adequately by the Arrhenius equation where and are called the Arrhenius activation energy and the frequency factor or preexponential factor respectively The Arrhenius equation is an empirical relationship As we see below for our collisiontheory model theoretical treatments predict that the preexponential term A is weakly temperature dependent When we investigate reaction rates experimentally the temperature dependence of A is usually obscured by the uncertainties in the measured rate constants It is often said as a rough rule of thumb that the rate of a chemical reaction doubles if the temperature increases by K However this rule can fail spectacularly A reaction can even proceed more slowly at a higher temperature and there are multistep reactions for which this is observed The Empirical Gas Laws Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Boyles LawCharles LawGayLussacs LawCombined Gas LawAvogadros LawContributors and Attributions A number of important relationships describing the nature of gas samples have been derived completely empirically meaning based solely on observation rather making an attempt to define the theoretical reason these relationships may exist These are the empirical gas laws Boyles Law One of the important relationships governing gas samples that can be modeled mathematically is the relationship between pressure and volume Robert Boyle Hunter did experiments to confirm the observations of Richard Towneley and Henry Powers to show that for a fixed sample of gas at a constant temperature pressure and volume are inversely proportional or Boyle used a glass utube that was closed at one end and with the lower portion filled with mercury trapping a sample of air in the closed end By adding mercury to the open end he was able to observe and quantify the compression of the trapped air Figure An apparatus similar to that used by Robert Boyle Image taken from Fazio Charles Law Charles Law states that the volume of a fixed sample of gas at constant pressure is proportional to the temperature For this law to work there must be an absolute minimum to the temperature scale since there is certainly an absolute minimum to the volume scale or The second law of thermodynamics also predicts an absolute minimum temperature but that will be developed in a later chapter GayLussacs Law GayLussacs Law states that the pressure of a fixed sample of gas is proportional to the temperature As with Charles Law this suggests the existence of an absolute minimum to the temperature scale since the pressure can never be negative or Combined Gas Law Boyles Charles and GayLussacs Laws can be combined into a single empirical formula that can be useful For a given amount of gas the following relationship must hold or Avogadros Law Amedeo Avogadro Encycolopedia did extensive work with gases in his studies of matter In the course of his work he noted an important relationship between the number of moles in a gas sample Avogadros Law Avogadro states that at the same temperature and pressure any sample of gas has the same number of molecules per unit volume or Figure Amedeao Avogadro Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay The Energy Change for A Spontaneous Process at Constant S and V Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers From the fundamental equation for a reversible process We find that the criterion for reversible change at constant entropy is For a reversible process at constant entropy and volume we find To consider the energy change for a spontaneous process we begin with which is independent of whether the change is spontaneous or reversible For a spontaneous process in which both pressurevolume and nonpressurevolume work are possible we have which we can rearrange to For a spontaneous constantentropy change that occurs while the system is in contact with its surroundings we have Hence we have Lettting we can express this as spontaneous process constant S If we introduce the further condition that the spontaneous process occurs while the volume of the system remains constant we have Making this substitution and repeating our earlier result for a reversible process we have the parallel relationships spontaneous process constant S and V reversible process constant S and V If we introduce the still further requirement that only pressurevolume work is possible we have The parallel relationships become spontaneous process constant S and V only PV work reversible process constant S and V only PV work These equations state the criteria for change under conditions in which the entropy and volume of the system remain constant If the process is reversible the energy change must be equal to the nonpressurevolume work If the process is spontaneous the energy change must be less than the nonpressure volume work If only pressurevolume work is possible the energy of the system must decrease in a spontaneous process and remain constant in a reversible process Each of these differentialexpression criteria applies to every incremental part of a change that falls within its scope In consequence corresponding criteria apply to finite spontaneous changes These criteria are listed in the summary in Section Now the question arises What sort of system can undergo a change at constant entropy If the process is reversible and involves no heat the entropy change will be zero If we have a system consisting of a collection of solid objects at rest we can rearrange the objects without transferring heat between the objects and their surroundings For such a process the change in the energy of the system is equal to the net work done on the system Evidently reversible changes in mechanical systems occur at constant entropy and satisfy the criterion For a change that occurs reversibly and in which the entropy of the system is constant the energy change is equal to the net work of all kinds done on the system A spontaneous change in a mechanical system dissipates mechanical energy as heat by friction If this heat appears in the surroundings and the thermal state of the system remains unchanged such a spontaneous processes satisfies the criterion We have arrived at the criterion for change that we are accustomed to using when we deal with a change in the potential energy of a constanttemperature mechanical system A spontaneous change can occur in such a system if and only if the change in the systems energy is less than the net work done on it The excess work is degraded to heat that appears in the surroundings This convergence notwithstanding the principles of mechanics and those of thermodynamics while consistent with one another are substantially independent We address this issue briefly in Section In the next section we develop spontaneouschange criteria based on the enthalpy change for a constantentropy process In subsequent sections we consider other constraints and find other criteria We find that the Helmholtz and Gibbs free energy functions are useful because they provide criteria for spontaneous change when the process is constrained to occur isothermally The Energy of A Collision between Gas Molecules Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers It is useful to extend our model of molecular collisions to suppose that one or both of the molecules can undergo chemical change as a result of the collision In doing so we are introducing some ideas that we develop further in Chapter When we ask about the factors that determine whether such a reaction can occur there can be several possibilities We want to focus on one such factorthe violence of the collision We expect that a collision is more likely to result in a reaction the harder the two molecules hit one another When we try to formulate our basis for this expectation we see that the underlying idea is that a collision deforms the colliding molecules The more violent the collision the greater the deformation and the greater the likelihood of reaction becomes To proceed we need to be more precise about what we mean by the violence of the collision Evidently what we have in mind has two components the relative velocity and the collision angle If the collision is a glancing one we expect the effect on the molecules to be minimal even if the relative velocity is high On the other hand a direct collision might lead to reaction even if the relative velocity is comparatively low With these ideas in mind we see that a reasonable model is to suppose that forces acting along the line of centers can lead to reaction whereas forces acting perpendicular to the line of centers cannot If the colliding molecules have complex shapes this may be a poor assumption We also need a way to specify how much deformation occurs in a collision If we want to specify the deformation by describing specific changes in the molecular structures this is a complex problem For a general model however we can avoid this level of detail To do so we recognize that any deformation can proceed only until the work done in deforming the molecules equals the energy that can be expended to do this work As the molecules are deformed their potential energies change The maximum change in this potential energy is just the amount of kinetic energy that the colliding molecules can use to effect this deformation We can identify this amount of kinetic energy with the component of the molecules kinetic energy that is associated with their relative motion along the line of centers If we now associate a threshold level of deformation with the occurrence of a chemical change the kinetic energy required to effect this deformation determines whether the change can occur If the available kinetic energy is less than that required to achieve the threshold level of deformation reaction cannot occur If the available kinetic energy exceeds this minimum reaction takes place We call the minimum kinetic energy the activation energy and usually represent it by the symbol In discussing reaction rates we usually express the activation energy per mole and represent it as where We can apply these ideas to our model for collision between spherical molecules In Section we develop relative velocity coordinates It follows that we can partition kinetic energy of the twoparticle system into a component that depends on the velocity of the center of mass and a component that depends on the relative velocity That is we have Only the component that depends on the relative velocity can contribute to the deformation of the colliding molecules The relative velocity can be resolved into components parallel and perpendicular to the line of centers The parallel component is the projection of the velocity vector onto the line of centers This is and the perpendicular component is We see that the kinetic energy associated with the relative motion of particles and has a component parallel to the line of centers and a component perpendicular to it The idea that the kinetic energy parallel to the line of centers must exceed for reaction to occur can now be expressed as the requirement that When we consider all possible collisions between molecules and the collision angle varies from to However only those collisions for which satisfies the inequality above will have sufficient kinetic energy along the line of centers for reaction to occur The smallest value of that can satisfy this inequality occurs when This minimum relative velocity is For relative velocities in excess of this minimum collisions are effective only when so that Let us designate the frequency of collisions satisfying these constraints as Recalling that we see that The integral involving is intmathrmcos left epsilon _amu v_right_theta mathrmsin theta mathrmcos theta dtheta leftfracmathrmsin thetarightmathrmcos leftepsilon _amu v_right_fracleftfracepsilon _amu v_right where to evaluate the integral at its upper limit we note that the angle lies in a triangle whose sides have lengths as indicated in Figure Figure Maximum angle for an effective collision The collision frequency becomes This integral can be evaluated by making the substitution The lower limit of integration becomes we have Then Note that when this reduces to the same expression for that we have obtained twice previously The frequency of collisions having kinetic energy along the line of centers in excess of depends exponentially on All else being equal this frequency increases as the temperature increases it decreases as the activation energy increases The Enthalpy Change for A Spontaneous Process at Constant S and P Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers From we have For a spontaneous process in which both pressurevolume and nonpressurevolume work are possible we can write this as which we can rearrange to For a spontaneous constantentropy change that occurs while the system is in contact with its surroundings we have so that Now let us introduce the additional constraint that the system is subjected to a constant applied pressure throughout the process Thus is a welldefined property that can be measured at any stage of the process The incremental pressurevolume work done by the surroundings on the system is In principle the system can undergo spontaneous change so rapidly that there can be a transitory difference between the system pressure and the applied pressure In practice pressure adjustments occur very rapidly Except in extreme cases we find that is a good approximation at all times Then the change in the pressure volume product is Making these substitutions the enthalpy inequality becomes spontaneous process constant S and From our earlier discussion of reversible processes we have the parallel relationship any reversible process constant S and If we introduce the still further requirement that only pressurevolume work is possible we have The parallel relationships become spontaneous process constant S and P only PV work reversible process constant S and P only PV work These equations state the criteria for change under conditions in which the entropy and pressure of the system remain constant If the process is reversible the enthalpy change must be equal to the nonpressurevolume work If the process is spontaneous the enthalpy change must be less than the nonpressurevolume work If only pressurevolume work is possible the enthalpy of the system must decrease in a spontaneous process and remain constant in a reversible process Since each of these differential criteria applies to every incremental part of a reversible change that falls within its scope corresponding criteria apply to finite spontaneous changes These criteria are listed in the summary in Section The Entropy Change around Any Cycle for Any Reversible System Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Any system reversibly traversing any closed curve on a pressurevolume diagram exchanges work with its surroundings and the area enclosed by the curve represents the amount of this work In the previous section we found for any system that traverses a Carnot cycle reversibly We now show that this is true for any system that traverses any closed path reversibly This establishes that is zero for any system traversing any closed path reversibly and proves that defined by is a state function To do so we introduce an experiencebased theorem The pressurevolume diagram for any reversible system can be tiled by intersecting lines that represent isothermal and adiabatic paths These lines can be packed as densely as we please so that the tiling of the pressurevolume diagram can be made as closely spaced as we please The perimeter of any one of the resulting tiles corresponds to a path around a Carnot cycle Given any arbitrary closed curve on the pressurevolume diagram we can select a set of tiles that just encloses it See Figure The perimeter of this set of tiles approximates the path of the arbitrary curve Since the tiling can be made as fine as we please the perimeter of the set of tiles can be made to approximate the path of the arbitrary curve as closely as we please Figure Tiling the PVplane with isotherms and adiabats Suppose that we traverse the perimeter of each of the individual tiles in a clockwise direction adding up as we go Segments of these perimeters fall into two groups One group consists of segments that are on the perimeter of the enclosing set of tiles The other group consists of segments that are common to two tiles When we traverse both of these tiles in a clockwise direction the shared segment is traversed once in one direction and once in the other When we add up for these two traverses of the same segment we find that the sum is zero because we have in one direction and in the other This means that the sum of around all of the tiles will just be equal to the sum of around those segments that lie on the perimeter of the enclosing set That is we have where because each interior segment is traversed twice and the two contributions cancel exactly This set of tiles has another important property Since each individual tile represents a reversible Carnot cycle we know that around each individual tile Since the sum around each tile is zero the sum of all these sums is zero It follows that the sum of around the perimeter of the enclosing set is zero By tiling the pressurevolume plane as densely as necessary we can make the perimeter of the enclosing set as close as we like to any closed curve The heat increments become arbitrarily small and For any reversible engine producing pressurevolume work we have around any cycle We can extend this analysis to reach the same conclusion for a reversible engine that produces any form of work To see this let us consider the tiling theorem more carefully When we say that the adiabats and isotherms tile the pressurevolume plane we mean that each point in the pressurevolume plane is intersected by one and only one adiabat and by one and only one isotherm When only pressurevolume work is possible every point in the pressurevolume plane represents a unique state of the system Therefore the tiling theorem asserts that every state of the variablepressure system can be reached along one and only one adiabat and one and only one isotherm From experience we infer that this statement remains true for any form of work That is every state of any reversible system can be reached by one and only one isotherm and by one and only one adiabat when any form of work is done If more than one form of work is possible there is an adiabat for each form of work If changing and changing change the energy of the system the effects on the energy of the system are not necessarily the same In general is not the same as where From we know that a reversible Carnot engine doing any form of work can be matched with a reversible idealgas Carnot engine in such a way that the engines complete the successive isothermal and adiabatic steps in parallel At each step each engine experiences the same heat work energy and entropy changes as the other Just as we can plot the reversible idealgas Carnot cycle as a closed path in pressurevolume space we can plot a Carnot cycle producing any other form of work as a closed path with successive isothermal and adiabatic steps in space Just as any closed path in pressurevolume space can be tiled or built up from arbitrarily small reversible Carnot cycles so any closed path in space can be tiled by such cycles Therefore the argument we use to show that for any closed reversible cycle in pressurevolume space applies equally well to a closed reversible cycle in which heat is used to produce any other form of work The Entropy Change for A Spontaneous Process at Constant E and V Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers For any spontaneous process we have which we can rearrange to Substituting our result from Section we have spontaneous process If the energy of the system is constant throughout the process we have and spontaneous process constant energy The spontaneous work is the sum of the pressurevolume work and the nonpressurevolume work If we introduce the further condition that the spontaneous process occurs while the volume of the system remains constant we have Making this substitution and repeating our earlier result for a reversible process we have the parallel relationships spontaneous process constant and reversible process constant and For a reversible process If the spontaneous process occurs while is constant summing the incremental contributions to a finite change of state produces the parallel relationships spontaneous process constant and reversible process constant and Constant corresponds to the common situation in chemical experimentation in which we place a reaction vessel in a constanttemperature bath If we introduce the further condition that only pressurevolume work is possible we have The parallel relationships become spontaneous process constant and only work reversible process constant and only work If the energy and volume are constant for a system in which only pressurevolume work is possible the system is isolated The conditions we have just derived are entirely equivalent to our earlier conclusions that and for an isolated system that is at equilibrium or undergoing a spontaneous change respectively Summing the incremental contributions to a finite change of state produces the parallel relationships spontaneous process only work reversible process only work The validity of these expressions is independent of any variation in either or The Entropy Change for A Spontaneous Process at Constant H and P Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers For any spontaneous process we have If the pressure is constant this becomes Substituting our result from Section we have spontaneous process constant If the enthalpy of the system is also constant throughout the process we have spontaneous process constant and Dividing by and repeating our earlier result for a reversible process we have the parallel relationships spontaneous process constant and reversible process constant and If it is also true that the temperature of the surroundings is constant summing the incremental contributions to a finite change of state produces the parallel relationships spontaneous process constant and reversible process constant and If only pressurevolume work is possible we have and spontaneous process constant only work reversible process constant and only work and for a finite change of state spontaneous process only work reversible process only work In this and earlier sections we develop criteria for spontaneous change that are based on and We are now able to develop similar criteria for a spontaneous change in a system that is in thermal contact with constanttemperature surroundings These criteria are based on and However before doing so we develop a general relationship between the isothermal work in a spontaneous process and the isothermal work in a reversible process when these processes take a system from a common initial state to a common final state The Entropy of the Universe Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers In Section we conclude that the entropy change is positive for any spontaneous change in an isolated system Since we can consider the universe to be an isolated system it follows that for any spontaneous process To reach this conclusion by a more detailed argument let us consider an arbitrary system that is in contact with its surroundings We can subdivide these surroundings into subsystems As diagrammed in Figure we define a surroundings subsystem Surroundings that interacts with the system and a more remote surroundings subsystem Surroundings that does not That is we assume that we can define Surroundings so that it is unaffected by the process Then we define an augmented system consisting of the original system plus Surroundings The augmented system is isolated from the remote portion of the surroundings so that the entropy change for the augmented system is positive by the argument in the previous section Denoting entropy changes for the system Surroundings Surroundings and the augmented system by and respectively we have and Since the remote portion of the surroundings is unaffected by the change we have For any spontaneous change whether the system is isolated or not we have any spontaneous change Figure Expanding a system to create a new augmented isolated system This statement is an essential part of the entropybased statement of the second law We have now developed it from the machinebased statement of the second law by convincing but not entirely rigorous arguments In Section we find that for any reversible process Thus for any possible process we have The equality applies when the process is reversible the inequality applies when it is spontaneous Because entropy is a state function and change sign when the direction of a process is reversed We say that a process for which is an impossible process Our definitions mean that these classificationsreversible spontaneous and impossibleare exhaustive and mutually exclusive We conclude that is necessary and sufficient for a process to be reversible is necessary and sufficient for a process to be spontaneous See problem The Expected Value of a Function of Several Variables and the Central Limit Theorem Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers We can extend the idea of an expected value to a function of multiple random variables Let U and V be distributions whose random variables are and respectively Let the probability density functions for these distributions be and In general these probability density functions are different functions that is and are different distributions Let be some function of these random variables The probability that an observation made on produces a value of in the range is and the probability that an observation made on produces a value of in the range is The probability that making one observation on each of these distributions produces a value of that lies in the range and a value of that lies in the range is In a straightforward generalization we define the expected value of as If is a sum of functions of independent variables we have If is a product of independent functions we have We can extend these conclusions to functions of the random variables of any number of distributions If is the random variable of distribution whose probability density function is the expected value of becomes and the expected value of becomes We are particularly interested in expected values for repeated trials made on the same distribution We consider distributions for which the outcome of one trial is independent of the outcome of any other trial The probability density function is the same for every trial so we have Let the values obtained for the random variable in a series of trials on the same distribution be For each trial we have If we consider the special case of repeated trials in which the functions are all the same function so that the expected value of becomes and the expected value of becomes Now let us consider independent trials on the same distribution and let Then the expected value of becomes By definition the average of repeated trials is so that the expected value of the mean of a distribution of an averageof repeated trials is This proves one element of the central limit theorem The mean of a distribution of averagesof values of a random variable drawn from a parent distribution is equal to the mean of the parent distribution The variance of these averagesof is sigma_Nleftlangle leftoverlineu_Nmu rightrightrangle leftlangle leftleftfracNsumN_iu_irightmu right rightrangle leftlangle leftleftfracNsumN_iu_irightfracNmu Nrightrightrangle fracN leftlangle leftleftsumN_iu_irightNmu rightrightrangle fracN leftlangle leftleftsumN_ileftu_imu rightrightright rightrangle fracN leftlangle sumN_ileftu_imu right rightrangle fracN leftlangle sumN_i leftu_imu rightsumN_ji leftu_jmu right right rangle fracNsumN_i leftlangle leftu_imu right rightrangle fracN leftlangle sumN_i leftu_imu right rightrangle leftlangle sumN_ji leftu_jmu right rightranglenonumber Where the last term is zero because and By definition so that we have This proves a second element of the central limit theorem The variance of an average of values of a random variable drawn from a parent distribution is equal to the variance of the parent distribution divided by The First Law of Thermodynamics Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers A state function must return to its original value if a system is taken through a series of changes and finally returned to its original state We say that the change in a state function must be zero if the system is taken through a cyclic process or somewhat more picturesquely if the system traverses a cyclic path While we can measure the heat and work that a system exchanges with its surroundings neither the heat nor the work is necessarily zero when the system traverses a cycle Heat and work are not state functions Nevertheless adding heat to a system increases its energy Likewise doing work on a system increases its energy If the system surrenders heat to the surroundings or does work on the surroundings the energy of the system is decreased In any change that a closed system undergoes the total energy change is where and can be either positive or negative For very small changes we write Anything we do to increase the energy of a closed system can be classified as either adding heat to the system or doing work on the system Heat work and energy are all extensive variables They are additive If a system acquires an increment of heat from one source and an increment from another source the total heat acquired by the system is If work of one kind and work of a second kind are done on the system the total work is In keeping with the thermodynamic perspective that we can partition the universe into system and surroundings we assume that any energy lost by the system is taken up by the surroundings and vice versa By definition we have and for any process This is the principle of conservation of energy which is usually stated For any change in any system the energy of the universe remains constant So conservation of energy is built into our energy accounting scheme It is a consequence of the thermodynamic perspective and our rules for keeping track of exchanges of heat and work between system and surroundings Conservation of energy is an accounting convention but it is not arbitrary That is we are not free to choose another convention for this energy accounting Ample experimental evidence supports our assumption that energy conservation is a fundamental property of nature In summary we postulate that for any change whatsoever that a closed system may undergo we can identify energy inputs either as heat or as one or more forms of work such that and if a system undergoes a series of changes that ultimately return it to its original state the energy change for the entire series of changes will be zero There are two components to this postulate The first component is an operational definition of energy An important aspect of this definition is that the principle of conservation of energy is embedded in it The second is an assertion that energy is a state function Our operational definition of energy is openended An essential element of the postulate is that we can always identify work inputs that make the energy whose changes we compute as a state function The facts that energy is conserved and that energy is a state function are related properties of a single aspect energy of nature The relationship between these facts is a characteristic property of physical reality it is not a matter of logic in the sense that one fact implies the other All of these ideas are essential components of the concept of energy We roll them all together and assert them as a postulate that we call the first law of thermodynamics We introduce the first law in Chapter We repeat it here The first law of thermodynamics In a process in which a closed system accepts increments of heat and work from its surroundings the change in the energy of the system is Energy is a state function For any process This statement of the first law does not deal explicitly with the mechanical energy of the system as a whole or with the energy effects of a transport of matter across the boundary of an open system Because can include work that changes the position or motion of a system relative to an external reference frame increments of mechanical energy can be included in In chemical applications we seldom need to consider the mechanical energy of the system as a whole we can assume that the system has no kinetic or potential energy associated with the movement or location of its mass When this is case the total incremental energy change is the same thing as the incremental change in the internal energy of the system When we need to distinguish the internal energy of a system from its total energy we write for the internal energy and for the total energy Letting incremental changes in the kinetic and potential energy of the whole system be and respectively we have and For processes of interest in chemical systems we normally have Then the total energy and the internal energy are the same thing In Section we introduce characteristic variables to represent changes in the system that result from various forms of nonpressurevolume work done on the system We let so that we can represent the incremental energy change that results from the nonpressurevolume work of all kinds as When both pressurevolume and nonpressurevolume work occur we have When a nonthermal process changes the energy of a closed constantvolume system we have We state the first law for a closed system Extending the first law to open systems is straightforward The energy of a system depends on the substances that are present their amounts and their states At any specified conditions a given amount of a particular substance makes a fixed contribution to the energy of the system If we transfer matter across the boundary of a system we change the energy of the system We can always alter the original system to include the matter that is to be transferred The altered system is closed and so by the first law its energy is the same after the transfer as it was before In Section we develop an explicit mathematical function to model the contribution made to the energy of a system by a specified quantity of matter in a specified state If matter crosses the boundary of a system the energy models for the separate collections of substances pretransfer must equate to that for the new system posttransfer Finally we make a further simple but important observation We imagine that we can always identify an energy increment that crosses a system boundary as work or heat However the essence of the first law is that these increments lose their identitiesso to speakin the system The effect of a work input doesnt necessarily appear as an increase in the mechanical energy of the system a heat input doesnt necessarily appear as in increase in the thermal energy of the system To illustrate this point let us consider a reversible process and an irreversible process each of which increases the temperature of one gram of water by one degree K The initial and final states of the system are the same for both processes In the reversible process we bring the water whose temperature is into contact with a thermal reservoir at an incrementally higher temperature and allow of heat to transfer to the system by convection No work is done We have and In this case there is no interconversion of heat and work In the irreversible process we stir one gram of water that is thermally isolated The stirring generates heat in the system We supply the energy to drive the stirrer from the surroundings perhaps by allowing a spring to uncoil When of work from the surroundings has been frictionally dissipated in the system the state of the onegram system is the same as it was at the end of the reversible process In this irreversible process all of the energy traverses the system boundary as work nonthermal energy No heat traverses the system boundary We have and Uncoiling the spring generates bulk motion within the water Within a short time the energy of this bulk motion is completely dissipated as molecularlevel kinetic energy or heat Beginning in we consider the reversible isothermal expansion of an ideal gas This simple process provides a further illustration of the interconversion of heat and work within a system For this process we find that thermal energy crosses the system boundary and is converted entirely into work that appears in the surroundings The energy of the system is unchanged The energy of an ideal gas depends only on temperature In an isothermal expansion the temperature is constant so the transport of heat across the system boundary has no effect on the energy of the system The Free Energy Changes for A Spontaneous Process at Constant T Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Now let us consider the change in the Helmholtz free energy when a system undergoes a spontaneous change while in thermal contact with surroundings whose temperature remains constant at We begin by considering an arbitrarily small increment of change in a process in which the temperature of the system remains constant at The change in the Helmholtz free energy for this process is Substituting gives spontaneous process constant Rearranging we have Using the inequality we have When we stipulate that this becomes spontaneous process constant where is all of the work of any kind done on the system during a small increment of the spontaneous process If we introduce the still further requirement that the volume is constant we have and Then spontaneous process constant and and if only pressurevolume work is possible spontaneous process constant and only work From our earlier discussion of reversible processes we have the parallel relationships reversible isothermal process reversible process at constant and reversible process at constant and only work Similarly under these conditions the change in the Gibbs free energy for a spontaneous isothermal process is Rearranging we have and since spontaneous process constant As we did when considering the enthalpy change for a spontaneous process we introduce the additional constraints that the system is subjected to a constant applied pressure and that throughout the process The irreversible pressurevolume work done by the surroundings on the system becomes and the change in the pressure volume product becomes The Gibbs free energy inequality becomes spontaneous process constant and If only pressurevolume work is possible this becomes spontaneous process constant and only work From our earlier discussion of reversible processes we have the parallel relationships reversible process constant and reversible process constant and only work Since each of these differentialexpression criteria applies to every incremental part of a reversible change that falls within its scope we have the following criteria for finite spontaneous changes when the temperature of the system is constant spontaneous process constant spontaneous process constant and spontaneous process constant and only work spontaneous process constant and spontaneous process constant and only work While the development we have just made assumes that the system temperature is strictly constant the validity of these finitechange inequalities is not restricted to the condition of strictly constant system temperature We can derive these finitechange inequalities by essentially the same argument from less restrictive conditions Let us consider a spontaneous process in which a system goes from state B to state C while in contact with surroundings whose temperature remains constant at We suppose that in both state B and state C the system temperature is equal to the surroundings temperature that is However at any intermediate point in the process the system can have any temperature whatsoever In states B and C the Helmholtz free energies are and The change in the Helmholtz free energy is or Rearranging and using we have so that spontaneous process constant If we require further that the system volume remain constant there is no pressurevolume work and we have spontaneous process constant and If only pressurevolume work is possible and spontaneous process constant and only work Under the same temperature assumptions and assuming that the Gibbs free energies are and So that or The pressurevolume work is Cancelling and rearranging we have and spontaneous process constant and If only pressurevolume work is possible spontaneous process constant and only work We find for any spontaneous process that occurs at constant pressure while the system is in contact with surroundings at the constant temperature and in which the initial and final system temperatures are equal to These are the most common conditions for carrying out a chemical reaction Consider the situation after we mix nonvolatile reactants in an open vessel in a constanttemperature bath We suppose that the initial temperature of the mixture is the same as that of the bath The atmosphere applies a constant pressure to the system The reaction is an irreversible process It proceeds spontaneously until its equilibrium position is reached Until equilibrium is reached the reaction cannot be reversed by an arbitrarily small change in the applied pressure or the temperature of the surroundings and are criteria for spontaneous change that apply to this situation whatever the temperature of the system might be during any intermediate part of the process The Frequency of Collisions between Unlike Gas Molecules Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Thus far in our theoretical development of the properties of gases we have assumed that ideal gas molecules are point masses While they can collide with the walls of their container point masses cannot collide with one another As we saw in our discussion of van der Waals equation the deviation of real gases from ideal gas behavior is one indication that an individual gas molecule occupies a finite volume To develop a model for molecular collisions we need to know the size and shape of the colliding molecules For a general model we want to use the simplest possible size and shape Accordingly we consider a model in which gas molecules are spheres with welldefined radii We let the radii of molecules and be and respectively See Figure When such molecules collide their surfaces must come into contact and the distance between their centers must be We call the collision radius Figure The molecular collision radius Let us consider a molecule of type in a container with a large number of molecules of type We suppose that there are molecules of type per unit volume Every molecule of type has some velocity relative to the molecule of type From our development above we know both the probability density function for and the expected value Both molecule and all of the molecules of type are moving with continuously varying speeds However it is reasonable to suppose thaton averagethe encounters between molecule and molecules of type are the same as they would be if all of the type molecules were fixed at random locations in the volume and molecule moved among them with a speed equal to the average relative velocity Under this assumption a molecule travels a distance equal to in unit time As it does so it collides with any type molecule whose center is within a distance of its own center For the moment let us suppose that the trajectory of molecule is unaffected by the collisions it experiences Then in unit time molecule sweeps out a cylinder whose length is and whose crosssectional area is The volume of this cylinder is See Figure Figure The collision volume of a gas molecule in unit time Since there are molecules of type per unit volume the number of type molecules in the cylinder is Each of these molecules is a molecule of type that experiences a collision with molecule in unit time Letting be the frequency number of collision per unit time with which molecule collides with molecules of type we have Two additional parameters that are useful for characterizing molecular collisions are the mean time between collisions and the mean distance that molecule travels between collisions with successive molecules of type is called the mean free path The mean time between collisions is simply the reciprocal of the collision frequency and the mean free path for molecule is the distance that molecule actually travels in this time which is not so that Now we need to reevaluate the assumption that the trajectory of a molecule of a molecule is unaffected by its collisions with molecules of type Clearly this is not the case The path of molecule changes abruptly at each collision The actual cylinder that molecule sweeps out will have numerous kinks as indicated in Figure The kinked cylinder can be produced from a straight one by making a series oblique cuts one for each kink across the straight cylinder and then rotating the ends of each cut into convergence If we think of the cylinder as a solid rod its volume is unchanged by these cuttings and rotations The volume of the kinked cylinder is the same as that of the straight cylinder Thus our conclusions about the collision frequency the mean time between collisions and the mean free path are not affected by the fact that the trajectory of molecule changes at each collision Figure The collision volume is unaffected by collisions The Fundamental Equation and Other Criteria for Reversible Change Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers To begin exploring the possibilities for stating the criteria for change using only the properties of the system let us consider how some thermodynamic functions change when a process is reversible We consider a closed system and focus on making incremental changes in the state of the system For a reversible process we have The reversible pressurevolume work is If nonpressurevolume work is also possible the reversible work becomes where is the increment of reversible nonpressurevolume work The energy change is any reversible process This equation is of central importance It is sometimes called the combined first and second laws of thermodynamics or the fundamental equation It applies to any closed system that is undergoing reversible change It specifies a relationship among the changes in energy entropy and volume that must occur if the system is to remain at equilibrium while an increment of nonpressurevolume work is done on it The burden of our entire development is that any reversible process must satisfy this equation Conversely any process that satisfies this equation must be reversible For a reversible process at constant entropy we have so that Since is the reversible pressurevolume work and the sum is the net work we have reversible process constant S where the subscript specifies that the entropy is constant For a reversible process in which all of the work is pressurevolume work we have and the fundamental equation becomes reversible process only pressurevolume work For a reversible process in which only pressurevolume work is possible this equation gives the amount by which the energy must change when the entropy changes by and the volume changes by Now let us apply the fundamental equation to an arbitrary process that occurs reversibly and at constant entropy and constant volume Under these conditions and Therefore at constant entropy and volume a necessary and sufficient condition for the process to be reversibleand hence to be continuously in an equilibrium state as the process takes placeis that reversible process and if only pressurevolume work is possible reversible process only pressurevolume work where the subscripts indicate that entropy and volume are constant If we consider an arbitrary reversible process that occurs at constant energy and volume we have and and the fundamental equation reduces to reversible process and if only pressurevolume work is possible reversible process only pressurevolume work In this case as noted in the system is isolated In we note that an isolated system in an equilibrium state can undergo no further change Thus the condition defines a unique or primitive equilibrium state If a closed system behaves reversibly any composition changes that occur in the system must be reversible For chemical applications composition changes are of paramount importance We return to these considerations in Chapter where we relate the properties of chemical substancestheir chemical potentialsto the behavior of systems undergoing both reversible and spontaneous composition changes If a closed system behaves reversibly and only pressurevolume work is possible we see from the fundamental equation that specifying the changes in any two of the three variables and is sufficient to specify the change in the system In particular if energy and entropy are constant the volume is also constant and the system is isolated Thus the state of an equilibrium system whose energy and entropy are fixed is unique specifies a primitive equilibrium state We see that the internal consistency of our model passes a significant test From the entropybased statement of the second law we deduce the same proposition that we introduce in as a heuristic conjecture In Chapter we expand on this idea Starting from the fundamental equation we can find similar sets of relationships for enthalpy the Helmholtz free energy and the Gibbs free energy We define For an incremental change in a system we have Using the fundamental equation to substitute for dE this becomes For a reversible process in which all of the work is pressurevolume work we have reversible process only pressurevolume work For a reversible process in which only pressurevolume work is possible this equation gives the amount by which the enthalpy must change when the entropy changes by and the pressure changes by If a reversible process occurs at constant entropy and pressure then and At constant entropy and pressure the process is reversible if and only if reversible process If only pressurevolume work is possible reversible process only pressurevolume work where the subscripts indicate that entropy and pressure are constant If we consider an arbitrary reversible process that occurs at constant enthalpy and pressure we have and and the total differential for reduces to reversible process and if only pressurevolume work is possible reversible process only pressurevolume work From we have Using the fundamental equation to substitute for we have For a reversible process in which all of the work is pressurevolume work reversible process only pressurevolume work For a reversible process in which only pressurevolume work is possible this equation gives the amount by which the Helmholtz free energy must change when the temperature changes by and the volume changes by For a reversible isothermal process we have and from we have reversible isothermal process where we recognize that the reversible pressurevolume work is and the work of all kinds is We see that is the total of all the work done on the system in a reversible process at constant temperature This is the reason that is used as the symbol for the Helmholtz free energy is the initial letter in Arbeit a German noun whose meaning is equivalent to that of the English noun work If a reversible process occurs at constant temperature and volume we have and At constant temperature and volume a process is reversible if and only if reversible process If only pressurevolume work is possible reversible process only pressurevolume work where the subscripts indicate that volume and temperature are constant Of course these conditions exclude all work because constant volume implies that there is no pressurevolume work From and the fundamental equation we have For a reversible process in which all of the work is pressurevolume work reversible process only pressurevolume work For a reversible process in which only pressurevolume work is possible this equation gives the amount by which the Gibbs free energy must change when the temperature changes by and the pressure changes by For a reversible process that occurs at constant temperature and pressure and At constant temperature and pressure the process will be reversible if and only if any reversible process If only pressurevolume work is possible reversible process only pressurevolume work where the subscripts indicate that temperature and pressure are constant In this section we develop several criteria for reversible change stating these criteria as differential expressions Since each of these expressions applies to every incremental part of a reversible change that falls within its scope corresponding expressions apply to finite changes For example we find for every incremental part of a reversible process in which the entropy has a constant value Since we can find the energy change for a finite amount of the process by summing up the energy changes in every incremental portion it follows that reversible process Each of the other differentialexpression criteria for reversible change also gives rise to a corresponding criterion for a finite reversible change These criteria are summarized in In developing the criteria in this section we stipulate that various combinations of the thermodynamic functions that characterize the system are constant We develop these criteria for systems undergoing reversible change consequently the requirements imposed by reversibility must be satisfied also In particular the system must be composed of homogeneous phases and its temperature must be the same as that of the surroundings The pressure of the system must be equal to the pressure applied to it by the surroundings When we specify that a reversible process occurs at constant temperature we mean that When we specify that a reversible process occur at constant pressure we mean that The Geometry of A Collision between Spherical Molecules Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Thus far we have not concerned ourselves with the relative orientation of a pair of colliding molecules We want to develop a more detailed model for the collision process itself and the first step is to specify what we mean by relative orientation As before we consider a molecule of type moving with the relative velocity through a gas of stationary type molecules In unit time molecule travels a distance and collides with many molecules of type We can characterize each such collision by the angle between the velocity vector and the line of centers of the colliding pair For glancing collisions we have For headon collisions we have All else being equal the collision will be more violent the smaller the angle Evidently we can describe the average effect of collisions more completely if we can specify the frequency of collisions as a function of More precisely we want to find the frequency of collisions in which this angle lies between and When a collision occurs the distance between the molecular centers is We can say that the center of molecule is at a particular point on the surface of a sphere of radius circumscribed about molecule As sketched in Figure we can rotate the line of centers around the velocity vector while keeping the angle between them constant at As we do so the line of centers traces out a circle on the surface of the sphere collisions that put the center of molecule at any two points on this circle are completely equivalent Letting the radius of this circle be we see that Evidently for spherical molecules specifying specifies the relative orientation at the time of collision If we now allow to vary by the locus of equivalent points on the circumscribed sphere expands to a band Measured along the surface of the sphere the width of this band is As molecule moves through the gas of stationary type molecules this band sweeps out a cylindrical shell Molecule collides at an angle between and with every type molecule in this cylindrical shell Conversely every type molecule in this cylindrical shell collides with molecule at an angle between and Molecule also collides with many other type molecules but those collisions are at other angles they have different orientations In unit time the length of the cylindrical shell is The volume of the cylindrical shell is its length times its crosssectional area Figure The geometry of collisions between spheres The crosssection of the cylindrical shell is a circular annulus Viewing the annulus as a rectangular strip whose length is the circumference of the shell and whose width is the radial thickness of the annulus the area of the annulus is the circumference times the radial thickness Since the radius of the shell is its circumference is The radial thickness of the annulus is just the change in the distance between the velocity vector and the wall of the cylinder when changes by a small amount This is Therefore the area of the annulus is and the volume of the cylindrical shell swept out by a type molecule traveling at exactly the speed in unit time is We again let be the number of molecules of type per unit volume The number of collisions per unit time between a molecule of type traveling at exactly and molecules of type in which the collision angle lies between and is We need to find the number of such collisions in which the relative velocity lies between and The probability of finding in this interval is Let be the number of collisions made in unit time by a type molecule with molecules of type in which the collision angle is between and and the scalar relative velocity is between and This is just the number of collisions when the relative velocity is multiplied by the probability that the relative velocity is between and We have the result we need Recognizing that possible values of lie in the range and that possible values of lie in the range we can find the frequency of all possible collisions by summing over all possible values of and That is In Section we obtained this result by a slightly different argument in which we did not explicitly consider the collision angle The GibbsDuhem Equation Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors and Attributions For a system at equilibrium the GibbsDuhem equation must hold This relationship places a compositional constraint upon any changes in the chemical potential in a mixture at constant temperature and pressure for a given composition This result is easily derived when one considers that represents the partial molar Gibbs function for component And as with other partial molar quantities Taking the derivative of both sides yields But can also be expressed as Setting these two expressions equal to one another And after canceling terms one gets sum_i n_i d mu_i Vdp sdT labeleq For a system at constant temperature and pressure Substituting Equation refeq into refeq results in the GibbsDuhem equation Equation refeq This expression relates how the chemical potential can change for a given composition while the system maintains equilibrium So for a binary system consisting of components and the two most often studied compounds in all of chemistry Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay The HartreeFock Approximation Last updated Save as PDF Page ID Koopmans TheoremOrbital Energies and the Total Energy Unfortunately the Hartree approximation ignores an important property of electronic wavefunctions their permutational antisymmetry The full electronic Hamiltonian is invariant ie is left unchanged under the operation in which a pair of electrons have their labels i j permuted We say that commutes with the permutation operator This fact implies that any solution to must also be an eigenfunction of Because permutation operators are idempotent which means that if one applies twice one obtains the identity it can be seen that the eigenvalues of must be either or That is if then but means that so or As a result of commuting with electron permutation operators and of the idempotency of the eigenfunctions must either be odd or even under the application of any such permutation Particles whose wavefunctions are even under are called Bose particles or Bosons those for which is odd are called Fermions Electrons belong to the latter class of particles The simple spinorbital product function used in Hartree theory does not have the proper permutational symmetry For example the Be atom function is not odd under the interchange of the labels of electrons and instead one obtains However such products of spinorbitals ie orbitals multiplied by or spin functions can be made into properly antisymmetric functions by forming the determinant of an matrix whose row index labels the spin orbital and whose column index labels the electron For example the Be atom function produces the matrix whose determinant is shown below leftbeginarraycccc salpha salpha salpha salpha sbeta sbeta sbeta sbeta salpha salpha salpha salpha sbeta sbeta sbeta sbeta endarrayright nonumber Clearly if one were to interchange any columns of this determinant one changes the sign of the function Moreover if a determinant contains two or more rows that are identical ie if one attempts to form such a function having two or more spinorbitals equal it vanishes This is how such antisymmetric wavefunctions embody the Pauli exclusion principle A convenient way to write such a determinant is as follows where the sum is over all N permutations of the spinorbitals and the notation means that a is affixed to any permutation that involves an odd number of pair wise interchanges of spinorbitals and a sign is given to any that involves an even number To properly normalize such a determinental wavefunction one must multiply it by So the final result is that a wavefunction of the form which is often written in shorthand notation as has the proper permutational antisymmetry Note that such functions consist of as sum of factors all of which have exactly the same number of electrons occupying the same spinorbitals the only difference among the terms involves which electron occupies which spinorbital For example in the function appropriate to the excited state of He one has This function is clearly odd under the interchange of the labels of the two electrons yet each of its two components has one electron is a spinorbital and another electron in a spinorbital Although having to make antisymmetric appears to complicate matters significantly it turns out that the Schrdinger equation appropriate to the spinorbitals in such an antisymmetrized product wavefunction is nearly the same as the Hartree Schrdnger equation treated earlier In fact if one variationally minimizes the expectation value of the electron Hamiltonian for the above antisymmetric product wavefunction subject to the condition that the spinorbitals are orthonormal one obtains the following equation for the optimal In this expression which is known as the HartreeFock equation the same kinetic and nuclear attraction potentials occur as in the Hartree equation Moreover the same Coulomb potential appears However one also finds a socalled exchange contribution to the HartreeFock potential that is equal to and is often written in shorthand notation as Notice that the Coulomb and exchange terms cancel for the case this causes the artificial selfinteraction term that can appear in the Hartree equations unless one explicitly eliminates it to automatically cancel with the exchange term in the HartreeFock equations To derive the above HartreeFock equations one must make use of the socalled SlaterCondon rules to express the Hamiltonian expectation value as langlephi_phi_cdots phi_Nphi_NNHphi_phi_cdots phi_Nphi_NNrangle sum_jNlanglephi_jrfracnablafracerphi_jrrangle fracsum_jkNleft langlephi_jrphi_krfracerrphi_jrphi_krrangle langlephi_jrphi_krfracerrphi_krphi_jrranglerightnonumber This expectation value is a sum of terms the kinetic energy and electronnuclear Coulomb potentials that vary quadratically on the spinorbitals ie as plus another sum the Coulomb and exchange electronelectron interaction terms that depend on the fourth power of the spinorbitals ie as When these terms are differentiated to minimize the expectation value they generate factors that scale linearly and with the third power of the spinorbitals These are the factors and appearing in the HartreeFock equations shown above When the LCAO expansion of each HartreeFock HF spinorbital is substituted into the above HF Schrdinger equation a matrix equation is again obtained where the overlap integral is as defined earlier and the matrix element is Clearly the only difference between this expression and the corresponding result of Hartree theory is the presence of the last term the exchange integral The SCF iterative procedure used to solve the Hartree equations is again used to solve the HF equations It is useful to reflect on the physical meaning of the Coulomb and exchange interactions between pairs of orbitals For example the Coulomb integral appropriate to the two orbitals shown in Figure represents the Coulombic repulsion energy of two charge densities and integrated over all locations and of the two electrons Figure An s and a p Orbital and Their Overlap Region In contrast the exchange integral can be thought of as the Coulombic repulsion between two electrons whose coordinates and are both distributed throughout the overlap region This overlap region is where both and have appreciable magnitude so exchange integrals tend to be significant in magnitude only when the two orbitals involved have substantial regions of overlap Finally a few words are in order about one of the most computer timeconsuming parts of any HartreeFock calculation or those discussed later the task of evaluating and transforming the twoelectron integrals When M GTOs are used as basis functions the evaluation of of these integrals often poses a major hurdle For example with basis orbitals there will be of the order of x such integrals With each integral requiring words of disk storage most integrals need to be evaluated in double precision this would require at least x Mwords of disk storage Even in the era of modern computers that possess Gby disks this is a significant requirement One of the more important technical advances that is under much current development is the efficient calculation of such integrals when the product functions and that display the dependence on the two electrons coordinates r and r are spatially distant In particular socalled multipole expansions of these product functions are used to obtain more efficient approximations to their integrals when these functions are far apart Moreover such expansions offer a reliable way to ignore ie approximate as zero many integrals whose product functions are sufficiently distant Such approaches show considerable promise for reducing the twoelectron integral list to one whose size scales much less strongly with the size of the AO basis and form an important component if efforts to achieve CPU and storage needs that scale linearly with the size of the molecule Koopmans Theorem The HFSCF equations imply that the orbital energies can be written as where represents the kinetic and nuclear attraction energies respectively Thus is the average value of the kinetic energy plus Coulombic attraction to the nuclei for an electron in plus the sum over all of the spinorbitals occupied in of Coulomb minus Exchange interactions of these electrons with the electron in If is an occupied spinorbital the term disappears in the above sum and the remaining terms in the sum represent the Coulomb minus exchange interaction of with all of the other occupied spinorbitals If is a virtual spinorbital this cancelation does not occur because the sum over does not include So one obtains the Coulomb minus exchange interaction of with all of the occupied spinorbitals in Hence the energies of occupied orbitals pertain to interactions appropriate to a total of electrons while the energies of virtual orbitals pertain to a system with electrons This difference is very important to understand and to keep in mind Let us consider the following model of the detachment or attachment of an electron in an electron system In this model both the parent molecule and the species generated by adding or removing an electron are treated at the singledeterminant level The HartreeFock orbitals of the parent molecule are used to describe both species It is said that such a model neglects orbital relaxation ie the reoptimization of the spinorbitals to allow them to become appropriate to the daughter species Within this model the energy difference between the daughter and the parent can be written as follows represents the particular spinorbital that is added or removed for electron detachment and for electron attachment Lets derive this result for the case in which an electron is added to the spinorbital Again using the SlaterCondon rules from Section of this Chapter the energy of the electron determinant with spinorbitals through occupied is which can also be written as Likewise the energy of the electron determinant wavefunction is The difference between these two energies is given by That is the energy difference is equal to minus the expression for the energy of the spinorbital which was given earlier So within the limitations of the HF frozenorbital model the ionization potentials IPs and electron affinities EAs are given as the negative of the occupied and virtual spinorbital energies respectively This statement is referred to as Koopmans theorem it is used extensively in quantum chemical calculations as a means of estimating IPs and EAs and often yields results that are qualitatively correct ie eV Orbital Energies and the Total Energy The total HFSCF electronic energy can be written as and the sum of the orbital energies of the occupied spinorbitals is given by These two expressions differ in a very important way the sum of occupied orbital energies double counts the Coulomb minus exchange interaction energies Thus within the HartreeFock approximation the sum of the occupied orbital energies is not equal to the total energy This finding teaches us that we can not think of the total electronic energy of a given orbital occupation in terms of the orbital energies alone We need to also keep track of the interelectron Coulomb and Exchange energies The Heat Exchanged by A Spontaneous Process at Constant Entropy Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers To continue our effort to find change criteria that use only properties of the system let us consider a spontaneous process during which the system is in contact with its surroundings and the entropy of the system is constant For every incremental part of this process we have and Hence It follows that and Earlier we found that the entropy changes for a spontaneous process in an isolated system are and The present system is not isolated Since the change that occurs in the system is irreversible does not mean that The requirement that places no constraints on the temperature of the system or of the surroundings at any time before during or after the process occurs In Section we find for any spontaneous process in a closed system If the entropy of the system is constant we have spontaneous process constant entropy for every incremental part of the process For any finite change it follows that the overall heat must satisfy the same inequality spontaneous process constant entropy For a spontaneous process that occurs with the system in contact with its surroundings but in which the entropy of the system is constant the system must give up heat to the surroundings and are criteria for spontaneous change at constant system entropy In Section we develop criteria for reversible processes The criteria relate changes in the systems state functions to the reversible nonpressurevolume work that is done on the system during the process Now we can develop parallel criteria for spontaneous processes The Ideal Gas Constant and Boltzmanns Constant Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Having developed the ideal gas equation and analyzed experimental results for a variety of gases we will have found the value of R It is useful to have R expressed using a number of different energy units Frequently useful values are We also need the gas constant expressed per molecule rather than per mole Since there is Avogadros number of molecules per mole we can divide any of the values above by to get on a permolecule basis Traditionally however this constant is given a different name it is Boltzmanns constant usually given the symbol This means that we can also write the ideal gas equation as Because the number of molecules in the sample is we have The Ideal Gas Law Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors and Attributions The ideal gas law combines the empirical laws into a single expression It also predicts the existence of a single universal gas constant which turns out to be one of the most important fundamental constants in science The ideal gas law constant is of fundamental importance and can be expressed in a number of different sets of units Value Units atm L mol K J mol K cal mol K The ideal gas law as derived here is based entirely on empirical data It represents limiting ideal behavior As such deviations from the behavior suggested by the ideal gas law can be understood in terms of what conditions are required for ideal behavior to be followed or at least approached As such it would be nice if there was a theory of gases that would suggest the form of the ideal gas law and also the value of the gas law constant As it turns out the kinetic molecular theory of gases does just that Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay The Ideal Gas Standard State Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers The ideal gas standard state is a useful invention which has additional advantages that emerge as our development proceeds For permanent gasesgases whose behavior is approximately ideal anywaythere is a negligible difference between the enthalpy in the ideal gas state and the enthalpy at bar For volatile substances that are normally liquid or solid at bar the ideal gas standard state becomes a second standard state For such substances data tables frequently give the standard enthalpy of formation for both the condensed phase designated or and the ideal gas standard state designated For example the CODATA values for the standard enthalpies of formation for liquid and idealgas methanol are and respectively at K The difference between these values is the enthalpy change in vaporizing one mole of liquid methanol to its ideal gas standard state at K Since this is the difference between the enthalpy of methanol in its standard state as an ideal gas and methanol in its standard state as a liquid we can call this difference the standard enthalpy of vaporization for methanol This is not a reversible process because liquid methanol at bar is not at equilibrium with its vapor at an arbitrarily low pressure at K Note that is not the same as the ordinary enthalpy of vaporization The ordinary enthalpy of vaporization is the enthalpy change for the reversible vaporization of liquid methanol to real methanol vapor at a pressure of atm and the normal boiling temperature We write it without the superscript degree sign because methanol vapor is not produced in its standard state For methanol the normal boiling point and enthalpy of vaporization are and respectively We can devise a cycle that relates these two vaporization processes to one another Summing the steps below yields the process for vaporizing liquid methanol in its standard state to methanol vapor in its standard state liq K bar liq K bar liq K bar liq K atm liq K atm g K atm g K atm g K bar g K bar g K bar Thus we have and can be evaluated by integrating the heat capacities for the liquid and gas respectively and can be evaluated by integrating for the liquid and gas respectively is negligible For the evaluation of these quantities see problem The Joule Experiment Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Application to an Ideal GasAppliation to a van der Waals GasContributors and Attributions Going back to the expression for changes in internal energy that stems from assuming that is a function of and or for short one quickly recognizes one of the terms as the constant volume heat capacity And so the expression can be rewritten But what about the first term The partial derivative is a coefficient called the internal pressure and given the symbol James Prescott Joule recognized that should have units of pressure Energyvolume pressure and designed an experiment to measure it He immersed two copper spheres A and B connected by a stopcock Sphere A is filled with a sample of gas while sphere B was evacuated The idea was that when the stopcock was opened the gas in sphere A would expand against the vacuum in sphere B doing no work since The change in the internal energy could be expressed But also from the first law of thermodynamics Equating the two and since Joule concluded that and as well since he did not observe a temperature change in the water bath which could only have been caused by the metal spheres either absorbing or emitting heat And because for the gas that underwent the expansion into an open space must also be zero In truth the gas did undergo a temperature change but it was too small to be detected within his experimental precision Later we once we develop the Maxwell Relations will show that left dfracpartial Upartial V right_T T left dfracpartial ppartial T right_V p labeleq Application to an Ideal Gas For an ideal gas so it is easy to show that so combining Equations refeq and refeq together to get left dfracpartial Upartial V right_T dfracRTV p labeleq And since also becuase then Equation refeq simplifies to So while Joules observation was consistent with limiting ideal behavior his result was really an artifact of his experimental uncertainty masking what actually happened Appliation to a van der Waals Gas For a van der Waals gas so and left dfracpartial Upartial V right_T TdfracRVb p labeleqV Substitution of the expression for Equation refeqV into this Equation refeqV In general it can be shown that And so the internal pressure can be expressed entirely in terms of measurable properties and need not apply to only gases real or ideal Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay The JouleThomson Effect Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors and Attributions In working with William Thomson who would later become Lord Kelvin Joule conducted an experiment in which they pumped gas at a steady rate through a lead pipe that was cinched to create a construction On the upstream side of the constriction the gas was at a higher pressure than on the downstream side of the constriction Also the temperature of the gas was carefully monitored on either side of the construction The cooling that they observed as the gas expanded from a high pressure region to a lower pressure region was extremely important and lead to a common design of modern refrigerators Not all gases undergo a cooling effect upon expansion Some gases such as hydrogen and helium will experience a warming effect upon expansion under conditions near room temperature and pressure The direction of temperature change can be determined by measuring the JouleThomson coefficient This coefficient has the definition Schematically the JouleThomson coefficient can be measured by measuring the temperature drop or increase a gas undergoes for a given pressure drop Figure The apparatus is insulated so that no heat can be transferred in or out making the expansion isenthalpic Figure The typical behavior of the JouleThomson coefficient can be summarized in Figure At the combinations of and for which inside the shaded region the sample will cool upon expansion At those and conditions outside of the shaded region where the gas will undergo a temperature increase upon expansion And along the boundary a gas will undergo neither a temperature increase not decrease upon expansion For a given pressure there are typically two temperatures at which changes sign These are the upper and lower inversion temperatures Figure The typical behavior of the JouleThomson coefficient at different temperatures and pressures Using the tools of mathematics it is possible to express the JouleThomson coefficient in terms of measurable properties Consider enthalpy as a function of pressure and temperature This suggests that the total differential can be expressed It will be shown later again once we develop the Maxwell Relations that A simple substitution shows So For an ideal gas so which causes the first term to vanish So for constant enthalpy expansion there can be no change in temperature This will mean that gases will only show nonzero values for only because they deviate from ideal behavior Example Derive an expression for in terms of and Solution Using the total differential for Equation reftotalH Dividing by and constraining to constant Noting that and so left dfracpartial Hpartial p right_T left dfracpartial Hpartial T right_p leftdfracpartial Tpartial p right_H We can then use the following substitutions To get And solving for gives Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay The Kelvin Temperature Scale Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Thus far we have assumed nothing about the value of the temperature corresponding to any particular volume of our standard fluid We could define one unit of temperature to be any particular change in the volume of our standard fluid Historically Fahrenheit defined one unit degree of temperature to be one onehundredth of the increase in volume of a fixed quantity of standard fluid as he warmed it from the lowest temperature he could achieve which he elected to call degrees to the temperature of his body which he elected to call degrees Fahrenheits zero of temperature was achieved by mixing salt with ice and water This is not a very reproducible condition so the temperature of melting ice with no salt present soon became the calibration standard Fahrenheits experiments put the melting point of ice at F The normal temperature for a healthy person is now taken to be F possibly Fahrenheit had a slight fever when he was doing his calibration experiments In any case human temperatures vary enough so that Fahrenheits degree point was not very practical either The boiling point of water which Fahrenheits experiments put at F became the calibration standard Later the centigrade scale was developed with fixed points at degrees and degrees at the melting point of ice and the boiling point of water respectively The centigrade scale is now called the Celsius scale after Anders Celsius Anders a Swedish astronomer In Celsius proposed a scale on which the temperature interval between the boiling point and the freezing point of water was divided into degrees however a more positive number corresponded to a colder condition Further reflection convinces us that the Charles law equation can be simplified by defining a new temperature scale When we extend the straight line in any of our volumeversustemperature plots it always intersects the zerovolume horizontal line at the same temperature Since we cannot associate any meaning with a negative volume we infer that the temperature at zero volume represents a natural minimum point for our temperature scale Let the value of at this intersection be Substituting into our volumetemperature relationship we have or So that where we have created a new temperature scale Temperature values on our new temperature scale T are related to temperature values on the old temperature scale by the equation When the size of one unit of temperature is defined using the Celsius scale ie is the temperature in degrees Celsius this is the origin of the Kelvin temperature scale Then on the Kelvin temperature scale is degrees That is when K is degrees Celsius The temperature at which the volume extrapolates to zero is called the absolute zero of temperature When the size of one unit of temperature is defined using the Fahrenheit scale and the zero of temperature is set at absolute zero the resulting temperature scale is called the Rankine scale after William Rankine a Scottish engineer who proposed it in The Kinetic Molecular Theory of Gases Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay No headers Theoretical models attempting to describe the nature of gases date back to the earliest scientific inquiries into the nature of matter and even earlier In about BC Lucretius a Roman philosopher proposed that macroscopic bodies were composed of atoms that continually collide with one another and are in constant motion despite the observable reality that the body itself is as rest However Lucretius ideas went largely ignored as they deviated from those of Aristotle whose views were more widely accepted at the time In Daniel Bernoulli Bernoulli published a model that contains the basic framework for the modern Kinetic Molecular theory Rudolf Clausius furthered the model in by among other things introducing the concept of mean free path Clausius These ideas were further developed by Maxwell Maxwell Molecules But because atomic theory was not fully embraced in the early th century it was not until Albert Einstein published one of his seminal works describing Brownian motion Einstein in which he modeled matter using a kinetic theory of molecules that the idea of an atomic or molecular picture really took hold in the scientific community In its modern form the Kinetic Molecular Theory of gasses is based on five basic postulates Gas particles obey Newtons laws of motion and travel in straight lines unless they collide with other particles or the walls of the container Gas particles are very small compared to the averages of the distances between them Molecular collisions are perfectly elastic so that kinetic energy is conserved Gas particles so not interact with other particles except through collisions There are no attractive or repulsive forces between particles The average kinetic energy of the particles in a sample of gas is proportional to the temperature Qualitatively this model predicts the form of the ideal gas law More particles means more collisions with the wall Smaller volume means more frequent collisions with the wall Higher molecular speeds means more frequent collisions with the walls Putting all of these together yields which is exactly the form of the ideal gas law The remainder of the job is to derive a value for the constant of proportionality that is consistent with experimental observation For simplicity imagine a collection of gas particles in a fixedvolume container with all of the particles traveling at the same velocity What implications would the kinetic molecular theory have on such a sample One approach to answering this question is to derive an expression for the pressure of the gas The pressure is going to be determined by considering the collisions of gas molecules with the wall of the container Each collision will impart some force So the greater the number of collisions the greater the pressure will be Also the larger force imparted per collision the greater the pressure will be And finally the larger the area over which collisions are spread the smaller the pressure will be Figure The collision volume is the subset of the total volume that contains molecules that will actually collide with area in the time interval First off the pressure that the gas exerts on the walls of the container would be due entirely to the force imparted each time a molecule collides with the interior surface of the container This force will be scaled by the number of molecules that hit the area of the wall in a given time For this reason it is convenient to define a collision volume where is the speed the molecules are traveling in the x direction is the time interval the product of gives the length to the collision volume box and A is the area of the wall with which the molecules will collide Half of the molecules within this volume will collide with the wall since half will be traveling toward it and half will be traveling away from it The number of molecules in this collision volume will be given by the total number of molecules in the sample and the fraction of the total volume that is the collision volume And thus the number of molecules that will collide with the wall is given by And thus the number of molecules colliding with the wall will be The magnitude of that force imparted per collision will be determined by the timerate of change in momentum of each particle as it hits the surface It can be calculated by determining the total momentum change and dividing by the total time required for the event Since each colliding molecule will change its velocity from vx to vx the magnitude of the momentum change is mvx Thus the force imparted per collision is given by and the total force imparted is Since the pressure is given as the total force exerted per unit area the pressure is given by The question then becomes how to deal with the velocity term Initially it was assumed that all of the molecules had the same velocity and so the magnitude of the velocity in the xdirection was merely a function of the trajectory However real samples of gases comprise molecules with an entire distribution of molecular speeds and trajectories To deal with this distribution of values we replace with the squared average of velocity in the x direction The distribution function for velocities in the x direction known as the MaxwellBoltzmann distribution is given by This function has two parts a normalization constant and an exponential term The normalization constant is derived by noting that Normalizing the MaxwellBoltzmann Distribution The MaxwellBoltzmann distribution has to be normalized because it is a continuous probability distribution As such the sum of the probabilities for all possible values of vx must be unity And since can take any value between and then Equation refprob must be true So if the form of is assumed to be The normalization constant can be found from The expression can be simplified by letting It is then more simply written A table of definite integrals says that So And thus the normalized distribution function is given by Calculating an Average from a Probability Distribution Calculating an average for a finite set of data is fairly easy The average is calculated by But how does one proceed when the set of data is infinite Or how does one proceed when all one knows are the probabilities for each possible measured outcome It turns out that that is fairly simple too where is the probability of measuring the value This can also be extended to problems where the measurable properties are not discrete like the numbers that result from rolling a pair of dice but rather come from a continuous parent population In this case if the probability is of measuring a specific outcome the average value can then be determined by where is the function describing the probability distribution and with the integration taking place across all possible values that x can take Calculating the average value of A value that is useful and will be used in further developments is the average velocity in the x direction This can be derived using the probability distribution as shown in the mathematical development box above The average value of is given by This integral will by necessity be zero This must be the case as the distribution is symmetric so that half of the molecules are traveling in the x direction and half in the x direction These motions will have to cancel So a more satisfying result will be given by considering the magnitude of which gives the speed in the x direction Since this cannot be negative and given the symmetry of the distribution the problem becomes In other words we will consider only half of the distribution and then double the result to account for the half we ignored For simplicity we will write the distribution function as where and A table of definite integrals shows so Substituting our definitions for and produces This expression indicates the average speed for motion of in one direction However real gas samples have molecules not only with a distribution of molecular speeds and but also a random distribution of directions Using normal vector magnitude properties or simply using the Pythagorean Theorem it can be seen that Since the direction of travel is random the velocity can have any component in x y or z directions with equal probability As such the average value of the x y or z components of velocity should be the same And so Substituting this into the expression for pressure Equation refpress yields All that remains is to determine the form of the distribution of velocity magnitudes the gas molecules can take One of the first people to address this distribution was James Clerk Maxwell In his paper Maxwell Illustrations of the dynamical theory of gases Part On the motions and collisions of perfectly elastic spheres proposed a form for this distribution of speeds which proved to be consistent with observed properties of gases such as their viscosities He derived this expression based on a transformation of coordinate system from Cartesian coordinates to spherical polar coordinates In this new coordinate system v represents the magnitude of the velocity or the speed and all of the directional data is carried in the angles and The infinitesimal volume unit becomes Applying this transformation of coordinates and ignoring the angular part since he was interested only in the speed Maxwells distribution Equation refMB took the following form This function has three basic parts to it a normalization constant a velocity dependence and an exponential term that contains the kinetic energy Since the function represents the fraction of molecules with the speed the sum of the fractions for all possible velocities must be unity This sum can be calculated as an integral The normalization constant ensures that Choosing the normalization constant as yields the final form of the Maxwell distribution of molecular speeds At low velocities the term causes the function to increase with increasing but then at larger values of the exponential term causes it to drop back down asymptotically to zero The distribution will spread over a larger range of speed at higher temperatures but collapse to a smaller range of values at lower temperatures Table Figure Maxwell Distribution of speeds for hydrogen molecules at differing temperatures Calculating the Average Speed Using the Maxwell distribution as a distribution of probabilities the average molecular speed in a sample of gas molecules can be determined The following can be found in a table of integrals So Which simplifies to Note the value of is twice that of which was derived in an earlier example Example What is the average value of the squared speed according to the Maxwell distribution law Solution A table of integrals indicates that Substitution noting that yields which simplifies to Note The square root of this average squared speed is called the root mean square RMS speed and has the value The entire distribution is also affected by molecular mass For lighter molecules the distribution is spread across a broader range of speeds at a given temperature but collapses to a smaller range for heavier molecules Table Figure Maxwell Distribution of speeds at K for different gasses of differing molecular masses The probability distribution function can also be used to derive an expression for the most probable speed the average and the rootmeansquare speeds as a function of the temperature and masses of the molecules in the sample The most probable speed is the one with the maximum probability That will be the speed that yields the maximum value of It is found by solving the expression for the value of that makes it true This will be the value that gives the maximum value of for the given temperature Similarly the average value can be found using the distribution in the following fashion and the rootmeansquare RMS speed by finding the square root of the average value of Both demonstrated above The Laws of Thermodynamics Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers We usually consider that the first second and third laws of thermodynamics are basic postulates One of our primary objectives is to understand the ideas that are embodied in these laws We introduce these ideas here using statements of the laws of thermodynamics that are immediately applicable to chemical systems In the next three chapters we develop some of the most important consequences of these ideas In the course of doing so we examine other ways that these laws have been stated The first law deals with the definition and properties of energy The second and third laws deal with the definition and properties of entropy The laws of thermodynamics assert that energy and entropy are state functions In the next chapter we discuss the mathematical properties of state functions Energy and entropy changes are defined in terms of the heat and work exchanged between a system and its surroundings We adopt the convention that heat and work are positive if they increase the energy of the system In a process in which a closed system accepts increments of heat and work from its surroundings we define the changes in the energy and the entropy of the system in terms of and the temperature The meaning of the first law is intimately related to a crucial distinction between the character of energy on the one hand and that of the variables heat and work on the other When we say that energy is a state function we mean that the energy is a property of the system In contrast heat and work are not properties of the system rather they describe a process in which the system changes When we say that the heat exchanged in a process is we mean that units of thermal energy are transferred from the surroundings to the system If the energy of the system increases by this amount and the energy of the surroundings decreases by the same amount has meaning only as a description of one aspect of the process When the process is finished the system has an energy but exists only as an accounting record Like the amount on a cancelled check that records how much we paid for something is just a datum about a past event Likewise is the record of the amount of nonthermal energy that is transferred Because we can effect the same change in the energy of a system in many different ways we have to measure and for a particular process as the process is taking place We cannot find them by making measurements on the system after the process has gone to completion In Section we introduce a superscripted caret to denote a property state function of the surroundings Thus is the energy of the system is the energy of the surroundings is an incremental change in the energy of the system and is an incremental change in the energy of the surroundings If we are careful to remember that heat and work are not state functions it is useful to extend this notation to increments of heat and work If units of energy are transmitted to the system as heat we let be the thermal energy transferred to the surroundings in the same process Then and Likewise we let be the work done on the system and be the work done on the surroundings in the same process so that and Unlike and which are properties of different systems and or and are merely alternative expressions of the same thingthe quantity of energy transferred as heat or work We define the incremental change in the energy of a closed system as The accompanying change in the energy of the surroundings is so that Whereas or is a tautology because it merely defines as the first law asserts that is a fundamental property of nature Any increase in the energy of the system is accompanied by a decrease in the energy of the surroundings and conversely Energy is conserved heat is not work is not The first law of thermodynamics In a process in which a closed system accepts increments of heat and work from its surroundings the change in the energy of the system is Energy is a state function For any process For a reversible process in which a system passes from state A to state B the amount by which the energy of the system changes is the line integral of along the path followed Denoting an incremental energy change along this path as we have We review line integrals in the next chapter The energy change for the surroundings is the line integral of along the path followed by the surroundings during the same process For any process in which energy is exchanged with the surroundings the change in the systems energy is where and are the amounts of thermal and nonthermal energy delivered to the system We can compute from and whether the process is reversible or irreversible In contrast the definition of entropy change applies only to reversible processes In a process in which a system reversibly accepts an increment of heat from its surroundings the entropy change is defined by We introduce the superscript rev to distinguish heat and work exchanged in reversible processes from heat and work exchanged in irreversible irrev or spontaneous spon processes When a system passes reversibly from state A to state B the entropy change for the system is the line integral of along the path followed The entropy change for the surroundings is defined by the same relationship Every system has an entropy The entropies of the system and of its surroundings can change whenever a system undergoes a change If the change is reversible The second law of thermodynamics In a reversible process in which a closed system accepts an increment of heat from its surroundings the change in the entropy of the system is Entropy is a state function For any reversible process and conversely For any spontaneous process and conversely We define the entropy change of the universe by it follows that for any process in which a system passes from a state A to a state B whether the process is reversible or not Since for every part of a reversible process we have for any reversible process Likewise since for every part of a spontaneous process we have for any spontaneous process The third law deals with the properties of entropy at temperatures in the neighborhood of absolute zero It is possible to view the third law as a statement about the properties of the temperature function It is also possible to view it as a statement about the properties of heat capacities A statement in which the third law attributes particular properties to the entropy of pure substances is directly applicable to chemical systems This statement is that of Lewis and Randall third law of thermodynamics If the entropy of each element in some crystalline state be taken as zero at the absolute zero of temperature every substance has a positive finite entropy but at the absolute zero of temperature the entropy may become zero and does so become in the case of perfect crystalline substances The Lewis and Randall statement focuses on the role that the third law plays in our efforts to express the thermodynamic properties of pure substances in useful ways To do so it incorporates a matter of definition when it stipulates that the entropy of each element be taken as zero at the absolute zero of temperature The third law enables us to find thermodynamic properties absolute entropies and Gibbs free energies of formation from which we can make useful predictions about the equilibrium positions of reactions The third law can be inferred from experimental observations on macroscopic systems It also arises in a natural way when we develop the theory of statistical thermodynamics In both developments the choice of zero for the entropy of each element in some crystalline state at absolute zero iswhile arbitrarylogical natural and compellingly convenient The LindemannHinshelwood Mechanism for Firstorder Decay Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Firstorder kinetics for a unimolecular reaction corresponds to a constant probability that a given molecule reacts in unit time In Section we outline a simple mechanism that rationalizes this fact This mechanism assumes that the probability of reaction is zero unless the molecule has some minimum energy For molecules whose energy exceeds the threshold value we assume that the probability of reaction is constant However when collisions are frequent a molecule can have excess energy only for brief intervals The LindemannHinshelwood mechanism for gasphase unimolecular reactions provides a mathematical model of these ideas Since molecules exchange energy via collisions any given molecule acquires excess energy by collisions with other molecules and loses it within a short time through other collisions If it retains its excess energy long enough it will react If collisions are very infrequent every molecule that acquires excess energy reacts before it undergoes a deactivating collision In this case the reaction rate is proportional to the rate at which molecules acquire excess energy which is proportional to the number of collisions In a collection of molecules the total number of collisions is proportional to not and so the reaction rate depends on not We represent molecules with excess energy as and assume that all molecules undergo reaction with a constant probability molecules are formed in collisions between molecules and they are deactivated by subsequent collisions with molecules where is the products of the reaction The rate at which the number of moles of molecules changes is and since we suppose that is always very small the steadystate approximation applies so that and The reaction rate is given by When the rate of deactivating collisions between and is greater than the rate at which molecules go on to become products the rate law Equation reflaw for consumption of becomes first order beginalign lim_k_ceAgg k_ frack_k_ceAk_ceAk_ frack_k_ceAcancelk_cancelceA where the first order rate constant is a function of and This is termed the rate laws highpressure limit The lowpressure limit occurs when The rate law Equation reflaw becomes second order in beginalign lim_k_ceAll k_ frack_k_ceAk_ceAk_ frack_ cancelk_ceAcancelk_ where the second order rate constant is a function of only The rate of product formation becomes equal to the rate at which molecules are formed The Mechanism of the Base Hydrolysis of CoNHX Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics Mechanism Mechanism Mechanism This chapter focuses on the relationship between rate laws and reaction mechanisms We have noted that the rate law is rarely sufficient to establish the mechanism of a particular reaction The base hydrolysis of cobalt pentammine complexes is a reaction for which numerous lines of evidence converge to establish the mechanism To illustrate the range of data that can be useful in the determination of reaction mechanisms we summarize this evidence here CobaltIII complexes usually undergo substitution reactions at readily measurable rates Cobalt pentammine complexes have been studied extensively Mechanism In acidic aqueous solutions the reaction etc usually proceeds exclusively through the aquo complex The first step in the reaction is the breaking of a bond and the formation of a bond step Subsequently a moiety can replace the aquo group step For example In aqueous solution water is always present at a much higher concentration than the various possible entering groups so it is reasonable that it should be favored in the competition to form the new bond to Nevertheless we expect the strength of the bond to be an indicator of the nucleophilicity of in these substitution reactions The fact that the aquo complex is the predominant reaction product strongly suggests that the energetics of the reaction are dominated by the breaking of the bond formation of the new bond to the incoming ligand apparently has little effect Whether the old bond has been completely broken so that is a true intermediate before the new bond has begun to form remains an issue on which it is possible to disagree Mechanism There is a conspicuous exception to the description given above When the entering group is the hydroxide ion the reaction is This is called the basehydrolysis reaction It is faster than the formation of the aquo complex in acidic solutions and the rate is law found to be This rate law is consistent with nucleophilic attack by the hydroxide ion at the cobalt center so that bond formation occurs simultaneously with breaking of the bond However this interpretation means that the hydroxide ion is a uniquely effective nucleophile toward cobaltIII Nucleophilic displacements have been investigated on many other electrophiles In general hydroxide is not a particularly effective nucleophile toward other electrophilic centers So assignment of an mechanism to this reaction is reasonable only if we can explain why hydroxide is uniquely reactive in this case and not in others Mechanism An alternative mechanism usually labeled the Substitution Nucleophilic firstorder in the Conjugate Base mechanism mechanism is also consistent with the secondorder rate law In this mechanism hydroxide removes a proton from one of the ammine ligands to give a sixcoordinate intermediate containing an amido ligand step This intermediate loses the leaving group in the rate determining step to form a fivecoordinate intermediate step This intermediate picks up a water molecule to give the aquo complex step In a series of proton transfers to step and from step the aqueous solvent the aquo complex rearranges to the final product With as the leaving group the mechanism is The evidence in favor of the mechanism is persuasive It requires that the ammine protons be acidic so that they can undergo the acidbase reaction in the first step That this reaction occurs is demonstrated by protonexchange experiments In basic the ammine protons undergo exchange according to The ammine protons are also necessary base hydrolysis does not occur for similar compounds like in which there are no protons on the nitrogen atoms that are bound to cobalt ie there are no moieties The evidence that is an intermediate is also persuasive When the base hydrolysis reaction is carried out in the presence of other possible entering groups the rate at which is consumed is unchanged but the product is a mixture of and If this experiment is done with a variety of leaving groups the proportions of and are constantindependent of which leaving group the reactant molecule contains These observations are consistent with the hypothesis that all reactants give the same intermediate The product distribution is always the same because it is always the same species undergoing the productforming reaction The MichaelisMenten Mechanism for Enzymecatalyzed Reactions Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers An enzyme is a molecule produced by a living organism Its enzymes are essential to the life processes of the organism Often enzymes are large molecules that are catalytically active only when folded into a particular conformation Molecules whose reactions are catalyzed by an enzyme are customarily referred to as substrates for that enzyme Two aspects of enzymatic catalysis are remarkable First it is often found that an enzyme can discriminate between two very similar substrates greatly enhancing the reaction rate of one while having a much smaller effect on the rate of the other Second the rate enhancements achieved by enzyme catalysis are often very large rate increases by a factor of are observed Simple mechanistic and kinetic models are sufficient to explain these essential features of enzyme catalysis We consider the simplest case Both the mechanisms and the rate laws for enzymatic reactions can become much more complex than the model we develop The literature of enzyme catalysis uses a specialized vocabulary Problem introduces some of this terminology and some of the mechanistic complications that can be observed The catalytic specificity of enzymes is explained by the idea that the enzyme and the substrate have complex threedimensional structures These structures complement one another in the sense that enzyme and substrate can fit together tightly bringing the catalytically active parts of the enzymes structure into close proximity with those substrate chemical bonds that are changed in the reaction This is often called the lock and key model for enzyme specificity invoking the idea that the detailed features of the enzymes structure are shaped to fit into the structure of its substrate just as a key is machined to match the arrangement of tumblers in the lock that it opens Figure illustrates this idea Figure The lock and key model The rates of enzymecatalyzed reactions can exhibit complex dependence on the relative concentrations of enzyme and substrate Most of these features are explained by the MichaelisMenten mechanism which postulates a rapid equilibration of enzyme and substrate with their enzymesubstrate complex Transformation of the substrate occurs within this complex The reaction products do not complex strongly with the enzyme After the substrate has been transformed the products diffuse away The enzyme can then complex with another substrate molecule and catalyze its reaction Representing the enzyme substrate enzymesubstrate complex and products as and respectively the simplestcase MichaelisMenten mechanism is Complexation equilibrium Substrate transformation where is the equilibrium constant for the dissociation of the enzymesubstrate complex and is the rate constant for the ratedetermining transformation of the enzymesubstrate complex into products Since the firstorder decay of the enzymesubstrate complex is the productforming step the reaction rate is expected to be Letting the product concentration be and the initial concentrations of enzyme and substrate be and respectively material balance requires and Most experiments are done with the substrate present at a much greater concentration than the enzyme In this case is negligible in the equation and the concentration of free substrate becomes The enzymesubstrate equilibrium imposes the relationship Using this relationship to eliminate from the expression for gives The rate law for product formation becomes If the dependence on substrate cancels and the rate law becomes pseudozeroorder where the observed zeroorder rate constant depends on If the rate law becomes pseudofirstorder with pseudofirstorder rate constant If neither of these simplifications is applicable fitting experimental data to the integrated rate law becomes inconvenient In practice the integrated form of the rate law is seldom used As noted earlier enzyme catalysis is usually studied using the method of initial rates That is the rate is approximated as by measuring the amount of product formed over a short time interval in which The rate and equilibrium constants can then be found by fitting the rate measured at various initial concentrations and to the equation Since the concentration of the enzymesubstrate complex is normally small compared to the concentration of the substrate the MichaelisMenten mechanism can also be analyzed by applying the steadystate approximation to If the productforming step occurs so rapidly that the concentration of the enzymesubstrate complex is not maintained at the equilibrium value the steadystate treatment becomes necessary The Normal Distribution Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers The normal distribution is very important The central limit theorem says that if we average enough values from any distribution the distribution of the averages we calculate will be the normal distribution The probability density function for the normal distribution is The integral of the normal distribution from to is unity However the definite integral between arbitrary limits cannot be obtained as an analytical function This turns out to be true for some other important distributions also this is one reason for working with probability density functions rather than the corresponding cumulative probability functions Of course the definite integral can be calculated to any desired accuracy by numerical methods and readily available tables give values for definite integrals from to We mention normal curve of error tables in Section where we introduce a method for testing whether a given set of data conforms to the normal distribution equation The Number of Variables Required to Specify Some Familiar Systems Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers If we are to model a physical system mathematically we must abstract measurable properties from itproperties that we can treat as variables in our model In Section we found that the size of the system does not matter when we consider the variables that specify an equilibrium state A halfsize version of an equilibrium system has the same equilibrium properties We can say that only intensive properties are relevant to the question of whether a system is at equilibrium The idea that we can subdivide a system without changing its equilibrium properties is subject to an important qualification We intend that both subsystems be qualitatively equivalent to the original For example if we divide a system at vaporliquid equilibrium into subsystems each subsystem must contain some liquid and some vapor If we subdivide it into one subsystem that is all liquid and another that is all vapor the subsystems are not qualitatively equivalent to the original We can be more precise about the criterion we have in mind An equilibrium system consists of one or more homogenous phases Two systems can be in the same equilibrium condition only if all of the phases present in one are also present in the other If a process changes the number of phases present in a system we consider that the system changes from one kind of equilibrium system to a second one We can describe one kind of equilibrium system by specifying a sufficient number of intensive variables This description will be complete to within a specification of the exact amount of each phase present If we apply these ideas to a macroscopic sample of a pure gas we know that we need four variables to completely describe the state of the gas the number of moles of the gas its pressure its volume and its temperature This assumes that we are not interested in the motion of the container that contains the gas It assumes also that no other extrinsic factorslike gravitational electric or magnetic fields affect the behavior that we propose to model When we do experiments in which the amount pressure volume and temperature of a pure gas vary we find that we can develop an equation that relates the values that we measure We call this an equation of state because it is a mathematical model that describes the state of the system In Chapter we reviewed the ideal gas equation van der Waals equation and the virial equation however we can devise many others Whatever equation of state we develop we know that it must have a particular property At constant pressure and temperature the volume must be directly proportional to the number of moles This means that any equation of state can be rewritten as a function of concentration For the case of an ideal gas we have where the number of moles per unit volume is the gas concentration We see that any equation of state can be expressed as a function of three intensive variables pressure temperature and concentration The existence of an equation of state means that only two of the three intensive variables that describe the gas sample are independent of one another At equilibrium a sample of pure gas has two degrees of freedom Viewed as a statement about the mathematical model this is true because knowledge of the equation of state and any two of the intensive variables enables us to calculate the third variable Viewed as a statement about our experimental observations this is true because so long as the changes are consistent with the system remaining a gas we can change any two of these variables independently That only two are independent is shown experimentally by the observation that we can start with a fixed quantity of gas at any pressure temperature and concentration and find after taking the system through any sequence of changes whatsoever that returning to the original pressure and temperature also restores the original concentration In the experiment or in the mathematical model fixing two of the three intensive variables is sufficient to fix the equilibrium properties of the system Fixing the equilibrium properties means of course that the state of the system is fixed to within an arbitrary factor which can be specified either as the number of moles present or as the system volume Similar results are obtained when we study the pressurevolumetemperature behavior of pure substances in condensed phases At equilibrium a pure liquid or a pure solid has two degrees of freedom If we consider a homogeneous mixture of two nonreacting gases we discover that three variables are necessary to fix the equilibrium properties of the system We must know the pressure and temperature of the system and the concentration of each gas Because the mixture must obey an equation of state determination of any three of these variables is sufficient to fix the value of the fourth Note that we can conclude that three intensive variables are sufficient to determine the equilibrium properties of the system even if we do not have a mathematical model for the equation of state If we experiment with a system in which the liquid and vapor of a pure substance are in phase equilibrium with one another we find that there is only one independent intensive variable Figure illustrates this for water To maintain phase equilibrium the system pressure must be the equilibrium vapor pressure of the substance at the system temperature If we keep the pressure and temperature constant at equilibrium values we can increase or decrease the concentration moles per unit system volume by removing or adding heat In this process we change one variable concentration while maintaining phase equilibrium If we keep the pressure constant and impose a temperature increase vaporization continues the concentration decreases until the liquid phase is completely consumed In this process two variables change and phase equilibrium cannot be maintained To reach a new equilibrium state in which both liquid and gas are present at a higher temperature we must increase the pressure to the new equilibrium vapor pressure the magnitude of the temperature increase completely determines the required pressure increase Two intensive variables change but the changes are not independent If we have pure gas there are two independent intensive variables If we have pure liquid there are two independent intensive variables However if we have liquid and gas in equilibrium with one another there is only one independent intensive variable In the liquid region of the water phase diagram we can vary pressure and temperature and the system remains liquid water Along the liquidgas equilibrium line we can vary the temperature and remain at equilibrium only if we simultaneously vary the pressure so as to remain on the liquidgas equilibrium line Similar statements apply if we contrast varying pressure and temperature for the pure solid to varying the pressure and temperature along the solidliquid or the solidgas equilibrium line At the triple point nothing is variable For a fixed quantity of water the requirement that the system be at equilibrium at the triple point fixes the system pressure temperature and concentration Evidently maintaining a phase equilibrium in a system imposes a constraint that reduces the number of intensive variables that we can control independently The equilibrium between water and ice is completely unaffected by the state of subdivision of the ice The ice can be present in a single lump or as a large number of very small pieces from experience we know that the equilibrium behavior of the system is the same so long as some ice and some water are both present A system contains as many phases as there are kinds of macroscopic homogeneous bounded portions that are either solid liquid or gas If we add a lump of pure aluminum to our icewater system the new system contains three phases water ice and aluminum The equilibrium properties of the new system are the same if the aluminum is added as a groundup powder The powder contains many macroscopic homogeneous bounded portions that are aluminum but each of these portions has the same composition there is only one kind of aluminum particle Molecules on the surface of a substance can behave differently from those in the bulk When a substance is very finely divided the fraction of the molecules that is on the surface can become large enough to have a significant effect on the behavior of the system In this book we do not consider systems whose behavior is surfacearea dependent Theoretical Tools for Studying Chemical Change and Dynamics Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Transition State Theory Variational Transition State Theory Reaction Path Hamiltonian Theory Classical Dynamics Simulation of Rates RRKM Theory Correlation Function Expressions for Rates Wave Packet Propagation Surface Hopping Dynamics LandauZener Surface JumpsContributors and Attributions Transition State Theory The most successful and widely employed theoretical approach for studying rates involving species undergoing reaction at or near thermalequilibrium conditions is the transition state theory TST of the authors late colleague Henry Eyring This would not be a good way to model for example photochemical reactions in which the reactants do not reach thermal equilibrium before undergoing significant reaction progress However for most thermal reactions it is remarkably successful In this theory one views the reactants as undergoing collisions that act to keep all of their degrees of freedom translational rotational vibrational electronic in thermal equilibrium Among the collection of such reactant molecules at any instant of time some will have enough internal energy to access a transition state TS on the BornOppenheimer potential energy surface upon which the reaction takes place Within TST the rate of progress from reactants to products is then expressed in terms of the concentration of species that exist near the TS multiplied by the rate at which these species move through the TS region of the energy surface The concentration of species at the TS is in turn written in terms of the equilibrium constant expression of statistical mechanics discussed in Chapter For example for a bimolecular reaction passing through a TS denoted AB one writes the concentration in molecules per unit volume of AB species in terms of the concentrations of A and of B and the respective partition functions as There is however one aspect of the partition function of the TS species that is specific to this theory The partition function contains all of the usual translational rotational vibrational and electronic partition functions that one would write down as we did in Chapter for a conventional AB molecule except for one modification It does not contain a vibrational contribution for motion along the one internal coordinate corresponding to the reaction path Figure Typical potential energy surface in two dimensions showing local minima transition states and paths connecting them As we discussed in Chapter in the vicinity of the TS the reaction path can be identified as that direction along which the PES has negative curvature along all other directions the energy surface is positively curved For example in Figure a reaction path begins at Transition Structure B and is directed downhill More specifically if one knows the gradients and Hessian matrix elements of the energy surface at the TS one can express the variation of the potential energy along the Cartesian coordinates of the molecule as follows where E is the energy at the TS and the denote displacements away from the TS geometry Of course at the TS the gradients all vanish because this geometry corresponds to a stationary point As we discussed in Chapter the Hessian matrix has zero eigenvalues whose eigenvectors correspond to overall translation and rotation of the molecule This matrix has positive eigenvalues whose eigenvectors correspond to the vibrations of the TS species as well as one negative eigenvalue The latter has an eigenvector whose components along the Cartesian coordinates describe the direction of the reaction path as it begins its journey from the TS backward to reactants when followed in one direction and onward to products when followed in the opposite direction Once one moves a small amount along the direction of negative curvature the reaction path is subsequently followed by taking infinitesimal steps downhill along the gradient vector whose components are Note that once one has moved downhill away from the TS by taking the initial step along the negatively curved direction the gradient no longer vanishes because one is no longer at the stationary point Returning to the TST rate calculation one therefore is able to express the concentration of species at the TS in terms of the reactant concentrations and a ratio of partition functions The denominator of this ratio contains the conventional partition functions of the reactant molecules and can be evaluated as discussed in Chapter However the numerator contains the partition function of the TS species but with one vibrational component missing ie Other than the one missing the TSs partition function is also evaluated as in Chapter The motion along the reaction path coordinate contributes to the rate expression in terms of the frequency ie how often with which reacting flux crosses the TS region given that the system is in nearthermal equilibrium at temperature To compute the frequency with which trajectories cross the TS and proceed onward to form products one imagines the TS as consisting of a narrow region along the reaction coordinate the width of this region we denote We next ask what the classical weighting factor is for a collision to have momentum along the reaction coordinate Remembering our discussion of such matters in Chapter we know that the momentum factor entering into the classical partition function for translation along the reaction coordinate is Here m is the mass factor associated with the reaction coordinate s We can express the rate or frequency at which such trajectories pass through the narrow region of width as with being the speed of passage cm s and being the inverse of the distance that defines the TS region So has units of s In summary we expect the rate of trajectories moving through the TS region to be However we still need to integrate this over all values of that correspond to enough energy to access the TSs energy relative to that of the reactants which we denote Moreover we have to account for the fact that it may be that not all trajectories with kinetic energy equal to or greater pass on to form product molecules some trajectories may pass through the TS but later recross the TS and return to produce reactants Moreover it may be that some trajectories with kinetic energy along the reaction coordinate less than can react by tunneling through the barrier The way we account for the fact that a reactive trajectory must have at least in energy along s is to integrate over only values of greater than To account for the fact that some trajectories with energies above may recross we include a socalled transmission coefficient k whose value is between zero and unity In the most elementary TST tunneling is ignored Putting all of these pieces together we carry out the integration over just described to obtain where the momentum is integrated from to and the scoordinate is integrated only over the small region If the transmission coefficient is factored out of the integral treating it as a multiplicative factor the integral over can be evaluated and yields the following The exponential energy dependence is usually then combined with the partition function of the TS species that reflect this species other vibrational coordinates and momenta and the reaction rate is then expressed as This implies that the rate coefficient for this bimolecular reaction is given in terms of molecular partition functions by which is the fundamental result of TST Once again we notice that ratios of partition functions per unit volume can be used to express ratios of species concentrations in number of molecules per unit volume just as appeared in earlier expressions for equilibrium constants as in Chapter The above rate expression undergoes only minor modifications when unimolecular reactions are considered For example in the hypothetical reaction via the TS one obtains where again is a partition function of A with one missing vibrational component Before bringing this discussion of TST to a close I need to stress that this theory is not exact It assumes that the reacting molecules are nearly in thermal equilibrium so it is less likely to work for reactions in which the reactant species are prepared in highly nonequilibrium conditions Moreover it ignores tunneling by requiring all reactions to proceed through the TS geometry For reactions in which a light atom ie an H or D atom is transferred tunneling can be significant so this conventional form of TST can provide substantial errors in such cases however there are straightforward approximations similar to those we discussed in Chapter that can be used to make tunneling corrections to this rate expression Nevertheless TST remains the most widely used and successful theory of chemical reaction rates and can be extended to include tunneling and other corrections as we now illustrate Variational Transition State Theory Within the TST expression for the rate constant of a bimolecular reaction or of a unimolecular reaction the height E of the barrier on the potential energy surface appears in the TS species partition function or respectively In particular the TS partition function contains a factor of the form in which the BornOppenheimer electronic energy of the TS relative to that of the reactant species appears This energy is the value of the potential energy at the TS geometry which we denote It turns out that the conventional TS approximation to overestimates reaction rates because it assumes all trajectories that cross the TS proceed onward to products unless the transmission coefficient is included to correct for this In the variational transition state theory VTST one does not evaluate the ratio of partition functions appearing in at but one first determines at what geometry S the TS partition function ie or is smallest Because this partition function is a product of i the factor as well as ii translational rotational and vibrational partition functions which depend on the value of for which this product is smallest need not be the conventional TS value What this means is that the location S along the reaction path at which the freeenergy reaches a saddle point is not the same the location where the BornOppenheimer electronic energy has its saddle This interpretation of how and differ can be appreciated by recalling that partition functions are related to the Helmholtz free energy by so determining the value of where reaches a minimum is equivalent to finding that where the free energy is at a maximum So in VTST one adjusts the dividing surface through the location of the reaction coordinate S to first find that value where has a minimum One then evaluates both and the other components of the TS species partition functions at this value Finally one then uses the expressions given above but with taken at This is how VTST computes reaction rates in a somewhat different manner than does the conventional TST As with TST the VTST in the form outlined above does not treat tunneling and the fact that not all trajectories crossing proceed to products These corrections still must be incorporated as an addon to this theory ie in the k factor for recrossing and through tunneling corrections to achieve high accuracy for reactions involving light species recall from Chapter that tunneling probabilities depend exponentially on the mass of the tunneling particle I refer the reader to the web page of Prof Don Truhlar who has been one of the pioneers of VTST for further details Reaction Path Hamiltonian Theory Let us review what the reaction path is as defined earlier in Chapter It is a path that begins at a transition state TS and evolves along the direction of negative curvature on the potential energy surface as found by identifying the eigenvector of the Hessian matrix H_jk dfracEq_kq_j that belongs to the negative eigenvalue moves further downhill along the gradient vector whose components are terminates at the geometry of either the reactants or products depending on whether one began moving away from the TS forward or backward along the direction of negative curvature The individual steps along the reaction coordinate can be labeled as they evolve from the TS to the products labeled S_P and as they evolve from reactants SR to the TS If these steps are taken in very small infinitesimal lengths they form a continuous path and a continuous coordinate that we label At any point along a reaction path the BornOppenheimer potential energy surfacef its gradient components and its Hessian components can be evaluated in terms of derivatives of with respect to the Cartesian coordinates of the molecule However when one carries out reaction path dynamics one uses a different set of coordinates for reasons that are similar to those that arise in the treatment of normal modes of vibration as given in Chapter In particular one introduces massweighted coordinates that are related to the Cartesian coordinates in the same way as we saw in Chapter The gradient and Hessian matrices along these new coordinates x_j can be evaluated in terms of the original Cartesian counterparts The eigenvalues and eigenvectors of the massweighted Hessian can then be determined Upon doing so one finds zero eigenvalues whose eigenvectors describe overall rotation and translation of the molecule positive eigenvalues and eigenvectors along which the gradient has zero or nearly so components and one eigenvalue that may be positive zero or negative along whose eigenvector the gradient has its largest component The one unique direction along gives the direction of evolution of the reaction path in these massweighted coordinates All other directions ie within the space spanned by the other vectors possess nearly zero gradient component and positive curvature This means that at any point on the reaction path being discussed one is at or near a local minimum along all directions that are transverse to the reaction path direction ie the gradient direction one can move to a neighboring point on the reaction path by moving a small infinitesimal amount along the gradient In terms of the massweighted Hessians eigenmode directions and the potential energy surface can be approximated in the neighborhood of each such point on the reaction path by expanding it in powers of displacements away from this point If these displacements are expressed as components along the eigenvectors and along the gradient direction one can write the BornOppenheimer potential energy surface locally as E ES textbfgcdot textbfv_S delta S dfrac omega_S delta S sum_K N dfrac omega_K delta X_K Within this local quadratic approximation describes a sum of harmonic potentials along each of the modes transverse to the reaction path direction Along the reaction path appears with a nonzero gradient and a curvature that may be positive negative or zero The eigenmodes of the local ie in the neighborhood of any point along the reaction path massweighted Hessian decompose the internal coordinates into along which is harmonic and one along which the reaction evolves In terms of these same coordinates the kinetic energy can also be written and thus the classical Hamiltonian can be constructed Because the coordinates we use are massweighted in Cartesian form the kinetic energy contains no explicit mass factors T dfrac sum_j m_j leftfracdq_jdtright dfrac sum_j leftfracdx_jdtright This means that the momenta conjugate to each massweighted coordinate obtained in the usual way as all have identical unit mass factors associated with them To obtain the working expression for the reaction path Hamiltonian RPH one must transform the above equation for the kinetic energy by replacing the Cartesian massweighted coordinates by the eigenmode displacement coordinates the reaction path displacement coordinate and translation and rotational coordinates The three translational coordinates can be separated and ignored because centerofmass energy is conserved in further consideration The rotational coordinates do not enter into the potential but they do appear in However it is most common to ignore their effects on the dynamics that occurs in the internalcoordinates this amounts to ignoring the effects of overall centrifugal forces on the reaction dynamics We will proceed with this approximation in mind although the reader should keep in mind that doing so is an approximation that one might have to revisit in more sophisticated treatments Although it is tedious to perform the coordinate transformation of outlined above it has been done in the paper W H Miller N C Handy and J E Adams Reaction Path Hamiltonian for Polyatomic Molecules J Chem Phys and results in the following form for the RPH H sum_KN dfracp_K delta X_K omega_KS ES dfrac dfracp_S sum_KKN p_K delta X_K B_KKF where In the absence of the socalled dynamical coupling factors and this expression for describes harmonicoscillator Hamiltonian each of which has a locally defined frequency that varies along the reaction path ie is dependent a Hamiltonian for motion along the reaction coordinate with serving as the potential In this limit ie with the factors turned off the reaction dynamics can be simulated in what is termed a vibrationally adiabatic manner by placing each transverse oscillator into a quantum level that characterizes the reactants population of this mode assigning an initial momentum to the reaction coordinate that is characteristic of the collision to be simulated eg could be sampled from a MaxwellBoltzmann distribution if a thermal reaction is of interest or could be chosen equal to the mean collision energy of a beamcollision experiment timeevolving the and coordinate and momentum using the above Hamiltonian assuming that each transverse mode remains in the quantum state that it had when the reaction began The assumption that remains fixed which is why this model is called vibrationally adiabatic does not mean that the energy content of the mode remains fixed because the frequencies vary as one moves along the reaction path As a result the kinetic energy along the reaction coordinate will change both because varies along and because varies along S Lets return now to the RPH theory in which the dynamical couplings among motion along the reaction path and the modes transverse to it are included In the full RPH the terms couple modes and while couples the reaction path to mode These couplings express how energy can flow among these various degrees of freedom Explicit forms for the and factors are given in terms of the eigenvectors of the massweighted Hessian matrix as follows B_KK langle dtextbfv_KdS textbfv_Krangle B_KS langle dtextbfv_KdS textbfv_Srangle where the derivatives of the eigenvectors are usually computed by taking the eigenvectors at two neighboring points and along the reaction path In summary once a reaction path has been mapped out one can compute along this path the massweighted Hessian matrix and the potential Given these quantities all terms in the RPH are in hand This knowledge can subsequently be used to perform the propagation of a set of classical coordinates and momenta forward in time For any initial ie momenta and one can use the above form for H to propagate the coordinates and momenta forward in time In this manner one can use the RPH theory to follow the time evolution of a chemical reaction that begins with coordinates and moment characteristic of reactants under specified laboratory conditions and moves through a TS and onward to products Once time has evolved long enough for product geometries to be realized one can interrogate the values of to determine how much energy has been deposited into various productmolecule vibrations and of to see what the final kinetic energy of the product fragments is Of course one also monitors what fraction of the trajectories whose initial conditions are chosen to represent some experimental situation progress to product geometries vs returning to reactant geometries In this way one can determine the overall reaction probability Classical Dynamics Simulation of Rates One can also perform classical dynamics simulations of reactive events without using the reaction path Hamiltonian Following a procedure like that outlined in Chapter where classical condensedmedia MD simulations were discussed one can timeevolve the Newton equations of motion of the molecular reaction species using for example the Cartesian coordinates of each atom in the system and with either a BornOppenheimer surface or a parameterized functional form eg a force field Of course it is essential that whatever function one uses must be able to accurately describe the reactive surface especially near the transition state recall that may force fields do not do so because they do not account for bond breaking and forming With each such coordinate having an initial velocity and an initial value one then uses Newtons equations written for a time step of duration to propagate and forward in time according for example to the following firstorder propagation formula or using the Verlet algorithm described in Chapter Here m_q is the mass factor connecting the velocity dqdt and the momentum p_q conjugate to the coordinate q and is the force along the coordinate at the initial geometry By applying the timepropagation process one generates a set of new coordinates and new velocities appropriate to the system at time Using these new coordinates and momenta as and and evaluating the forces at these new coordinates one can again use the Newton equations to generate another finitetimestep set of new coordinates and velocities Through the sequential application of this process one generates a sequence of coordinates and velocities that simulate the systems dynamical behavior In using this kind of classical trajectory approach to study chemical reactions it is important to choose the initial coordinates and momenta in a way that is representative of the experimental conditions that one is attempting to simulate The tools of statistical mechanics discussed in Chapter guide us in making these choices and allow us efficient methods eg the Monte Carlo technique for sampling such initial values When one attempts for example to simulate the reactive collisions of an A atom with a BC molecule to produce AB C it is not appropriate to consider a single classical or quantal collision between A and BC Why Because in any laboratory setting The A atoms are probably moving toward the BC molecules with a distribution of relative speeds That is within the sample of molecules which likely contains or more molecules some A BC pairs have low relative kinetic energies when they collide and others have higher relative kinetic energies There is a probability distribution for this relative kinetic energy that must be properly sampled in choosing the initial conditions The BC molecules may not all be in the same rotational or vibrational state There is a probability distribution function describing the fraction of BC molecules that are in a particular state and a particular state An ensemble of initial values of the BC molecules internal vibrational coordinate and momentum as well as its orientation and rotational angular momentum must be selected to represent this When the A and BC molecules collide with a relative motion velocity vector they do not all hit head on Some collisions have small impact parameter the closest distance from A to the center of mass of BC if the collision were to occur with no attractive or repulsive forces and some have large values see Figure The probability function for these impact parameters is which is simply a statement of the geometrical fact that larger values have more geometrical volume element than smaller values Figure Coordinates needed to characterize an atomdiatom collision showing the impact parameter b So to simulate the entire ensemble of collisions that occur between A atoms and BC molecules in various states and having various relative kinetic energies and impact parameters b one must run classical trajectories or quantum propagations for a large number of and values with each such trajectory assigned an overall weighting or importance factor of After such an ensemble of trajectories representative of an experimental condition has been carried out one has available a great deal of data This data includes knowledge of what fraction of the trajectories produced final geometries characteristic of products so the net reaction probability can be calculated In addition the kinetic and potential energy content of the internal vibrational and rotational modes of the product molecules can be interrogated and used to compute histograms giving probabilities for observing products in these states This is how classical dynamics simulations allow us to study chemical reactions andor energy transfer RRKM Theory Another theory that is particularly suited for studying unimolecular decomposition reactions is named after the four scientists who developed it Rice Ramsperger Kassel and Marcus To use this theory one imagines an ensemble of molecules that have been activated to a state in which they possess a specified total amount of internal energy of which an amount exists as rotational energy and the remainder as internal vibrational energy The mechanism by which the molecules become activated could involve collisions or photochemistry It does not matter as long as enough time has passed to permit one to reasonably assume that these molecules have the energy distributed randomly among all their internal vibrational degrees of freedom When considering thermally activated unimolecular decomposition of a molecule the implications of such assumptions are reasonably clear For photochemically activated unimolecular decomposition processes one usually also assumes that the molecule has undergone radiationless relaxation and returned to its ground electronic state but in a quite vibrationally hot situation That is in this case the molecule contains excess vibrational energy equal to the energy of the optical photon used to excite it Finally when applied to bimolecular reactions one assumes that collision between the two fragments results in a longlived complex The lifetime of this intermediate must be long enough to allow the energy which is related to the fragments collision energy to be randomly distributed among all vibrational modes of the collision complex For bimolecular reactions that proceed directly ie without forming a longlived intermediate one does not employ RRKMtype theories because their primary assumption of energy randomization almost certainly would not be valid in such cases The RRKM expression of the unimolecular rate constant for activated molecules A ie either a longlived complex formed in a bimolecular collision or a hot molecule dissociating to products through a transition state A rightarrow TS rightarrow P is k_rm rate dfracGEE_ E_rm rotNEE_rm roth Here the total energy is related to the energies of the activated molecules by E E_rm rot E_rm vib where is the rotational energy of the activated molecule and is the vibrational energy of this molecule This same energy must of course appear in the transition state where it is decomposed as an amount needed to move from A to the TS ie the energy needed to reach the barrier and vibrational translational along the reaction coordinate and rotational energies E E_ E_rm vib E_rm trans E_rm rot In the rate coefficient expression is the total sum of internal vibrational quantum states that the transition state possesses having energies up to and including This energy is the total energy but with the activation energy removed and the overall rotational energy of the TS removed The quantity is the density of internal vibrational quantum states excluding the mode describing the reaction coordinate that the activated molecule possesses having an energy between and In this expression the energy is the total energy with the rotational energy of the activated species removed In the most commonly employed version of RRKM theory the rotational energies of the activated molecules and of the TS are assumed to be related by Here and are the average taken over the three eigenvalues of the moment inertia tensors moments of inertia of the activated molecules and TS species respectively The primary assumption embodied in the above relationship is that the rotational angular momenta of the activated and TS species are the same so their rotational energies can be related as expressed in the equation to changes in geometries as reflected in their moments of inertia Because RRKM theory assumes that the vibrational energy is randomly distributed its fundamental rate coefficient equation k_rm rate dfracGEE_ E_rm rot NEE_rm roth depends on the total energy the energy required to access the TS and the amount of energy contained in the rotational degrees of freedom that is thus not available to the vibrations To implement a RRKM rate coefficient calculation one must know the total energy available the barrier energy the geometries and hence the moments of inertia and of the activated molecules and of the TS respectively the rotational energy of the activated molecules as well as all vibrational energies of the activated molecules and all vibrational energies of the TS ie excluding the reaction coordinate The rotational energy of the TS species can then be related to that of the activated molecules through E_rm rot E_rm rot E_rm rot left fracIIright To simulate an experiment in which the activated molecules have a thermal distribution of rotational energies the RRKM rate constant is computed for a range of values and then averaged over using the thermal Boltzmann population as a weighting factor This can be carried out for example using the MC process for selecting rotational values This then produces a rate constant for any specified total energy E Alternatively to simulate experiments in which the activated species are formed in bimolecular collisions at a specified energy the RRKM rate coefficient is computed for a range of values with each related to the collisional impact parameter that we discussed earlier In that case the collisional angular momentum is given as where is the relative collision speed related to the collision energy and m is the reduced mass of the two colliding fragments Again using E_rm rot E_rm rot E_rm rot left fracIIright the TS rotational energy can be related to that of the activated species Finally the RRKM rate coefficient is evaluated by averaging the result over a series of impact parameters each of which implies a value and thus an with as the weighting factor he evaluation of the sum of states and the density of states that appear in the RRKM expression is usually carried out using a statecounting algorithm such as that implemented by Beyer and Swinehart in Commun Assoc Comput Machin This algorithm uses knowledge of the harmonic vibrational frequencies of the activated molecules and the frequencies of the TS and determines how many ways a given amount of energy can be distributed among these modes By summing over all such distributions for energy varying from zero to the algorithm determines GE By taking the difference it determines Professor Bill Hase has been one of the early pioneers involved in applying RRKM theory to chemical processes Correlation Function Expressions for Rates Recall from Chapter that rates of photon absorption can in certain circumstances be expressed either in terms of squares of transition dipole matrix elements connecting each initial state to each final state textbfE_ cdot langle Phi_f boldsymbolmu Phi_i rangle or in terms of the equilibrium average of the product of a transition dipole vector at time dotted into this same vector at another time sum_i rho_i langle Phi_i textbfE_ cdot boldsymbolmu textbfE_ boldsymbolmu t Phi_i rangle That is these rates can be expressed either in a statetostate manner or in a timedependent correlation function framework In Chapter this same correlation function approach was examined further In an analogous fashion it is possible to express chemical reaction rate constants in a timedomain language again using time correlation functions The TST or VTST and RRKM expressions for the rate constant all involve through the partition functions or state densities the reactant and transitionstate energy levels and degeneracies These theories are therefore analogs of the statetostate photonabsorption rate equations To make the connection between the statetostate and timecorrelation function expressions one can begin with a classical expression for the rate constant given below Here is the partition function of the reactant species L is the number of coordinates and momenta upon which the Hamiltonian depends and is The flux factor and the reaction probability are defined in terms of a dividing surface which could for example be a plane perpendicular to the reaction coordinate and located along the reaction path that was discussed earlier in this Chapter in Section Points on such a surface can be defined by specifying one condition that the L coordinates qj must obey and we write this condition as Points lying where are classified as lying in the reactant region of coordinate space while those lying where are in the product region For example if the dividing surface is defined as being a plane perpendicular to the reaction path the function f can be written as Here is the reaction coordinate which of course depends on all of the variables and is the value of at the dividing surface If the dividing surface is placed at the transition state on the energy surface vanishes because the transition state is then by convention the origin of the reaction coordinate So now we see how the dividing surface can be defined but how are the flux and probability c constructed The flux factor is defined in terms of the dividing surface function as follows deltaftextbfq sum_j dfracfq_j dfracdq_jdt Here is the Heaviside step function if if whose derivative is the Dirac delta function and the other identities follow by using the chain rule When the dividing surface is defined in terms of the reaction path coordinate as introduced earlier ie the factor sum_j dfracfq_j dfracdq_jdt contains only one term when the L coordinates are chosen as in the reaction path theory to be the reaction coordinate and L coordinates perpendicular to the reaction path For such a choice one obtains sum_j dfracfq_j dfracdq_jdt fracdSdt dfracP_Sm_S where is the momentum along and is the mass factor associated with in the reaction path Hamiltonian So in this case the total flux factor reduces to We have seen exactly this construct before in Section where the TST expression for the rate coefficient was developed The reaction probability factor is defined in terms of those trajectories that evolve at long time onto the product side of the dividing surface such trajectories obey ctextbfptextbfq lim_t rightarrow infty hfqt This longtime limit can in turn be expressed in a form where the flux factor again occurs In this expression the flux pertains to coordinates and momenta at Because of time reversibility the integral can be extended to range from until t infty Using the expressions for c and for as developed above in the equation for the rate coefficient given at the beginning of this Section allows the rate coefficient to be rewritten as follows In this form the rate constant appears as an equilibrium average represented by the integral over the initial values of the variables and with the weighting factor of the time correlation function of the flux To evaluate the rate constant in this timedomain framework for a specific chemical reaction one would proceed as follows Run an ensemble of trajectories whose initial coordinates and momenta are selected eg using MonteCarlo methods discussed in Chapter from a distribution with as its weighting factor Make sure that the initial coordinates lie on the dividing surface because the flux expression contains the factor Monitor each trajectory to observe when it again crosses the dividing surface ie when again obeys at which time the quantity can be evaluated as Ftextbfptextbfq deltaftextbfq sum_j dfracfq_j dfracdq_jdt using the coordinates and momenta at time to compute these quantities Using a planar dividing surface attached to the reaction path at as noted earlier allows to be calculated in terms of the initial momentum lying along the reaction path direction as and permits to be computed when the trajectory again crosses this surface at at time as So all that is really needed if the dividing surface is defined in this manner is to start trajectories with to keep track of the initial momentum along to determine at what times the trajectory returns to and to form the product for each such time It is in this manner that one can compute fluxflux correlation functions and thus the rate coefficient Notice that trajectories that undergo surface recrossings contribute negative terms to the fluxflux correlation function computed as discussed above That is a trajectory with a positive initial value of can at some later time t cross the dividing surface with a negative value of ie be directed back toward reactants This recrossing will contribute a negative value via the product to the total correlation function which integrates over all times Of course if this same trajectory later undergoes yet another crossing of the dividing surface at t with positive it will contribute a positive term to the correlation function via Thus the correlation function approach to computing the rate coefficient can properly account for surface recrossings unlike the TST which requires one to account for such effects in the transmission coefficient k Wave Packet Propagation The discussions in Chapters and should have made it clear that it is very difficult to timepropagate wave functions rigorously using quantum mechanics On the other hand to propagate a classical trajectory is relatively straightforward In addition to the semiclassical tools introduced in Chapter there is another powerful tool that allows one to retain much of the computational ease and convenient interpretation of the classical trajectory approach while also incorporating quantum effects that are appropriate under certain circumstances In this wave packet propagation approach one begins with a quantum mechanical wave function that is characterized by two parameters specifying the average value of the position and of the momentum along each coordinate One then propagates not the quantum wave function but the values of these two parameters which one assumes will evolve according to Newtonian dynamics Lets see how these steps are taken in more detail and try to understand when such an approach is expected to work or to fail First the form of the socalled wave packet quantum function is written as follows Here we have a total of N coordinates that we denote It is these coordinates that the quantum wave function depends upon The total wave function is a product of terms one for each coordinate Notice that this wave function has two distinct ways in which the coordinate appear First it has a Gaussian spatial dependence centered at the values and having Gaussian width factors related to This dependence tends to make the wave functions amplitude largest when is close to Secondly it has a form that looks like the travelling wave that we encountered in Chapter in which the coordinate moves with momentum So these wave packet functions have built into them characteristics that allow them to describe motion via the of an amplitude that is centered at with a width given by the parameter In this approach to chemical dynamics we assume the parameters and will undergo classical time evolution according to the Newton equations where is the potential energy surface BornOppenheimer or force field upon which we wish to propagate the wave packet and is the mass associated with coordinate For the form of the wave function given above the and parameters can be shown to be the expectation values of the coordinates and momenta P_J int Y i hbardfracq_J Y dq Moreover the parameter appearing in the Gaussian part of the function can be shown to equal the dispersion or spread of this wave function along the coordinate There is an important characteristic of the above Gaussian wave packet functions that we need to point out It turns out that functions of the form can be shown to have uncertainties in and in whose product is as small as possible The proof that the wave packet form of the wave function has the smallest uncertainty product is given in the text book Quantum Mechanics rd ed L I Schiff McGrawHill New York The Heisenberg uncertainty relation which is discussed in many texts dealing with quantum mechanics says that this product of coordinate and momentum dispersions must be greater than or equal to In a sense the Gaussian wave packet function is the most classical function that one can have because its uncertainty product is as small as possible ie equals We say this is the most classical possible quantum function because in classical mechanics both the coordinate and the momentum can be known precisely So whatever quantum wave function allows these two variables to be least uncertain is the most classical To use wave packet propagation to simulate a chemical dynamics event one begins with a set of initial classical coordinates and momenta as well as a width or uncertainty for each coordinate Each width must be chosen to represent the range of that coordinate in the experiment that is to be simulated For example assume one were to represent the dynamics of a wave function that is prepared by photon absorption of a vibrational state of the HCl molecule from the ground S state to an excitedstate energy surface Such a situation is described qualitatively in Figure In this case one could choose to be the half width of the harmonic or Morse oscillator wave function of HCl and take because this is the average value of the momentum for and the equilibrium bond length For such initial conditions classical Newtonian dynamics would then be used to propagate the and In the HCl example introduced above this propagation would be performed using the excitedstate energy surface for since for the molecule is assumed to be on this surface The total energy at which the initial wave packet it delivered to the upper surface would be dictated by the energy of the photon used to perform the excitation In Figure two such examples are shown Once the packet is on the upper surface its position and momentum begin to change according to the Newton equations This in turn causes the packet to move as shown for several equally spaced time steps in Figure for the two different photons cases At such subsequent times the quantum wave function is then assumed within this model to be given by That is it is taken to be of the same form as the initial wave function but to have simply moved its center from to with a momentum that has changed from to Figure Propagation of wave packet prepared by absorption of two different photons It should be noticed that the time evolution of the wave packet shown in Figure displays clear classical behavior For example as time evolves it moves to large Rvalues and its speed as evidenced by the spacings between neighboring packets for equal time steps is large when the potential is low and small when the potential is higher As we learned in Chapter the time correlation function can be used to extract spectral information by Fourier transformation For the HCl example considered here this correlation function will be large at but will decay in magnitude as the wave packet moves to the right at t t etc because its overlap with becomes smaller and smaller as time evolves This decay in will occur more rapidly for the highenergy photon case because moves to the right more quickly because the classical momentum grows more rapidly These dynamics will induce exponential decays in ie will vary as at short times In fact the decay of discussed above produces when is Fourier transformed the primary characteristic of the correlation function for the higherenergy photon case where dissociation ultimately occurs In such photodissociation spectra one observes a Lorentzian line shape whose width is characterized by the decay rate which in turn relates to the total energy of the packet and the steepness of the excitedstate surface This steepness determines how fast grows which then determines how fast the HCl bond fragments In the lowerenergy photon case shown in Figure a qualitatively different behavior occurs in and thus in the spectrum The packets movement to larger causes to initially undergo decay However as the packet moves to its largeR turning point shortly after time it strikes the outer wall of the surface where it is reflected Subsequently it undergoes motion to smaller R eventually returning to its initial value of R Such recurrences which occur on time scales that we denote are characteristic of bound motion in contrast to the directly dissociative motion discussed earlier This recurrence will cause to again achieve a large amplitude but will subsequently again undergo decay as the packet once again departs Clearly the correlation function will display a series of recurrences followed by exponential decays The frequency of the recurrences is determined by the frequency with which the packet traverses from its inner to outer turning points and back again which is proportional to This of course is the vibrational period of the HCl bond So in such boundmotion cases the spectrum ie the Fourier transform of Ct will display a series of peaks spaced by with the envelope of such peaks having a width determined by In more complicated multimode cases eg in molecules containing several coordinates the periodic motion of the wave packet usually shows another feature that we have not yet discussed Let us for simplicity consider a case in which only two coordinates are involved For the wave packet to return to or near its initial location enough time must pass for both coordinates to have undergone an excursion to their turning points and back For example consider the situation in which one coordinates vibrational frequency is ca cm and the others is cm these two modes then require ca ps and ps respectively to undergo one complete oscillation At the wave packet which is a product of two packets one for each mode produces a large Ct After ps the first modes coordinate has returned to its initial location but the second mode is only of the way along in its periodic motion Moreover after ps the second modes coordinate has returned to near where it began but now the first mode has moved away So at both ps and ps the correlation function will not be large because one of the mode contribution to will be small However after ps both modes coordinates will be in positions to produce a large value of Ct the highfrequency mode will have undergone oscillations and the lowerfrequency mode will have undergone oscillations My point in discussing this example is to illustrate that molecules having many coordinates can produce spectra that display rather complicated patterns but which in principle can be related to the time evolution of these coordinates using the correlation functions connection to the spectrum Of course there are problems that arise in using the wave packet function to describe the time evolution of a molecule or any system that should be treated using quantum mechanics One of the most important limitations of the wave packet approach to be aware of relates to it inability to properly treat wave reflections It is well know that when a wave strikes a hard wall it is reflected by the wall However when for example a water wave moves suddenly from a region of deep water to a much more shallow region one observes both a reflected and a transmitted wave In the discussion of tunneling resonances given in Chapter we also encountered reflected and transmitted waves Furthermore when a wave strikes a barrier that has two or more holes or openings in it one observes wave fronts coming out of these openings The problem with the most elementary form of wave packets presented above is that each packet contains only one piece It therefore can not break into two or more pieces as it for example reflects from turning points or passes through barriers with holes Because such wave packets can not fragment into two or more packets that subsequently undergo independent dynamical evolution they are not able to describe dynamical processes that require multiplefragmentation events It is primarily for this reason that wave packet approaches to simulating dynamics are usually restricted to treating shorttime dynamics where such fragmentation of the wave packet is less likely to occur Prompt molecular photodissociation processes such as we discussed above is a good example of such a shorttime phenomenon There have been many refinements of the wave packet approach described above some of which are designed to allow for splitting of the wave function I refer the reader to the work of one of the pioneers of the timedependent wave packet approach Prof Eric Heller for more information on this subject Surface Hopping Dynamics There are of course chemical reactions and energytransfer collisions in which two or more BornOppenheimer BO energy surfaces are involved Under such circumstances it is essential to have available the tools needed to describe the coupled electronic and nuclearmotion dynamics appropriate to this situation The way this problem is addressed is by returning to the Schrdinger equation before the singlesurface BO approximation was made and expressing the electronic wave function which depends on the electronic coordinates and the nuclear coordinates as Here can be the BO electronic wave function belonging to the electronic state in which case we say we are using an adiabatic basis of electronic states The are amplitudes that will relate to the probability that the system is on the energy surface Next we assume that the coordinates of the nuclei undergo classical motion in a manner to be specified in further detail below that allows us to know their locations and velocities or momenta at any time This assumption implies that the time dependence of the above wave function is carried in the time dependence of the coordinates as well as in the amplitudes We next substitute this expansion into the timedependent Schrdinger equation where is the electronic Hamiltonian which depends on the nuclear coordinates and thus on the time variable We then multiply the resultant equation on the left by one of the wave functions and integrate over the electronic coordinates to obtain an equation for the amplitudes Here is the electronic Hamiltonian matrix element that couples to This set of coupled differential equations for the amplitudes can be solved numerically by for example starting at with and and propagating the amplitudes values forward in time The next step is to express using the chain rule in terms of derivatives with respect to the nuclear coordinates and the time rate of change of these coordinates So now the equations for the read as follows The are called nonadiabatic coupling matrix elements for each pair of states and they are a vector in the space of the nuclear coordinates and it is their magnitudes that play a central role in determining the efficiency of surface hoppings Below we will make use of the following symmetry property of these quantities which derive from the orthogonality of the These matrix elements are becoming more commonly available in widely utilized quantum chemistry and dynamics computer packages although their efficient evaluation remains a challenge that is undergoing significant study Qualitatively one can expect a coupling to be large if motion along a coordinate causes an orbital occupied in to be distorted in a manner that would produce significant overlap with an orbital in If the electronic functions appearing in the equations are BO eigenfunctions the offdiagonal elements vanish and the diagonal elements are the BO energy levels In this case only the terms involving generate transitions between surfaces On the other hand if one chooses electronic functions that have vanishing values only the terms induce transitions among surfaces The latter case is said to involve using diabatic wave functions while the former involves adiabatic wave functions For the remainder of this discussion I will assume we are making use of adiabatic ie BO wave functions but I will carry through the derivation in a manner that will allow either adiabatic or diabatic functions to be used Because one is eventually interested in the populations for being in various electronic states it is common to recast the above equations for the amplitudes into equations for socalled density matrix elements The diagonal elements of the matrix are the state probabilities while the offdiagonal elements contain information about the phases of the complex quantities So in place of the equations for the one can use the following equations for the Setting it is then possible to derive an equation for the time evolution of the diagonal elements of the density matrix where In addition to calculating amplitudes the probabilities then being computed as one often needs to identify using perhaps the kind of strategy discussed in Chapter the seam at which the surfaces of interest intersect This helps focus attention on those geometries near which a surface hop is most likely to occur To utilize the most basic form of surface hopping theory one proceeds as follows One begins with initial values of the nuclear coordinates and their velocities that properly characterize the kind of collision or reaction one wishes to simulate Of course one has to utilize an ensemble of trajectories with initial conditions chosen to properly describe such an experimental situation In addition one specifies which electronic surface say the surface the system is initially on For each such set of initial conditions one propagates a classical trajectory describing the time evolution of the Ra and dRadt on this initial surface As one is propagating the classical trajectory one also propagates the coupled differential equations for the density matrix elements with the nuclei moving on the energy surface After each timepropagation step of duration one evaluates the quantity shown above these elements give estimates for the rate of change of the population of the state due to transitions to other states from which one computes These quantities control the fractional change in the probability of being on the surface due to transitions from state into state They are used as follows A random number is chosen If a hop to surface is allowed to occur otherwise no hop occurs and the system remains to continue its time evolution on surface K If a hop occurs the coordinates and momenta are allowed to now propagate on the energy surface where the forces will of course be different but with one change The component of the velocity vector along the nonadiabatic coupling vector is modified to allow for the fact that the systems electronic energy has suddenly changed from to which must be compensated for by a change in the kinetic energy of the nuclei so that total energy is conserved If this results in an increase in speed if it produces a decrease in speed In the latter case if lies considerably below it might turn out that there is just not enough total energy to access the surface in this case the hop is not allowed to occur Following the above decision about allowing the hop and adjusting the speed along the direction of the vector the trajectory is then continued with the system now propagating on the or surface and the differential equations involving continue to be propagated with no changes other than the fact the nuclei may or may not be evolving on a different surface The entire process is repeated until the trajectory reaches termination eg a reaction or quenching is observed or some specified time limit is reached at which time one can probe the properties of the products as reflected in the coordinates and velocities of the nuclei Carrying out surface hopping trajectories for an ensemble of trajectories with initial conditions representative of an experiment generates an ensemble of final values ie at the end of each trajectory whose averages can be used to estimate the overall probability of ending up in the electronic state The algorithm discussed above is the socalled fewestswitches method detailed in J C Tully J Chem Phys pioneered by Prof John Tully This surfacehopping algorithm remains one of the most widely used approaches to treating such coupledstate dynamics LandauZener Surface Jumps There is a simplified version of the surface hopping procedure just discussed that is often used when one has two electronic surfaces that intersect in a region of space that i is energetically accessible in the experiment being simulated and ii can be located and characterized eg in terms of its coordinates and energy gradients in a computationally feasible manner To illustrate we again consider the case of Al interacting with whose potential energy surfaces are reproduced below from Figure c Figure a Depiction of the and BornOppenheimer surfaces arising when combines with to form With the LandauZener model described in this Section trajectories are propagated on one energy surface until a point on or very near the seam denoted in Figure a is encountered at which time an equation giving the probability of undergoing a jump to the other surface is invoked It is the purpose of this Section to derive and explain this LandauZener equation In Chapter we learned that the rates of transitions from one state labeled to another labeled can sometimes be expressed in terms of matrix elements of the perturbation connecting the two states as follows Because the coupling matrix elements have units of energy and the function has units of inverse frequency the rate expression clearly has units of In the rate equation is the energy of the transition induced by light of energy and is the perturbation due to the electric dipole operator These photoninduced rates can be viewed as relating to transitions between two surfaces that cross i one surface being that of the initial state plus a photon of energy and ii the second being that of the final state with no photon In this point of view the photon lifts the lowerenergy state upward in energy until it crosses the upper state and then the dipole operator effects the transition Making analogy with the photonabsorption case we consider expressing the rates of transitions between an initial state consisting of an electronic state multiplied by a state describing the initial vibrational including interfragment collisional and rotational state of the system a final state consisting of the product of another electronic and vibrationrotation state as follows That is we use the same golden rule rate expression but with no photon energy needed to cause the two surfaces to intersect Next we use the identity to write which can be substituted into our rate expression to obtain rm Ratefracpiint_inftyinftyexpBigfracivarepsilon_fvarepsilon_ithbarBig dfracpi langle Psi_fchi_fRvrPsi_ichi_iRrangle langle Psi_fchi_fRvrPsi_ichi_iRrangle hbardt Defining two nuclearmotion Hamiltonian one for each BO surface and assuming that the nuclearmotion wave functions obey this expression becomes In the expression the elements of for our surfacejumping problem would involve either the electronic Hamiltonian couplings if one uses a diabatic basis or the nonadiabatic coupling elements if one used a BO adiabatic basis In either case these elements are functions of the nuclear coordinates and thus do not commute with the differential operators appearing in As a result the operator combination must be handled carefully eg as one does in the coupledcluster expansion treated in Chapter by expanding the exponential operators and keeping track of the fact that not all terms commute The lowestorder term in the expansion of this combination of operators is which yields the approximation I now want to pursue Using this approximation in our expression for the rate of surface jumping transitions gives We now use to write the rate as where we define the electronic transition integrals in shorthand as Because of the energyconserving dfunction we can actually simplify this expression even further by summing over the complete set of the finalstates vibrationrotation functions and making use of the completeness relation to obtain This expression can be seen to have units of s since the delta function has units of inverse energy and each electronic coupling integral has units of energy In the above rate expression we see a dfunction that limits the integration to only those geometries for which these are the geometries that lie on the intersection seam Any geometry can be expressed in terms of the geometry of the point on the seam closest to plus a displacement of magnitude along the unit vector normal to the seam at point If we now expand the energy difference in a Taylor series about the point lying on the seam we obtain The gradient of the potential difference has zero components within the subspace of the seam its only nonvanishing component lies along the normal vector Now using the function can be expressed as with the factor constraining the integral to lie within the seam This result can be interpreted as follows gives the probability density for being at a point on the seam this factor has units of lengthN gives the rate of transitions from one surface to the other at the point on the seam this factor has units of length times s The factor has units of length N so the entire expression has units of s as it should In this form the rate expression can be used by i sampling eg using Monte Carlo over as much of the seam as is energetically accessible using the initialstate spatial probability density as a weighting factor and ii forming the sampling average of the rate quantity computed for each accepted geometry There is another way to utilize the above rate expression If we think of a swarm of trajectories ie an ensemble representative of the experiment of interest and ask what is the rate at which trajectories pass through a narrow region of thickness at a point on the seam we could write where gives the probability density for a trajectory being at the point on the seam and lying within a distance along the direction normal to the seam The quantity is the component of the velocity along with which the system moves through the seam divided by the thickness This ratio gives the inverse of the time the system spends within the thin region or equivalently the frequency of passing through the thin strip of the seam at S The quantity is the volume element whose units cancel those of If we multiply this rate at which trajectories pass through by the probability that a surface jump will occur and integrate over the entire seam space we can express the rate at which the trajectories will undergo jumps If we divide this rate by the number of trajectories to produce the average rate per trajectory and compare this expression to the rate we derived earlier we see that they would be equivalent if the probability of a surface jump were given by The above expression for the probability of jumping from to is known as the LandauZener LZ formula The way it is used in most applications is as follows An ensemble of classical trajectories with initial coordinates and momenta selected to represent an experimental condition are run on the potential energy surface Whenever any trajectory passes very close to an intersection seam between and another surface the seam geometry nearest to is determined and the gradient of the energy difference is evaluated at In addition the component of the velocity along the direction of this gradient is computed The electronic coupling matrix elements between the two states are evaluated at S and the above formula is used to estimate the probability of a surface jump In most applications of LZ theory the electronic states in the region of a crossing seam are taken to be diabatic states because then the coupling matrix elements can be taken from the splitting between the two adiabatic states that undergo an avoided crossing near rather than by evaluating nonadiabatic coupling matrix elements between adiabatic BO states In summary the LZ expression for the probability of a surface jump should be viewed as an approximate version of the algorithm provided by the fewestswitches surface hopping approach discussed earlier Before closing this Section it is useful to point out how this formula applies to two distinct cases If as suggested in Figure b a molecule is prepared eg by photon absorption in an excited electronic state the upper blue curve that undergoes a crossing with a dissociative electronic state the green curve one may wish to estimate the rate of the process called predissociation in which the excited molecule jumps to the dissociative surface and falls apart This rate is often computed by multiplying the frequency at which the excited molecule passes through the curve crossing by the LZ estimate of the surface jumping probability P with computed as discussed above and usually being equal to the vibrational frequency of the bond whose stretching generates the curve crossing igure b Qualitative depiction of predissociation that can occur from an excited blue surface onto a dissociative green surface Alternatively one may be interested in determining the probability that the fragment species atoms in Figure b collide on the green curve and undergo a transition to the upper blue curve as a result of this collision For example prompt fluorescence from this upper blue curve might be the experimental signature one wishes to simulate In this case the outcome ie generation of the molecule in the upper blue curves electronic state can occur in either of two ways a The system collides on the green curve and undergoes a surface jump at the crossing thus ending up on the blue surface from which it promptly fluoresces this process has a probability computed using the LZ formula b The system collides on the green curve and does not jump to the blue curve at the crossing but remains on the green curve this has probability until it reaches the turning point After reflecting off the turning point the system still on the green curve jumps to the blue curve this has probability when it again reaches the crossing after which prompt fluorescence occurs The overall probability for this path is So the total yield of fluorescence would be related to the quantity The point of these two examples is that the LZ formula gives an estimate of the jump probability for a given crossing event one still needs to think about how various crossing events relate to the particular experiment at hand Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Theoretical Treatment of Electronic Structure Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Atomic UnitsContributors and Attributions In Chapter I introduced you to the strategies that theory uses to interpret experimental data relating to such matters and how and why theory can also be used to simulate the behavior of molecules In carrying out simulations the BornOppenheimer electronic energy as a function of the coordinates of the atoms in the molecule plays a central role It is on this landscape that one searches for stable isomers and transition states and it is the second derivative Hessian matrix of this function that provides the harmonic vibrational frequencies of such isomers In the present Chapter I want to provide you with an introduction to the tools that we use to solve the electronic Schrdinger equation to generate and the electronic wave function In essence this treatment will focus on orbitals of atoms and molecules and how we obtain and interpret them For an atom one can approximate the orbitals by using the solutions of the hydrogenic Schrdinger equation discussed in Part of this text Although such functions are not proper solutions to the actual electron Schrdinger equation believe it or not no one has ever solved exactly any such equation for of any atom they can be used as perturbation or variational startingpoint approximations when one may be satisfied with qualitatively accurate answers In particular the solutions of this oneelectron hydrogenic problem form the qualitative basis for much of atomic and molecular orbital theory As discussed in detail in Part these orbitals are labeled by and quantum numbers for the bound states and by and quantum numbers and the energy for the continuum states Much as the particleinabox orbitals are used to qualitatively describe electrons in conjugated polyenes or electronic bands in solids these socalled hydrogenlike orbitals provide qualitative descriptions of orbitals of atoms with more than a single electron By introducing the concept of screening as a way to represent the repulsive interactions among the electrons of an atom an effective nuclear charge can be used in place of in the hydrogenic and formulas to generate approximate atomic orbitals to be filled by electrons in a manyelectron atom For example in the crudest approximation of a carbon atom the two electrons experience the full nuclear attraction so for them whereas the and electrons are screened by the two electrons so for them Within this approximation one then occupies two orbitals with two orbitals with and two orbitals with in forming the full sixelectron product wave function of the lowestenergy state of carbon However such approximate orbitals are not sufficiently accurate to be of use in quantitative simulations of atomic and molecular structure In particular their energies do not properly follow the trends in atomic orbital AO energies that are taught in introductory chemistry classes and that are shown pictorially in Figure Figure Energies of Atomic Orbitals as Functions of Nuclear Charge for Neutral Atoms For example the relative energies of the and orbitals are not adequately described in a model that treats electron repulsion effects in terms of a simple screening factor So now it is time to examine how we can move beyond the screening model and take the electron repulsion effects which cause the interelectronic couplings that render the Schrdinger equation insoluble into account in a more reliable manner Atomic Units The electronic Hamiltonian that appears throughout this text is commonly expressed in the literature and in other texts in socalled atomic units aus In that form it is written as follows Atomic units are introduced to remove all of the h e and me factors from the Schrdinger equation To effect the unit transformation that results in the Hamiltonian appearing as above one notes that the kinetic energy operator scales as whereas the Coulomb potentials scale as and as So if each of the Cartesian coordinates of the electrons and nuclei were expressed as a unit of length multiplied by a dimensionless length factor the kinetic energy operator would involve terms of the form and the Coulomb potentials would appear as and with the and factors now referring to the dimensionless coordinates A factor of which has units of energy since a_ has units of length can then be removed from the Coulomb and kinetic energies after which the kinetic energy terms appear as and the potential energies appear as and Then choosing changes the kinetic energy terms into as a result the entire electronic Hamiltonian takes the form given above in which no me or factors appear The value of the socalled Bohr radius turns out to be  and the socalled Hartree energy unit which factors out of He is eV or kcalmol Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis The Principle of Microscopic Reversibility Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers The equilibrium constant expression is an important and fundamental relationship that relates the concentrations of reactants and products at equilibrium We deduce it above from a simple model for the concentration dependence of elementaryreaction rates In doing so we use the criterion that the time rate of change of any concentration must be zero at equilibrium Clearly this is a necessary condition if any concentration is changing with time the reaction is not at equilibrium However our deduction uses another assumption that we have not yet emphasized We assume that the forward and reverse rates of each elementary step are equal when the overall reaction is at equilibrium This is a special case of the principle of microscopic reversibility Definition Principle of Microscopic Reversibility Any molecular process and its reverse occur with equal rates at equilibrium The principle of microscopic reversibility applies to any molecular process it is inferred from the fact that such processes can be described by their equations of motion if the initial state of the constituent particles can be specified The equations of motion can be either classical mechanical or quantum mechanical We consider the implications of the principle for molecular processes that constitute elementary reactions However the principle also applies to equilibria in other molecular processes notably the absorption and emission of radiation When we apply it to elementary reactions we see that the principle of microscopic reversibility provides a necessary and sufficient condition for equilibrium from a reactionmechanism perspective The principle also imposes several significant conditions on the sequences of elementary processes that constitute a mechanism and on their relative rates In the previous section we see that microscopic reversibility provides a sufficient basis for deducing the relationship relating reactant and product concentrations at equilibriumthe equilibrium constant expressionfrom our rate equations for elementary reactions We now want to see that the principle of microscopic reversibility is indeed necessary That is setting for all species involved in the reaction is not in itself sufficient to assure that the system is at equilibrium Figure Cyclic equilibrium We consider the triangular network of elementary reactions shown in Figure This network gives rise to the following reactionrate equations At equilibrium each of these equations must equal zero Since we have three equations in three unknowns it might at first appear that we can solve for the three unknowns and We can see however either from the equations themselves or by considering the physical situation that they represent that only two of these equations are independent That is we have While we cannot solve for and independently we can solve for their ratios which are Since we deduce these equations from the condition that all the time derivatives are zero it might seem that they should represent the criteria for the system of reactions to be at equilibrium Purely as a name for easy reference let us call these equations the cyclic equilibrium set When we consider the reactions one at a time we deduce the following equilibrium relationships For easy reference let us call these equations the oneatatime set Now it cannot be true that both sets of relationships specify a sufficient condition for the system to be at equilibrium To see this let us first suppose that the principle of microscopic reversibility is a sufficient condition for equilibrium Then the oneatatime set of equations must be sufficient to uniquely specify the position of equilibrium It is easy to show that a set of rate constants that satisfies the oneatatime set also satisfies the cyclic set Therefore if microscopic reversibility is a sufficient condition for equilibrium the cyclic network rate equations are necessarily equal to zero at equilibrium In short if we assume that microscopic reversibility is a sufficient condition for equilibrium we encounter no inconsistencies because the cyclic set of equations is satisfied by the same equilibriumconcentration ratios On the other hand if we suppose that setting for all species is a sufficient condition for equilibrium then the cyclic set of equations must be sufficient to uniquely specify the position of equilibrium Let us consider a particular set of rate constants and This set of rate constants satisfies the cyclic set of equations and requires that each of the equilibriumconcentration ratios be equal to In this case the oneatatime set of equations implied by microscopic reversibility cannot be satisfied We have and Therefore That is if we assume that setting for all species is a sufficient condition for equilibrium we must conclude that the principle of microscopic reversibility is false Using the contrapositive If the principle of microscopic reversibility is true it is false that setting for all species is a sufficient condition for equilibrium Figure Potential energy versus reaction coordinate Setting the derivatives for the reaction network equal to zero is not sufficient to assure that the system is at equilibrium It is merely necessary To assure that the network is at equilibrium we must apply the principle of microscopic reversibility and require that each elementary process in the network be at equilibrium The principle of microscopic reversibility requires that any elementary process occur via the same sequence of transitory molecular structures in both the forward and reverse directions Consequently if a sequence of elementary steps is a mechanism for a forward reaction the same sequence of stepstraversed backwardsmust be a mechanism for the reverse reaction The principle does not exclude the possibility that a given reaction can occur simultaneously by two different mechanisms However it does mean that a given reaction cannot have one mechanism in the forward direction and a second different mechanism in the reverse direction In describing reaction mechanisms we assume that the energy of the reacting molecules depends on their progress along the path that they follow during the course of the reaction We call this path the reaction coordinate We suppose that we can plot the energy of the system as a function of the systems position on the path or displacement along the reaction coordinate In the context of such a graph the principle of microscopic reversibility is essentially the observation that the path is the same irrespective of the direction in which it is traversed Two such paths are sketched in Figure In this sketch and are the activation energies for the two forward reactions and are the activation energies for the reverse reactions The Probabilitydensity Function for Gas Velocities in One Dimension Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers In Section we find a differential equation in the function Unlike the velocity which takes values from zero to infinity the component takes values from minus infinity to plus infinity The probability density at an infinite velocity in either direction is necessarily zero Therefore we cannot evaluate the integral of from to an arbitrary velocity However we know from Maxwells assumption that the probability density for must be independent of whether the molecule is traveling in the direction of the positive axis or the negative axis That is must be an even function the probability density function must be symmetric around Hence we can express relative to its fixed value at We integrate from to as goes from zero to an arbitrary velocity to find or The value of must be such as to make the integral of over all possible values of equal to unity That is we must have where we use the definite integral See Appendix D It follows that The onedimensional probabilitydensity function becomes Note that this is the normal distribution with and So is the variance of the normal onedimensional probabilitydensity function As noted above in Section we find that The Probability Density Function for the Relative Velocity Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers From our development of the MaxwellBoltzmann probability density functions we can express the probability that the velocity components of particle lie in the intervals to to to while those of particle simultaneously lie in the intervals to to to as We want to express this probability using the relative velocity coordinates Since the velocity of the center of mass and the relative velocity are independent we might expect that the Jacobian of this transformation is just the product of the two individual Jacobians This turns out to be the case The Jacobian of the transformation is a sixbysix determinate It is messy but straightforward to show that it is equal to the product of two threebythree determinants and that the absolute value of this product is one Therefore we have We transform the probability density by substituting into the onedimensional probability density functions That is where the last expression specifies the probability density as a function of the relative velocity coordinates Next we make a further transformation of variables We convert the velocity of the center of mass and the relative velocity from Cartesian coordinates to spherical coordinates referred to the axis system The motion of the center of mass is most readily visualized in the original frame The relative motion is most readily visualized in the ParticleOne Centered Frame In the motion of particle is specified by and The motion of the center of mass is specified by and Since it is the relative motion that is actually of interest it might seem that we should refer the spherical coordinates to the frame This is an unnecessary distinction because all three coordinate frames are parallel to one another and and are the same vectors in all three frames Letting the Cartesian velocity components are expressed in spherical coordinates by The angles and are defined in the usual manner relative to the axis system The Jacobian of this transformation is a sixbysix determinate which can again be converted to the product of two threebythree determinates We find The probability that the components of the velocity of the center of mass lie in the intervals to to to while the components of the relative velocity lie in the intervals to to to becomes We are interested in the probability increment for the relative velocityrelative velocityprobability density function irrespective of the velocity of the center of mass To sum the contributions for all possible motions of the center of mass we integrate this expression over the possible ranges of and We have This is the same as the probability increment for a singleparticle velocityalbeit with replacing replacing replacing and replacing As in the singleparticle case we can obtain the probability increment for the scalar component of the relative velocity by integrating over all possible values of and We find In we find the most probable velocity the mean velocity and the rootmeansquare velocity for a gas whose particles have mass By identical arguments we obtain the most probable relative velocity the mean relative velocity and the rootmeansquare relative velocity To do so we can simply substitute for in the earlier results In particular the mean relative velocity is If particles and have the same mass the reduced mass becomes In this case we have We can arrive at this same conclusion by considering the relative motion of two particles that represents the average case As illustrated in Figure this occurs when the two particles have the same speed but are moving at degree angles to one another In this situation the length of the resultant vectorthe relative speed is just The Rate of Collisions between Unlike Gas Molecules Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers We define the collision frequencycollision frequency as the number of collision per unit time between a single molecule of type and any of the molecules of type present in the same container We find If there are molecules of type present in a unit volume of the gas the total number of collisions between type molecules and type molecules is times greater For clarity let us refer to the total number of such collisions per unit volume and per unit time as the collision rate We have The Reversible Work is the Minimum Work at Constant T Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers The Clausius inequality leads to an important constraint on the work that can be done on a system during a spontaneous process in which the temperature of the surroundings is constant As we discuss in Section the initial state of the spontaneous process cannot be a true equilibrium state In our present considerations we assume that the initial values of all the state functions of the spontaneously changing system are the same as those of a true equilibrium system Likewise we assume that the final state of the spontaneously changing system is either a true equilibrium state or a state whose thermodynamic functions have the same values as those of a true equilibrium system From the first law applied to any spontaneous process in a closed system we have and Since the temperature of the system and its surroundings are equal and constant for the reversible process we have So long as the temperature of the surroundings is constant we have for the spontaneous process It follows that so that constant A given isothermal process does the minimum possible amount of work on the system when it is carried out reversibly In Section we find this result for the special case in which the only work is the exchange of pressurevolume work between an ideal gas and its surroundings Equivalently a given isothermal process produces the maximum amount of work in the surroundings when it is carried out reversibly Since and we have or Thermodynamic Criteria for Change Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers When the state of an isolated system can change we say that the system is capable of spontaneous change When an isolated system is incapable of spontaneous change we say that it is at equilibrium Ultimately this statement defines what we mean by primitive equilibrium From our statement of the second law of thermodynamics we have criteria for spontaneous change and for equilibrium in any macroscopic system An isolated system can undergo any change that results in an increase in the entropy of the system The converse is also true an isolated system whose entropy can increase can undergo change Any such change is said to be spontaneous If an isolated system cannot change in such a way that its entropy increases the system cannot change at all and is said to be at equilibrium A system that is not isolated can undergo any change that results in an increase in the entropy of the universe and conversely Such changes are also said to be spontaneous If a system that is not isolated undergoes a change but the entropy of the universe remains constant the change is not spontaneous The entropy changes for the system and the surroundings are equal in magnitude and opposite in sign The change is said to be reversible Although the first statement applies to isolated systems and the second applies to systems that are not isolated we usually consider that both are statements of the same criterion because the second statement follows from the first when we view the universe as an isolated system We can restate these criteria for spontaneous change and equilibrium using the compact notation that we introduce in Section From our definitions any change that occurs in an isolated system must be spontaneous From our statement of the second law the entropy of the universe must increase in any such process To indicate this we write The surroundings must be unaffected by any change in an isolated system hence none of the surroundings state functions can change Thus and since we have For a spontaneous change in a system that is not isolated can be greater or less than zero However and must satisfy In a system that is not isolated reversible change may be possible A system that undergoes a reversible change is ator is arbitrarily close toone of its equilibrium states during every part of the process For a reversible change it is always true that so that Our criteria for change are admirably terse but to appreciate them we need to understand precisely what is meant by entropy To use the criteria to make predictions about a particular system we need to find the entropy changes that occur when the system changes To use these ideas to understand chemistry we need to relate these statements about macroscopic systems to the properties of the molecules that comprise the system Since an isolated system does not interact with its surroundings in any way no change in an isolated system can cause a change in its surroundings If an isolated system is at equilibrium no change is possible and hence there is no system change for which the entropy of the universe can increase Evidently the entropy of the universe is at a maximum when the system is at equilibrium Typically we are interested in what happens when the interaction between the system and surroundings serves to impose conditions on the final state of a system A common example of such conditions is that the surroundings maintain the system at a constant pressure while providing a constanttemperature heat reservoir with which the system can exchange heat In such cases the system is not isolated It turns out that we can use the entropy criterion to develop supplemental criteria based on other thermodynamic functions These supplemental criteria provide the most straightforward means to discuss equilibria and spontaneous change in systems that are not isolated Which thermodynamic function is most convenient depends upon the conditions that we impose on the system Thermodynamics of Mixing Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Enthalpy of MixingEntropy of MixingFree Energy of MixingContributors and Attributions A natural place to begin a discussion of mixtures is to consider a mixture of two gases Consider samples of the two gases filling two partitions in a single container both at the same pressure temperature having volumes and After being allowed to mix isothermally the partial pressures of the two gases will drop by a factor of although the total pressure will still be the original value and the volumes occupied by the two gases will double Enthalpy of Mixing Assuming ideal behavior so that interactions between individual gas molecules are unimportant it is fairly easy to calculate Delta H for each gas as it is simply an isothermal expansion The total enthalpy of mixing is then given by And since the enthalpy change for an isothermal expansion of an ideal gas is zero is a straightforward conclusion This will be the criterion for an ideal mixture In general real mixtures will deviate from this limiting ideal behavior due to interactions between molecules and other concerns Also many substances undergo chemical changes when they mix with other substances But for now we will limit ourselves to discussing mixtures in which no chemical reactions take place Entropy of Mixing The entropy change induced due to isothermal mixing assuming again no interactions between the molecules in the gas mixture is again going to be the sum of the contributions from isothermal expansions of the two gases Fortunately entropy changes for isothermal expansions are easy to calculate for ideal gases If we use the initial volumes VA and VB for the initial volumes of gases A and B the total volume after mixing is and the total entropy change is Noting that the term where is the mole fraction of after mixing and that can be expresses as the product of and the total number of moles the expression can be rewritten Delta S_mix n_tot R left chi_A ln chi_A chi_B ln chi_B right It should be noted that because the mole fraction is always between and that As such the entropy change for a system undergoing isothermal mixing is always positive as one might expect since mixing will make the system less ordered The entropy change for a system undergoing isothermal mixing is always positive Free Energy of Mixing Calculating should be no more difficult than calculating For isothermal mixing and constant total pressure and so it follows from above that for the isothermal mixing of two gases at constant total pressure Delta G_mix n_tot RT left chi_A ln chi_A chi_B ln chi_B right The relationships describing the isothermal mixing of two ideal gases and is summarized in the graph below Again because then implying that mixing is always a spontaneous process for an ideal solution This is true for gases But for many combinations of liquids or solids the strong intermolecular forces may make mixing unfavorable for example in the case of vegetable oil and water Also these interactions may make the volume nonadditive as well as in the case of ethanol and water Mixing is always a spontaneous process for an ideal solution Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Thermodynamic Systems and Variables Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers We characterize the system by specifying the values of enough variables so that the system can be exactly replicated By exactly replicated we mean of course that we are not able to distinguish the system from its replicate by any experimental measurement Any variable that can be used to characterize the system in this way is called a variable of state a state variable or a state function We can say the same thing in slightly different words by saying that the state of a system is completely specified when the values of all of its state variables are specified If we initially have a system in some equilibrium state and change one or more of the variables that characterize it the system will eventually reach a new equilibrium state in which some state variables will have values different from those that characterized the original state If we want to return the system to its original state we must arrange matters so that the value of every state variable is the same as it was originally The variables that are associated with a chemical system include pressure volume temperature and the number of moles of each substance present All of these variables can be measured directly that is every equilibrium state of a system is associated with a specific value of each of these variables and this value can be determined without reference to any other state of the system Energy and entropy are also variables that are associated with a thermodynamic system We can only measure changes in energy and entropy that is we can only measure energy and entropy for a process in which a system passes from one state to another Other important thermodynamic variables are defined as functions of pressure volume temperature energy and entropy These include enthalpy the Gibbs free energy the Helmholtz free energy chemical activity and the chemical potential Our goals in developing the subject of chemical thermodynamics are to define each of these state functions learn how to measure each of them and provide a theory that relates the change that occurs in any one of them to the changes that occur in the others when a chemical system changes from one state to another Any interaction through which a chemical system can exchange work with its surroundings can affect its behavior Workproducing forces can involve many phenomena including gravitational field electric field and magnetic fields surface properties and sound pressure waves In Chapter we discuss the work done when an electric current passes through an electrochemical cell Otherwise this book focuses on pressurevolume workpressurevolume work and gives only passing attention to the job of incorporating other forms of work into the general theory We include pressurevolume work because it occurs whenever the volume of a system changes A thermodynamic theory that did not include volume as a variable would be of limited utility Thermodynamic variables can be sorted into two classes in another way Consider the pressure temperature and volume of an equilibrium system We can imagine inserting a barrier that divides this original system into two subsystemswithout changing anything else Each of the subsystems then has the temperature and pressure of the original system however the volume of each subsystem is different from the volume of the original system We say that temperature and pressure are intensive variables by which we mean that the temperature or pressure of an equilibrium system is independent of the size of the system and the same at any location within the system Intensive variables stand in contrast to extensive variables The magnitude of an extensive variable is directly proportional to the size of the system Thus volume is an extensive variable Energy is an extensive variable We shall see that entropy enthalpy the Helmholtz free energy and the Gibbs free energy are extensive variables also For any extensive variable we can create a companion intensive variable by dividing by the size of the system For example we can convert the mass of a homogeneous system into a companion variable the density by dividing by the systems volume We will discover that it is useful to define certain partial molar quantities which have units like energy per mole Partial molar quantities are intensive variables We will find a partial molar quantity that is particularly important in describing chemical equilibrium It is called the chemical potential and since it is a partial molar quantity the chemical potentialchemical potential is an intensive thermodynamic variable We think of a system as a specific collection of matter containing specified phases Our goal is to develop mathematical models equations that relate a systems state functions to one another A system can be at equilibrium under a great many different circumstances We say that the system can have many equilibrium positions A complete description of all of these equilibrium positions requires models that can specify how much of each of the substances that make up the system is present in each phase However if a system is at equilibrium a halfsize copy of it is also at equilibrium whether a system is at equilibrium can be specified without specifying the sizes of the phases that make it up This means that we can characterize the equilibrium states of any system that contains specified substances and phases by specifying the values of the systems intensive variables In general not all of these intensive variables will be independent The number of intensive variables that are independent is called the number of degrees of freedom available to the system This is also the number of intensive variables that can change independently while a given system remains at equilibrium To completely define a particular system we must specify the size and composition of each phase To do so we must specify the values of some number of extensive variables These extensive variables can change while all of the intensive variables remain constant and the system remains at equilibrium In the next section we review the phase equilibria of water A system comprised of liquid and gaseous water in phase equilibrium illustrates these points Specifying either the pressure or temperature specifies the equilibrium state to within the sizes of the two phases For a complete description we must specify the number of moles of water in each phase By adding or removing heat while maintaining the original pressure and temperature we can change the distribution of the water between the two phases In J Willard Gibbs developed an equation called Gibbs phase rule from which we can calculate the number of degrees of freedom available to any particular system We introduce Gibbs phase rule in Section The perspective and analysis that underlie Gibbs phase rule have a significance that transcends use of the rule to find the number of degrees of freedom available to a system In essence the conditions assumed in deriving Gibbs phase rule define what we mean by equilibrium in chemical systems From experience we are usually confident that we know when a system is at equilibrium and when it is not One of our goals is to relate thermodynamic functions to our experiencebased ideas about what equilibrium is and is not To do so we need to introduce the idea of a reversible process in which the system undergoes a reversible change We will see that the states that are accessible to a system that is at equilibrium in terms of Gibbs phase rule are identically the states that the system can be in while undergoing a reversible change A principal goal of the remainder of this chapter is to clarify this equivalence between the range of states accessible to the system at equilibrium and the possible paths along which the system can undergo reversible change The thermodynamic theory that we develop predicts quantitatively how a systems equilibrium position changes in response to a change that we impose on one or more of its state functions The principle of Le Chatelier makes qualitative predictions about such changes We introduce the principle of Le Chatelier and its applications later in this chapter In Chapter we revisit this principle to understand it as a restatement in qualitative terms of the thermodynamic criteria for equilibrium The Role of the Ideal Gas Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers The concept of ideal gas behavior plays a pivotal role in the development of science and particularly in the development of thermodynamics As we shall emphasize intermolecular forces do not influence the behavior of an ideal gas Ideal gas molecules are neither attracted to one another nor repelled by one another For this reason the properties of an ideal gas are particularly simple Because ideal gas behavior is so important we begin by studying ideal gases from both an experimental and a theoretical perspective In Chapter we review the experimental observations that we can make on gases and the idealizations that we introduce to extrapolate the behavior of ideal gases from the observations we make on real gases We also develop Boyles law from a very simple model for the interactions between pointmass gas molecules and the walls of their container In Chapter we develop a detailed model for the behavior of an ideal gas The physical model is the one we use in Chapter but the mathematical treatment is much more sophisticated For this treatment we need to develop a number of ideas about probability distribution functions and statistics Chapter introduces these topics all of which again play important roles when we turn to the development of statistical thermodynamics in Chapter The Schrdinger Equation and Its Components Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Operators Wave functions The Schrdinger Equation The TimeDependent Equation The TimeIndependent EquationContributors and Attributions It has been well established that electrons moving in atoms and molecules do not obey the classical Newton equations of motion People long ago tried to treat electronic motion classically and found that features observed clearly in experimental measurements simply were not consistent with such a treatment Attempts were made to supplement the classical equations with conditions that could be used to rationalize such observations For example early workers required that the angular momentum be allowed to assume only integer multiples of which is often abbreviated as which can be shown to be equivalent to the Bohr postulate However until scientists realized that a new set of laws those of quantum mechanics applied to light microscopic particles a wide gulf existed between laboratory observations of moleculelevel phenomena and the equations used to describe such behavior Quantum mechanics is cast in a language that is not familiar to most students of chemistry who are examining the subject for the first time Its mathematical content and how it relates to experimental measurements both require a great deal of effort to master With these thoughts in mind i have organized this material in a manner that first provides a brief introduction to the two primary constructs of quantum mechanics operators and wave functions that obey a Schrdinger equation Next I demonstrate the application of these constructs to several chemically relevant model problems By learning the solutions of the Schrdinger equation for a few model systems the student can better appreciate the treatment of the fundamental postulates of quantum mechanics as well as their relation to experimental measurement for which the wave functions of the known model problems offer important interpretations Operators Each physically measurable quantity has a corresponding operator The eigenvalues of the operator tell the only values of the corresponding physical property that can be observed in an experimental probe of that property Some operators have a continuum of eigenvalues but others have only discrete quantized eigenvalues Any experimentally measurable physical quantity eg energy dipole moment orbital angular momentum spin angular momentum linear momentum kinetic energy has a classical mechanical expression in terms of the Cartesian positions and momenta of the particles that comprise the system of interest Each such classical expression is assigned a corresponding quantum mechanical operator formed by replacing the in the classical form by the differential operator and leaving the coordinates that appear in untouched If one is working with a classical quantity expressed in terms of curvilinear coordinates it is important that this quantity first be rewritten in Cartesian coordinates The replacement of the Cartesian momenta by can then be made and the resultant expression can be transformed back to the curvilinear coordinates if desired Example For example the classical kinetic energy of particles with masses moving in a potential field containing both quadratic and linear coordinatedependence can be written as The quantum mechanical operator associated with this is Such an operator would occur when for example one describes the sum of the kinetic energies of a collection of particles the first term in Eq plus the sum of Hookes Law parabolic potentials the second term in Eq and the interactions of the particles with an externally applied field the last term Eq whose potential energy varies linearly as the particles move away from their equilibrium positions Let us try more examples The sum of the components of angular momenta recall that vector angular momentum is defined as of a collection of particles has the following classical expression Fsum_jN x_jp_yj y_jp_xjtag and the corresponding operator is If one transforms these Cartesian coordinates and derivatives into polar coordinates the above expression reduces to where is the azimuthal angle of the particle The component of the dipole moment for a collection of particles has a classical form of for which the quantum operator is where is the charge on the particle Notice that in this case classical and quantum forms are identical because contains no momentum operators Remember the mapping from to is straightforward only in terms of Cartesian coordinates To map a classical function given in terms of curvilinear coordinates even if they are orthogonal into its quantum operator is not at all straightforward The mapping can always be done in terms of Cartesian coordinates after which a transformation of the resulting coordinates and differential operators to a curvilinear system can be performed The relationship of these quantum mechanical operators to experimental measurement lies in the eigenvalues of the quantum operators Each such operator has a corresponding eigenvalue equation in which the are called eigenfunctions and the scalar numbers are called eigenvalues All such eigenvalue equations are posed in terms of a given operator in this case and those functions that acts on to produce the function back again but multiplied by a constant the eigenvalue Because the operator usually contains differential operators coming from the momentum these equations are differential equations Their solutions depend on the coordinates that contains as differential operators An example will help clarify these points The differential operator acts on what functions of to generate the same function back again but multiplied by a constant The answer is functions of the form since So we say that is an eigenfunction of and is the corresponding eigenvalue As I will discuss in more detail shortly the eigenvalues of the operator tell us the only values of the physical property corresponding to the operator that can be observed in a laboratory measurement Some operators that we encounter possess eigenvalues that are discrete or quantized For such properties laboratory measurement will result in only those discrete values Other operators have eigenvalues that can take on a continuous range of values for these properties laboratory measurement can give any value in this continuous range An important characteristic of the quantum mechanical operators formed as discussed above for any measurable property is the fact that they are Hermitian An operator that acts on coordinates denoted is Hermitian if int phi_I textbfF phi_J dq int textbfF phi_I phi_J dq tag or equivalently for any functions and The operator corresponding to any power of the coordinate itself is easy to show obeys this identity but what about the corresponding momentum operator Lets take the left hand side of the above identity for and rewrite it using integration by parts as follows If the functions and are assumed to vanish at the righthand side of this equation can be rewritten as So ihbar dfracq is indeed a Hermitian operator Moreover using the fact that and are Hermitian one can show that any operator formed using the rules described above is also Hermitian One thing you need to be aware of concerning the eigenfunctions of any Hermitian operator is that each pair of eigenfunctions and belonging to different eigenvalues display a property termed orthonormality This property means that not only may and each normalized so their probability densities integrate to unity int psi_n dx int psi_n dxtag but they are also orthogonal to each other where the complex conjugate of the first function appears only when the solutions contain imaginary components eg the functions which eigenfunctions of the component of angular momentum The orthogonality condition can be viewed as similar to the condition of two vectors and being perpendicular in which case their scalar sometimes called dot product vanishes textbfv_ cdot textbfv_ I want you to keep this property in mind because you will soon see that it is a characteristic of all eigenfunctions of any Hermitian operator It is common to write the integrals displaying the normalization and orthogonality conditions in the following socalled Dirac notation and where the and symbols represent and respectively and putting the two together in the construct implies the integration over the variables that y depends upon The Hermitian character of an operator means that this operator forms a Hermitian matrix when placed between pairs of functions and the coordinates are integrated over For example the matrix representation of an operator when acting on a set of functions denoted is For all of the operators formed following the rules stated earlier one finds that these matrices have the following property which makes the matrices what we call Hermitian If the functions upon which F acts and F itself have no imaginary parts ie are real then the matrices turn out to be symmetric F_IJ F_JI tag The importance of the Hermiticity or symmetry of these matrices lies in the fact that it can be shown that such matrices have all real ie not complex eigenvalues and have eigenvectors that are orthogonal or in the case of degenerate eigenvalues can be chosen to be orthogonal Lets see how these conditions follow from the Hermiticity property If the operator has two eigenfunctions and having eigenvalues and respectively then Multiplying this equation on the left by and integrating over the coordinates denoted that acts on gives The Hermitian nature of allows us to also write which because gives If is not equal to the only way the leftmost and rightmost terms in this equality can be equal is if which means the two eigenfunctions are orthogonal If the two eigenfunctions and have equal eigenvalues the above derivation can still be used to show that and are orthogonal to the other eigenfunctions etc of that have different eigenvalues For the eigenfunctions and that are degenerate ie have equal eigenvalues we cannot show that they are orthogonal because they need not be so However because any linear combination of these two functions is also an eigenfunction of having the same eigenvalue we can always choose a combination that makes and orthogonal to one another Finally for any given eigenfunction we have However the Hermitian character of F allows us to rewrite the left hand side of this equation as int psi_textbfF psi_ dq int textbfFpsi_psi_ dq lambda_ int psi_psi_ dq tag These two equations can only remain valid if which means that is a real number ie has no imaginary part So all quantum mechanical operators have real eigenvalues this is good since these eigenvalues are what can be measured in any experimental observation of that property and can be assumed to have orthogonal eigenfunctions It is important to keep these facts in mind because we make use of them many times throughout this text Wave functions The eigenfunctions of a quantum mechanical operator depend on the coordinates upon which the operator acts The particular operator that corresponds to the total energy of the system is called the Hamiltonian operator The eigenfunctions of this particular operator are called wave functions A special case of an operator corresponding to a physically measurable quantity is the Hamiltonian operator that relates to the total energy of the system The energy eigenstates of the system are functions of the coordinates that depends on and of time t The function gives the probability density for observing the coordinates at the values at time For a manyparticle system such as the molecule the wave function depends on many coordinates For it depends on the and or and coordinates of the ten electrons and the and or and coordinates of the oxygen nucleus and of the two protons a total of thirtynine coordinates appear in If one is interested in what the probability distribution is for finding the corresponding momenta at time the wave function has to first be written as a combination of the eigenfunctions of the momentum operators Expressing in this manner is possible because the momentum operator is Hermitian and it can be shown that the eigenfunctions of any Hermitian operator form a complete set of functions The momentum operators eigenfunctions are and they obey These eigenfunctions can also be shown to be orthonormal Expanding in terms of these normalized momentum eigenfunctions gives We can find the expansion coefficients by multiplying the above equation by the complex conjugate of another labeled momentum eigenfunction and integrating over The quantities then give the probability of finding momentum at time In classical mechanics the coordinates and their corresponding momenta are functions of time The state of the system is then described by specifying and In quantum mechanics the concept that qj is known as a function of time is replaced by the concept of the probability density for finding coordinate qj at a particular value at a particular time or the probability density for finding momentum at time The Hamiltonian eigenstates are especially important in chemistry because many of the tools that chemists use to study molecules probe the energy states of the molecule For example most spectroscopic methods are designed to determine which energy state electronic vibrational rotational nuclear sp_in etc a molecule is in However there are other experimental measurements that measure other properties eg the component of angular momentum or the total angular momentum As stated earlier if the state of some molecular system is characterized by a wave function Y that happens to be an eigenfunction of a quantum mechanical operator F one can immediately say something about what the outcome will be if the physical property F corresponding to the operator F is measured In particular since where is one of the eigenvalues of we know that the value will be observed if the property is measured while the molecule is described by the wave function In fact once a measurement of a physical quantity has been carried out and a particular eigenvalue has been observed the systems wave function becomes the eigenfunction that corresponds to that eigenvalue That is the act of making the measurement causes the systems wave function to become the eigenfunction of the property that was measured This is what is meant when one hears that the act of making a measurement can change the state of the system in quantum mechanics What happens if some other property G whose quantum mechanical operator is is measured in a case where we have already determined We know from what was said earlier that some eigenvalue mk of the operator G will be observed in the measurement But will the molecules wave function remain after G is measured the eigenfunction of or will the measurement of G cause Y to be altered in a way that makes the molecules state no longer an eigenfunction of It turns out that if the two operators F and G obey the condition then when the property G is measured the wave function will remain unchanged This property that the order of application of the two operators does not matter is called commutation that is we say the two operators commute if they obey this property Let us see how this property leads to the conclusion about Y remaining unchanged if the two operators commute In particular we apply the G operator to the above eigenvalue equation from which we concluded that Next we use the commutation to rewrite the lefthand side of this equation and use the fact that is a scalar number to thus obtain So now we see that itself is an eigenfunction of F having eigenvalue So unless there are more than one eigenfunction of F corresponding to the eigenvalue ie unless this eigenvalue is degenerate must itself be proportional to We write this proportionality conclusion as G chi_j mu_j chi_j tag which means that is also an eigenfunction of G This in turn means that measuring the property G while the system is described by the wave function does not change the wave function it remains If there are more than one function that are eigenfunctions of F having the same eigenvalue then the relation only allows us to conclude that is some combination of these degenerate functions Below I offer some examples that i hope will clarify what these rules mean and how the relate to laboratory measurements In summary when the operators corresponding to two physical properties commute once one measures one of the properties and thus causes the system to be an eigenfunction of that operator subsequent measurement of the second operator will if the eigenvalue of the first operator is not degenerate produce a unique eigenvalue of the second operator and will not change the system wave function If either of the two properties is subsequently measured even over and over again the wave function will remain unchanged and the value observed for the property being measured will remain the same as the original eigenvalue observed However if the two operators do not commute one simply cannot reach the above conclusions In such cases measurement of the property corresponding to the first operator will lead to one of the eigenvalues of that operator and cause the system wave function to become the corresponding eigenfunction However subsequent measurement of the second operator will produce an eigenvalue of that operator but the system wave function will be changed to become an eigenfunction of the second operator and thus no longer the eigenfunction of the first I think an example will help clarify this discussion Let us consider the following orbital angular momentum operators for particles or and It turns out that the operator can be shown to commute with any one of or but or do not commute with one another we will discuss these operators in considerably more detail in Chapter section for now please accept these statements Let us assume a measurement of is carried out and one obtains the value Thus far all one knows is that the system can be described by a wave function that is some combination of etc angular momentum functions having different values but all having but one does not know the amplitudes telling how much a given value contributes to One can express as such a linear combination because the Hermitian quantum mechanical operators formed as described above can be shown to possess complete sets of eigenfunctions this means that any function of the appropriate variables can be written as a linear combination of these eigenfunctions as done above If one subsequently carries out a measurement of the fact that and commute means that this second measurement will not alter the fact that contains only contributions with but it will result in observing only one specific value The probability of observing any particular value will be given by Once this measurement is realized the wave function will contain only terms having that specific value and For example if is found we know the wave function has and so we know it is a Fsymmetry function with but we dont know any more That is we dont know if it is an etc Ffunction What now happens if we make a measurement of when the system is in the state recall this is a value of the component of angular momentum Because and commute the measurement of will not alter the fact that contains only components However because and do not commute we can not assume that is still an eigenfunction of it will be a combination of eigenfunctions of having but having values between and with m now referring to the eigenvalue of no longer to When is measured the value will be found with probability after which the wave function will be the eigenfunction of and and no longer an eigenfunction of I understand that these rules of quantum mechanics can be confusing but I assure you they are based on laboratory observations about how atoms ions and molecules behave when subjected to statespecific measurements So I urge you to get used to the fact that quantum mechanics has rules and behaviors that may be new to you but need to be mastered by you The Schrdinger Equation This equation is an eigenvalue equation for the energy or Hamiltonian operator its eigenvalues provide the only allowed energy levels of the system The TimeDependent Equation If the Hamiltonian operator contains the time variable explicitly one must solve the timedependent Schrdinger equation Before moving deeper into understanding what quantum mechanics means it is useful to learn how the wave functions are found by applying the basic equation of quantum mechanics the Schrdinger equation to a few exactly soluble model problems Knowing the solutions to these easy yet chemically very relevant models will then facilitate learning more of the details about the structure of quantum mechanics The Schrdinger equation is a differential equation depending on time and on all of the spatial coordinates necessary to describe the system at hand thirtynine for the example cited above It is usually written where is the unknown wavefunction and is the operator corresponding to the total energy of the system This Hermitian operator is called the Hamiltonian and is formed as stated above by first writing down the classical mechanical expression for the total energy kinetic plus potential in Cartesian coordinates and momenta and then replacing all classical momenta by their quantum mechanical operators For the example used above the classical mechanical energy of all thirteen particles is where the indices and are used to label the ten electrons whose thirty Cartesian coordinates and thirty Cartesian momenta are and and and label the three nuclei whose charges are denoted and whose nine Cartesian coordinates and nine Cartesian momenta are and The electron and nuclear masses are denoted and respectively The corresponding Hamiltonian operator is H sum_i Big frachbarm_e fracpartialpartial q_i Big frac sum_jne i fracer_ij sum_asum_i fracZ_aer_ia sum_a Big frachbarm_a fracpartialpartial q_i Big frac sum_bne a fracZ_aZ_ber_ab tag where and denote the distances between electron pairs electrons and nuclei and nuclear pairs respectively Notice that is a second order differential operator in the space of the thirtynine Cartesian coordinates that describe the positions of the ten electrons and three nuclei It is a second order operator because the momenta appear in the kinetic energy as and and the quantum mechanical operator for each momentum is of first order The Schrdinger equation for the example at hand then reads leftsum_i Big frachbarm_e fracpartialpartial q_i Big frac sum_jne i fracer_ij sum_asum_i fracZ_aer_ia right Psi leftsum_a Big frachbarm_e fracpartialpartial q_a Big frac sum_bne a fracZ_aZ_ber_ab right Psi i hbar fracpartial Psipartial t tag The Hamiltonian in this case contains nowhere An example of a case where does contain occurs for example when the an oscillating electric field along the axis interacts with the electrons and nuclei and a term is added to the Hamiltonian Here and denote the coordinates of the nucleus and the electron respectively The TimeIndependent Equation If the Hamiltonian operator does not contain the time variable explicitly one can solve the timeindependent Schrdinger equation In cases where the classical energy and hence the quantum Hamiltonian do not contain terms that are explicitly time dependent eg interactions with time varying external electric or magnetic fields would add to the above classical energy expression time dependent terms the separations of variables techniques can be used to reduce the Schrdinger equation to a timeindependent equation In such cases is not explicitly time dependent so one can assume that is of the form nb this step is an example of the use of the separations of variables method to solve a differential equation Substituting this ansatz into the timedependent Schrdinger equation gives Psiq_J ihbar fracpartial Fpartial t Ft textbfHPsiq_J tag Dividing by then gives Since is only a function of time and is only a function of the spatial coordinates and because the left hand and right hand sides must be equal for all values of t and of both the left and right hand sides must equal a constant If this constant is called E the two equations that are embodied in this separated Schrdinger equation read as follows The first of these equations is called the timeindependent Schrdinger equation it is an eigenvalue equation in which one is asked to find functions that yield a constant multiple of themselves when acted on by the Hamiltonian operator Such functions are called eigenfunctions of and the corresponding constants are called eigenvalues of For example if were of the form then functions of the form would be eigenfunctions because frachbarI fracpartialpartial phi expi mphi fracmhbarI expi mphitag In this case is the eigenvalue In this example the Hamiltonian contains the square of an angular momentum operator recall earlier that we showed the component of angular momentum for a single particle is to equal When the Schrdinger equation can be separated to generate a timeindependent equation describing the spatial coordinate dependence of the wave function the eigenvalue must be returned to the equation determining to find the time dependent part of the wave function By solving once is known one obtains and the full wave function can be written as For the above example the time dependence is expressed by In such cases the spatial probability density does not depend upon time because the product reduces to unity In summary whenever the Hamiltonian does not depend on time explicitly one can solve the timeindependent Schrdinger equation first and then obtain the time dependence as once the energy is known In the case of molecular structure theory it is a quite daunting task even to approximately solve the full Schrdinger equation because it is a partial differential equation depending on all of the coordinates of the electrons and nuclei in the molecule For this reason there are various approximations that one usually implements when attempting to study molecular structure using quantum mechanics It should be noted that it is possible to prepare in the laboratory even when the Hamiltonian contains no explicit time dependence wave functions that are time dependent and that have timedependent spatial probability densities For example one can prepare a state of the Hydrogen atom that is a superposition of the and wave functions where the two eigenstates obey and When does not contain explicitly it is possible to then express in terms of as follows This function which is a superposition of and functions does indeed obey the full timedependent Schrdinger equation The probability of observing the system in the state if a measurement capable of making this determination were carried out is and the probability of finding it in the state is both of which are independent of time This does not mean that or the spatial probability density describes is timeindependent because the product contains cross terms that depend on time It is important to note that applying to such a superposition state in the manner shown above which then produces a superposition of states each of whose amplitudes carries its own time dependence only works when has no time dependence If were timedependent acting on would contain an additional factor involving as a result of which one would not have Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis The Second Law of Thermodynamics Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers The first law of thermodynamics is concerned with energy and its properties As we saw in Chapter the first law arose from the observation that the dissipation of mechanical work through friction creates heat In a synthesis that was partly definition and partly a generalization from experience it was proposed that mechanical energy and heat are manifestations of a common quantity energy Later by further definition and generalization the concept was expanded to include other forms of energy The energy concept evolved into the prescript that there exists a quantity state function that is conserved through any manner of change whatsoever The element of definition arises from the fact that we recognize new forms of energy whenever necessary in order to ensure that the conservation condition is satisfied The element of experience arises from the fact that this prescript has resulted in a body of theory and a body of experimental results that are mutually compatible When we define and measure energy correctly we do indeed find that energy is a state function and that it is conserved The theory of relativity introduced a significant expansion of the energy concept For chemical processes we can view mass and energy conservation as independent postulates For processes in which fundamental particles undergo changes and for systems moving at velocities near that of light we cannot Relativity asserts that the energy of a particle is given by Einsteins equation In this equation is the particle energy is its momentum is its rest mass and is the speed of light In transformations of fundamental particles in which the sum of the rest masses of the product particles is less than that of the reactant particles conservation of energy requires that the sum of the momenta of the product particles exceed that of the reactant particles The momentum increase means that the product particles have high velocities corresponding to a high temperature for the product system The most famous expression of this result is that meaning that we can associate this quantity of energy with the mass of a stationary particle for which The situation with respect to the second law is similar From experience with devices that convert heat into work the idea evolved that such devices must have particular properties Consideration of these properties led to the discovery of a new state function which we call entropy and to which we customarily assign the symbol We introduce the laws of thermodynamics in We repeat our statement of the second law here The Second Law of Thermodynamics In a reversible process in which a closed system accepts an increment of heat from its surroundings the change in the entropy of the system is Entropy is a state function For any reversible process and conversely For any spontaneous process and conversely If a spontaneous process takes a system from state A to state B state B may or may not be an equilibrium state State A cannot be an equilibrium state Since we cannot use the defining equation to find the entropy change for a spontaneous process we must use some other method if we are to estimate the value of the entropy change This means that we must have either an empirical mathematical model from which we can estimate the entropy of a nonequilibrium state or an equilibrium system that is a good model for the initial state of the spontaneous process We can usually find an equilibrium system that is a good model for the initial state of a spontaneous process Typically some alteration of an equilibrium system makes the spontaneous change possible The changeenabled state is the initial state for a spontaneous process but its thermodynamic state functions are essentially identical to those of the prealteration equilibrium state For example suppose that a solution contains the reactants and products for some reaction that occurs only in the presence of a catalyst In this case the solution can be effectively at equilibrium even when the composition does not correspond to an equilibrium position of the reaction In an effort to be more precise we can term this a quasiequilibrium state by which we mean that the system is unchanging even though a spontaneous change is possible If we introduce a very small quantity of catalyst and consider the state of the system before any reaction occurs all of the state functions that characterize the system must be essentially unchanged Nevertheless as soon as the catalyst is introduced the system can no longer be considered to be in an equilibrium state The spontaneous reaction proceeds until it reaches equilibrium We can find the entropy change for the spontaneous process by finding the entropy change for a reversible process that takes the initial precatalyst quasiequilibrium state to the final postcatalyst equilibrium state Our statement of the second law establishes the properties of entropy by postulate While this approach is rigorously logical it does not help us understand the ideas involved Like the first law the second law can be stated several ways To develop our understanding of entropy and its properties it is useful to again consider a more traditional statement of the second law A Traditional statement of the second law It is impossible to construct a machine that operates in a cycle exchanges heat with its surroundings at only one temperature and produces work in the surroundings When we introduce the qualification that the machine exchanges heat with its surroundings at only one temperature we mean that the temperature of the surroundings has a particular value whenever the machine and surroundings exchange heat The statement does not place any conditions on the temperature of the machine at any time In this chapter we have frequent occasion to refer to each of these statements To avoid confusing them we will refer to our statement of the second law as the entropybased statement We will refer to the statement above as the machinebased statement of the second law By a machine we mean a heat enginea device that accepts heat and produces mechanical work This statement asserts that a perpetual motion machine of the second kind cannot exist Such a machine accepts heat energy and converts all of it into work while itself returning to the same state at the end of each cycle In we note that a perpetual motion machine of the first kind is one whose operation violates the principle of conservation of energy Normally we view this statement as a postulate We consider that we infer it from experience Unlike our statements about entropy which are entirely abstract this statement makes an assertion about real machines of the sort that we encounter in daily life We can understand the assertion that it makes in concrete terms A machine that could convert heat from a constanttemperature source into work could extract heat from ice water producing ice cubes in the water and an equivalent amount of work elsewhere in the surroundings This machine would not exchange heat with any other heat reservoir Our machinebased statement of the second law postulates that no such machine can exist Our entropybased statement of the second law arose from thinking about the properties of machines that do convert heat into work We trace this thinking to see how our entropybased statement of the second law was developed Understanding this development gives us a better appreciation for the meaning of entropy We find that we must supplement the machinebased statement of the second law with additional assumptions in order to arrive at all of the properties of the entropy function that are asserted in the entropybased statement However before we undertake to develop the entropybased statement of the second law from the machinebased statement let us develop the converse that is let us show that the machinebased statement is a logical consequence of the entropybased statement To do so we assume that a perpetual motion machine of the second kind is possible To help keep our argument clear let proposition be the machinebased statement We are assuming that proposition is false so that proposition is true We let be the entropybased statement of the second law The sketch in Figure describes the interaction of this perpetual motion machine with its surroundings From our entropybased statement of the second law we can assert some important facts about the entropy changes that accompany operation of the machine Since entropy is a state function for one cycle of the machine If the machine works that is is true then the entropybased statement requires that Since it follows that We can make this more explicit by writing The machinebased statement of the second law also enables us to determine the entropy change in the surroundings from our secondlaw definition of entropy In one cycle this machine system delivers net work to the surroundings it accepts a net quantity of heat from the surroundings which are at temperature Simultaneously the surroundings surrender a quantity of heat where and The change that occurs in one cycle of the machine need not be reversible However whether the change is reversible or not the entire thermal change in the surroundings consists in the exchange of an amount of heat by a constant temperature reservoir at We can effect identically the same change in the surroundings using some other process to reversibly extract this amount of heat The entropy change in the surroundings in this reversible process will be and this will be the same as the entropy change for the surroundings in one cycle of the machine We consider this conclusion further in It follows that and since while we have We can write this conclusion more explicitly Figure A perpetual motion machine PPM that violates the second law By assuming a perpetual motion machine of the second kind is possiblethat is by assuming is truewe derive the contradiction that both and Therefore proposition must be false Proposition must be true The entropybased second law of thermodynamics implies that a perpetual motion machine of the second kind is not possible That is the entropybased statement of the second law implies the machinebased statement We prove that it follows that For a more detailed argument see problem The Significance of The Machinebased Statement of The Second Law Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Our entropybased statement of the second law asserts the definition and basic properties of entropy that we need in order to make predictions about natural processes The ultimate justification for these assertions is that the predictions they make agree with experimental observations We have devoted considerable attention to arguments that develop the definition and properties of entropy from the machinebased statement of the second law These arguments parallel those that were made historically as these concepts were developed Understanding these arguments greatly enhances our appreciation for the relationship between the properties of the entropy function and the changes that can occur in various physical systems While these arguments demonstrate that our machinebased statement implies the entropybased statement we introduce additional postulates in order to make them These include the premise that the pressure temperature volume and energy of a reversible system are continuous functions of one another Duhems theorem the tiling theorem and the presumption that the conclusions we develop for pressurevolume work are valid for any form of work We can sum up this situation by saying that our machinebased statement serves a valuable heuristic purpose The entropybased statement of the second law is a postulate that we infer by reasoning about the consequences of the machinebased statement When we want to apply the second law to physical systems the entropybased statement and other statements that we introduce below are much more useful Finally we note that our machinebased statement of the second law is not the only statement of this type Other similar statements have been given The logical relationships among them are interesting and they can be used to develop the entropybased statement of the second law by arguments similar to those we make in Section to Section The SlaterCondon Rules Last updated Save as PDF Page ID No headers To form Hamiltonian matrix elements between any pair of Slater determinants constructed from spinorbitals that are orthonormal one uses the socalled SlaterCondon rules These rules express all nonvanishing matrix elements involving either one or two electron operators Oneelectron operators are additive and appear as twoelectron operators are pairwise additive and appear as The SlaterCondon rules give the matrix elements between two determinants and for any quantum mechanical operator that is a sum of one and two electron operators It expresses these matrix elements in terms of oneand twoelectron integrals involving the spinorbitals that appear in and and the operators and As a first step in applying these rules one must examine and and determine by how many if any spinorbitals and differ In so doing one may have to reorder the spinorbitals in one of the determinants to achieve maximal coincidence with those in the other determinant it is essential to keep track of the number of permutations that one makes in achieving maximal coincidence The results of the SlaterCondon rules given below are then multiplied by to obtain the matrix elements between the original and The final result does not depend on whether one chooses to permute or to determine The Hamiltonian is of course a specific example of such an operator that contains both one and twoelectron components the electric dipole operator and the electronic kinetic energy are examples of oneelectron operators for which one takes the electronelectron coulomb interaction is a twoelectron operator for which one takes The two Slater determinants whose matrix elements are to be determined can be written as where the spinorbitals and appear in the first and second determinants respectively and the operators and describe the permutations of the spinorbitals appearing in these two determinants The factors and are the signs associated with these permutations as discussed earlier in Section Any matrix element involving one and twoelectron operators needs to be expressed in terms of integrals involving the spinorbitals in the two determinants and the one and twoelectron operators To simplify the above expression which contains terms in its two summations one proceeds as follows a Use is made of the identity to move the permutation operator to just before the langle P phi_phi_cdotsphi_kkcdotsphi_nncdots phi_NN FG Q phi_phi_cdotsphi_kkcdotsphi_nncdotsphi_NNrangle langle phi_phi_cdotsphi_kkcdotsphi_nncdots phi_NN PFG Q phi_phi_cdotsphi_kkcdotsphi_nncdotsphi_NNrangle b Because and contain sums over all electrons in a symmetric fashion any permutation acting on leaves these sums unchanged So commutes with and with This allows the above quantity to be rewritten as c For any permutation operator the operator is just another permutation operator Moreover for any the set of all operators runs over all permutations and the sign associated with the operator is the sign belonging to times the sign associated with So the double sum ie over and over appearing in the above expression for the general matrix element of contains identical sums over the single operator of the sign of this operator multiplied by the effect of this operator on the spinorbital product on the righthand side langle FGrangle fracsqrtNN sum_PQ pq langle phi_phi_cdotsphi_kkcdotsphi_nncdots phi_NN FG PQ phi_phi_cdotsphi_kkcdotsphi_nncdotsphi_NNrangle By assumption as explained earlier the two Slater determinants have been compared and arranged in an order of maximal coincidence and the factor needed to bring them into maximal coincidence has been determined So let us begin by assuming that the two determinants differ by three spinorbitals and let us first consider the terms arising from the identity permutation ie the permutation that alters none of the spinorbitals labels These terms will involve integrals of the form where the threespin orbitals that differ in the two determinants appear in positions and In these dimensional spatial and spin coordinate for each of electrons integrals a Integrals of the form for all or and for all i and or vanish because the spinorbitals appearing in positions and in the two determinants are orthogonal to one another For the operator even integrals with or vanish because there are still two spinorbital mismatches at the other two locations among and For the operator even integrals with or or vanish because two mismatches remain and even with both and or the integrals vanish because one spinorbital mismatch remains The main observation to make is that even for if there are three spinorbital differences neither the nor operator gives rise to any nonvanishing results b If we now consider any other permutation the situation does not improve because any permutation cannot alter the fact that three spinorbital mismatches do not generate any nonvanishing results If there are only two spinorbital mismatches say in locations and the integrals we need to evaluate are of the form and c Again beginning with we can conclude that all of the integrals involving the operator ie and vanish because the two spinorbital mismatch is too much even for or to overcome at least one spinorbital orthogonality integral remains For the operator the only nonvanishing result arises from the and term d The only other permutation that generates another nonvanishing result is the permutation that interchanges and and it produces where the negative sign arises from the factor All other permutations would interchange other spinorbitals and thus generate orthogonality integrals involving other electrons coordinates If there is only one spinorbital mismatch say in location the integrals we need to evaluate are of the form and e Again beginning with the only nonvanishing contribution from the operator is For all other permutations the operator produces no nonvanishing contributions because these permutations generate orthogonality integrals For the operator and the only nonvanishing contributions are where the sum over runs over all of the spinorbitals that are common to both of the two determinants f Among all other permutations the only one that produces a nonvanishing result are those that permute the spinorbital in the kth location with another spinorbital and they produce The minus sign arises from the factor associated with this pair wise permutation operator Finally if there is no mismatch ie the two determinants are identical then g The identity permutation generates from the operator and from the operator h The permutation that interchanges spinorbitals in the kth and jth location produces The summations over and appearing above can alternatively be written as and So in summary once maximal coincidence has been achieved the SlaterCondon SC rules provide the following prescriptions for evaluating the matrix elements of any operator containing a oneelectron part and a twoelectron part If and are identical then where the sums over and run over all spinorbitals in If and differ by a single spinorbital mismatch where the sum over runs over all spinorbitals in except If and differ by two spinorbitals and note that the contribution vanishes in this case If and differ by three or more spin orbitals then or the identity operator the matrix elements if and differ by one or more spinorbitals ie the Slater determinants are orthonormal if their spinorbitals are In these expressions is used to denote the oneelectron integral and or in short hand notation represents the twoelectron integral The notation introduced above gives the twoelectron integrals for the operator in the socalled Dirac notation in which the and indices label the spinorbitals that refer to the coordinates and the and l indices label the spinorbitals referring to coordinates The and denote and with and being the or spin functions If the operators and do not contain any electron spin operators then the spin integrations implicit in these integrals all of the are spinorbitals so each is accompanied by an or spin function and each involves the adjoint of one of the or spin functions can be carried out using thereby yielding integrals over spatial orbitals The System and the Surroundings Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors and Attributions The Zeroth Law of Thermodynamics deals with the temperature of a system And while it may seem intuitive as to what terms like temperature and system mean it is important to define these terms The easiest terms to define are the ones used to describe the system of interest and the surroundings both of which are subsets of the universe Universe everything System subset of the universe that is being studied andor measured Surroundings every part of the universe that is not the system itself As it turns out there can be several types of systems depending on the nature of the boundary that separates the system from the surroundings and specifically whether or not it allows to the transmittance of matter or energy across it Open System allows for both mass and energy transfer across its boundary Closed System allows for energy transfer across its boundary but not mass transfer Isolated System allows neither mass nor energy transfer across its boundary Further systems can be homogeneous consisting of only a single phase of matter and with uniform concentration of all substances present throughout or heterogeneous containing multiple phases andor varying concentrations of the constituents throughout A very important variable that describes a system is its composition which can be specified by the number of moles of each component or the concentration of each component The number of moles of a substance is given by the ratio of the number of particles to Avogadros number where is the number of moles is the number of particles atoms molecules or formula units and is Avogadros number NA x mol Other important variables that are used to describe a system include the important variables of pressure temperature and volume Other variables may also be important but can often be determined if these state variables are known Oftentimes knowing a small number of state variables is all that is required to determine all of the other properties of a system The relationship that allows for the determination of these properties from the values of a couple of state variables is called an equation of state Variables that describe a system can be either intensive independent of the amount of any given substance present in the system or extensive dependent on the amount of substance present in the system Temperature and color are examples of intensive variables whereas volume and mass are examples of extensive variables The value of intensive properties is that they can be conveniently tabulated for various substances whereas extensive properties would be specific to individual systems Oftentimes it is the case that the ratio of two extensive variables results in an intensive variable since the amount of substance cancels out An example of this is density which is the ratio of mass and volume Another example is molar volume which is the ratio of volume and number of moles of substance For a given substance the molar volume is inversely proportional to the density of the substance In a homogeneous system an intensive variable will describe not just the system as a whole but also any subset of that system However this may not be the case in a heterogeneous system Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay The Thermodynamic Perspective Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Classical thermodynamics does not consider the atomic and molecular characteristics of matter In developing it we focus exclusively on the measurable properties of macroscopic quantities of matter In particular we study the relationship between the thermodynamic functions that characterize a system and the increments of heat and work that the system receives as it undergoes some change of state In doing so we adopt some particular perspectives The first is to imagine that we can segregate the macroscopic sample that we want to study from the rest of the universe As sketched in Figure we suppose that we can divide the universe into two mutually exclusive pieces the system that we are studying and the surroundings which we take to encompass everything else Figure The thermodynamic universe We imagine the system to be enclosed by a boundary which may or may not correspond to a material barrier surrounding the collection of matter that we designate as the system For our purposes a system will always contain a macroscopic quantity of matter However this is not necessary thermodynamic principles can be applied to a volume that is occupied only by radiant energy Everything inside the boundary is part of the system Everything outside the boundary is part of the surroundingssurroundings Every increment of energy that the system receives as either heat or work is passed to it from the surroundings and conversely An open system can exchange both matter and energy with its surroundings A closed system can exchange energy but not matter with its surroundings An isolated system can exchange neither matter nor energy Together system and surroundings comprise the universe thermodynamic If we are too literalminded this reference to the universe can start us off on unnecessary ruminations about cosmological implications All we really have in mind is an energyaccounting scheme much like the accountants system of doubleentry bookkeeping in which every debit to one account is a credit to another When we talk about the universe we are really just calling attention to the fact that our scheme involves only two accounts One is labeled system and the other is labeled surroundings Since we do our bookkeeping one system at a time the combination of system and surroundings encompasses the universe of things affected by the change Figure Transferring heat and work in a thermodynamic universe Figure schematically depicts a closed system that can exchange heat and work with its surroundings The surroundings comprise a heat reservoir and a device that can convert potential energy in the surroundings into work exchanged with the system The heat reservoir can exchange heat but not work with the system In this sketch the heat reservoir is at a constant temperature It might comprise for example a large quantity of ice and water in phase equilibrium The workgenerating device cannot exchange heat but it can exchange work with the system A partially extended spring represents the potential energy available in the surroundings The system can do work on the device and increase the potential energy of the spring Alternatively the surroundings can transfer energy to the system at the expense of the potential energy of the spring Since nothing else in the rest of the universe is affected by these exchanges our sketch encompasses the entire universe insofar as these changes are concerned A system that cannot interact with anything external to itself is isolated The combination of system and surroundings depicted in Figure is itself an isolated system When we deal with the entropy change that accompanies some change in the state of the system the properties of the surroundings become important We develop the reason for this in Chapter It is useful to introduce notation to distinguish properties of the surroundings from properties of the system In Figure we indicate the temperatures of system and surroundings by and respectively We adopt this general rule When a thermodynamic quantity appears with a superscripted caret the quantity is that of the surroundings If there is no superscripted caret the quantity is that of the system Thus and are the temperature the energy and the entropy of the surroundings respectively whereas and are the corresponding quantities for the system We develop thermodynamics by reasoning about closed chemical systems that consist of one or more homogeneous phases A phase can be a solid a liquid or a gas A phase can consist of a single chemical substance or it can be a homogeneous solution containing two or more chemical substances When we say that a phase is homogeneous we mean that the pressure temperature and composition of the phase are the same in every part of the phase Since gases are always miscible a system cannot contain two gas phases that are in contact with one another However multiple solid and immiscibleliquid phases can coexist The Third Law of Thermodynamics Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Calculating a third Law EntropyContributors and Attributions One important consequence of Botlzmanns proposal is that a perfectly ordered crystal ie one that has only one energetic arrangement in its lowest energy state will have an entropy of This makes entropy qualitatively different than other thermodynamic functions For example in the case of enthalpy it is impossible have a zero to the scale without setting an arbitrary reference which is that the enthalpy of formation of elements in their standard states is zero But entropy has a natural zero It is the state at which a system has perfect order This also has another important consequence in that it suggests that there must also be a zero to the temperature scale These consequences are summed up in the Third Law of Thermodynamics The entropy of a perfectly ordered crystal at K is zero This also suggests that absolute molar entropies can be calculated by where is the heat capacity An entropy value determined in this manner is called a Third Law Entropy Naturally the heat capacity will have some temperature dependence It will also change abruptly if the substance undergoes a phase change Unfortunately it is exceedingly difficult to measure heat capacities very near zero K Fortunately many substances follow the Debye Extrapolation in that at very low temperatures their heat capacities are proportional to T Using this assumption we have a temperature dependence model that allows us to extrapolate absolute zero based on the heat capacity measured at as low a temperature as can be found Example SiO is found to have a molar heat capacity of J mol K at K Yamashita et al Calculate the molar entropy of SiO at K Solution Using the Debye model the heat capacity is given by The value of a can be determined by The entropy is then calculated by Calculating a third Law Entropy Start at K and go from there Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay The Tiling Theorem and the Paths of Cyclic Process in Other Spaces Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers We view the tiling theorem as a generalization from experience just as the machinebased statement of the second law is such a generalization Let us consider the kinds of familiar observations from which we infer that every equilibrium state of any system is intersected by one and only one adiabat and by one and only one isotherm When only pressurevolume work is possible each pressurevolume point specifies a unique equilibrium state of the system Since temperature is a state function the temperature of this state has one and only one value When another form of work is possible every point specifies a unique state for which the temperature has one and only one value From experience we know that we can produce a new state of the system at the same temperature by exchanging heat and work with it in a concerted fashion We can make this change of state arbitrarily small so that successive equilibrium states with the same temperature are arbitrarily close to one another This succession of arbitrarily close equilibrium states is an isotherm Therefore at least one isotherm intersects any equilibrium state There cannot be two such isotherms If there were two isotherms the system would have two temperatures violating the principle that temperature is a state function In an adiabatic process the system exchanges energy as work but not as heat From experience we know that we can effect such a change with any reversible system The result is a new equilibrium state When we make the increment of work arbitrarily small the new equilibrium state is arbitrarily close to the original state Successive exchanges of arbitrarily small work increments produce successive equilibrium states that are arbitrarily close to one another This succession of arbitrarily close equilibrium states is an adiabat If the same state of a system could be reached by two reversible adiabats involving the same form of work the effect of doing a given amount of this work on an equilibrium system would not be unique From the same initial state two reversible adiabatic experiments could do the same amount of the same kind of work and reach different final states of the system For example in two different experiments we could raise a weight reversibly from the same initial elevation do the same amount of work in each experiment and find that the final elevation of the weight is different Any such outcome conflicts with the observations that underlie our ideas about reversible processes More specifically the existence of two adiabats through a given point in any space violates the machinebased statement of the second law Two such adiabats would necessarily intersect a common isotherm A path along one adiabat the isotherm and the second adiabat would be a cycle that restored the system to its original state This path would enclose a finite area Traversed in the appropriate direction the cycle would produce work in the surroundings By the first law the system would then accept heat as it traverses the isotherm The system would exchange heat with surroundings at a single temperature and produce positive work in the surroundings thus violating the machinebased statement If an adiabatic process that connects two states A and B is reversible we see that the system follows the same path in opposite directions when it does work going from A to B as it does when work is done on it as it goes from B to A From another perspective we can say that the tiling theorem is a consequence of our assumptions about reversible processes Our conception of a reversible process is that the energy pressure temperature and volume are continuous functions of state with continuous derivatives That there is one and only one isotherm for every state is equivalent to the assumption that temperature is a continuous singlevalued function of the state of the system That there is one and only one adiabat for every state is equivalent to the assumption that or generally is a continuous singlevalued function of the state of the system With these ideas in mind let us now observe that any reversible cycle can be described by a closed path in a space whose coordinates are and entropy In Figure we sketch this space with on the abscissa then an isotherm is a horizontal line and line of constant entropy an isentrope is vertical A reversible Carnot cycle is a closed rectangle and the area of this rectangle corresponds to the reversible work done by the system on its surroundings in one cycle Any equilibrium state of the system corresponds to a particular point in this space Any closed path can be tiled arbitrarily densely by isotherms and isentropes Any reversible cycle involving any form of work is represented by a closed path in this space Figure is an alternative illustration of the argument that we make in Section The path in this space is independent of the kind of work done reinforcing the conclusion that for a reversible Carnot cycle producing any form of work The fact that a cyclic process corresponds to a closed path in this space is equivalent to the fact that entropy is a state function Figure A reversible cycle described using coordinates and To appreciate this aspect of the path of a cyclic process in space let us describe the path of the same process in a space whose coordinates are and With on the abscissa isotherms are again horizontal lines and adiabats are vertical lines In this space a reversible Carnot cycle does not begin and end at the same point The path is not closed Similarly the representation of an arbitrary reversible cycle is not a closed figure See Figure The difference between the representations of a reversible cyclic process in these two spaces illustrates graphically the fact that entropy is a state function while heat is not Figure A reversible cycle described using and The Total Differential Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics Inexact Differentials If is a continuous function of the variables and we can think of as a surface in a threedimensional space is the height of the surface above the plane at the point in the plane If we consider points and in the plane the vertical separation between the corresponding points on the surface and is We can add to without changing its value Then If we consider a small change such that and we have Letting we have We call the total differential of the function where is the amount by which changes when changes by an arbitrarily small increment and changes by an arbitrarily small increment We use the notation and to represent the partial derivatives more compactly In this notation We indicate the partial derivative with respect to with held constant at the particular value by writing We can also write the total differential of as in which case and are merely new names for and respectively To express the fact that there exists a function such that and we say that is an exact differential Inexact Differentials It is important to recognize that a differential expression in Equation reftotal may not be exact In our efforts to model physical systems we encounter differential expressions that have this form but for which there is no function such that and We call a differential expression for which there is no corresponding function an inexact differential Heat and work are important examples We will develop differential expressions that describe the amount of heat and work exchanged between a system and its surroundings We will find that these differential expressions are not necessarily exact We develop examples in Section to Section It follows that heat and work are not state functions The Variance of the Average The Central Limit Theorem Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers The central limit theorem establishes very important relationships between the statistics for two distributions that are related in a particular way It enables us to understand some important features of physical systems The central limit theorem concerns the distribution of averages If we have some original distribution and sample it three times we can calculate the average of these three data points Call this average We could repeat this activity and obtain a second average of three values We can do this repeatedly generating averages Several things will be true about these averages The set of all of the possible averagesofthree is itself a distribution This averagesofthree distribution is different from the original distribution Each averageofthree is a value of the random variable associated with the averagesofthree distribution Each of the is an estimate of the mean of the original distribution The distribution of the will be less spread out than the original distribution There is nothing unique about averaging three values We could sample the original distribution seven times and compute the average of these seven values calling the result Repeating we could generate averages All of the things we say about the averagesofthree are also true of these averagesofseven However we can now say something more The distribution of the will be less spread out than the distribution of the The corresponding probability density functions are sketched in Figure Figure The Variance of an Average of is proportional to The central limit theorem relates the mean and variance of the distribution of averages to the mean and variance of the original distribution If random samples of values are taken from a distribution whose mean is  and whose variance is averages of these values are approximately normally distributed with a mean of  and a variance of The approximation to the normal distribution becomes better as becomes larger It turns out that the number of trials that is needed to get a good estimate of the variance is substantially larger than the number required to get a good estimate of the mean The Variational Method Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Contributors and Attributions Let us now turn to the other method that is used to solve Schrdinger equations approximately the variational method In this approach one must again have some reasonable wavefunction that is used to approximate the true wavefunction Within this approximate wavefunction one embeds one or more variables that one subsequently varies to achieve a minimum in the energy of computed as an expectation value of the true Hamiltonian The optimal values of the parameters are determined by making To achieve the desired energy minimum We also should verify that the second derivative matrix has all positive eigenvalues otherwise one may not have found the minimum The theoretical basis underlying the variational method can be understood through the following derivation Suppose that someone knew the exact eigenstates ie true and true of the true Hamiltonian These states obey Because these true states form a complete set it can be shown that the eigenfunctions of all the Hamiltonian operators we ever encounter have this property our socalled trial wavefunction can in principle be expanded in terms of these Before proceeding further allow me to overcome one likely misconception What I am going through now is only a derivation of the working formula of the variational method The final formula will not require us to ever know the exact or the exact but we are allowed to use them as tools in our derivation because we know they exist even if we never know them With the above expansion of our trial function in terms of the exact eigenfunctions let us now substitute this into the quantity that the variational method instructs us to compute Using the fact that the obey and that the are orthonormal the above expression reduces to One of the basic properties of the kind of Hamiltonian we encounter is that they have a lowestenergy state Sometimes we say they are bounded from below which means their energy states do not continue all the way to minus infinity There are systems for which this is not the case we saw one earlier when studying the Stark effect but we will now assume that we are not dealing with such systems This allows us to introduce the inequality which says that all of the energies are higher than or equal to the energy of the lowest state which we denote Introducing this inequality into the above expression gives This means that the variational energy computed as will lie above the true groundstate energy no matter what trial function we use The significance of the above result that is as follows We are allowed to imbed into our trial wavefunction parameters that we can vary to make computed as Equation as low as possible because we know that we can never it lower than the true groundstate energy The philosophy then is to vary the parameters in to render as low as possible because the closer is to the better is our variational wavefunction Let me now demonstrate how the variational method is used in such a manner by solving an example problem Example Two electron Atoms Suppose you are given a trial wavefunction of the form to represent a twoelectron ion of nuclear charge and suppose that you are lucky enough that I have already evaluated the variational energy expression Equation refenergy which Ill call for you and found Now lets find the optimum value of the variational parameter for an arbitrary nuclear charge by setting After finding the optimal value of well then find the optimal energy by plugging this into the above expression Note that represents the shielding factor of one s electron to the other reducing the optimal effective nuclear charge by this amount those familiar with Slaters Rules will not be surprised by this number Now using this optimal in our energy expression gives Since is the Bohr radius  eV or one atomic unit of energy Is this energy any good The total energies of some twoelectron atoms and ions have been experimentally determined to be as shown in Table below Using our optimized expression for lets now calculate the estimated total energies of each of these atoms and ions as well as the percent error in our estimate for each ion Table Comparison of Experimental true total energies with predicted for select twoelectron species Z Atom Experimental Calculated Error H eV eV He eV eV Li eV eV Be eV eV B eV eV C eV eV N eV eV O eV eV The energy errors are essentially constant over the range of but produce a larger percentage error at small Z Aside In when quantum mechanics was quite young it was not known whether the isolated gasphase hydride ion was stable with respect to loss of an electron to form a hydrogen atom Lets compare our estimated total energy for to the ground state energy of a hydrogen atom and an isolated electron which is known to be eV When we use our expression for W and take we obtain eV which is greater than eV so this simple variational calculation erroneously predicts to be unstable More complicated variational treatments give a ground state energy of of eV in agreement with experiment and agreeing that is indeed stable with respect to electron detachment Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis The Zeroth Law of Thermodynamics Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay No headers Temperature is an important property when it comes to measuring energy flow through a system But how does one use or measure temperature Fortunately there is a simple and intuitive relationship which can be used to design a thermometer a device to be used to measure temperature and temperature changes The zeroth law of thermodynamics can be stated as follows If a system A is in thermal equilibrium with a system B which is also in thermal equilibrium with system C then systems A and C share a property called temperature This basic principle has been used to define standard temperature scales by the International Committee on Weights and Measures BIPM to guide the adoption of the International Practical Temperature Scale of Mangum Furukawa IPT is defined by using various physical properties of substances such as the triple point of water which occur at ver specific temperatures and pressures and then assigning the measurable values such as the resistance on a standard platinum resistance thermometer Strouse Time Correlation Functions Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Contributors and Attributions One of the most active research areas in statistical mechanics involves the evaluation of socalled equilibrium time correlation functions such as we encountered in Chapter The correlation function is defined in terms of two physical operators and a time dependence that is carried by a Hamiltonian via and an equilibrium average over a Boltzmann population The quantum mechanical expression for is while the classical mechanical expression here we allow the factor that occurs in the partition function shown in Section to be canceled out in the numerator and denominator for simplicity is where and are the values of all the coordinates and momenta of the system at and and are their values according to Newtonian mechanics at time As shown above an example of a time correlation function that relates to molecular spectroscopy is the dipoledipole correlation function that we discussed in Chapter for which and are both the electric dipole interaction between the photons electric field whose direction is characterized by the vector and the molecules dipole operator The Fourier transform of this particular relates to the absorption intensity for light of frequency It turns out that many physical properties eg absorption line shapes Raman scattering intensities and transport coefficients eg diffusion coefficients viscosity can be expressed in terms of timecorrelation functions It is beyond the scope of this text to go much further in this direction so I will limit my discussion to the optical spectroscopy case at hand which requires that we now discuss how the timeevolution aspect of this problem is dealt with The text Statistical Mechanics D A McQuarrie Harper and Row New York has a nice treatment of such other correlation functions so the reader is directed to that text for further details The computation of correlation functions involves propagating either wave functions or classical trajectories which produce the qt values entering into the expression for In the classical case one carries out a large number of Newtonian trajectories with initial coordinates and momenta chosen to represent the equilibrium condition of the molecule system For example one could use the MC method to select these variables employing as the probability function for accepting or rejecting initial and values In this case the weighting function contains not just the potential energy but also the kinetic energy and thus the total Hamiltonian because now we need to also select proper initial values for the momenta So with many eg M selections of the initial and variables of the molecules being made one would allow the Newton dynamics of each set of initial conditions to proceed During each such trajectory one would monitor the initial value of the property and the time progress of the property One would then compute the MC average to obtain the correlation function Where the index labels the accepted configurations and momenta of the MC sampling In the quantum case the time propagation is especially challenging and is somewhat beyond the scope of this text However I want to give you some idea of the steps that are involved realizing that this remains an area of very active research development As noted in Section it is possible to timepropagate a wave function that is known at if one is able to expand in terms of the eigenfunctions of the Hamiltonian However for systems comprised of many molecules which are most common in statistical mechanics studies it is impossible to compute or realistically approximate these eigenfunctions Thus it is not productive to try to express in terms of these eigenfunctions Therefore an entirely new set of tools has been introduced to handle timepropagation in the quantum case and it is these new devices that I now attempt to describe in a manner much like we saw in Section s discussion of time propagation of wave functions To illustrate consider the time propagation issue contained in the quantum definition of shown above One is faced with propagating from up to time using and then acting with the operator acting with the operator on and then propagating from up to time using then requires that these two timepropagated functions be multiplied together and integrated over the coordinates that depends on The operator that also appears in the definition of can be combined for example with the first time propagation step and actually handled as part of the time propagation as follows The latter expression can be viewed as involving a propagation in complex time from to Although having a complex time may seem unusual as I will soon point out it turns out that it can have a stabilizing influence on the success of these tools for computing quantum correlation functions Much like we saw earlier in Section socalled Feynman path integral techniques can be used to carry out the above time propagations One begins by dividing the time interval into discrete steps this can be the real time interval or the complex interval The number will eventually be taken to be large so each time step has a small magnitude This fact allows us to use approximations to the exponential operator appearing in the propagator that are valid only for short time steps For each of these short time steps one then approximates the propagator in the most commonly used socalled split symmetric form Here and are the potential and kinetic energy operators that appear in It is possible to show that the above approximation is valid up to terms of order So for short times ie small these symmetric split operator approximation to the propagator should be accurate The time evolved wave function can then be expressed as The potential is except when external magnetic fields are present a function only of the coordinates of the system while the kinetic term is a function of the momenta assuming Cartesian coordinates are used By making use of the completeness relations for eigenstates of the coordinate operator int dq q_jrangle langle q_jlabel and inserting this identity times once between each combination of factors the expression given above for can be rewritten as follows Phiq_P t int dq_P dq_P dq_ dq_ prod_jP expbig fracidelta t hbarVq_j Vq_jbig langle q_j expbigfraci delta tThbarbig q_jrangle Phiq_ Then by using the analogous completeness identity for the momentum operator one can write Finally by using the fact recall this from Section that the momentum eigenfunctions when expressed as functions of coordinates are given by langle q_jp rangle fracsqrtpi expbigfracipqhbarbig the above integral becomes This integral over can be carried out analytically to give When substituted back into the multidimensional integral for we obtain or Phiq_P t leftfracmpi ihbar delta trightP int dq_P dq_P dq_ dq_ expBigsum_jP big fracidelta t hbarVq_j Vq_j fraci mq_j q_j hbar delta tbigBig Fq_ Recall what we said earlier that the time correlation function was to be computed by propagating from up to time using and then acting with the operator B acting with the operator on and then propagating from up to time using multiplying together these two functions and integrating over the coordinates that depends on So all of the effort described above would have to be expended for taken to be after which the result would be multiplied by the operator B as well as for taken to be to allow the quantum time correlation function to be evaluated These steps can be performed but they are very difficult to implement so I will refer the student to Computer Simulations of Liquids M P Allen and D J Tildesley Oxford U Press New York for further discussion on this topic Why are the multidimensional integrals of the form shown above called path integrals Because the sequence of positions describes a path connecting to By integrating over all of the intermediate positions for any given and one is integrating over all paths that connect to Further insight into the meaning of the above is gained by first realizing that fracmdelta t q_j q_j fracmdelta t q_j q_j delta t int T dt is the finitedifference representation within the discrete time steps of length dt of the integral of Tdt over the jth time step and that is the representation of the integral of over the jth time step So for any particular path ie any specific set of values the sum over all such terms represents the integral over all time from until of the socalled Lagrangian This time integral of the Lagrangian is called the action in classical mechanics recall that in Chapter we used quantization of the action in the particleinabox problem Hence the Ndimensional integral in terms of which is expressed can be written as F q_P t leftfracmpi ihbar delta trightP sum_text all paths expbigfracihbar int dt L big Fq_ t Here the notation all paths is realized in the earlier version of this equation by dividing the time axis from to into equal divisions and denoting the coordinates of the system at the jth time step by By then allowing each to assume all possible values ie integrating over all possible values of using for example the MonteCarlo method discussed earlier one visits all possible paths that begin at at and end at at By forming the classical action for each path and then summing over all paths and multiplying by one is able to form The difficult step in implementing this Feynman path integral method in practice involves how one identifies all paths connecting to Each path contributes an additive term involving the complex exponential of the quantity Because the time variable appearing in each action component can be complex recall that in one of the time evolutions is really the exponentials of these action components can have both real and imaginary parts The real parts which arise from the cause the exponential terms to be damped ie to undergo exponential decay but the imaginary parts give rise in to oscillations The sum of many many actually an infinite number of oscillatory terms is extremely difficult to evaluate because of the tendency of contributions from one path to cancel those of another path The practical evaluation of such sums remains a very active research subject The most commonly employed approximation to this sum involves finding the paths for which the action is smallest because such paths produce the lowestfrequency oscillations in and thus may be less subject to cancelation by contributions from other paths The paths that minimize the action are in fact the classical paths That is they are the paths that the system whose quantum wave function is being propagated would follow if the system were undergoing classical Newtonian mechanics subject to the conditions that the system be at at and at at In this socalled semiclassical approximation to the propagation of the initial wave function using Feynman path integrals one finds all classical paths that connect at and at at and one evaluates the action for each such path One then applies the formula Phiq_P t leftfracmpi ihbar delta trightP sum_text all paths expbigfracihbar int dt L big Fq_ t but includes in the sum only the contribution from the classical paths In this way one obtains an approximate quantum propagated wave function via a procedure that requires knowledge of only classical propagation paths Clearly the quantum propagation of wave functions even within the semiclassical approximation discussed above is a rather complicated affair However keep in mind the alternative that one would face in evaluating for example spectroscopic line shapes if one adopted a timeindependent approach One would have to know the energies and wave functions of a system comprised of many interacting molecules This knowledge is simply not accessible for any but the simplest molecules For this reason the timedependent framework in which one propagates classical trajectories or uses pathintegral techniques to propagate initial wave functions offers the most feasible way to evaluate the correlation functions that ultimately produce spectral line shapes and other time correlation functions for complex molecules in condensed media Before finishing this Section it might help if I showed how one obtains the result that classical paths are those that make the action integral minimum This provides the student with an introduction to the subject called calculus of variations or functional analysis which most students reading this text have probably not studied in a class First lets clarify what a functional is A function depends on one or more variables x that take on scalar values that is given a scalar number produces the value of the function at this value of A functional is a function of the function if given the function acts on it to produce a value In more general functionals might depend not only of f but on various derivatives of Lets consider an example Suppose one has a functional of the form meaning that the functional involves an integral from through of an integrand that may contain i the variable explicitly ii the function and iii the derivative of this function with respect to the variable This is the kind of integral one encounters when evaluating the action integral where the function is the coordinate that evolves from to The task at hand is to determine that function for which this integral is a minimum We solve this problem proceeding much as one would do if one had to minimize a function of a variable we differentiate with respect to the variable and set the derivative to zero However in our case we have a function of a function not a function of a variable so how do we carry out the derivative We assume that the function that minimizes is known and we express any function that differs a little bit from the correct as where is a scalar quantity used to suggest that and differ by only a small amount and is a function that obeys this is how we guarantee that we are only considering paths that connect to the proper at and at By considering all possible functions that obey these conditions we have in a parameterization of all paths that begin at and end at tf where the exact path does but differ by a small amount from Substituting into gives The terms in the integrand are then expanded in powers of the parameter and substituted into the integral for Collecting terms of each power of allows this integral to be written as The condition that Se be stable with respect to variations in can be expressed as which is equivalent to requiring that the terms linear in in the above expansion for vanish Next we use integration by parts to rewrite the first term involving as a term involving instead Because the function vanishes at and the first term vanishes so this identity can be used to rewrite the condition that the terms in that are linear in vanish as Because this result is supposed to be valid for any function that vanishes at and tf the factor multiplying in the above integral must itself vanish This shows that the path that makes stationary is the path that obeys Newtons equations the classical path I urge the student reader to study this example of the use of functional analysis because this mathematical device is an important tool too master Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Time Dependent Perturbation Theory Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah DerivationApplication Coupling to a ContinuumApplication Experimental OscillationsApplication Collisionally induced TransitionsReferencesContributors and Attributions When dealing with the effects of external perturbations eg applied fields collisions with other species one needs to have a way to estimate the probabilities and rates of transitions among states of the system of interest induced by these perturbations Timedependent perturbation theory TDPT offers a framework within which such estimates can be achieved Derivation In deriving the working equations of TDPT one begins with the timedependent Schrdinger equation in which is the Hamiltonian for the system whose transitions are to be probed and is the perturbation caused by the external field or the collision The wave function that solves this equation is expanded in an orderbyorder manner as in conventional perturbation theory Here is the eigenfunction of from which transitions to other eigenstates denoted of are being considered Because in the absence of the external perturbation the states of are known to vary with time as this component of the time dependence of the total wave function is included in the above expansion Then the firstorder correction is expanded in terms of the complete set of states after which the expansion coefficients become the unknowns to be solved for It should be noted that this derivation treats the zerothorder states and as eigenfunctions of However in most practical applications of TDPT and are not known exactly and in fact are usually approximated by using variational or perturbative methods eg to treat differences between HF meanfield and true Coulombic interactions among electrons So the derivation of TDPT that we are pursuing assumes the and are exact eigenfunctions When the final TDPT working equations are thus obtained one usually substitutes perturbative or variational approximations to and into these equations Substituting the orderbyorder expansion into the Schrdinger equation gives for the left and righthand sides ihbar fracpartial Psipartial t EpsirexpBigitfracEhbarBig sum_f left E_fpsi_frexpbiggitfracE_fhbarbiggC_ft ihbarpsi_frexpbiggitfracE_fhbarbiggfracC_ftdt right labela and H_VtPsiEpsirexpBigitfracEhbarBig sum_f E_fpsi_frexpbiggitfracE_fhbarbiggC_ft VtpsirexpBigitfracEhbarBig labelb respectively through firstorder Multiplying each of these equations on the left by the complex conjugate of a particular and integrating over the variables that depends on produces the following equation for the unknown firstorder coefficients The states and can be different electronic states vibrational states or rotational states In Chapter of my book Quantum Mechanics in Chemistry referred to in Chapter I treat each of these types of transitions in detail In the present discussion I will limit myself to the general picture of TDPT rather than focusing on any of these particular forms of spectroscopic transitions To proceed further one needs to say something about how the perturbation depends on time In the most common application of TDPT the perturbation is assumed to consist of a term that depends on spatial variables denoted multiplied by a timedependent factor of sinusoidal character An example of such a perturbation is provided by the electric dipole potential VttextbfEcdot esum_n Z_n textbfR_n e sum_i textbfr_i cosomega t characterizing photons of frequency interacting with the nuclei and electrons of a molecule textbfEcdot esum_n Z_n textbfR_n e sum_i textbfr_i is the spatial part and is the timedependence To allow for the possibility that photons over a range of frequencies may impinge on the molecules we can proceed with the derivation for photons of a given frequency and after obtaining our final result average over a distribution of frequencies characterized by a function giving the number of photons with frequencies between and For perturbations that do not vary in a sinusoidal manner eg a perturbation arising from a collision with another molecule the derivation follows a different path at this point application below Because spectroscopic timedependent perturbations are extremely common in chemistry we will focus much of our attention to this class of perturbations in this Chapter To proceed deriving the working equations of TDPT the above expression for is inserted into the differential equation for the expansion coefficients and the equation is integrated from an initial time to a final time These times describe when the external perturbation is first turned on and when it is turned off respectively For example a laser whose photon intensity profile is described by might be pulsed on from to and one wants to know what fraction of the molecules initially in have undergone transitions to each of the Alternatively the molecules may be flowing in a stream that passes through a laser light source that is continually on entering the laser beam at and exiting from the laser beam at In either case the molecules would be exposed to the photons from until The result of integrating the differential equation is beginsplitC_ftfracihbarint_t_it_flangle psi_fvrpsi_fr rangle expiomega texpiomega texpbiggitfracEE_fhbarbigg fracihbarint_t_it_flangle psi_fvrpsi_fr rangle expiomegaomega_f texpiomegaomega_f t fracihbarlangle psi_fvrpsi_fr rangle timesleftfracexpiomegaomega_f t_fexpiomegaomega_f t_iiomegaomega_f fracexpiomegaomega_f t_fexpiomegaomega_f t_iiomegaomega_f rightendsplit label where the transition frequencies are defined by and is the time interval Now if the frequency is close to one of the transition frequencies the term with in the denominator will be larger than the term containing Of course if has a higher energy than so one is studying stimulate emission spectroscopy will be negative in which case the term containing will dominate In onresonance absorption spectroscopy conditions the above expression for the firstorder coefficients reduces to C_ftfracihbarlangle psi_fvrpsi_frrangle fracexpiomegaomega_f t_fexpiomegaomega_f t_iiomegaomega_f label The modulus squared of this quantity gives a measure of the probability of observing the system in state after being subjected to the photons of frequency for a length of time C_ftfraclangle psi_fvrpsi_frranglehbar fraccosomegaomega_ftomegaomega_f fraclangle psi_fvrpsi_frranglehbar fracsinomegaomega_ftomegaomega_f label The function is plotted in Figure for a given value of as a function of It is sharply peaked around decays rapidly as increases and displays recurrences of smaller and smaller intensity when passes through multiples of Figure Plot of vs for a given value of At larger values of the main peak in the plot of this function becomes narrower and higher such that in the limit the area under this plot approaches The importance of this observation about the area under the plot shown in Figure can be appreciated by returning to our result and introducing the fact that the photon source used to induce the transitions being studied most likely is not perfectly monochromatic If it is characterized as suggested earlier by a distribution of frequencies that is broader than the width of the large central peak in Figure nb this will be true if the time duration is long enough then when we average over to obtain a result that directly relates to this kind of experiment we obtain int_inftyinfty fomegaC_ftdomega fraclangle psi_fvrpsi_frranglehbar int_inftyinfty fomegafracsinomegaomega_ftomegaomega_fdomega fracpilangle psi_fvrpsi_frranglethbarfomega_flangle C_ft rangle label We are allowed to write the integral over as ranging from to because the function shown in Figure is so sharply peaked around that extending the range of integration makes no difference We are allowed to factor the out of the integral as f by assuming the light sources distribution function is very smoothly varying ie not changing much in the narrow range of frequencies around where the function in Figure is sharply peaked The result of this derivation of TDPT is the above expression for the average probability of observing a transition from state to state This probability is seen to grow linearly with the time duration over which the system is exposed to the light source Because we carried out this derivation within firstorder perturbation theory we should trust this result only under conditions where the effects of the perturbation are small In the context of the example considered here this means only for short times That is we should view as expressing the shorttime estimate of the probability of a transition from to and obtained as as expressing the initial rate of such transitions within the firstorder TDPT approximation It should be noted that the rate expression given above will not be valid if the time duration t of the perturbation does not obey only when this condition is met an the function shown in Figure be integrated to generate a probability prediction that grows linearly with time So one has to be careful when using pulsed lasers of very short duration to not employ the simplified rate expression given above eg eV corresponds to a frequency of ca x s so to study an electronic transition of this energy one needs to use a light source of duration significantly longer than s to make use of the simplified result The working equations of TDPT given above allow one to estimate because this is a firstorder theory the rates of transitions from one quantum state to another induced by a perturbation whose spatial dependence is characterized by and whose time dependence is sinusoidal The same kind of coupling matrix elements as we experienced in timeindependent PT govern the selection rules and intensities for these transitions so there is no need to repeat how symmetry can be used to analyze these integrals Before closing this treatment of TDPT it is useful to address a few issues that were circumvented in the derivation presented above Application Coupling to a Continuum In some cases one is interested in transitions from a particular initial state into a manifold of states that exist in a continuum having energies between and This occurs for example when treating photoionization of a neutral or photodetachment of an anion here the ejected electron exists in a continuum wave function whose density of states is given by the formulas discussed in Chapter In such cases the expression given above for the rate is modified by summing over all final states having energies within and Returning to the earlier expression intrhoE_ffracpilangle psi_fvrpsi_frranglehbar int_inftyinfty fomegafracsinomegaomega_ftomegaomega_fdomega dE_f label using and assuming the matrix elements do not vary significantly within the narrow range between and one arrives at a rate expression of which is much like we obtained earlier but now contains the density of states In some experiments one may not have only a single state that can absorb light of a given frequency w in such a situation attenuation of the light source at this frequency can occur through absorptions from many initial states into all possible final states whose energy differs from that of the initial state by In this case the correct expression for the total rate of absorption of photons of energy is obtained by averaging the above result over the probabilities of the system being in various initial states which we label Here the function guarantees that only states and whose energies differ by are permitted to enter the sum The nature of the initialstate probability depends on what kind of experiment is being carried out might be a Boltzmann distribution if the initial states are in thermal equilibrium for example Application Experimental Oscillations In Figure the function is plotted for one value of as a function of There also appear in this figure dots that represent experimental data These data were obtained by allowing a stream of molecules to flow through a laser beam of width with the laser frequency tuned to From the flow velocity of the stream and the laser beam width one can determine the duration over which the molecules were exposed to the light source After the molecules exited the laser beam they were probed to determine whether they were in an excited state This experiment was repeated for various values of the frequency The population of excited states was then plotted as a function of to obtain the data plotted in Figure This experiment is described in the text Molecules and Radiation J I Steinfeld MIT Press Cambridge Mass This kind of experiment provided direct proof of the oscillatory frequency dependence observed in the population of excited states as predicted in our derivation of TDPT Application Collisionally induced Transitions To give an example of how one proceeds in TDPT when the perturbation is not oscillatory in time let us consider an atom located at the origin of our coordinate system that experiences a collision with an ion of charge c whose trajectory is described in Figure Figure An atom at the origin undergoing a collision with an ion of charge moving along the axis with constant velocity As an approximation we assume that the ion moves in a straight line characterized by an impact parameter and a velocity this would be appropriate if the ion were moving so fast that it would not be deflected by interactions with the atom that the perturbation caused by the ion on the electrons of the atom at the origin can be represented by where is the position of the ith electron in the atom and is the position of the ion The time dependence of the perturbation arises from the motion of the ion along the axis Writing the distance as and expanding in inverse powers of we can express the ionatom interaction potential as The first term contains no factors dependent on the atoms electronic coordinates so it plays no role in causing electronic transitions In the second term the factor can be neglected compared to the terms because the ion is assumed to be somewhat distant from the atoms valence electrons To derive an equation for the probability of the atom undergoing a transition from to one returns to the TDPT expression and substitutes the above expression for the perturbation to obtain This is the equation that must be solved to evaluate by integrating from to representing the full collision with the ion starting far to the left on the axis and proceeding far to the right There are two limiting cases in which the solution is straightforward First if the time duration of the collision ie the time over which the ion is close to the atom is long compared to where then the integrand will oscillate repeatedly during the time as a result of which the integral will be vanishingly small So in this socalled adiabatic case ie with the ion moving slowly relative to the oscillation frequency electronic transitions should not be expected In the other limit the factor will remain approximately equal to unity so the integration needed reduces to The integral involving vanishes because is odd and the remainder of the integrand is an even function of The integral involving can be performed by trigonometric substitution so the denominator reduces to and gives This result suggests that the probability of a transition should vary as the square of the ions charge and inversely with the speed of the collision Of course this result can not be trusted if the speed is too low because then the condition will not hold This example shows how one must rederive the equations of TDPT when dealing with perturbations whose timedependence is not sinusoidal References For the reader who wishes a more complete and diverse treatment of TDPT as applied to chemistry I suggest the text Radiation and Noise in Quantum Electronics W H Louisell R E Krieger Pub Huntington N Y as well as my text Quantum Mechanics in Chemistry Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Total and Exact Differentials Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Exact DifferentialsContributors and Attributions The fact that we can define the constant volume heat capacity as suggests that the internal energy depends very intimately on two variables volume and temperature In fact we will see that for a single component system state variables are always determined when two state variables are defined In the case of internal energy we might write or This suggests that the way to change is to change either or or both And if there is a mathematical function that relates the internal energy to these two variables it should easy to see how it changes when either or both are changed This can be written as a total differential Even without knowing the actually mathematical function relating the variables to the property we can imagine how to calculate changes in the property from this expression In words this implies that we can think of a change in occurring due to an isothermal change followed by an isochoric change And all we need to know is the slope of the surface in each pathway direction There are a couple of very important experiments people have done to explore the measurement of those kinds of slopes Understanding them it turns out depends on two very important physical properties of substances Exact Differentials We have seen that the total differential of can be expressed as Equation reftotal In general if a differential can be expressed as the differential will be an exact differential if it follows the Euler relation In order to illustrate this concept consider using the ideal gas law The total differential of can be written Example Euler Relation Does Equation refEq follow the Euler relation Equation refeuler Solution Lets confirm is in fact an exact differential The differentials of all of the thermodynamic functions that are state functions will be exact Heat and work are not exact differential and and are called inexact differentials instead Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Useful Definitions and Relationships Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay No headers In this chapter and in the previous chapter several useful definitions have been stated Toolbox of useful Relationships The following measurable quantities have been defined Heat Capacities C_V equiv left dfracpartial Upartial T right_V and C_p equiv left dfracpartial Hpartial T right_p Coefficient of Thermal Expansion alpha equiv left dfracpartial Vpartial T right_p or left dfracpartial Vpartial T right_p V alpha Isothermal Compressibility kappa_T equiv dfracV left dfracpartial Vpartial p right_T or left dfracpartial Vpartial p right_T V kappa _T The following relation has been derived And the following relationships were given without proof yet and Together these relationships and definitions make a powerful set of tools that can be used to derive a number of very useful expressions Example Expanding Thermodynamic Function Derive an expression for in terms of measurable quantities Solution Begin by using the total differential of dH left dfracpartial Hpartial p right_T dp left dfracpartial Hpartial T right_p dT Divide by and constrain to constant to generate the partial of interest on the left The last term on the right will vanish since for constant After converting to partial derivatives leftdfracpartial Hpartial V right_T left dfracpartial Hpartial p right_T leftdfracpartial ppartial V right_T labeleq This result is simply a demonstration of the chain rule on partial derivatives But now we are getting somewhere We can now substitute for using our toolbox of useful relationships leftdfracpartial Hpartial V right_T left T leftdfracpartial Vpartial T right_p V right leftdfracpartial ppartial V right_T Using the distributive property of multiplication this expression becomes leftdfracpartial Hpartial V right_T T leftdfracpartial Vpartial T right_pleftdfracpartial ppartial V right_T V leftdfracpartial ppartial V right_T labeleq Using the cyclic permutation rule Transformation Type II the middle term of Equation refeq can be simplified leftdfracpartial Hpartial V right_T T leftdfracpartial ppartial T right_V V leftdfracpartial ppartial V right_T And now all of the partial derivatives on the right can be expressed in terms of and along with and which are also measurable properties or Example Isothermal Compression Calculate for the isothermal compression of ethanol which will decrease the molar volume by at K For ethanol and Solution Integrating the total differential of at constant temperature results in From Example we know that so Delta H left dfrac times atm left K times K right right Lmol Delta H left dfraccancelatmLmolright underbraceleftdfracJ cancelatmLright_textconversion factor Jmol Contributors Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Using Thermochemical Cycles to Find Enthalpy Changes Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers Figure A cyclic path on the phase diagram for water Because enthalpy is a state function the enthalpy change in going between any two states of a system is independent of the path For a series of changes that restore a system to its original state the sum of all the enthalpy changes must be zero This fact enables us to find the enthalpy changes for many processes for which it is difficult to measure heat and work directly It is easiest to see what is involved by considering a specific example Figure shows a cyclic path AABA superimposed on a nottoscale presentation of the phase diagram for water Let us look at the sublimation of ice at the melting point of pure water The sublimation of ice is the conversion of pure ice to pure water vapor The melting point of pure water is the temperature at which pure ice is at equilibrium with pure liquid water at a pressure of one atmosphere it is represented by points A and A on the diagram We want to find the enthalpy of sublimation at the temperature and pressure represented by points D and D Points A A D and D are all at the same temperature this temperature is about K or C This temperature is very slightly greater than K or Cwhich is the temperature at which ice and water are at equilibrium in the presence of air at a total pressure of one atmosphere We want to calculate the enthalpy change for the equilibrium conversion of one mole of ice to gaseous water at the pressure where the solidgas equilibrium line intersects the line On the diagram this sublimation pressure is represented as and the sublimation process is represented as the transition from D to D is less than the triplepoint pressure of or However the difference is less than or In equation form the successive states traversed in this cycle are A ice at C and atm A water at C and atm B water at C and atm B water vapor at C and atm C water vapor at C and D water vapor at C and Dice at C and A ice at C and atm We select these steps because it is experimentally straightforward to find the enthalpy change for all of them except the sublimation step DD All of these steps can be carried out reversibly This strategy is useful in general We make extensive use of reversible cycles to find thermodynamic information for chemical systems The enthalpy changes for these steps are s C atm liq C atm liq C atm liq C atm liq C atm g C atm g C atm g C g C g C g C s C s C s C atm Summing the enthalpy changes around the cycle gives Using results that we find in the next section and we have The enthalpy of fusion the enthalpy of vaporization and the heat capacities are measurable in straightforward experiments Their values are given in standard compilations so we are now able to evaluate a quantity that is not susceptible to direct measurement from other thermodynamic quantities that are See Problem Van der Waals Equation Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers An equation due to van der Waals extends the ideal gas equation in a straightforward way Van der Waals equation is It fits pressurevolumetemperature data for a real gas better than the ideal gas equation does The improved fit is obtained by introducing two parameters designated and that must be determined experimentally for each gas Van der Waals equation is particularly useful in our effort to understand the behavior of real gases because it embodies a simple physical picture for the difference between a real gas and an ideal gas In deriving Boyles law from Newtons laws we assume that the gas molecules do not interact with one another Simple arguments show that this can be only approximately true Real gas molecules must interact with one another At short distances they repel one another At somewhat longer distances they attract one another The ideal gas equation can also be derived from the basic assumptions that we make in by an application of the theory of statistical thermodynamics By making different assumptions about molecular properties we can apply statistical thermodynamics to derive van der Waals equation The required assumptions are that the molecules occupy a finite volume and that they attract one another with a force that varies as the inverse of a power of the distance between them The attractive force is usually assumed to be proportional to To recognize that real gas molecules both attract and repel one another we need only remember that any gas can be liquefied by reducing its temperature and increasing the pressure applied to it If we cool the liquid further it freezes to a solid Now two distinguishing features of a solid are that it retains its shape and that it is almost incompressible We attribute the incompressibility of a solid to repulsive forces between its constituent molecules they have come so close to one another that repulsive forces between them have become important To compress the solid the molecules must be pushed still closer together which requires inordinate force On the other hand if we throw an ice cube across the room all of its constituent water molecules fly across the room together Evidently the water molecules in the solid are attracted to one another otherwise they would all go their separate waysthrowing the ice cube would be like throwing a handful of dry sand But water molecules are the same molecules whatever the temperature or pressure so if there are forces of attraction and repulsion between them in the solid these forces must be present in the liquid and gas phases also In the gas phase molecules are far apart in the liquid or the solid phase they are packed together At its boiling point the volume of a liquid is much less than the volume of the gas from which it is condensed At the freezing point the volume of a solid is only slightly different from the volume of the liquid from which it is frozen and it is certainly greater than zero These commonplace observations are readily explained by supposing that any molecule has a characteristic volume We can understand this in turn to be a consequence of the nature of the intermolecular forces evidently these forces become stronger as the distance between a pair of molecules decreases Since a liquid or a solid occupies a definite volume the repulsive force must increase more rapidly than the attractive force when the intermolecular distance is small Often it is useful to talk about the molar volume of a condensed phase By molar volume we mean the volume of one mole of a pure substance The molar volume of a condensed phase is determined by the intermolecular distance at which there is a balance between intermolecular forces of attraction and repulsion Evidently molecules are very close to one another in condensed phases If we suppose that the empty spaces between molecules are negligible the volume of a condensed phase is approximately equal to the number of molecules in the sample multiplied by the volume of a single molecule Then the molar volume is Avogadros number times the volume occupied by one molecule If we know the density D and the molar mass we can find the molar volume as The volume occupied by a molecule V becomes The pressure and volume appearing in van der Waals equation are the pressure and volume of the real gas We can relate the terms in van der Waals equation to the ideal gas equation It is useful to think of the terms and as the pressure and volume of a hypothetical ideal gas That is Then we have We derive the ideal gas equation from a model in which the molecules are noninteracting point masses So the volume of an ideal gas is the volume occupied by a gas whose individual molecules have zero volume If the individual molecules of a real gas effectively occupy a volume then moles of them effectively occupy a volume Van der Waals equation says that the volume of a real gas is the volume that would be occupied by noninteracting point masses plus the effective volume of the gas molecules themselves When data for real gas molecules are fit to the van der Waals equation the value of is usually somewhat greater than the volume estimated from the liquid density and molecular weight See problem Similarly we have We can understand this as a logical consequence of attractive interactions between the molecules of the real gas With it says that the pressure of the real gas is less than the pressure of the hypothetical ideal gas by an amount that is proportional to The proportionality constant is Since is the molar density moles per unit volume of the gas molecules it is a measure of concentration The number of collisions between molecules of the same kind is proportional to the square of their concentration We consider this point in more detail in Chapters and So is a measure of the frequency with which the real gas molecules come into close contact with one another If they attract one another when they come close to one another the effect of this attraction should be proportional to So van der Waals equation is consistent with the idea that the pressure of a real gas is different from the pressure of the hypothetical ideal gas by an amount that is proportional to the frequency and strength of attractive interactions But why should attractive interactions have this effect why should the pressure of the real gas be less than that of the hypothetical ideal gas Perhaps the best way to develop a qualitative picture is to recognize that attractive intermolecular forces tend to cause the gas molecules to clump up After all it is these attractive forcesattractive force that cause the molecules to aggregate to a liquid at low temperatures Above the boiling point the ability of gas molecules to go their separate ways limits the effects of this tendency however even in the gas the attractive forces must act in a way that tends to reduce the volume occupied by the molecules Since the volume occupied by the gas is dictated by the size of the containernot by the properties of the gas itselfthis clumpingup tendency finds expression as a decrease in pressure Figure Potential energy versus distance for hard sphere molecules It is frequently useful to describe the interaction between particles or chemical moieties in terms of a potential energy versus distance diagram The van der Waals equation corresponds to the case that the repulsive interaction between molecules is nonexistent until the molecules come into contact Once they come into contact the energy required to move them still closer together becomes arbitrarily large Often this is described by saying that they behave like hard spheres The attractive force between two molecules decreases as the distance between them increases When they are very far apart the attractive interaction is very small We say that the energy of interaction is zero when the molecules are infinitely far apart If we initially have two widely separated stationary mutually attracting molecules they will spontaneously move toward one another gaining kinetic energy as they go Their potential energy decreases as they approach one another reaching its smallest value when the molecules come into contact Thus van der Waals equation implies the potential energy versus distance diagram sketched in Figure Various Approaches to Electron Correlation Last updated Save as PDF Page ID a The CI Methodb Perturbation Theoryc The CoupledCluster Methodd The Density Functional Methode Energy Difference Methods There are numerous procedures currently in use for determining the best BornOppenheimer electronic wave function that is usually expressed in the form where is a spinand space symmetryadapted configuration state function CSF that consists of one or more determinants combined to produce the desired symmetry In all such wave functions there are two kinds of parameters that need to be determined the CI coefficients and the LCAOMO coefficients describing the fIk in terms of the AO basis functions The most commonly employed methods used to determine these parameters include a The CI Method In this approach the LCAOMO coefficients are determined first usually via a singleconfiguration HF SCF calculation The CI coefficients are subsequently determined by making the expectation value variationally stationary with chosen to be of the form As with all such linear variational problems this generates a matrix eigenvalue equation to be solved for the optimum coefficients and for the optimal energy The CI wave function is most commonly constructed from spin and spatial symmetry adapted combinations of determinants called configuration state functions CSFs that include The socalled reference CSF that is the SCF wave function used to generate the molecular orbitals CSFs generated by carrying out single double triple etc level excitations ie orbital replacements relative to the reference CSF CI wave functions limited to include contributions through various levels of excitation are denoted S singly D doubly SD singly and doubly SDT singly doubly and triply excited The orbitals from which electrons are removed can be restricted to focus attention on correlations among certain orbitals For example if excitations out of core orbitals are excluded one computes a total energy that contains no core correlation energy The number of CSFs included in the CI calculation can be large CI wave functions including to CSFs are routine and functions with one to several billion CSFs are within the realm of practicality The need for such large CSF expansions can be appreciated by considering i that each electron pair requires at least two CSFs to form the polarized orbital pairs discussed earlier in this Chapter ii there are of the order of electron pairs for a molecule containing electrons hence iii the number of terms in the CI wave function scales as For a molecule containing ten electrons there could be terms in the CI expansion This may be an over estimate of the number of CSFs needed but it demonstrates how rapidly the number of CSFs can grow with the number of electrons The Hamiltonian matrix elements between pairs of CSFs are in practice evaluated in terms of one and two electron integrals over the molecular orbitals Prior to forming the matrix elements the one and two electron integrals which can be computed only for the atomic eg STO or GTO basis must be transformed to the molecular orbital basis This transformation step requires computer resources proportional to the fifth power of the number of basis functions and thus is one of the more troublesome steps in most configuration interaction and most other correlated calculations To transform the twoelectron integrals from this AO basis to the MO basis one proceeds as follows First one utilizes the original AObased integrals to form a partially transformed set of integrals This step requires of the order of operations Next one takes the list and carries out another socalled oneindex transformation This list is then subjected to another oneindex transformation to generate after which is subjected to the fourth oneindex transformation to form the final MObased integral list In total these four transformation steps require computer operations A variant of the CI method that is sometimes used is called the multiconfigurational selfconsistent field MCSCF method To derive the working equations of this approach one minimizes the expectation value of the Hamiltonian for a trial wave function consisting of a linear combination of CSFs In carrying out this minimization process one varies both the linear expansion coefficients and the LCAOMO coefficients describing those spinorbitals that appear in any of the CSFs This produces two sets of equations that need to be solved A matrix eigenvalue equation of the same form as arises in the CI method and equations that look very much like the HF equations but in which the he matrix element is sum_etagamma Gammaetagamma langlechi_nur chi_etar fracerr chi_mur chi_gammarrangle langlechi_nur chi_etar fracerr chi_gammar chi_mu rrangle Here replaces the sum that appears in the HF equations with depending on both the LCAOMO coefficients of the spinorbitals and on the expansion coefficients These equations are solved through a selfconsistent process in which initial coefficients are used to form the matrix and solve for the coefficients after which the can be determined and the HFlike equations solved for a new set of coefficients and so on until convergence is reached b Perturbation Theory This method uses the singleconfiguration SCF process to determine a set of orbitals Then with a zerothorder Hamiltonian equal to the sum of the electrons Fock operators perturbation theory is used to determine the CI amplitudes for the other CSFs The MllerPlesset perturbation MPPT procedure is a special case in which the above sum of Fock operators is used to define The amplitude for the reference CSF is taken as unity and the other CSFs amplitudes are determined by using as the perturbation This perturbation is the difference between the true Coulomb interactions among the electrons and the meanfield approximation to those interactions where and are the Coulomb and exchange operators defined earlier in this Chapter and the sum over runs over the spinorbitals that are occupied in the HartreeFock wave function that forms the zerothorder approximation to In the MPPT method once the reference CSF is chosen and the SCF orbitals belonging to this CSF are determined the wave function and energy are determined in an orderbyorder manner as is the case in the RSPT discussed in Chapter In fact MPPT is just RSPT with the above fluctuation potential as the perturbation The perturbation equations determine what CSFs to include through any particular order This is one of the primary strengths of this technique it does not require one to make further choices in contrast to the CI treatment where one needs to choose which CSFs to include For example the firstorder wave function correction is where the SCF orbital energies are denoted and represents a CSF that is doubly excited and are replaced by and relative to the SCF wave function The denominators arise from because each of these zerothorder energies is the sum of the orbital energies for all spinorbitals occupied The excited CSFs are the zerothorder wave functions other than the reference CSF Only doubly excited CSFs contribute to the firstorder wave function the fact that the contributions from singly excited configurations vanish in is known at the Brillouin theorem The Brillouin theorem can be proven by considering Hamiltonian matrix elements coupling the reference CSF to singlyexcited CSFs Fim The rules for evaluating all such matrix elements are called SlaterCondon rules and are given later in this Chapter If you dont know them this would be a good time to go read the subsection on these rules before returning here From the SlaterCondon rules we know that the matrix elements in question are given by Here the factor simply permutes the coordinates and to generate the exchange integral The sum of two electron integrals on the righthand side above can be extended to include the terms arising from because vanishes As a result the entire righthand side can be seen to reduce to the matrix element of the Fock operator The matrix elements vanish because the spinorbitals are eigenfunctions of and are orthogonal to each other The MPPT energy is given through second order as in RSPT by and again only contains contributions from the doubly excited CSFs Both and are expressed in terms of twoelectron integrals that are sometimes denoted coupling the virtual spinorbitals and to the spinorbitals from which electrons were excited and as well as the orbital energy differences accompanying such excitations Clearly major contributions to the correlation energy are made by double excitations into virtual orbitals with large integrals and small orbital energy gaps In higher order corrections contributions from CSFs that are singly triply etc excited relative to the HF reference function appear and additional contributions from the doubly excited CSFs also enter The various orders of MPPT are usually denoted MPn eg MP means secondorder MPPT c The CoupledCluster Method As noted above when the HartreeFock wave function is used as the zerothorder starting point in a perturbation expansion the first and presumably most important corrections to this function are the doublyexcited determinants In early studies of CI treatments of electron correlation it was observed that double excitations had the largest coefficients after the SCF wave function which has the very largest Moreover in CI studies that included single double triple and quadruple level excitations relative to the dominant SCF determinant it was observed that quadruple excitations had the next largest amplitudes after the double excitations And very importantly it was observed that the amplitudes of the quadruply excited CSFs could be very closely approximated as products of the amplitudes of the doubly excited CSFs and This observation prompted workers to suggest that a more compact and efficient expansion of the correlated wave function might be realized by writing as where is the SCF determinant and the operator appearing in the exponential is taken to be a sum of operators that create single double etc level excited CSFs when acting on As I show below this socalled coupledcluster CC form for then has the characteristic that the dominant contributions from quadruple excitations have coefficients nearly equal to the products of the coefficients of their constituent double excitations In any practical calculation this sum of operators would be truncated to keep the calculation practical For example if excitation operators higher than were neglected then one would use However even when is so truncated the resultant would contain excitations of higher order For example using the truncation just introduced we would have This function contains single excitations in double excitations in and in triple excitations in and and quadruple excitations in a variety of terms including and as well as even higher level excitations By the design of this wave function the quandruple excitations will have amplitudes given as products of the amplitudes of the double excitations just as were found by earlier CI workers to be most important Hence in CC theory we say that quadruple excitations include unlinked products of double excitations arising from the product the quadruple excitations arising from would involve linked terms and would have amplitudes that are not products of doubleexcitation amplitudes After writing in terms of an exponential operator one is faced with determining the amplitudes of the various single double etc excitations generated by the operator acting on This is done by writing the Schrdinger equation as and then multiplying on the left by to obtain The CC energy is then calculated by multiplying this equation on the left by and integrating over the coordinates of all the electrons In practice the combination of operators appearing in this expression is rewritten and dealt with as follows this socalled BakerCampbellHausdorf expansion of the exponential operators can be shown truncate exactly after the fourth power term shown here So once the various operators and their amplitudes that comprise are known is computed using the above expression that involves various powers of the operators The equations used to find the amplitudes eg those of the operator where the are the amplitudes and are the excitation operators that promote two electrons from and into and of the various excitation level are obtained by multiplying the above Schrdinger equation on the left by an excited determinant of that level and integrating For example the equation for the doubleexcitations is The zero arises from the righthand side of and the fact that that is the determinants are orthonormal The number of such equations is equal to the number of doubly excited determinants which is equal to the number of unknown amplitudes So the above quartic equations must be solved to determine the amplitudes appearing in the various operators Then as noted above once these amplitudes are known the energy can be computed using the earlier quartic equation Having to solve many coupled quartic equations is one of the most severe computational challenges of CC theory Clearly the CC method contains additional complexity as a result of the exponential expansion form of the wave function and the resulting coupled quartic equations that need to be solved to determine the amplitudes However it is this way of writing that allows us to automatically build in the fact that products of double excitations are the dominant contributors to quadruple excitations and is the dominant component of sixfold excitations not In fact the CC method is today one of the most accurate tools we have for calculating molecular electronic energies and wave functions d The Density Functional Method These approaches provide alternatives to the conventional tools of quantum chemistry which move beyond the singleconfiguration picture by adding to the wave function more configurations ie excited determinants whose amplitudes they each determine in their own way As noted earlier these conventional approaches can lead to a very large number of CSFs in the correlated wave function and as a result a need for extraordinary computer resources The density functional approaches are different Here one solves a set of orbitallevel equations in which the orbitals feel potentials due to the nuclear centers having charges Coulombic interaction with the total electron density and a socalled exchangecorrelation potential denoted The particular electronic state for which the calculation is being performed is specified by forming a corresponding density that in turn is often expressed as a sum of squares of occupied orbitals multiplied by orbitial occupation numbers Before going further in describing how DFT calculations are carried out let us examine the origins underlying this theory The socalled HohenbergKohn theorem states that the groundstate electron density of the atom or molecule or ion of interest uniquely determines the potential in the molecules electronic Hamiltonian ie the positions and charges of the systems nuclei and because H determines all of the energies and wave functions of the system the groundstate density therefore determines all properties of the system One proof of this theorem proceeds as follows determines the number of electrons because Assume that there are two distinct potentials aside from an additive constant that simply shifts the zero of total energy and which when used in and respectively to solve for a ground state produce and that have the same oneelectron density If we think of as trial variational wave function for the Hamiltonian we know that Similarly taking as a trial function for the Hamiltonian one finds that Adding the equations in c and d gives a clear contradiction unless the electronic state of interest is degenerate Hence there cannot be two distinct potentials and that give the same nondegenerate groundstate So the groundstate density uniquely determines and and thus H Furthermore because the eigenfunctions of determine all properties of the ground state then in principle determines all such properties This means that even the kinetic energy and the electronelectron interaction energy of the groundstate are determined by It is easy to see that gives the average value of the electronnuclear plus any additional oneelectron additive potential interaction in terms of the groundstate density However how are the kinetic energy and the electronelectron interaction energy expressed in terms of r There is another point of view that I find sheds even more light on why it makes sense that the groundstate electron density contains all the information needed to determine all properties It was shown many years ago by examining the mathematical character of the Schrdinger equation that the groundstate wave function has certain socalled cusps in the neighborhoods of the nuclear centers In particular must obey That is the derivative or slope of the natural logarithm of the true groundstate wave function must be as any of the electrons positions approach the nucleus of charge residing at position Because the groundstate electron density can be expressed in terms of the groundstate wave function as it can be shown that the groundstate density also displays cusps at the nuclear centers as where me is the electron mass and e is the unit of charge So imagine that you knew the true groundstate density at all points in space You could integrate the density over all space to determine how many electrons the system has Then you could explore over all space to find points at which the density had sharp points characterized by nonzero derivatives in the natural logarithm of the density The positions of such points specify the nuclear centers and by measuring the slopes in at each location one could determine the charges of these nuclei through This demonstrates why the groundstate density is all one needs to fully determine the locations and charges of the nuclei as well as the number of electrons and thus the entire Hamiltonian The main difficulty with DFT is that the HohenbergKohn theorem shows the values of etc are all unique functionals of the groundstate ie that they can in principle be determined once is given but it does not tell us what these functional relations are To see how it might make sense that a property such as the kinetic energy whose operator involves derivatives can be related to the electron density consider a simple system of noninteracting electrons moving in a threedimensional cubic box potential The energy states of such electrons are known to be where is the length of the box along the three axes and and are the quantum numbers describing the state We can view as defining the squared radius of a sphere in three dimensions and we realize that the density of quantum states in this space is one state per unit volume in the space Because and must be positive integers the volume covering all states with energy less than or equal to a specified energy is the volume of the sphere of radius Since there is one state per unit of such volume is also the number of states with energy less than or equal to and is called the integrated density of states The number of states with energy between and the density of states is the derivative of If we calculate the total energy for these noninteracting electrons that doubly occupy all states having energies up to the socalled Fermi energy ie the energy of the highest occupied molecular orbital HOMO we obtain the groundstate energy The total number of electrons can be expressed as which can be solved for in terms of to then express in terms of instead of in terms of This gives the total energy which is also the kinetic energy in this case because the potential energy is zero within the box and because the electrons are assumed to have no interactions among themselves in terms of the electron density It therefore may be plausible to express kinetic energies in terms of electron densities but it is still by no means clear how to do so for real atoms and molecules with electronnuclear and electronelectron interactions operative In one of the earliest DFT models the ThomasFermi theory the kinetic energy of an atom or molecule is approximated using the above kind of treatment on a local level That is for each volume element in space one assumes the expression given above to be valid and then one integrates over all to compute the total kinetic energy where the last equality simply defines the constant Ignoring the correlation and exchange contributions to the total energy this is combined with the electronnuclear and Coulombic electronelectron potential energies to give the ThomasFermi total energy This expression is an example of how is given as a local density functional approximation LDA The term local means that the energy is given as a functional ie a function of which depends only on at points in space but not on at more than one point in space or on spatial derivatives of Unfortunately the ThomasFermi energy functional does not produce results that are of sufficiently high accuracy to be of great use in chemistry What is missing in this theory are the exchange energy and the electronic correlation energy Moreover the kinetic energy is treated only in the approximate manner described earlier ie for noninteracting electrons within a spatially uniform potential Dirac was able to address the exchange energy for the uniform electron gas Coulomb interacting electrons moving in a uniform positive background charge whose magnitude balances the total charge of the electrons If the exact expression for the exchange energy of the uniform electron gas is applied on a local level one obtains the commonly used Dirac local density approximation to the exchange energy with Adding this exchange energy to the ThomasFermi total energy gives the socalled ThomasFermiDirac TFD energy functional Because electron densities vary rather strongly spatially near the nuclei corrections to the above approximations to and are needed One of the more commonly used socalled gradientcorrected approximations is that invented by Becke and referred to as the Becke exchange functional where and is a parameter chosen so that the above exchange energy can best reproduce the known exchange energies of specific electronic states of the inert gas atoms Becke finds to equal A common gradient correction to the earlier local kinetic energy functional is called the Weizsacker correction and is given by Although the above discussion suggests how one might compute the groundstate energy once the groundstate density is given one still needs to know how to obtain Kohn and Sham KS introduced a set of socalled KS orbitals obeying the following equation where the socalled exchangecorrelation potential could be obtained by functional differentiation if the exchangecorrelation energy functional were known KS also showed that the KS orbitals could be used to compute the density by simply adding up the orbital densities multiplied by orbital occupancies here or is the occupation number of the orbital in the state being studied and that the kinetic energy should be calculated as The same investigations of the idealized uniform electron gas that identified the Dirac exchange functional found that the correlation energy per electron could also be written exactly as a function of the electron density of the system for this model system but only in two limiting cases the highdensity limit large and the lowdensity limit There still exists no exact expression for the correlation energy even for the uniform electron gas that is valid at arbitrary values of Therefore much work has been devoted to creating efficient and accurate interpolation formulas connecting the low and high density uniform electron gas One such expression is where is the correlation energy per electron Here and and The parameter is how the density enters since is equal to that is is the radius of a sphere whose volume is the effective volume occupied by one electron A reasonable approximation to the full would contain the Dirac and perhaps gradient corrected exchange functional plus the above but there are many alternative approximations to the exchangecorrelation energy functional Currently many workers are doing their best to cook up functionals for the correlation and exchange energies but no one has yet invented functionals that are so reliable that most workers agree to use them To summarize in implementing any DFT one usually proceeds as follows An atomic orbital basis is chosen in terms of which the KS orbitals are to be expanded Most commonly this is a Gaussian basis or a planewave basis Some initial guess is made for the LCAOKS expansion coefficients of the occupied KS orbitals The density is computed as Often itself is expanded in an atomic orbital basis which need not be the same as the basis used for the and the expansion coefficients of are computed in terms of those of the this new basis It is also common to use an atomic orbital basis to expand which together with is needed to evaluate the exchangecorrelation functionals contribution to The current iterations density is used in the KS equations to determine the Hamiltonian whose new eigenfunctions and eigenvalues are found by solving the KS equations These new are used to compute a new density which in turn is used to solve a new set of KS equations This process is continued until convergence is reached ie until the used to determine the current iterations are the same that arise as solutions on the next iteration Once the converged is determined the energy can be computed using the earlier expression e Energy Difference Methods In addition to the methods discussed above for treating the energies and wave functions as solutions to the electronic Schrdinger equation there exists a family of tools that allow one to compute energy differences directly rather than by finding the energies of pairs of states and subsequently subtracting them Various energy differences can be so computed differences between two electronic states of the same molecule ie electronic excitation energies differences between energy states of a molecule and the cation or anion formed by removing or adding an electron ie ionization potentials IPs and electron affinities EAs In the early s the author developed one such tool for computing EAs J Simons and W D Smith Theory of Electron Affinities of Small Molecules J Chem Phys and he called this the equations of motion EOM method Throughout much of the s and s his group advanced and applied this tool to their studies of molecular EAs and electronmolecule interactions Because of space limitations we will not be able to elaborate much in great detail on these methods However it is important to stress that These socalled EOM or Greens function or propagator methods utilize essentially the same input information eg atomic orbital basis sets and perform many of the same computational steps eg evaluation of one and two electron integrals formation of a set of meanfield molecular orbitals transformation of integrals to the MO basis etc as do the other techniques discussed earlier These methods are now rather routinely used when IP or EA information is sought The basic ideas underlying most if not all of the energydifference methods are One forms a reference wave function this can be of the SCF MPn CI CC DFT etc variety the energy differences are computed relative to the energy of this function One expresses the finalstate wave function ie that describing the excited cation or anion state in terms of an operator acting on the reference Clearly the operator must be one that removes or adds an electron when one is attempting to compute IPs or EAs respectively One writes equations which and are expected to obey For example in the early development of these methods the Schrdinger equation itself was assumed to be obeyed so and are the two equations One combines with the equations that and obey to obtain an equation that must obey In the above example one a uses in the Schrdinger equation for b allows to act from the left on the Schrdinger equation for and c subtracts the resulting two equations to achieve or in commutator form One can for example express in terms of a superposition of configurations whose amplitudes have been determined from a CI or MPn calculation and express in terms of operators that cause single double etc level excitations for the IP EA cases is given in terms of operators that remove add remove and singly excite add and singly excite etc electrons Substituting the expansions for and for into the equation of motion EOM and then projecting the resulting equation on the left against a set of functions eg gives a matrix eigenvalueeigenvector equation to be solved for the operator coefficients and the excitation or IP or EA energies Such are the working equations of the EOM or Greens function or propagator methods In recent years these methods have been greatly expanded and have reached a degree of reliability where they now offer some of the most accurate tools for studying excited and ionized states In particular the use of time dependent variational principles have allowed a much more rigorous development of equations for energy differences and nonlinear response properties In addition the extension of the EOM theory to include coupledcluster reference functions now allows one to compute excitation and ionization energies using some of the most accurate ab initio tools Vibrations of Molecules Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Contributors and Attributions This Schrdinger equation forms the basis for our thinking about bond stretching and angle bending vibrations as well as collective vibrations in solids called phonons The radial motion of a diatomic molecule in its lowest rotational level can be described by the following Schrdinger equation where is the reduced mass of the two atoms If the molecule is rotating then the above Schrdinger equation has an additional term on its lefthand side Thus each rotational state labeled by the rotational quantum number has its own vibrational Schrdinger equation and thus its own set of vibrational energy levels and wave functions It is common to examine the vibrational problem and then to use the vibrational levels of this state as approximations to the vibrational levels of states with nonzero values treating the vibrationrotation coupling via perturbation theory Let us thus focus on the situation By substituting into this equation one obtains an equation for in which the differential operators appear to be less complicated This equation is exactly the same as the equation seen earlier in this text for the radial motion of the electron in the hydrogenlike atoms except that the reduced mass m replaces the electron mass m and the potential is not the Coulomb potential If the vibrational potential is approximated as a quadratic function of the bond displacement expanded about the equilibrium bond length where has its minimum the resulting harmonicoscillator equation can be solved exactly Because the potential grows without bound as approaches or only boundstate solutions exist for this model problem That is the motion is confined by the nature of the potential so no continuum states exist in which the two atoms bound together by the potential are dissociated into two separate atoms In solving the radial differential equation for this potential the larger behavior is first examined For larger the equation reads dfracdFdx dfrac k x dfracmuhbar Phi dfrackmuhbar x F where is the bond displacement away from equilibrium Defining and as a new scaled radial coordinate and realizing that dfracddx beta dfracddx allows the larger Schrdinger equation to be written as which has the solution The general solution to the radial equation is then expressed as this larger solution multiplied by a power series in the variable where the are coefficients to be determined Substituting this expression into the full radial equation generates a set of recursion equations for the amplitudes As in the solution of the hydrogenlike radial equation the series described by these coefficients is divergent unless the energy happens to equal specific values It is this requirement that the wave function not diverge so it can be normalized that yields energy quantization The energies of the states that arise by imposing this nondivergence condition are given by and the eigenfunctions are given in terms of the socalled Hermite polynomials as follows where Within this harmonic approximation to the potential the vibrational energy levels are evenly spaced In experimental data such evenly spaced energy level patterns are seldom seen most commonly one finds spacings that decrease as the quantum number increases In such cases one says that the progression of vibrational levels displays anharmonicity Because the Hermite functions are odd or even functions of depending on whether n is odd or even the wave functions ynx are odd or even This splitting of the solutions into two distinct classes is an example of the effect of symmetry in this case the symmetry is caused by the symmetry of the harmonic potential with respect to reflection through the origin along the axis ie changing to Throughout this text many symmetries arise in each case symmetry properties of the potential cause the solutions of the Schrdinger equation to be decomposed into various symmetry groupings Such symmetry decompositions are of great use because they provide additional quantum numbers ie symmetry labels by which the wave functions and energies can be labeled The basic idea underlying how such symmetries split the solutions of the Schrdinger equation into different classes relates to the fact that a symmetry operator eg the reflection plane in the above example commutes with the Hamiltonian That is the symmetry operator obeys textbfS textbfH textbfH textbfS So leaves unchanged as it acts on this allows us to pass through in the above equation Any operator that leaves the Hamiltonian ie the energy unchanged is called a symmetry operator If you have never learned about how point group symmetry can be used to help simplify the solution of the Schrdinger equation this would be a good time to interrupt your reading and go to Chapter and read the material there The harmonic oscillator energies and wave functions comprise the simplest reasonable model for vibrational motion Vibrations of a polyatomic molecule are often characterized in terms of individual bondstretching and anglebending motions each of which is in turn approximated harmonically This results in a total vibrational wave function that is written as a product of functions one for each of the vibrational coordinates Two of the most severe limitations of the harmonic oscillator model the lack of anharmonicity ie nonuniform energy level spacings and lack of bond dissociation result from the quadratic nature of its potential By introducing model potentials that allow for proper bond dissociation ie that do not increase without bound as the major shortcomings of the harmonic oscillator picture can be overcome The socalled Morse potential see Figure is often used in this regard In this form the potential is zero at the equilibrium bond length and is equal to as Sometimes the potential is written as Vr D_e exparr_e D_e so it vanishes as and is equal to at The latter form is reflected in Figure Figure Morse potential energy as a function of bond length In the Morse potential function is the bond dissociation energy is the equilibrium bond length and is a constant that characterizes the steepness of the potential and thus affects the vibrational frequencies The advantage of using the Morse potential to improve upon harmonicoscillatorlevel predictions is that its energy levels and wave functions are also known exactly The energies are given in terms of the parameters of the potential as follows where the force constant is given in terms of the Morse potentials parameters by The Morse potential supports both bound states those lying below the dissociation threshold for which vibration is confined by an outer turning point and continuum states lying above the dissociation threshold for which there is no outer turning point and thus the no spatial confinement Its degree of anharmonicity is governed by the ratio of the harmonic energy to the dissociation energy The energy spacing between vibrational levels and are given by E_n E_n hbar sqrtdfrackmu left dfrac nhbar sqrtkmuD_e right These spacings decrease until reaches the value at which after which the series of bound Morse levels ceases to exist ie the Morse potential has only a finite number of bound states and the Morse energy level expression shown above should no longer be used It is also useful to note that if becomes too small ie in the Morse model the potential may not be deep enough to support any bound levels It is true that some attractive potentials do not have a large enough value to have any bound states and this is important to keep in mind So bound states are to be expected when there is a potential well and thus the possibility of inner and outer turning points for the classical motion within this well but only if this well is deep enough The eigenfunctions of the harmonic and Morse potentials display nodal character analogous to what we have seen earlier in the particleinboxes model problems Namely as the energy of the vibrational state increases the number of nodes in the vibrational wave function also increases The state having vibrational quantum number has nodes I hope that by now the student is getting used to seeing the number of nodes increase as the quantum number and hence the energy grows As the quantum number grows not only does the wave function have more nodes but its probability distribution becomes more and more like the classical spatial probability as expected In particular for large the quantum and classical probabilities are similar and are large near the outer turning point where the classical velocity is low They also have large amplitudes near the inner turning point but this amplitude is rather narrow because the Morse potential drops off strongly to the right of this turning point in contrast to the left of the outer turning point the potential decreases more slowly so the large amplitudes persist over longer ranges near this turning point Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Virial Equations Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers It is often useful to fit accurate pressurevolumetemperature data to polynomial equations The experimental data can be used to compute a quantity called the compressibility factor which is defined as the pressurevolume product for the real gas divided by the pressurevolume product for an ideal gas at the same temperature We have Letting P and V represent the pressure and volume of the real gas and introducing the molar volume we have Since if the real gas behaves exactly like an ideal gas experimental values of Z will tend toward unity under conditions in which the density of the real gas becomes low and its behavior approaches that of an ideal gas At a given temperature we can conveniently ensure that this condition is met by fitting the Z values to a polynomial in P or a polynomial in The coefficients are functions of temperature If the data are fit to a polynomial in the pressure the equation is For a polynomial in the equation is These empirical equations are called virial equations As indicated the parameters are functions of temperature The values of and must be determined for each real gas at every temperature Note also that etc However it is true that Values for these parameters are tabulated in various compilations of physical data In these tabulations and are called the second virial coefficient and third virial coefficient respectively Volume Dependence of Helmholtz Energy Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay Contributors If one needs to know how the Helmholtz function changes with changing volume at constant temperature the following expression can be used But how does one derive an expression for the partial derivative in Equation refeq This is a fairly straight forward process that begins with the definition of Differentiating and using the chain rule to evaluate yields Now it is convenient to use the combined first and second laws which assumes a reversible change and only work is being done Substituting Equation refeq into Equation refeq yields Canceling the terms gives the important result dA pdV SdT labeleq The natural variables of are therefore and So the total differential of is conveniently expressed as dA left dfracpartial Apartial V right_T dV left dfracpartial Apartial T right_V dT labelTotal and by simple comparison of Equations refeq and refTotal it is clear that left dfracpartial Apartial V right_T p left dfracpartial Apartial T right_V S And so one can evaluate Equation refeq as If the pressure is independent of the temperature it can be pulled out of the integral Otherwise the temperature dependence of the pressure must be included Fortunately this is easy if the substance is an ideal gas or if some other equation of state can be used such as the van der Waals equation Example Ideal Gas Expansion Calculate for the isothermal expansion of mol of an ideal gas from L to L at K Solution For an ideal gas So left dfracpartial Apartial V right_T p becomes left dfracpartial Apartial V right_T dfracnRTV And so Equation refeq Delta A int_V_V_ left dfracpartial Apartial V right_T dV becomes or Substituting the values from the problem But further it is easy to show that the Maxwell relation that arises from the simplified expression for the total differential of is left dfracpartial ppartial T right_V left dfracpartial Spartial V right_T This particular Maxwell relation is exceedingly useful since one of the terms depends only on and As such it can be expressed in terms of our old friends and left dfracpartial ppartial T right_V dfracalphakappa_T Contributors Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay What is Theoretical Chemistry About Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Molecular Structure bonding shapes electronic structures Molecular Change reactions and interactionsChanges in bonding Energy Conservation Conservation of Orbital Symmetry the WoodwardHoffmann Rules Rates of change Statistical Mechanics Treating Large Numbers of Molecules in Close ContactContributors and Attributions The science of chemistry deals with molecules including the radicals cations and anions they produce when fragmented or ionized Chemists study isolated molecules eg as occur in the atmosphere and in astronomical environments solutions of molecules or ions dissolved in solvents as well as solid liquid and plastic materials comprised of molecules All such forms of molecular matter are what chemistry is about Chemical science includes how to make molecules synthesis how to detect and quantitate them analysis how to probe their properties and the changes they undergo as reactions occur physical Molecular Structure bonding shapes electronic structures One of the more fundamental issues chemistry addresses is molecular structure which means how the molecules atoms are linked together by bonds and what the interatomic distances and angles are Another component of structure analysis relates to what the electrons are doing in the molecule that is how the molecules orbitals are occupied and in which electronic state the molecule exists For example in the arginine molecule shown in Figure a carboxylic acid group its oxygen atoms are shown in red is linked to an adjacent carbon atom yellow which itself is bonded to an amino group whose nitrogen atom is blue Also connected to the acarbon atom are a chain of three methylene groups a group then a carbon atom attached both by a double bond to an imine group and to an amino group Figure The arginine molecule in its nonzwitterion form with dotted hydrogen bond The connectivity among the atoms in arginine is dictated by the well known valence preferences displayed by H C O and N atoms The internal bond angles are to a large extent also determined by the valences of the constituent atoms ie the or nature of the bonding orbitals However there are other interactions among the several functional groups in arginine that also contribute to its ultimate structure In particular the hydrogen bond linking the aamino groups nitrogen atom to the groups hydrogen atom causes this molecule to fold into a less extended structure than it otherwise might What does theory have to do with issues of molecular structure and why is knowledge of structure so important It is important because the structure of a molecule has a very important role in determining the kinds of reactions that molecule will undergo what kind of radiation it will absorb and emit and to what active sites in neighboring molecules or nearby materials it will bind A molecules shape eg rod like flat globular etc is one of the first things a chemist thinks of when trying to predict where at another molecule or on a surface or at a cell membrane the molecule will fit and be able to bind and perhaps react The presence of lone pairs of electrons which act as Lewis base sites of orbitals which can act as electron donor and electron acceptor sites and of highly polar or ionic groups guide the chemist further in determining where on the molecules framework various reactant species eg electrophilic or nucleophilic or radical will be most strongly attracted Clearly molecular structure is a crucial aspect of the chemists toolbox How does theory relate to molecular structure As we discussed in the Part of this text the BornOppenheimer approximation leads us to use quantum mechanics to predict the energy of a molecule for any positions of its nuclei given the number of electrons Ne in the molecule or ion This means for example that the energy of the arginine molecule in its lowest electronic state ie with the electrons occupying the lowest energy orbitals can be determined for any location of the nuclei if the Schrdinger equation governing the movements of the electrons can be solved If you have not had a good class on how quantum mechanics is used within chemistry I urge you to take the time needed to master Part In those pages I introduce the central concepts of quantum mechanics and I show how they apply to several very important cases including electrons moving in and dimensions and how these models relate to electronic structures of polyenes and to electronic bands in solids the classical and quantum probability densities and how they differ time propagation of quantum wave functions the Hckel or tightbinding model of chemical bonding among atomic orbitals harmonic vibrations molecular rotations electron tunneling atomic orbitals angular and radial characteristics and point group symmetry and how it is used to label orbitals and vibrations You need to know this material if you wish to understand most of what this text offers so I urge you to read Part if your education to date has not yet adequately been exposed to it Let us now return to the discussion of how theory deals with molecular structure We assume that we know the energy at various locations of the nuclei In some cases we denote this energy and in others we use because within the BornOppenheimer approximation the electronic energy serves as the potential V for the molecules vibrational motions As discussed in Part one can then perform a search for the lowest energy structure eg by finding where the gradient vector vanishes and where the second derivative or Hessian matrix has no negative eigenvalues By finding such a localminimum in the energy landscape theory is able to determine a stable structure of such a molecule The word stable is used to describe these structures not because they are lower in energy than all other possible arrangements of the atoms but because the curvatures as given in terms of eigenvalues of the Hessian matrix are positive at this particular geometry The procedures by which minima on the energy landscape are found may involve simply testing whether the energy decreases or increases as each geometrical coordinate is varied by a small amount Alternatively if the gradients are known at a particular geometry one can perform searches directed downhill along the negative of the gradient itself By taking a small step along such a direction one can move to a new geometry that is lower in energy If not only the gradients but also the second derivatives are known at some geometry one can make a more intelligent step toward a geometry of lower energy For additional details about how such geometry optimization searches are performed within modern computational chemistry software see Chapter where this subject was treated in greater detail It often turns out that a molecule has more than one stable structure isomer for a given electronic state Moreover the geometries that pertain to stable structures of excited electronic state are different than those obtained for the ground state because the orbital occupancy and thus the nature of the bonding is different Again using arginine as an example its ground electronic state also has the structure shown in Figure as a stable isomer Notice that this isomer and that shown earlier have the atoms linked together in identical manners but in the second structure the aamino group is involved in two hydrogen bonds while it is involved in only one in the former In principle the relative energies of these two geometrical isomers can be determined by solving the electronic Schrdinger equation while placing the constituent nuclei in the locations described in the two figures Figure Another stable structure for the arginine molecule If the arginine molecule is excited to another electronic state for example by promoting a nonbonding electron on its CO oxygen atom into the neighboring CO orbital its stable structures will not be the same as in the ground electronic state In particular the corresponding CO distance will be longer than in the ground state but other internal geometrical parameters may also be modified albeit probably less so than the CO distance Moreover the chemical reactivity of this excited state of arginine will be different than that of the ground state because the two states have different orbitals available to react with attacking reagents In summary by solving the electronic Schrdinger equation at a variety of geometries and searching for geometries where the gradient vanishes and the Hessian matrix has all positive eigenvalues one can find stable structures of molecules and ions The Schrdinger equation is a necessary aspect of this process because the movement of the electrons is governed by this equation rather than by Newtonian classical equations The information gained after carrying out such a geometry optimization process include all of the interatomic distances and internal angles needed to specify the equilibrium geometry and the total electronic energy at this particular geometry It is also possible to extract much more information from these calculations For example by multiplying elements of the Hessian matrix by the inverse square roots of the atomic masses of the atoms labeled a and b one forms the massweighted Hessian whose nonzero eigenvalues give the harmonic vibrational frequencies of the molecule The eigenvectors of the massweighted Hessian matrix give the relative displacements in coordinates that accompany vibration in the normal mode ie they describe the normal mode motions Details about how these harmonic vibrational frequencies and normal modes are obtained were discussed earlier in Chapter Molecular Change reactions and interactions Changes in bonding Chemistry also deals with transformations of matter including changes that occur when molecules react are excited electronically vibrationally or rotationally or undergo geometrical rearrangements Again theory forms the cornerstone that allows experimental probes of chemical change to be connected to the molecular level and that allows simulations of such changes Molecular excitation may or may not involve altering the electronic structure of the molecule vibrational and rotational excitation do not but electronic excitation ionization and electron attachment do As illustrated in Figure where a bimolecular reaction is displayed chemical reactions involve breaking some bonds and forming others and thus involve rearrangement of the electrons among various molecular orbitals Figure Two bimolecular reactions a and b show an atom combining with a diatomic c and d show an atom abstracting an atom from a diatomic In this example in part a the green atom collides with the brown diatomic molecule and forms the bound triatomic molecule b Alternatively in c and d a pink atom collides with a green diatomic to break the bond between the two green atoms and form a new bond between the pink and green atoms Both such reactions are termed bimolecular because the basic step in which the reaction takes place requires a collision between to independent species ie the atom and the diatomic A simple example of a unimolecular chemical reaction is offered by the arginine molecule considered above In the first structure shown for arginine the carboxylic acid group retains its bonding However in the zwitterion structure of this same molecule shown in Figure the group has been deprotonated to produce a carboxylate anion group with the ion now bonded to the terminal imine group thus converting it to an amino group and placing the net positive charge on the adjacent carbon atom The unimolecular tautomerization reaction in which the two forms of arginine are interconverted involves breaking an bond forming a bond and changing a carbonnitrogen double bond into a carbonnitrogen single bond In such a process the electronic structure is significantly altered and as a result the two isomers can display very different chemical reactivities toward other reagents Notice that once again the ultimate structure of the zwitterion tautomer of arganine is determined by the valence preferences of its constituent atoms as well as by hydrogen bonds formed among various functional groups the carboxylate group and one amino group and one group Figure The arginine molecule in a zwitterion stable structure Energy Conservation In any chemical reaction as in all physical processes other than nuclear event in which mass and energy can be interconveted total energy must be conserved Reactions in which the summation of the strengths of all the chemical bonds in the reactants exceeds the sum of the bond strengths in the products are termed endothermic For such reactions external energy must to provided to the reacting molecules to allow the reaction to occur Exothermic reactions are those for which the bonds in the products exceed in strength those of the reactants For exothermic reactions no net energy input is needed to allow the reaction to take place Instead excess energy is generated and liberated when such reactions take place In the former endothermic case the energy needed by the reaction usually comes from the kinetic energy of the reacting molecules or molecules that surround them That is thermal energy from the environment provides the needed energy Analogously for exothermic reactions the excess energy produced as the reaction proceeds is usually deposited into the kinetic energy of the product molecules and into that of surrounding molecules For reactions that are very endothermic it may be virtually impossible for thermal excitation to provide sufficient energy to effect reaction In such cases it may be possible to use a light source ie photons whose energy can excite the reactant molecules to induce reaction When the light source causes electronic excitation of the reactants eg one might excite one electron in the bound diatomic molecule discussed above from a bonding to an antibonding orbital one speaks of inducing reaction by photochemical means Conservation of Orbital Symmetry the WoodwardHoffmann Rules An example of how important it is to understand the changes in bonding that accompany a chemical reaction let us consider a reaction in which butadiene is converted via ringclosure to form cyclobutene Specifically focus on the four orbitals of butadiene as the molecule undergoes socalled disrotatory closing along which the plane of symmetry which bisects and is perpendicular to the bond is preserved The orbitals of the reactant and product can be labeled as being evene or oddo under reflection through this symmetry plane It is not appropriate to label the orbitals with respect to their symmetry under the plane containing the four C atoms because although this plane is indeed a symmetry operation for the reactants and products it does not remain a valid symmetry throughout the reaction path That is in applying the WoodwardHoffmann rules we symmetry label the orbitals using only those symmetry elements that are preserved throughout the reaction path being examined Figure The active valence orbitals of butadiene and of cyclobutene The four orbitals of butadiene are of the following symmetries under the preserved symmetry plane see the orbitals in Figure The and and and orbitals of the product cyclobutane which evolve from the four orbitals of the butadiene are of the following symmetry and energy order The WoodwardHoffmann rules instruct us to arrange the reactant and product orbitals in order of increasing energy and to then connect these orbitals by symmetry starting with the lowest energy orbital and going through the highest energy orbital This process gives the following socalled orbital correlation diagram Figure The orbital correlation diagram for the butadiene to cyclobutene reaction We then need to consider how the electronic configurations in which the electrons are arranged as in the ground state of the reactants evolves as the reaction occurs We notice that the lowest two orbitals of the reactants which are those occupied by the four electrons of the reactant do not connect to the lowest two orbitals of the products which are the orbitals occupied by the two and two electrons of the products This causes the groundstate configuration of the reactants to evolve into an excited configuration of the products This in turn produces an activation barrier for the thermal disrotatory rearrangement in which the four active electrons occupy these lowest two orbitals of butadiene to produce cyclobutene If the reactants could be prepared for example by photolysis in an excited state having orbital occupancy then reaction along the path considered would not have any symmetryimposed barrier because this singly excited configuration correlates to a singlyexcited configuration of the products The fact that the reactant and product configurations are of equivalent excitation level causes there to be no symmetry constraints on the photochemically induced reaction of butadiene to produce cyclobutene In contrast the thermal reaction considered first above has a symmetryimposed barrier because the orbital occupancy is forced to rearrange by the occupancy of two electrons from to for the groundstate wave function of the reactant to smoothly evolve into that of the product Of course if the reactants could be generated in an excited state having orbital occupancy then products could also be produced directly in their ground electronic state However it is difficult if not impossible to generate such doublyexcited electronic states so it is rare that one encounters reactions being induced via such states It should be stressed that although these symmetry considerations may allow one to anticipate barriers on reaction potential energy surfaces they have nothing to do with the thermodynamic energy differences of such reactions What the above WoodwardHoffmann symmetry treatment addresses is whether there will be symmetryimposed barriers above and beyond any thermodynamic energy differences The enthalpies of formation of reactants and products contain the information about the reactions overall energy balance and need to be considered independently of the kind of orbital symmetry analysis just introduced As the above example illustrates whether a chemical reaction occurs on the ground or an excitedstate electronic surface is important to be aware of This example shows that one might want to photoexcite the reactant molecules to cause the reaction to occur at an accelerated rate With the electrons occupying the lowestenergy orbitals the ring closure reaction can still occur but it has to surmount a barrier to do so it can employ thermal collision al energy to surmount this barrier so its rate might be slow If an electron is excited there is no symmetry barrier to surmount so the rate can be greater Reactions that take place on excited states also have a chance to produce products in excited electronic states and such excitedstate products may emit light Such reactions are called chemiluminescent because they produce light luminescence by way of a chemical reaction Rates of change Rates of reactions play crucial roles in many aspects of our lives Rates of various biological reactions determine how fast we metabolize food and rates at which fuels burn in air determine whether an explosion or a calm flame will result Chemists view the rate of any reaction among molecules and perhaps photons or electrons if they are used to induce excitation in reactant molecules to be related to the frequency with which the reacting species encounter one another and the probability that a set of such species will react once they do encounter one another The former aspects relate primarily to the concentrations of the reacting species and the speeds with which they are moving The latter have more to do with whether the encountering species collide in a favorable orientation eg do the enzyme and substrate dock properly or does the ion collide with the end of or with the end in the SN reaction that yields and with sufficient energy to surmount any barrier that must be passed to effect breaking bonds in reactants to form new bonds in products The rates of reactions can be altered by changing the concentrations of the reacting species by changing the temperature or by adding a catalyst Concentrations and temperature control the collision rates among molecules and temperature also controls the energy available to surmount barriers Catalysts are molecules that are not consumed during the reaction but which cause the rate of the reaction to be increased species that slow the rate of a reaction are called inhibitors Most catalysts act by providing orbitals of their own that interact with the reacting molecules orbitals to cause the energies of the latter to be lowered as the reaction proceeds In the ringclosure reaction cited earlier the catalysts orbitals would interact ie overlap with the butadienes orbitals in a manner that lowers their energies and thus reduces the energy barrier that must be overcome for reaction to proceed In addition to being capable of determining the geometries bond lengths and angles energies vibrational frequencies of species such as the isomers of arginine discussed above theory also addresses questions of how and how fast transitions among these isomers occur The issue of how chemical reactions occur focuses on the mechanism of the reaction meaning how the nuclei move and how the electronic orbital occupancies change as the system evolves from reactants to products In a sense understanding the mechanism of a reaction in detail amounts to having a mental moving picture of how the atoms and electrons move as the reaction is occurring The issue of how fast reactions occur relates to the rates of chemical reactions In most cases reaction rates are determined by the frequency with which the reacting molecules access a critical geometry called the transition state or activated complex near which bond breaking and bond forming takes place The reacting molecules potential energy along the path connecting reactants through a transition state to produces is often represented as shown in Figure Figure Energy vs reaction progress plot showing the transition state or activated complex and the activation energy In this figure the potential energy ie the electronic energy without the nucleis kinetic energy included is plotted along a coordinate connecting reactants to products The geometries and energies of the reactants products and of the activated complex can be determined using the potential energy surface searching methods discussed briefly above and detailed earlier in Chapter Chapter provides more information about the theory of reaction rates and how such rates depend upon geometrical energetic and vibrational properties of the reacting molecules The frequencies with which the transition state is accessed are determined by the amount of energy termed the activation energy needed to access this critical geometry For systems at or near thermal equilibrium the probability of the molecule gaining energy is shown for three temperatures in Figure Figure Distributions of energies at various temperatures For such cases chemical reaction rates usually display a temperature dependence characterized by linear plots of vs Of course not all reactions involve molecules that have been prepared at or near thermal equilibrium For example in supersonic molecular beam experiments the kinetic energy distribution of the colliding molecules is more likely to be of the type shown in Figure Figure Molecular speed distributions in thermal and supersonic beam cases In this figure the probability is plotted as a function of the relative speed with which reactant molecules collide It is common in making such collision speed plots to include the volume element factor in the plot That is the normalized probability distribution for molecules having reduced mass m to collide with relative velocity components is Because only the total collisional kinetic energy is important in surmounting reaction barriers we convert this Cartesian velocity component distribution to one in terms of the collision speed This is done by changing from Cartesian to polar coordinates in which the radial variable is v itself and gives after integrating over the two angular coordinates It is the factor in this speed distribution that causes the MaxwellBoltzmann distribution to vanish at low speeds in the above plot Another kind of experiment in which nonthermal conditions are used to extract information about activation energies occurs within the realm of ionmolecule reactions where one uses collisioninduced dissociation CID to break a molecule apart For example when a complex consisting of a cation bound to a uracil molecule is accelerated by an external electric field to a kinetic energy and subsequently allowed to impact into a gaseous sample of Xe atoms the highenergy collision allows kinetic energy to be converted into internal energy This collisional energy transfer may deposit into the Nauracil complex enough energy to fragment the uracil attractive binding energy thus producing and neutral uracil fragments If the signal for production of is monitored as the collision energy is increased one generates a CID reaction rate profile such as I show in Figure Figure Reaction crosssection as a function of collision energy On the vertical axis is plotted a quantity proportional to the rate at which ions are formed On the horizontal axis is plotted the collision energy in two formats The laboratory kinetic energy is simply the mass of the complex multiplied by the square of the speed of these ion complexes measured with respect to a laboratoryfixed coordinate frame The centerofmass CM kinetic energy is the amount of energy available between the complex and the Xe atom and is given by E_rm CM dfrac dfracm_rm complex m_Xem_rm complex m_Xe v where is the relative speed of the complex and the Xe atom and and are the respective masses of the colliding partners The most essential lesson to learn from such a graph is that no dissociation occurs if is below some critical threshold value and the CID reaction Narm uracil rightarrow Na rm uracil occurs with higher and higher rate as the collision energy increases beyond the threshold For the example shown above the threshold energy is ca eV These CID thresholds can provide us with estimates of reaction endothermicities and are especially useful when these energies are greatly in excess of what can be realized by simply heating the sample Statistical Mechanics Treating Large Numbers of Molecules in Close Contact When one has a large number of molecules that undergo frequent collisions thereby exchanging energy momentum and angular momentum the behavior of this collection of molecules can often be described in a simple way At first glance it seems unlikely that the treatment of a large number of molecules could require far less effort than that required to describe one or a few such molecules To see the essence of what I am suggesting consider a sample of cm of water at room temperature and atmospheric pressure In this macroscopic sample there are approximately x water molecules If one imagines having an instrument that could monitor the instantaneous speed of a selected molecule one would expect the instrumental signal to display a very jerky irregular behavior if the signal were monitored on time scales of the order of the time between molecular collisions On this time scale the water molecule being monitored may be moving slowly at one instant but upon collision with a neighbor may soon be moving very rapidly In contrast if one monitors the speed of this single water molecule over a very long time scale ie much longer than the average time between collisions one obtains an average square of the speed that is related to the temperature of the sample via dfrac mv dfrac kT This relationship holds because the sample is at equilibrium at temperature An example of the kind of behavior I describe above is shown in Figure Figure The energy possessed by a ion as a function of time In this figure on the vertical axis is plotted the log of the energy kinetic plus potential of a single anion in a solution with water as the solvent as a function of time The vertical axis label says Eq because this figure was taken from a literature article The ion initially has excess vibrational energy in this simulation which was carried out in part to model the energy flow from this hot solute ion to the surrounding solvent molecules One clearly sees the rapid jerks in energy that this ion experiences as it undergoes collisions with neighboring water molecules These jerks occur approximately every ps and some of them correspond to collisions that take energy from the ion and others to collisions that given energy to the ion On longer time scales eg over ps we also see a gradual drop off in the energy content of the ion which illustrates the slow loss of its excess energy on the longer time scale Now lets consider what happens if we monitor a large number of molecules rather than a single molecule within the cm sample of mentioned earlier If we imagine drawing a sphere of radius and monitoring the average speed of all water molecules within this sphere we obtain a qualitatively different picture if the sphere is large enough to contain many water molecules For large R one finds that the average square of the speed of all the water molecules residing inside the sphere ie is independent of time even when considered at a sequence of times separated by fractions of ps and is related to the temperature through This example shows that at equilibrium the longtime average of a property of any single molecule is the same as the instantaneous average of this same property over a large number of molecules For the single molecule one achieves the average value of the property by averaging its behavior over time scales lasting for many many collisions For the collection of many molecules the same average value is achieved at any instant of time because the number of molecules within the sphere which is proportional to is so much larger than the number near the surface of the sphere proportional to that the molecules interior to the sphere are essentially at equilibrium for all times Another way to say the same thing is to note that the fluctuations in the energy content of a single molecule are very large ie the molecule undergoes frequent large jerks but last a short time ie the time between collisions In contrast for a collection of many molecules the fluctuations in the energy for the whole collection are small at all times because fluctuations take place by exchange of energy with the molecules that are not inside the sphere and thus relate to the surface area to volume ratio of the sphere So if one has a large number of molecules that one has reason to believe are at thermal equilibrium one can avoid trying to follow the instantaneous shorttime detailed dynamics of any one molecule or of all the molecules Instead one can focus on the average properties of the entire collection of molecules What this means for a person interested in theoretical simulations of such condensedmedia problems is that there is no need to carry out a Newtonian molecular dynamics simulation of the system or a quantum simulation if it is at equilibrium because the longtime averages of whatever is calculated can be found another way How one achieves this is through the magic of statistical mechanics and statistical thermodynamics One of the most powerful of the devices of statistical mechanics is the socalled MonteCarlo simulation algorithm Such theoretical tools provide a direct way to compute equilibrium averages and small fluctuations about such averages for systems containing large numbers of molecules In Chapter I provide a brief introduction to the basics of this subdiscipline of theoretical chemistry where you will learn more about this exciting field Sometimes we speak of the equilibrium behavior or the dynamical behavior of a collection of molecules Let me elaborate a little on what these phrases mean Equilibrium properties of molecular collections include the radial and angular distribution functions among various atomic centers For example the OO and radial distribution functions in liquid water and in ice are shown in Figure Figure Radial OO distribution functions at three temperatures Such properties represent averages over long times or over a large collection of molecules of some property that is not changing with time except on a very fast time scale corresponding to individual collisions In contrast dynamical properties of molecular collections include the folding and unfolding processes that proteins and other polymers undergo the migrations of protons from water molecule to water molecule in liquid water and along chains within ion channels and the self assembly of molecular monolayers on solid surfaces as the concentration of the molecules in the liquid overlayer varies These are properties that occur on time scales much longer than those between molecular collisions and on time scales that we wish to probe by some experiment or by simulation Having briefly introduced the primary areas of theoretical chemistry structure dynamics and statistical mechanics let us now examine each of them in somewhat greater detail keeping in mind that Chapters are where each is treated more fully Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis When Two Variables Change at Once Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay No headers So far we have derived a number of expressions and developed methods for evaluating how thermodynamic variables change as one variable changes while holding the rest constant But real systems are seldom this accommodating For example a piece of metal such as a railroad rail left in the sun will undergo both an increase in temperature and an expansion due to the absorption of energy from sunlight So both and are changing at the same time If the change in a thermodynamic variable such as is needed contributions from both changes are required to be taken into account Weve already seen how to express this in terms of a total differential Fortunately like the other thermodynamic functions and is kind enough to be a state variable This means that we can consider the changes independently and then simply add the results Another way to think of this is that the system may follow either of two pathways to get from the initial conditions to the final conditions Pathway I An isothermal expansion from to at followed by An isochoric temperature increase from to at Pathway An isochoric temperature increase from to at followed by And isothermal expansion from to at And since has the good sense to be a state variable the pathway connecting the initial and final states is unimportant We are free to choose any path that is convenient to calculate the change Example NonIsothermal Gas Expansion Calculate the entropy change for mol of a monatomic ideal gas CV R expanding from L at K to L at K Solution If one considers entropy to be a function of temperature and volume one can write the total differential of entropy as and thus The first term is the contribution due to an isochoric temperature change The second term is the contribution due to an isothermal expansion From the Maxwell relation on So Equation refsecond becomes And the total entropy change is Deriving an expression for a partial derivative Type III Thermodynamics involves many variables But for a single component sample of matter only two state variables are needed to describe the system and fix all of the thermodynamic properties of the system As such it is conceivable that two functions can be specified as functions of the same two variables In general terms and So an important question that can be answered is What happens to if is held constant but is changed To explore this consider the total differential of but can also be considered a function of and This implies that the total differential can also be written as and these two total differentials must be equal to one another If we constrain the system to a change in which remains constant the last term will vanish since but also since is a function and the total differential for can be written And it too must be zero for a process in which is held constant From this expression it can be seen that Substituting this into the Equation refeq yields which simplifies to left dfracpartial zpartial x right_y dx left dfracpartial zpartial w right_x left dfracpartial wpartial x right_y dx left dfracpartial zpartial x right_w dx So for implies that left dfracpartial zpartial x right_y left dfracpartial zpartial w right_x left dfracpartial wpartial x right_y left dfracpartial zpartial x right_w or left dfracpartial zpartial x right_y left dfracpartial zpartial x right_w left dfracpartial zpartial w right_x left dfracpartial wpartial x right_y labelfinal As with partial derivative transformation types I and II this result can be achieved in a formal albeit less mathematically rigorous method Consider This allows us to write the total differential for Now divide by and constrain to constant noting that and converting the other ratios to partial derivatives yields left dfracpartial zpartial x right_y left dfracpartial zpartial x right_w left dfracpartial zpartial w right_x left dfracpartial wpartial x right_y labelfinal which agrees with the previous result Equation reffinal Again the method is not mathematically rigorous but it works so long as and are state functions and the total differentials and are exact Contributors Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Where Does the N Come from Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers If we know and we have a set of data points the best estimate we can make of the variance is We have said that if we must use to approximate the mean the best estimate of usually denoted is The use of rather than in the denominator is distinctly nonintuitive so much so that this equation often causes great irritation Let us see how this equation comes about Suppose that we have a distribution whose mean is and variance is Suppose that we draw values of the random variable from the distribution We want to think about the expected value of Let us write as Squaring this gives From our definition of expected value we can write From our discussion above we can recognize each of these expected values The expected value of is the variance of the original distribution which is Since this is a definition it is exact The best possible estimate of the expected value of is The expected value of is the expected value of the variance of averages of random variables drawn from the original distribution That is the expected value of is what we would get if we repeatedly drew values from the original distribution computed the average of each set of values and then found the variance of this new distribution of average values By the central limit theorem this variance is Thus the expected value of is exactly Since is constant the expected value of is which is equal to zero because by the definition of Substituting our expression for the expected value of becomes so that and That is as originally stated when we must use rather than the true mean in the sum of squared differences the best possible estimate of usually denoted is obtained by dividing by rather than by Why Quantum Mechanics is Necessary Last updated Save as PDF Page ID Contributed by Jack SimonsProfessor Emeritus and Henry Eyring Scientist Chemistry at University of Utah Contributors and Attributions The field of theoretical chemistry deals with the structures bonding reactivity and physical properties of atoms molecules radicals and ions all of whose sizes range from ca  for atoms and small molecules to a few hundred  for polymers and biological molecules such as DNA and proteins Sometimes these building blocks combine to form nanoscopic materials eg quantum dots graphene sheets whose dimensions span up to thousands of  making them amenable to detection using specialized microscopic tools However description of the motions and properties of the particles comprising such small systems has been found to not be amenable to treatment using classical mechanics Their structures energies and other properties have only been successfully described within the framework of quantum mechanics This is why quantum mechanics has to be mastered as part of learning theoretical chemistry We know that all molecules are made of atoms that in turn contain nuclei and electrons As I discuss in this Chapter the equations that govern the motions of electrons and of nuclei are not the familiar Newton equations but a new set of equations called Schrdinger equations When scientists first studied the behavior of electrons and nuclei they tried to interpret their experimental findings in terms of classical Newtonian motions but such attempts eventually failed They found that such small light particles behaved in a way that simply is not consistent with the Newton equations Let me now illustrate some of the experimental data that gave rise to these paradoxes and show you how the scientists of those early times then used these data to suggest new equations that these particles might obey I want to stress that the Schrdinger equation was not derived but postulated by these scientists In fact to date to the best of my knowledge no one has been able to derive the Schrdinger equation From the pioneering work of Bragg on diffraction of xrays from planes of atoms or ions in crystals it was known that peaks in the intensity of diffracted xrays having wavelength l would occur at scattering angles q determined by the famous Bragg equation n lambda d sintheta tag where d is the spacing between neighboring planes of atoms or ions These quantities are illustrated in Figure shown below There are may such diffraction peaks each labeled by a different value of the integer The Bragg formula can be derived by considering when two photons one scattering from the second plane in the figure and the second scattering from the third plane will undergo constructive interference This condition is met when the extra path length covered by the second photon ie the length from points to to is an integer multiple of the wavelength of the photons Figure Scattering of two beams at angle from two planes in a crystal spaced by d The importance of these xray scattering experiments to electrons and nuclei appears in the experiments of Davisson and Germer in who scattered electrons of reasonably fixed kinetic energy from metallic crystals These workers found that plots of the number of scattered electrons as a function of scattering angle displayed peaks at angles that obeyed a Bragglike equation The startling thing about this observation is that electrons are particles yet the Bragg equation is based on the properties of waves An important observation derived from the DavissonGermer experiments was that the scattering angles observed for electrons of kinetic energy could be fit to the Bragg equation if a wavelength were ascribed to these electrons that was defined by where is the mass of the electron and h is the constant introduced by Max Planck and Albert Einstein in the early s to relate a photons energy to its frequency via These amazing findings were among the earliest to suggest that electrons which had always been viewed as particles might have some properties usually ascribed to waves That is as de Broglie has suggested in an electron seems to have a wavelength inversely related to its momentum and to display wavetype diffraction I should mention that analogous diffraction was also observed when other small light particles eg protons neutrons nuclei and small atomic ions were scattered from crystal planes In all such cases Bragglike diffraction is observed and the Bragg equation is found to govern the scattering angles if one assigns a wavelength to the scattering particle according to where is the mass of the scattered particle and is Plancks constant x erg sec The observation that electrons and other small light particles display wave like behavior was important because these particles are what all atoms and molecules are made of So if we want to fully understand the motions and behavior of molecules we must be sure that we can adequately describe such properties for their constituents Because the classical Newtonian equations do not contain factors that suggest wave properties for electrons or nuclei moving freely in space the above behaviors presented significant challenges Another problem that arose in early studies of atoms and molecules resulted from the study of the photons emitted from atoms and ions that had been heated or otherwise excited eg by electric discharge It was found that each kind of atom ie H or C or O emitted photons whose frequencies were of very characteristic values An example of such emission spectra is shown in Figure for hydrogen atoms Figure Emission spectrum of atomic hydrogen with some lines repeated below to illustrate the series to which they belong In the top panel we see all of the lines emitted with their wave lengths indicated in nanometers The other panels show how these lines have been analyzed by scientists whose names are associated into patterns that relate to the specific energy levels between which transitions occur to emit the corresponding photons In the early attempts to rationalize such spectra in terms of electronic motions one described an electron as moving about the atomic nuclei in circular orbits such as shown in Figure Figure Characterization of small and large stable orbits for an electron moving around a nucleus A circular orbit was thought to be stable when the outward centrifugal force characterized by radius and speed on the electron perfectly counterbalanced the inward attractive Coulomb force exerted by the nucleus of charge This equation in turn allows one to relate the kinetic energy to the Coulombic energy and thus to express the total energy of an orbit in terms of the radius of the orbit The energy characterizing an orbit or radius relative to the reference of energy at becomes more and more negative ie lower and lower as becomes smaller This relationship between outward and inward forces allows one to conclude that the electron should move faster as it moves closer to the nucleus since However nowhere in this model is a concept that relates to the experimental fact that each atom emits only certain kinds of photons It was believed that photon emission occurred when an electron moving in a larger circular orbit lost energy and moved to a smaller circular orbit However the Newtonian dynamics that produced the above equation would allow orbits of any radius and hence any energy to be followed Thus it would appear that the electron should be able to emit photons of any energy as it moved from orbit to orbit The breakthrough that allowed scientists such as Niels Bohr to apply the circularorbit model to the observed spectral data involved first introducing the idea that the electron has a wavelength and that this wavelength l is related to its momentum by the de Broglie equation lambda hp The key step in the Bohr model was to also specify that the radius of the circular orbit be such that the circumference of the circle be equal to an integer multiple of the wavelength Only in this way will the electrons wave experience constructive interference as the electron orbits the nucleus Thus the Bohr relationship that is analogous to the Bragg equation that determines at what angles constructive interference can occur is Both this equation and the analogous Bragg equation are illustrations of what we call boundary conditions they are extra conditions placed on the wavelength to produce some desired character in the resultant wave in these cases constructive interference Of course there remains the question of why one must impose these extra conditions when the Newton dynamics do not require them The resolution of this paradox is one of the things that quantum mechanics does Returning to the above analysis and using as well as the forcebalance equation one can then solve for the radii that stable Bohr orbits obey and in turn for the velocities of electrons in these orbits These two results then allow one to express the sum of the kinetic and Coulomb potential energies as Just as in the Bragg diffraction result which specified at what angles special high intensities occurred in the scattering there are many stable Bohr orbits each labeled by a value of the integer Those with small have small radii scaling as high velocities scaling as n and more negative total energies nb the reference zero of energy corresponds to the electron at and with So it is the result that only certain orbits are allowed that causes only certain energies to occur and thus only certain energies to be observed in the emitted photons It turned out that the Bohr formula for the energy levels labeled by of an electron moving about a nucleus could be used to explain the discrete line emission spectra of all oneelectron atoms and ions ie etc sometimes called hydrogenic species to very high precision In such an interpretation of the experimental data one claims that a photon of energy hnu R leftdfracn_i dfracn_fright tag is emitted when the atom or ion undergoes a transition from an orbit having quantum number to a lowerenergy orbit having Here the symbol is used to denote the following collection of factors and is called the Rydberg unit of energy and is equal to eV The Bohr formula for energy levels did not agree as well with the observed pattern of emission spectra for species containing more than a single electron However it does give a reasonable fit for example to the Na atom spectra if one examines only transitions involving only the single s valence electron Moreover it can be greatly improved if one introduces a modification designed to treat the penetration of the Na atoms s and higher orbitals within the regions of space occupied by the s s and p orbitals Such a modification to the Bohr model is achieved by introducing the idea of a socalled quantum defect d into the principal quantum number so that the expression for the dependence of the orbitals changes to Example For example choosing equal to or for Li Na K Rb and Cs respectively in this socalled Rydberg formula one finds decent agreement between the dependence of the energy spacings of the singly excited valence states of these atoms The fact that is larger for Na than for Li and largest for Cs reflects that fact that the s orbital of Na penetrates the s s and p shells while the s orbital of Li penetrates only the s shell and the s orbital of Cs penetrates and shells It turns out this Rydberg formula can also be applied to certain electronic states of molecules In particular for closedshell cations such as protonated alcohols and protonated amines even on side chains of amino acids an electron can be attached into a socalled Rydberg orbital to form corresponding neutral radicals such as or For example in the electron bound to an underlying cation core The lowestenergy state of this Rydberg species is often labeled s because is isoelectronic with the Na cation which binds an electron in its s orbital in its ground state As in the cases of alkali atoms these Rydberg molecules also possess excited electronic states For example the NH radical has states labeled p d s p d f etc By making an appropriate choice of the quantum defect parameter d the energy spacings among these states can be fit reasonably well to the Rydberg formula Equation In Figure a several Rydberg orbitals of are shown Figure a The and Rydberg orbitals of with their outermost contours containing of their electron density The smaller orbitals are supposed to depict CC CN or CO orbitals to give perspective of the Rydberg orbitals sizes These Rydberg orbitals can be quite large their sizes scale as clearly have the s p or d angular shapes and possess the expected number of radial nodes However for molecular Rydberg orbitals and unlike atomic Rydberg orbitals the three five seven etc orbitals are not degenerate instead they are split in energy in a manner reflecting the symmetry of the underlying cations symmetry For example for the three orbitals are degenerate and belong to symmetry in the point group the five orbitals are split into three degenerate and two degenerate e orbitals So the Bohr model works well for oneelectron atoms or ions and the quantum defectmodified Bohr equation describes reasonably well some states of alkali atoms and of Rydberg molecules The primary reason for the breakdown of the Bohr formula is the neglect of electronelectron Coulomb repulsions in its derivation which are qualitatively corrected for by using the quantum defect parameter for Rydberg atoms and molecules Nevertheless the success of the Bohr model made it clear that discrete emission spectra could only be explained by introducing the concept that not all orbits were allowed Only special orbits that obeyed a constructiveinterference condition were really accessible to the electrons motions This idea that not all energies were allowed but only certain quantized energies could occur was essential to achieving even a qualitative sense of agreement with the experimental fact that emission spectra were discrete In summary two experimental observations on the behavior of electrons that were crucial to the abandonment of Newtonian dynamics were the observations of electron diffraction and of discrete emission spectra Both of these findings seem to suggest that electrons have some wave characteristics and that these waves have only certain allowed ie quantized wavelengths So now we have some idea about why Newtons equations fail to account for the dynamical motions of light and small particles such as electrons and nuclei We see that extra conditions eg the Bragg condition or constraints on the de Broglie wavelength could be imposed to achieve some degree of agreement with experimental observation However we still are left wondering what equations can be applied to properly describe such motions and why the extra conditions are needed It turns out that a new kind of equation based on combining wave and particle properties needed to be developed to address such issues These are the socalled Schrdinger equations to which we now turn our attention As I said earlier no one has yet shown that the Schrdinger equation follows deductively from some more fundamental theory That is scientists did not derive this equation they postulated it Some idea of how the scientists of that era dreamed up the Schrdinger equation can be had by examining the time and spatial dependence that characterizes socalled traveling waves It should be noted that the people who worked on these problems knew a great deal about waves eg sound waves and water waves and the equations they obeyed Moreover they knew that waves could sometimes display the characteristic of quantized wavelengths or frequencies eg fundamentals and overtones in sound waves They knew for example that waves in one dimension that are constrained at two points eg a violin string held fixed at two ends undergo oscillatory motion in space and time with characteristic frequencies and wavelengths For example the motion of the violin string just mentioned can be described as having an amplitude at a position along its length at time given by where is its oscillation frequency The amplitudes spatial dependence also has a sinusoidal dependence given by where is the cresttocrest length of the wave Two examples of such waves in one dimension are shown in Figure Figure Fundamental and first overtone notes of a violin string of length In these cases the string is fixed at and at so the wavelengths belonging to the two waves shown are and If the violin string were not clamped at the waves could have any value of However because the string is attached at the allowed wavelengths are quantized to obey where The equation that such waves obey called the wave equation reads where is the speed at which the wave travels This speed depends on the composition of the material from which the violin string is made stiff string material produces waves with higher speeds than for softer material Using the earlier expressions for the and dependences of the wave we find that the waves frequency and wavelength are related by the socalled dispersion equation or This relationship implies for example that an instrument string made of a very stiff material large will produce a higher frequency tone for a given wavelength ie a given value of than will a string made of a softer material smaller For waves moving on the surface of for example a rectangular twodimensional surface of lengths and one finds Hence the waves are quantized in two dimensions because their wavelengths must be constrained to cause to vanish at and as well as at and for all times It is important to note in closing this discussion of waves on strings and surfaces that it is not being a solution to the Schrdinger equation that results in quantization of the wavelengths Instead it is the condition that the wave vanish at the boundaries that generates the quantization You will see this trend time and again throughout this text when a wave function is subject to specific constraints at its inner or outer boundary or both quantization will result if these boundary conditions are not present quantization will not occur Let us now return to the issue of waves that describe electrons moving The pioneers of quantum mechanics examined functional forms similar to those shown above For example forms such as were considered because they correspond to periodic waves that evolve in and under no external or dependent forces Noticing that and using the de Broglie hypothesis in the above equation one finds If is supposed to relate to the motion of a particle of momentum p under no external forces since the waveform corresponds to this case can be related to the energy of the particle by So the equation for can be rewritten as or alternatively Returning to the timedependence of and using one can also show that which using the first result suggests that i BigdfrachpiBig dfracdAdt BigdfrachpiBig dfracm dfracdAdx tag This is a primitive form of the Schrdinger equation that we will address in much more detail below Briefly what is important to keep in mind that the use of the de Broglie and PlanckEinstein connections and both of which involve the constant h produces suggestive connections between and between or alternatively between These connections between physical properties energy and momentum and differential operators are some of the unusual features of quantum mechanics The above discussion about waves and quantized wavelengths as well as the observations about the wave equation and differential operators are not meant to provide or even suggest a derivation of the Schrdinger equation Again the scientists who invented quantum mechanics did not derive its working equations Instead the equations and rules of quantum mechanics have been postulated and designed to be consistent with laboratory observations My students often find this to be disconcerting because they are hoping and searching for an underlying fundamental basis from which the basic laws of quantum mechanics follow logically I try to remind them that this is not how theory works Instead one uses experimental observation to postulate a rule or equation or theory and one then tests the theory by making predictions that can be tested by further experiments If the theory fails it must be refined and this process continues until one has a better and better theory In this sense quantum mechanics with all of its unusual mathematical constructs and rules should be viewed as arising from the imaginations of scientists who tried to invent a theory that was consistent with experimental data and which could be used to predict things that could then be tested in the laboratory Thus far this theory has proven to be reliable but of course we are always searching for a new and improved theory that describes how small light particles move If it helps you to be more accepting of quantum theory I should point out that the quantum description of particles reduces to the classical Newton description under certain circumstances In particular when treating heavy particles eg macroscopic masses and even heavier atoms it is often possible to use Newton dynamics Soon we will discuss in more detail how the quantum and classical dynamics sometimes coincide in which case one is free to use the simpler Newton dynamics So let us now move on to look at this strange Schrdinger equation that we have been digressing about for so long Contributors and Attributions Jack Simons Henry Eyring Scientist and Professor of Chemistry U Utah Telluride Schools on Theoretical Chemistry Integrated by Tomoyuki Hayashi UC Davis Why Unimolecular Reactions are First Order Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers In the discussion above we assume that a molecule with energy in excess of the minimum activation energy undergoes reaction with some fixed probability represented by the rate constant A complete answer to the question of why unimolecular processes are characteristically firstorder in the high pressure limit requires that we rationalize this assumption Another way of phrasing this question is to ask why the activated molecule does not react immediately Why isnt The total energy of a molecule is distributed among numerous degrees of freedom The molecule has translational kinetic energy rotational kinetic energy and vibrational energy When it acquires excess energy through a collision with another molecule the additional energy could go directly into any of these modes However before the molecule can react enough energy must find its way into some rather particular mode If for example the reaction involves the breaking of a chemical bond and the collision puts excess kinetic energy into the molecules translational modes the reaction can occur only after some part of the excess translational energy has been converted to excess vibrational energy in the breaking bond This intramolecular transfer of energy among the molecules various internal modes is timedependent From this perspective the probability that an excited molecule will react in unit time is the probability that the necessary energy will reach the critical locus in unit time The reshuffling of energy among the molecules internal modes is a stochastic process and the probability that the reshuffling will put the necessary energy where it is needed is a constant characteristic of the molecule Work and Energy Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay EnergyWorkThe work of a reversible expansionContributors and Attributions Temperature pressure and volume are important variables in the description of physical systems They will also be important to describe how energy flows from one system to another Generally energy can flow in two important forms work and heat The bookkeeping needed to track the flow of energy is what the subject of Thermodynamics is all about so these topics will be discussed at length in subsequent chapters However a little bit of review is in order just to set the foundation for the discussions that are forthcoming Energy Energy is an important entity in the modern world We use energy to light our homes drive our cars and power our electronic devices According to Richard Smalley cowinner of the Nobel Prize in Chemistry energy is one of the if not the biggest challenge we face moving into the st century energysenategov Energy is at the core of virtually every problem facing humanity We cannot afford to get this wrong Somehow we must find the basis for energy prosperity for ourselves and the rest of humanity for the st century By the middle of this century we should assume we will need to at least double world energy production from its current level with most of this coming from some clean sustainable COfree source For worldwide peace and prosperity it needs to be cheap Richard Smalley Testimony to the Senate Committee on Energy and Natural Resources April Energy can be measured in a multitude of different units including joules J kilojoules kJ calories cal kilocalories kcal as well as several other set of units such as kJmol or kcalmol A calorie cal was once defined as the amount of energy needed to raise the temperature of g of water by C This definition suggests a convenient property of water called the specific heat The modern definition of a calorie is joule where a joule is the energy necessary to move a mass a distance of m against a resisting force of N A dietary Calorie Cal is equal to cal or kcal and is often listed on the labels of food containers to indicate the energy content of the food inside Energy can take the form of potential energy stored energy and kinetic energy realized energy forms Kinetic energy is the energy of motion On the other hand potential energy can be defined as the energy stored in a system that can be converted to kinetic energy someplace in the universe Kinetic energy of a particle can be expressed as where is the mass of the particle and is the magnitude of its velocity or speed Equation reftransKE describes the kinetic energy associated with translation other expressions exist for different motions eg rotation or vibration An example of a system in which energy is converted between kinetic energy and potential energy is a Hookes Law oscillator According to Hookes Law the force acting on an object is proportional in magnitude to the displacement of the object from an equilibrium position and opposite in sign In this equation is the force is the displacement from equilibrium and is the constant of proportionality The negative sign is necessary to insure that the force acting on the object is one that will tend to restore it to an equilibrium position irrespective of whether is positive or negative As the object that follows Hookes Law moves from its equilibrium position the kinetic energy of its motion is converted into potential energy until there is no more kinetic energy left At this point the change in displacement will change direction returning the object to the equilibrium position by converting potential energy back into kinetic energy Figure An example of a harmonic oscillator As the object is displaced in the along the xaxis in the case shown in Figure this would be accomplished by stretching or compressing the spring the potential energy increases The force acting on the object will also increase as the object is displaced and will be directed opposite of the direction of displacement Equation refhook According to Newtonian physics the potential energy is given by the negative integral of the force with respect to position U x int Fx dx labelenergy Substituting Equation refhook in Equation refenergy yields With the proper choice of coordinate system and other definitions the constant of integration can be arbitrarily made to be zero for example by choosing it to offset any other forces acting on the object such as the force due to gravity The kinetic energy is then given by the total energy minus the potential energy since the total energy must be constant due to the conservation of energy in the system Work Work is defined as the amount of energy expended to move a mass against a resisting force For a mass being moved along a surface the amount of energy expended must be sufficient to overcome the resisting force perhaps due to friction and also sufficient to cause motion along the entire path Figure The work of displacement The energy expended as work in this case if the force is independent of the position of the object being moved is given by where F is the magnitude of the resisting force and Dx is the displacement of the object The negative sign is necessary since the force is acting in the opposite direction of the motion A more general expression and one that can be used if the force is not constant over the entire motion is This expression can then be integrated including any dependence might have on as needed for a given system Another important way that work can be defined includes that for the expansion of a gas sample against an external pressure In this case the displacement is defined by a change in volume for the sample This is a very convenient expression and will be used quite often when discussing the work expended in the expansion of a gas The conversion of potential energy into kinetic energy generally is accomplished through work which is done someplace in the universe As such the concepts of energy and work are inexorably intertwined They will be central to the study of thermodynamics The work of a reversible expansion An important case of limiting ideal behavior is that of the reversible expansion For a change to be reversible there can be no net force pushing the change in one direction or the other In order for this to be the case the internal pressure that of the system and external pressure that of the surroundings must be the same In this case the work of expansion can be calculated by integrating the expression for dw Making a simple substitution from the ideal gas law allows for the expression in terms of volume and temperature If the temperature is constant so that it can be placed before the integral the expression becomes w nRT int_V_V_ dfracdVV nRT ln left dfracV_V_ right labelworkIG where and are the initial and final volumes of the expansion respectively Example Consider mol of an ideal gas expanding isothermally at K from an initial volume of L to a final volume of L What is the final pressure of the gas Calculate the work of the expansion if it occurs against a constant external pressure equal to the final pressure you have calculated reversibly Solution First lets calculate the final pressure via Equation refIGL p dfracnRTV dfracmole atmLmol KK L atm This may be a relationship you remember from General Chemistry that mole of an idea gas occupies L at oC Okay now for the irreversible expansion against a constant external pressure so But what the heck is an atm L It is actually a fairly simply thing to convert from units of atm L to J by using the ideal gas law constant Note that the negative sign indicated that the system is expending energy by doing work on the surroundings This concept will be vital in the Chapter Now for the reversible pathway The work done by the system can be calculated for this change using Equation refworkIG Notes First notice how the value for the gas law constant R was chosen in order to match the units required in the problem Read and recite that previous sentence to yourself a few times The incorrect choice of the value of R is one of the most common errors made by students in physical chemistry By learning how the units will dictate your choice of R you will save yourself a considerable number of headaches as you learn physical chemistry Second You may note that the magnitude of work done by the system in the reversible expansion is larger than that of the irreversible expansion This will always be the case There are many cases of limiting ideal behavior which we use to derive andor explore the nature of chemical systems The most obvious case perhaps is that of the Ideal Gas Law Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay Work and Heat Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay HeatWorkContributors and Attributions One of the pioneers in the field of modern thermodynamics was James P Joule Among the experiments Joule carried out was an attempt to measure the effect on the temperature of a sample of water that was caused by doing work on the water Using a clever apparatus to perform work on water by using a falling weight to turn paddles within an insulated canister filled with water Joule was able to measure a temperature increase in the water Figure left James Prescott Joule right Joules apparatus for measuring the work equivalent of heat CC BYSA Dr Mirko Junge Thus Joule was able to show that work and heat can have the same effect on matter a change in temperature It would then be reasonable to conclude that heating as well as doing work on a system will increase its energy content and thus its ability to perform work in the surroundings This leads to an important construct of the First Law of Thermodynamics The capacity of a system to do work is increased by heating the system or doing work on it The internal energy U of a system is a measure of its capacity to supply energy that can do work within the surroundings making U the ideal variable to keep track of the flow of heat and work energy into and out of a system Changes in the internal energy of a system can be calculated by where the subscripts and indicate initial and final states of the system as it turns out is a state variable In other words the amount of energy available in a system to be supplied to the surroundings is independent on how that energy came to be available Thats important because the manner in which energy is transferred is path dependent There are two main methods energy can be transferred to or from a system These are suggested in the previous statement of the first law of thermodynamics Mathematically we can restate the first law as or where q is defined as the amount of energy that flows into a system in the form of heat and w is the amount of energy lost due to the system doing work on the surroundings Heat Heat is the kind of energy that in the absence of other changes would have the effect of changing the temperature of the system A process in which heat flows into a system is endothermic from the standpoint of the system qsystem qsurroundings Likewise a process in which heat flows out of the system into the surroundings is called exothermic qsystem qsurroundings In the absence of any energy flow in the form or work the flow of heat into or out of a system can be measured by a change in temperature In cases where it is difficult to measure temperature changes of the system directly the amount of heat energy transferred in a process can be measured using a change in temperature of the soundings This concept will be used later in the discussion of calorimetry An infinitesimal amount of heat flow into or out of a system can be related to a change in temperature by where C is the heat capacity and has the definition Heat capacities generally have units of J mol K and magnitudes equal to the number of J needed to raise the temperature of mol of substance by K Similar to a heat capacity is a specific heat which is defined per unit mass rather than per mol The specific heat of water for example has a value of J g K at constant pressure a pathway distinction that will be discussed later Example Heat required to Raise Temperature Example How much energy is needed to raise the temperature of g of water from C to C Solution What is a partial derivative A partial derivative like a total derivative is a slope It gives a magnitude as to how quickly a function changes value when one of the dependent variables changes Mathematically a partial derivative is defined for a function by Because it measures how much a function changes for a change in a given dependent variable infinitesimal changes in the in the function can be described by So that each contribution to the total change in the function can be considered separately For simplicity consider an ideal gas The pressure can be calculated for the gas using the ideal gas law In this expression pressure is a function of temperature and molar volume The partial derivatives of p can be expressed in terms of T and V as well and So that the change in pressure can be expressed or by substituting Equations refmax and refmax Macroscopic changes can be expressed by integrating the individual pieces of Equation refeq over appropriate intervals This can be thought of as two consecutive changes The first is an isothermal constant temperature expansion from to at and the second is an isochoric constant volume temperature change from to at For example suppose one needs to calculate the change in pressure for an ideal gas expanding from Lmol at K to Lmol at K The set up might look as follows or Delta p int_ Lmol Lmol left dfracR KV right dV int_ K K left dfracR Lmol right dT Delta p R left left dfracK Lmol dfracK Lmolright left dfracK Lmol dfracK Lmolright right Alternatively one could calculate the change as an isochoric temperature change from T to T at V followed by an isothermal expansion from V to V at T Delta p int_T_T_left dfracRV right dT int_V_V_ left dfracRTV right dV or Delta p int_ K K left dfracR Lmol right dT int_ Lmol Lmol left dfracR KV right dV Delta p R left left dfracK Lmol dfracK Lmolright left dfracK Lmol dfracK Lmolright right This results demonstrates an important property of pressure in that pressure is a state variable and so the calculation of changes in pressure do not depend on the pathway Work Work can take several forms such as expansion against a resisting pressure extending length against a resisting tension like stretching a rubber band stretching a surface against a surface tension like stretching a balloon as it inflates or pushing electrons through a circuit against a resistance The key to defining the work that flows in a process is to start with an infinitesimal amount of work defined by what is changing in the system Table Changes to the System Type of work Displacement Resistance dw Expansion dV volume pext pressure pextdV Electrical dQ charge W resistence W dQ Extension dL length t tension t dL Stretching dA s surf tens sdA The pattern followed is always an infinitesimal displacement multiplied by a resisting force The total work can then be determined by integrating along the pathway the change follows Example Work from a Gas Expansion What is the work done by mol an ideal gas expanding from a volume of L to a volume of L against a constant external pressure of atm Solution since the pressure is constant we can integrate easily to get total work Note The ratio of gas law constants can be used to convert between atmL and J quite conveniently Contributors and Attributions Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay A G and Maximum Work Last updated Save as PDF Page ID Contributed by Patrick FlemingAssistant Professor Chemistry and Biochemistry at California State University East Bay No headers The functions and are oftentimes referred to as free energy functions The reason for this is that they are a measure of the maximum work in the case of or non pV work in the case of that is available from a process To show this consider the total differentials First consider the differential of Substituting the combined first and second laws for but expressing the work term as yields And cancelling the terms gives or at constant temperature Since the only assumption made here was that the change is reversible allowing for the substitution of for and for a reversible change is the maximum amount of work it follows that gives the maximum work that can be produced from a process at constant temperature Similarly a simple expression can be derived for Starting from the total differential of Using an expression for where and is split into two terms one describing the work of expansion and the other describing any other type of work electrical stretching etc can be expressed as dG cancelTdS cancelpdV dw_e cancelpdV Vdp cancelTdS SdT Cancelling the and terms leaves So at constant temperature and pressure This implies that gives the maximum amount of non pV work that can be extracted from a process This concept of and giving the maximum work under the specified conditions is where the term free energy comes from as it is the energy that is free to do work in the surroundings If a system is to be optimized to do work in the soundings for example a steam engine that may do work by moving a locomotive the functions A and will be important to understand It will therefore be useful to understand how these functions change with changing conditions such as volume temperature and pressure Contributors Patrick E Fleming Department of Chemistry and Biochemistry California State University East Bay
