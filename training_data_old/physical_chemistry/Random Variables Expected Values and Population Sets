Random Variables Expected Values and Population Sets Last updated Save as PDF Page ID Contributed by Paul EllgenRetired Teach Chemistry at Oklahoma School of Science Mathematics No headers When we sample a particular distribution the value that we obtain depends on chance and on the nature of the distribution described by the function The probability that any given trial will produce in the interval is equal to We often find situations in which a second function of call it is also of interest If we sample the distribution and obtain a value of the random variable then the value of associated with that trial is The question arises Given and the distribution function what should we expect the value of to be That is if we get a value of from the distribution and then find what value should we expect to find for While this seems like a reasonable question it is obvious that we can give a meaningful answer only when we can define more precisely just what we mean by expect To understand our definition of the expected value sometimes called the expectation value of let us consider a game of chance Suppose that we have a needle that rotates freely on a central axis When spun the needle describes a circular path and its point eventually comes to rest at some point on this path The location at which the needle stops is completely random Imagine that we divide the circular path into six equal segments which we number from one to six When we spin the needle it is equally likely to stop over any of these segments Now let us suppose that we conduct a lottery by selling six tickets also numbered from one to six We decide the winner of the lottery by spinning the needle The holder of the ticket whose number matches the number on which the needle stops receives a payoff of After the spin one ticket is worth and the other five are valueless We ask Before the spin what is any one of the lottery tickets worth In this context it is reasonable to define the expected value of a ticket as the amount that we should be willing to pay to buy a ticket If we buy them all we receive when the winning ticket is selected If we pay per ticket to buy them all we get our money back If we buy all the tickets the expected value of each ticket is What if we buy only one ticket Is it reasonable to continue to say that its expected value is We argue that it is One argument is that the expected value of a ticket should not depend on who owns the ticket so it should not depend on whether we buy one two or all of them A more general argument supposes that repeated lotteries are held under the same rules If we spend to buy one ticket in each of a very large number of such lotteries we expect that we will eventually break even Since the needle comes to rest at each number with equal probability we reason that Since we assume that the fraction of times our ticket would be selected in a long series of identical lotteries is the same thing as the probability that our ticket will be selected in any given drawing we can also express the expected value as Clearly the ticket is superfluous The game depends on obtaining a value of a random variable from a distribution The distribution is a spin of the needle The random variable is the location at which the needle comes to rest We can conduct essentially the same game by allowing any number of participants to bet that the needle will come to rest on any of the six equally probable segments of the circle If an individual repeatedly bets on the same segment in many repetitions of this game the total of his winnings eventually matches the total amount that he has wagered More precisely the total of his winnings divided by the total amount he has wagered becomes arbitrarily close to one Suppose now that we change the rules Under the new rules we designate segment of the circle as the payoff segment Participants pay a fixed sum to be eligible for the payoff for a particular game Each game is decided by a spin of the needle If the needle lands in segment everyone who paid to participate in that game receives Evidently the new rules have no effect on the value of participation Over the long haul a participant in a large number of games wins in onesixth of these games We take this to be equivalent to saying that he has a probability of onesixth of winning in a given game in which he participates His expected payoff is Let us change the game again We subdivide segment into equalsize segments and The probability that the needle lands in or is In this new game the payoff is when the needle lands in either segment or segment We can use any of the arguments that we have made previously to see that the expected payoff game is now However the analysis that is most readily generalized recognizes that the payoff from this game is just the sum of the payout from the previous game plus the payout from a game in which the sole payout is whenever the needle lands in segment For the new game we have We can devise any number of new games by dividing the needles circular path into nonoverlapping segments Each segment is a possible outcome We number the possible outcomes â„¦ label these outcomes and denote their probabilities as We say that the probability of outcome is the expected frequency of outcome We denote the respective payoffs as Straightforward generalization of our last analysis shows that the expected value for participation in any game of this type is Moreover the spinner is representative of any distribution so it is reasonable to generalize further We can say that the expected value of the outcome of a single trial is always the probabilityweighted sum over all possible outcomes of the value of each outcome A common notation uses angular brackets to denote the expected value for a function of the random variable the expected value of is For a discrete distribution with exhaustive mutuallyexclusive outcomes probabilities and outcome values payoffs we define the expected value expected value of to be Now let us examine the expected value of from a slightly different perspective Let the number of times that each of the various outcomes is observed in a particular sample of observations be We have The set specifies the way that the possible outcomes are populated in this particular series of observations We call a population set If we make a second series of N observations we obtain a second population set We infer that the best forecast we can make for the number of occurrences of outcome in any future series of N observations is We call the expected number of observations of outcome in a sample of size In a particular series of trials the number of occurrences of outcome and hence of is For the set of outcomes the average value of is Collecting a second sample of observations produces a second estimate of If is small successive estimates of may differ significantly from one another If we make a series of observations multiple times we obtain multiple population sets In general the population set from one series of observations is different from the population set for a second series of observations If collecting such samples of a sufficiently large number of times must produce some population sets more than once and among those that are observed more than once one must occur more often than any other We call it the most probable population set Let the elements of the most probable population set be We infer that the most probable population set is the best forecast we can make about the outcomes of any future sample of from this distribution Moreover we infer that the best estimate we can make of is that it equals the expected number of observations of outcome that is Now and must be natural numbers while need only be real In particular we can have must be or or some higher integer This is a situation of practical importance because circumstances may limit the sample size to a number that is much less than the number of possible outcomes We encounter this situation in our discussion of statistical thermodynamics in Chapter We find that the number of molecules in a system can be much smaller than the number of outcomesobservable energy levelsavailable to any given molecule If many more than outcomes have about the same probability repeated collection of samples of observations can produce a series of population sets each population set different from all of the others in each of which every element is either zero or one When this occurs it may be that no single population set is significantly more probable than any of many others Nevertheless every outcome occurs with a welldefined probability We infer that the set is always an adequate proxy for calculating the expected value for the most probable population set To illustrate this kind of distribution suppose that there are possible outcomes of which the first and last thousand have probabilities that are so low that they can be taken as zero while the middle outcomes have approximately equal probabilities Then for and while for We are illustrating the situation in which the number of outcomes we can observe is much less than the number of outcomes that have appreciable probability which is So let us take the number of trials to be If the value of for each of the middle outcomes is the same say for then our calculation of the expected value of will be regardless of which population set results from the four trials That is because all of the populations sets that have a significant chance to be observed have and for exactly four values of in the range all of the population sets that have a significant chance to be observed give rise to the same expected value Let us compute the arithmetic average using the most probable population set for a sample of N trials In this case the number of observations of the outcome is For a discrete distribution is the value of that we calculate from the most probable population set or its proxy We can extend the definition of the expected value to cases in which the cumulative probability distribution function and the outcomevalue function are continuous in the domain of the random variable To do so we divide this domain into a finite number of intervals We let be the lower limit of in the interval Then the probability that a given trial yields a value of the random variable in the interval is and we can approximate the expected value of for the continuous distribution by the finite sum In the limit as becomes arbitrarily large and all of the intervals become arbitrarily small the expected value of for a continuous distribution becomes This integral is the value of where is the probability density function for the distribution If c is a constant we have If is a second function of the random variable we have